{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Perspectives in Computational Research: Homework 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD AND PROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Load the Fashion-MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data by converting the data to a 2D tensor with individual values between 0 and 1\n",
    "x_train_full = x_train.reshape((60000, 28*28))\n",
    "x_train_full = x_train_full.astype('float32') / 255\n",
    "\n",
    "x_test_2D = x_test.reshape((10000, 28*28))\n",
    "x_test_final = x_test_2D.astype('float32')/ 255\n",
    "\n",
    "y_train_full = to_categorical(y_train)\n",
    "y_test_final = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly split the training data into 50,000 training observations and 10,000 validation observations\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train_full, y_train_full, test_size=1/6, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Setup Model - 5 layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.8693 - acc: 0.6836 - val_loss: 0.5758 - val_acc: 0.7556\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.5217 - acc: 0.8036 - val_loss: 0.4666 - val_acc: 0.8322\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4368 - acc: 0.8356 - val_loss: 0.4066 - val_acc: 0.8488\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.3891 - acc: 0.8552 - val_loss: 0.4518 - val_acc: 0.8367\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.3536 - acc: 0.8680 - val_loss: 0.5128 - val_acc: 0.8186\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3326 - acc: 0.8754 - val_loss: 0.4319 - val_acc: 0.8439\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3109 - acc: 0.8831 - val_loss: 0.3751 - val_acc: 0.8690\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.2946 - acc: 0.8878 - val_loss: 0.3444 - val_acc: 0.8730\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2831 - acc: 0.8931 - val_loss: 0.3200 - val_acc: 0.8864\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2682 - acc: 0.8980 - val_loss: 0.3707 - val_acc: 0.8614\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.2555 - acc: 0.9025 - val_loss: 0.3390 - val_acc: 0.8813\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.2467 - acc: 0.9064 - val_loss: 0.3291 - val_acc: 0.8842\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.2380 - acc: 0.9068 - val_loss: 0.3504 - val_acc: 0.8770\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 0.2299 - acc: 0.9113 - val_loss: 0.3476 - val_acc: 0.8879\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 0.2242 - acc: 0.9145 - val_loss: 0.3769 - val_acc: 0.8771\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.2148 - acc: 0.9179 - val_loss: 0.3733 - val_acc: 0.8881\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2123 - acc: 0.9189 - val_loss: 0.3771 - val_acc: 0.8789\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1999 - acc: 0.9230 - val_loss: 0.5095 - val_acc: 0.8571\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.2004 - acc: 0.9233 - val_loss: 0.4172 - val_acc: 0.8805\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.1922 - acc: 0.9270 - val_loss: 0.3367 - val_acc: 0.8865\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 0.1860 - acc: 0.9295 - val_loss: 0.3800 - val_acc: 0.8911\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 0.1821 - acc: 0.9297 - val_loss: 0.3568 - val_acc: 0.8925\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.1794 - acc: 0.9319 - val_loss: 0.4246 - val_acc: 0.8796\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.1730 - acc: 0.9336 - val_loss: 0.3651 - val_acc: 0.8952\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.1706 - acc: 0.9363 - val_loss: 0.3962 - val_acc: 0.8852\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.1672 - acc: 0.9363 - val_loss: 0.4045 - val_acc: 0.8933\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.1656 - acc: 0.9379 - val_loss: 0.3926 - val_acc: 0.8942\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1611 - acc: 0.9381 - val_loss: 0.4039 - val_acc: 0.8920\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1609 - acc: 0.9383 - val_loss: 0.4249 - val_acc: 0.8805\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1578 - acc: 0.9410 - val_loss: 0.4278 - val_acc: 0.8885\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1560 - acc: 0.9414 - val_loss: 0.3920 - val_acc: 0.8921\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1502 - acc: 0.9424 - val_loss: 0.5010 - val_acc: 0.8892\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1466 - acc: 0.9439 - val_loss: 0.5001 - val_acc: 0.8885\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1464 - acc: 0.9455 - val_loss: 0.4997 - val_acc: 0.8917\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1462 - acc: 0.9448 - val_loss: 0.4656 - val_acc: 0.8960\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.1425 - acc: 0.9458 - val_loss: 0.4258 - val_acc: 0.8910\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.1465 - acc: 0.9460 - val_loss: 0.4086 - val_acc: 0.8980\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.1424 - acc: 0.9483 - val_loss: 0.4857 - val_acc: 0.8903\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1405 - acc: 0.9478 - val_loss: 0.4183 - val_acc: 0.8925\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1351 - acc: 0.9493 - val_loss: 0.5210 - val_acc: 0.8876\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1375 - acc: 0.9490 - val_loss: 0.4108 - val_acc: 0.8922\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1337 - acc: 0.9520 - val_loss: 0.5011 - val_acc: 0.8887\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1378 - acc: 0.9491 - val_loss: 0.4580 - val_acc: 0.8953\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1294 - acc: 0.9536 - val_loss: 0.6350 - val_acc: 0.8685\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1307 - acc: 0.9522 - val_loss: 0.5056 - val_acc: 0.8891\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.1305 - acc: 0.9534 - val_loss: 0.5003 - val_acc: 0.8964\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1221 - acc: 0.9554 - val_loss: 0.5435 - val_acc: 0.8896\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1277 - acc: 0.9539 - val_loss: 0.6075 - val_acc: 0.8937\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1237 - acc: 0.9557 - val_loss: 0.4554 - val_acc: 0.8870\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1248 - acc: 0.9558 - val_loss: 0.4796 - val_acc: 0.8975\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1198 - acc: 0.9552 - val_loss: 0.4628 - val_acc: 0.8964\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.1147 - acc: 0.9584 - val_loss: 0.5548 - val_acc: 0.8881\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1250 - acc: 0.9563 - val_loss: 0.5044 - val_acc: 0.8987\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1195 - acc: 0.9574 - val_loss: 0.5610 - val_acc: 0.8963\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1143 - acc: 0.9581 - val_loss: 0.5625 - val_acc: 0.8950\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1200 - acc: 0.9590 - val_loss: 0.6179 - val_acc: 0.8877\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1205 - acc: 0.9583 - val_loss: 0.6498 - val_acc: 0.8881\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1098 - acc: 0.9607 - val_loss: 0.5095 - val_acc: 0.8947\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1192 - acc: 0.9594 - val_loss: 0.5845 - val_acc: 0.8977\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1037 - acc: 0.9633 - val_loss: 0.5786 - val_acc: 0.8963\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1129 - acc: 0.9603 - val_loss: 0.5117 - val_acc: 0.8905\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.1075 - acc: 0.9624 - val_loss: 0.5962 - val_acc: 0.8925\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1155 - acc: 0.9592 - val_loss: 0.6353 - val_acc: 0.8839\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1151 - acc: 0.9629 - val_loss: 0.5852 - val_acc: 0.8962\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1063 - acc: 0.9623 - val_loss: 0.7773 - val_acc: 0.8844\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1077 - acc: 0.9626 - val_loss: 0.5400 - val_acc: 0.8986\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1075 - acc: 0.9627 - val_loss: 0.5169 - val_acc: 0.8977\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1015 - acc: 0.9645 - val_loss: 0.5662 - val_acc: 0.8935\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.1010 - acc: 0.9634 - val_loss: 0.5758 - val_acc: 0.8946\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0987 - acc: 0.9654 - val_loss: 0.5684 - val_acc: 0.8995\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1012 - acc: 0.9663 - val_loss: 0.5734 - val_acc: 0.8833\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0974 - acc: 0.9664 - val_loss: 0.6274 - val_acc: 0.8964\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0933 - acc: 0.9673 - val_loss: 0.6578 - val_acc: 0.9004\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1064 - acc: 0.9661 - val_loss: 0.6009 - val_acc: 0.8817\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1002 - acc: 0.9667 - val_loss: 0.6316 - val_acc: 0.8891\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0976 - acc: 0.9671 - val_loss: 0.6125 - val_acc: 0.8935\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1054 - acc: 0.9670 - val_loss: 0.6338 - val_acc: 0.8869\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1052 - acc: 0.9664 - val_loss: 0.5727 - val_acc: 0.8795\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0960 - acc: 0.9682 - val_loss: 0.5569 - val_acc: 0.9018\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0941 - acc: 0.9694 - val_loss: 0.6743 - val_acc: 0.8943\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0915 - acc: 0.9689 - val_loss: 0.6194 - val_acc: 0.8970\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0950 - acc: 0.9688 - val_loss: 0.6818 - val_acc: 0.8642\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0902 - acc: 0.9701 - val_loss: 0.6480 - val_acc: 0.8990\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0944 - acc: 0.9701 - val_loss: 0.5957 - val_acc: 0.9021\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0887 - acc: 0.9704 - val_loss: 0.6522 - val_acc: 0.8946\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0883 - acc: 0.9720 - val_loss: 0.5863 - val_acc: 0.9019\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0939 - acc: 0.9691 - val_loss: 0.6049 - val_acc: 0.8961\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0913 - acc: 0.9735 - val_loss: 0.8567 - val_acc: 0.8799\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0859 - acc: 0.9710 - val_loss: 0.5872 - val_acc: 0.9023\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0912 - acc: 0.9703 - val_loss: 0.6715 - val_acc: 0.9036\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0893 - acc: 0.9708 - val_loss: 0.6951 - val_acc: 0.8834\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0941 - acc: 0.9704 - val_loss: 0.6948 - val_acc: 0.8782\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0983 - acc: 0.9702 - val_loss: 0.6350 - val_acc: 0.9000\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0853 - acc: 0.9721 - val_loss: 0.5582 - val_acc: 0.8876\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0799 - acc: 0.9727 - val_loss: 0.6794 - val_acc: 0.9017\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0790 - acc: 0.9743 - val_loss: 0.6986 - val_acc: 0.8985\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0882 - acc: 0.9728 - val_loss: 0.6629 - val_acc: 0.8963\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0834 - acc: 0.9730 - val_loss: 0.7641 - val_acc: 0.8925\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0870 - acc: 0.9722 - val_loss: 0.6006 - val_acc: 0.8960\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0816 - acc: 0.9746 - val_loss: 0.7086 - val_acc: 0.8906\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0827 - acc: 0.9738 - val_loss: 0.6413 - val_acc: 0.8984\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0806 - acc: 0.9760 - val_loss: 0.6744 - val_acc: 0.8756\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0958 - acc: 0.9729 - val_loss: 0.6169 - val_acc: 0.8956\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0734 - acc: 0.9762 - val_loss: 0.6243 - val_acc: 0.8997\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0794 - acc: 0.9756 - val_loss: 0.8059 - val_acc: 0.8886\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0973 - acc: 0.9726 - val_loss: 0.7365 - val_acc: 0.8985\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0780 - acc: 0.9756 - val_loss: 0.8742 - val_acc: 0.8604\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0772 - acc: 0.9756 - val_loss: 0.6717 - val_acc: 0.8959\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0740 - acc: 0.9772 - val_loss: 0.7262 - val_acc: 0.8902\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0759 - acc: 0.9756 - val_loss: 0.8133 - val_acc: 0.8705\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0833 - acc: 0.9755 - val_loss: 0.5818 - val_acc: 0.9003\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0748 - acc: 0.9762 - val_loss: 0.6631 - val_acc: 0.8995\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0803 - acc: 0.9759 - val_loss: 0.6985 - val_acc: 0.8893\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0861 - acc: 0.9781 - val_loss: 0.7054 - val_acc: 0.9002\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0779 - acc: 0.9763 - val_loss: 0.6796 - val_acc: 0.8944\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0807 - acc: 0.9760 - val_loss: 0.6947 - val_acc: 0.9000\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0716 - acc: 0.9770 - val_loss: 0.6997 - val_acc: 0.8949\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0664 - acc: 0.9782 - val_loss: 0.7397 - val_acc: 0.8991\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0716 - acc: 0.9781 - val_loss: 0.6879 - val_acc: 0.8962\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0647 - acc: 0.9796 - val_loss: 0.7047 - val_acc: 0.8966\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0735 - acc: 0.9778 - val_loss: 0.6486 - val_acc: 0.8939\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0695 - acc: 0.9794 - val_loss: 0.6605 - val_acc: 0.8966\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0691 - acc: 0.9786 - val_loss: 0.7580 - val_acc: 0.8920\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0667 - acc: 0.9804 - val_loss: 0.6813 - val_acc: 0.8968\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0656 - acc: 0.9796 - val_loss: 0.6847 - val_acc: 0.9010\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0736 - acc: 0.9782 - val_loss: 0.8086 - val_acc: 0.8962\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0687 - acc: 0.9801 - val_loss: 0.7986 - val_acc: 0.8981\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0630 - acc: 0.9810 - val_loss: 0.7996 - val_acc: 0.8985\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0635 - acc: 0.9804 - val_loss: 0.7239 - val_acc: 0.8963\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0658 - acc: 0.9805 - val_loss: 0.7250 - val_acc: 0.9013\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0662 - acc: 0.9802 - val_loss: 0.7846 - val_acc: 0.8992\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0658 - acc: 0.9809 - val_loss: 0.8695 - val_acc: 0.9000\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0676 - acc: 0.9809 - val_loss: 0.7602 - val_acc: 0.8972\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0686 - acc: 0.9815 - val_loss: 0.9137 - val_acc: 0.8909\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0672 - acc: 0.9802 - val_loss: 0.7918 - val_acc: 0.8988\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0696 - acc: 0.9795 - val_loss: 0.7480 - val_acc: 0.9010\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0750 - acc: 0.9795 - val_loss: 0.6868 - val_acc: 0.8973\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0728 - acc: 0.9811 - val_loss: 0.7562 - val_acc: 0.8939\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0662 - acc: 0.9804 - val_loss: 0.7342 - val_acc: 0.8865\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0751 - acc: 0.9809 - val_loss: 0.8181 - val_acc: 0.8983\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0588 - acc: 0.9816 - val_loss: 0.7472 - val_acc: 0.8964\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0746 - acc: 0.9803 - val_loss: 0.8171 - val_acc: 0.8828\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0568 - acc: 0.9834 - val_loss: 0.7911 - val_acc: 0.9009\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0729 - acc: 0.9802 - val_loss: 0.7657 - val_acc: 0.9001\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0611 - acc: 0.9827 - val_loss: 0.8422 - val_acc: 0.8990\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0740 - acc: 0.9807 - val_loss: 0.9206 - val_acc: 0.8670\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0620 - acc: 0.9824 - val_loss: 0.8077 - val_acc: 0.8886\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0696 - acc: 0.9816 - val_loss: 0.8196 - val_acc: 0.8908\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0634 - acc: 0.9828 - val_loss: 0.8470 - val_acc: 0.8888\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0691 - acc: 0.9815 - val_loss: 0.9213 - val_acc: 0.8726\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0597 - acc: 0.9835 - val_loss: 0.8147 - val_acc: 0.8935\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0620 - acc: 0.9821 - val_loss: 0.6954 - val_acc: 0.8910\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0706 - acc: 0.9818 - val_loss: 0.8198 - val_acc: 0.8962\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0623 - acc: 0.9841 - val_loss: 0.7423 - val_acc: 0.8985\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0616 - acc: 0.9829 - val_loss: 0.8121 - val_acc: 0.8964\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0649 - acc: 0.9820 - val_loss: 0.6931 - val_acc: 0.8997\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0658 - acc: 0.9814 - val_loss: 0.7856 - val_acc: 0.8904\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0780 - acc: 0.9815 - val_loss: 0.7310 - val_acc: 0.8994\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0676 - acc: 0.9807 - val_loss: 0.7215 - val_acc: 0.8997\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0622 - acc: 0.9829 - val_loss: 0.9248 - val_acc: 0.8921\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0686 - acc: 0.9818 - val_loss: 0.6882 - val_acc: 0.9005\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0725 - acc: 0.9838 - val_loss: 0.7698 - val_acc: 0.8885\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0648 - acc: 0.9828 - val_loss: 0.7470 - val_acc: 0.8985\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0559 - acc: 0.9839 - val_loss: 0.7223 - val_acc: 0.9005\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0597 - acc: 0.9848 - val_loss: 0.7888 - val_acc: 0.8911\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0575 - acc: 0.9851 - val_loss: 0.9170 - val_acc: 0.8979\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0614 - acc: 0.9829 - val_loss: 0.7567 - val_acc: 0.9015\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0700 - acc: 0.9830 - val_loss: 0.9042 - val_acc: 0.9024\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0654 - acc: 0.9834 - val_loss: 0.9078 - val_acc: 0.8913\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0721 - acc: 0.9829 - val_loss: 0.8892 - val_acc: 0.8904\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0555 - acc: 0.9845 - val_loss: 0.7878 - val_acc: 0.8982\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0648 - acc: 0.9834 - val_loss: 0.7987 - val_acc: 0.8938\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0680 - acc: 0.9832 - val_loss: 0.7801 - val_acc: 0.8904\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0586 - acc: 0.9836 - val_loss: 0.7430 - val_acc: 0.8912\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0608 - acc: 0.9853 - val_loss: 0.8649 - val_acc: 0.8818\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0629 - acc: 0.9842 - val_loss: 0.8749 - val_acc: 0.8994\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0691 - acc: 0.9830 - val_loss: 0.6969 - val_acc: 0.8969\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0565 - acc: 0.9859 - val_loss: 0.7262 - val_acc: 0.8833\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0619 - acc: 0.9845 - val_loss: 0.9235 - val_acc: 0.8987\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0552 - acc: 0.9858 - val_loss: 0.8059 - val_acc: 0.8980\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0620 - acc: 0.9848 - val_loss: 0.9214 - val_acc: 0.8958\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0727 - acc: 0.9829 - val_loss: 0.7723 - val_acc: 0.8973\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0510 - acc: 0.9859 - val_loss: 0.7313 - val_acc: 0.9012\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0537 - acc: 0.9854 - val_loss: 0.7768 - val_acc: 0.8907\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0632 - acc: 0.9842 - val_loss: 0.8243 - val_acc: 0.8943\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0932 - acc: 0.9823 - val_loss: 0.7992 - val_acc: 0.8974\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0529 - acc: 0.9860 - val_loss: 0.8473 - val_acc: 0.8987\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.0676 - acc: 0.9822 - val_loss: 0.7909 - val_acc: 0.8981\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0642 - acc: 0.9841 - val_loss: 0.8018 - val_acc: 0.8994\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0496 - acc: 0.9871 - val_loss: 0.8789 - val_acc: 0.8920\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0590 - acc: 0.9854 - val_loss: 0.9021 - val_acc: 0.8927\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0609 - acc: 0.9856 - val_loss: 0.8370 - val_acc: 0.8941\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0575 - acc: 0.9861 - val_loss: 1.0416 - val_acc: 0.8938\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0819 - acc: 0.9833 - val_loss: 0.7960 - val_acc: 0.8951\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0575 - acc: 0.9862 - val_loss: 0.8421 - val_acc: 0.8975\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0577 - acc: 0.9859 - val_loss: 0.8208 - val_acc: 0.8980\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0532 - acc: 0.9870 - val_loss: 0.8514 - val_acc: 0.8905\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0596 - acc: 0.9842 - val_loss: 0.7285 - val_acc: 0.8985\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0573 - acc: 0.9867 - val_loss: 0.8311 - val_acc: 0.8927\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0573 - acc: 0.9858 - val_loss: 0.8522 - val_acc: 0.8933\n"
     ]
    }
   ],
   "source": [
    "#Train Model and Track Accuracy\n",
    "track = model.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Accuracy and Loss from keras callback history\n",
    "metrics = track.history\n",
    "val_accuracy = metrics['val_acc']\n",
    "val_loss = metrics['val_loss']\n",
    "epochs = numpy.arange(1, len(val_accuracy)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXeYJVWZuN/v5r63c5rp6cmBCQzRAQYEAckgiHHFxbAmdFVWxZ+K67LGVVfdZVcxsqBgQAQVUYKCZIYwgRkm59Q5d9+czu+PU1W37u3b3Xdmupme6Xqfp5++lU9VnTrf+cL5jiilcHBwcHBwOBxcR7sADg4ODg7HLo4QcXBwcHA4bBwh4uDg4OBw2DhCxMHBwcHhsHGEiIODg4PDYeMIEQcHBweHw8YRIscQIjJXRJSIeIzlh0XkfaXsexjX+qKI3H4k5XVwOFJE5Osi0i0i7Ue7LAAi8n4RefZol2My4QiR1xAReUREvlpk/ZtFpP1QG3yl1BVKqV+MQ7kuEJGDBef+D6XUh4703GNcU4nI5yfqGlMZEdkrIjERCRt16+ciUn60y3UoiMhs4CZgmVJqepHtF4hI1rhH+9/Zr31ppy6OEHlt+QVwvYhIwfr3AL9SSqWPQpmOFu8DeoH3vtYXPlztbDIimpG+46uVUuXAqcBpwM2vXcnGhdlAj1Kqc5R9WpVS5QV/q16rAjo4QuS15o9AHXCeuUJEaoA3AXcZy1eJyDoRGRSRAyLy5ZFOJiJPisiHjN9uEfmuofrvBq4q2PefRGSLiAyJyG4RucFYHwIeBmbYenIzROTLIvJL2/HXiMgmEek3rrvUtm2viHxWRDaIyICI/FZEAqOUOwS8Hfg4sEhEVhRsP1dEnjeudUBE3m+sLxOR74nIPuM6zxrrhmlSRpkuNn5/WUTuE5Ffisgg8H4ROVNEVhnXaBORH4iIz3b8iSLyNxHpFZEOw7w3XUSiIlJn2+90EekSEW+R+/SLyK0i0mr83SoifmPbFhF5k21fj3Ge043llbZnsF5ELih4798QkeeAKDB/pGcNoJRqBx5FCxPzHCPWM8mZQt8nIvuNOvWvtu1lIvILEekz7uNz9udv1J/7jfvZIyI3jlQ2EakSkbuMffeJyJdExGW8u7+Rq5c/H+0eRzj3kyLyTRF5ybjPB0Sk1rZ9tDo9S0R+b5SrR0R+UHDu7xr3v0dErrCtf7/o72vI2PaPh1ruYw6llPP3Gv4BPwNuty3fALxiW74AOAkt4E8GOoBrjW1zAQV4jOUngQ8Zvz8KbAVmAbXAEwX7XgUsAAQ4H934nG675sGCcn4Z+KXx+wQgAlwCeIHPATsBn7F9L/ASMMO49hbgo6M8g/cAbYAbeBD4vm3bHGAIuM64Vh1wqrHtNuOem41jzwH8I5R/L3Cx7V5SwLXGcy0DXgesBDzGc90CfMrYv8Io301AwFg+y9j2EPAx23X+217+gjJ8FXgBaAQagOeBrxnbbkFrn9jezxbjdzPQA1xplPcSY7nB9t73Ayca5fcWubb9/mcCrwL/c4j17GfGszoFSABLje3fAp4CaoxzbzCfv3G+Ncb9+dACbjdw2QjP6C7gAeMZzwW2Ax8cqV4WHDvW9ieBFmA5EALup4Q6ja5b6413GzLqwLnGce9H16UPG/t9DGhFf1chYBBYbOzbBJx4tNucCW/TjnYBptofcC7QDwSM5eeAT4+y/63Afxu/zY+7mBD5O7aGG7jUvm+R8/4R+Bfj97CPkXwh8m/AvbZtLuPjvMBY3gtcb9v+n8CPR7mnx4Bbjd/XAV0YDSHa5PKHIse4gBhwSpFtxcq/l3wh8vQY7+VT5nWNMq0bYb9/AJ4zfruBduDMEfbdBVxpW74M2Gv8XogWlkFj+VfALcbvzwN3F5zrUeB9tvf+1THuZy8QNq6hgMeB6kOsZzNt218C3mX8zhMKwIfICZGzgP0F574ZuLPINd1AEu3zMNfdADw50nst8t6z6O/J/heyPadv2fZfZlzPzSh1GjjbqJPDvh20ENlpWw4az2o6Woj0A28DykZ7P8fTn2POeo1RSj0LdAPXisgC4Ezg1+Z2ETlLRJ4w1OgBtIZRX8KpZwAHbMv77BtF5AoRecEwz/Sje7mlnNc8t3U+pVTWuFazbR979EwUKOrEFZFZwIXoRhN0LzRAzvw2C934FlJv7FdsWynYnw0icoKI/Fm003kQ+A9yz2OkMpjlXSYi89C92AGl1Esj7Jv33IzfMwCUUjvR2s/VIhIEriFXD+YA7zDMLP3G+zoX3bMtej8jcK1SqgLdMC6x3V+p9Wykd1pY1+y/56BNUPayfxGYVqR89WgtoPAZNRfZdyRalVLVBX+REcq2z7hePaPX6VnAPjWyj7LddlzU+FluXPcf0M+yTUT+IiJLDuFejkkcIXJ0uAvtUL4eeFQp1WHb9mvgT8AspVQV8GO0qjwWbejKbzLb/GHY4e8HvgtMU0pVo80y5nnHSuXcim4czPOJca2WEspVyHvQ9e5B0WGbu9HCwQxVPoA2uxXSDcRH2BZB9wjN8rnR5iM7hff4I7T5b5FSqhLd0JnP4wAj+BmUUnHgXvS7ew9wd7H9DPKeG/qdtNqWf4PWet4MbDYEi3n9uwsaxpBS6luj3M+IKKWeAn6Ofv8mh1vPQNe1mbZle707AOwpKHuFUurKIufpRpuGCp/R4dSrkSj8JlLGdUer0weA2XIYARhKqUeVUpegBf5WtEnwuMYRIkeHu4CL0XbVwhDdCqBXKRUXkTOBd5d4znuBG0Vkpmhn/Rds23xo30EXkDYcgZfatncAdSJSNcq5rxKRiwwH8k1oG/nzJZbNzvuAr6CdvObf24ArDYf1r4CLReSdhrO5TkRONXqKdwD/ZThu3SJytiEgtwMBw1nsBb5k3O9oVKDt12Gjt/gx27Y/A00i8inRzvEKETnLtv0utFnjGkYXIr8BviQiDSJSj/YT/NK2/R70e/gYNm3U2OdqEbnMuM+A6OABe8N9qNwKXCIipxjLh1vPQNeHm0WkRkSagU/Ytr0EDInI5w0HvFtElovIGYUnUUpljHN9w3jGc4DPkP+MjpTrRWSZoe19FbjPdt2R6vRLaEH5LREJGc//9WNdSESmiQ7XDxnnCqPNbcc1jhA5Ciil9qIrawjdG7Tzz8BXRWQI3ejcW+Jpf4a2m68H1gK/t11vCLjROFcfusH4k237VnSDt9swQcwoKO82dM/7++he3NXo8NFkiWUDdMQRuvd3m1Kq3fb3J7RT8zql1H60qe0mdAjwK2jHLsBn0Q7il41t3wZcSqkB9HO7Hd2TjAB50VpF+KzxHIbQz+63tvsdQpuqrkabLnagTXDm9ufQjcNapVSe2bCArwOr0Y7nV9Hv5eu287QBq9ABAvbrH0BrJ19EC/4DwP/jCL5XpVQXWvjdYqw63HoGujE+COxB+7fuQzeapmB4E7pzsAddX24HRuqgfBL9vnYDz6KF6R2HUBZ7VKH59zbb9rvRWlg7WuO90SjniHXauIer0X6r/ca9/kMJZXGhhWArun6eT37n5LhEDOeQg4PDISAifwd+rZSa8qP6ReRjaKf7+Ue7LHZE5El0cMiUf0cTiaOJODgcIoZp5nRs2sNUQkSaROT1osdzLEZrjX842uVyODocNyN3HRxeC0TkF+jxJv9imL2mIj7gJ8A8dEjrPcAPj2qJHI4ajjnLwcHBweGwccxZDg4ODg6HzXFjzqqvr1dz58492sVwOE5IZxW7OsNklGJZU+XRLo6Dw4SxZs2abqVU4biqkjluhMjcuXNZvXr10S6GwzFAPJUhlclSERiWMxGARDrDO3/yAv0H+hGBl75xJS5XqePwHI5HdnQM8dfNHXz0/AW4j7O6ICKjhamPyYSas0TkchHZJiI7ReQLRbbPEZHHRWd/fdI+mEp0BtEdxl/RiZccHArJZhX/9seNbO8Y2ed90+/Wc/3tLwKwryfCW374HF1DCWv7mn19rD/Qz/LmSpSCSLJ49otMVnHbEzvpjRzScBmHY4yHXm3jzbc9x3ce3cbGloGjXZxJx4QJESP1xG3AFejEZ9eJyLKC3b4L3KWUOhk9gOmbxrG1wL+jk7mdCfy7MQrbwWFUusIJ7n5hHw+uby26vSec4NGN7WxuGySdyfLMjm7W7e/n+V3d1j6DMS00Tpulq9xQvLgQ2do+yHce3cb/Pbt7nO/itWf13l4e39Ix4vat7YOs+Prf2HCwf9TzJNIZfvTkLgaiqZKuG09leHxLB+nM5BzY3TWU4MbfrKM2pGcJ6BiMT9i1osk0773jpTGf8WRjIjWRM9HZLncbI5vvQY/CtbMMnX0WdOpyc/tlwN+UUr1KqT70vAKXT2BZHSY58VSGrzy4KU9jKEY4oRv83V2Rotv/tL6VdFaRyigO9MXY1RUGYFProLVPxDjH9KpA3jlBZ73OZnVEo6mBPPBKq7VuoshkFXev2kunrRFTSvHU9i4yxrUzWXXY5fjyg5v43H0bGCla84mtXXSHk3zjL1tQSo14rbtX7ePbj2zlNy/vL+m6D7zSwgd/sZp3/mQV+3qKv7OJIJ7K8KFfrGZre/57/9AvXmbNvj5r3WNbOkhnFV+/djkAHWPUvyPh6e3dPL29i2d3do+98yRiIoVIM/kZNA8yPDvneuCtxu+3ABVG/qRSjnU4TlFK8cLunrxG6omtndz53F6e2dE16rGmADCFQyG/X9tCyOcGYHdXmJ2der9XD+bMFKb5anqlFiJD8Vyv+pcv7ue8/3wCpZQlRA72xVizP9fwlHqPP/j7jlHNbnZW7+3l3x7YxGW3Ps1jm7XGsLltkPfd8RIPvdoGwPW3v8i//nHjIZUDtHa2qXWQnkiS3d3FG/I1+3oRgRf39PKNv2xhxdf/xn88tCVvn0gizY+e1MmP/7Z5ZK3GTndYP8MdnWGuve25cTMXvXpwgJ88tStv+X8f38Gtj21HKcX2jiEe29LBsztyDfYPn9zJY1s6eWpbbiLFRza2M7s2yHmLGnAJdAwcmibSG0kST2VK2veJrfq67SVco2MwTjI9ObS3ox3i+1ngfBFZh84z0wKU9sQBEfmIiKwWkdVdXaM3Lg6HTziRJpYs+bUcMS/s7uVdP32B52wmpie36fc7kmnJxNQa9vZEhvWUd3QM8WrLAB88Tyfo3d0VsTSWja0DVi/cPEeToYkM2q65qzNMS3+MwXiaHqMB9LiEP6w7tMSzu7rCfPev27l/7VgpvjRR4/m7RPj0b19BKcWB3hgA6w/0E09leGlvL08aDeDa/X185t5XSjITPberB1MBeXlP77DtSinW7Ovj2lObmVcf4vZn9xBNZvj1S/vzBOydz+2hJ5LkoiWNrN3fN6bWCDAYS+H3uPjzJ88l6PNw3c9eKFmwjsZ3/7qNbz68lXgqw76eCFf/4Fn+62/bufWxHXSHk+zr0RnczTIe6I3ys2f2AHCwXz/XwXiK53d1c/ny6bhdQkOF/5DNWdf99AU+c+8reevCifQwwZLNKp4w3l1bESGilKJtQJfr+Z3dnPvtv3PHc3sOqSwTxUQKkRby0zDPpCDFs1KqVSn1VqXUacC/Guv6SznW2PenSqkVSqkVDQ2HHaF2TBJPZUru4RwpH7jzZT5y9/hHvr31h89xw92rGYjl289f3NMDQOeg/sCVUjy5XX9gg7HRbe1ho8GPp7K0Gh+dycZW3cu95pQZ1IZ8bGwdoKU/RnN1GUPxNPt7dcMSSaRxu4T6Cn/eOc1toBufvmgSl8AVJzXxlw1tIwraTFZxywMb80wnT23vzrvHu1/Yx5f/tGnE+zLf9cVLpzGUSNMfTVkN2qstA2xuGySTVbQNxGntj/HLF/bx+7UtPLFt7M7VM9u7qCrzUhfy8dKeXjJZxX1rDvKe/3uRT/x6Lbu7I/RFU6ycX8v3rzuNr735RH794bOIJjP80SY873n5AOef0MBnLj0BpeDvW/O1kQO9UX781K484T4YT1FZ5mVOXYjf3rCSoXiaRze2c6gopfjYL9dw+zO76QknLJNQS3/OZPnR8/UsAru7wta77jSEyK2P7cAtwvz6EC19ut48sbWTVEZx2Yl6KpTplQHabUIklcny4PrRTZkt/TEe3tiepxl/4M6XOffbT/DHdS1Wx2VT6yCdQwncLhmmiSil+MqDmzn7m3/nfXe8xA13ryGVUXkm2LGeTZ8t+OOLf3iVu184ooCsPCZSiLyMnj97nui5q99FQcZaEakXEbMMN5PL3vkocKmRaroGnS770Qks6zHHZ+59hY//au24n3fNvt5hpqAdnUM8s6ObtWOYbB54pYWfl9g7SmWyrN3fz6ObOrjmB8/mVfLVe/V1+g2BsaVtiA6jsR1KjK6J2COpCv0i8ZTulYf8bubXhyzt5s2n6qTFrxqmlEgiQ8jnpiKgI+Dt2k/YJkR6Iklqgj7ed/YcBmIpfrFqb9Ey7e+Ncteqffx9a85M8tR2fW2zwfjrpnYeG8WxHTOEyPyGEACtAzGrQdvcOsj6Azln7Jp9fTxjmGnueWl034RSimd2dPP6hXWcMbeWl/b28qMnd/LZ361nc+sgf97Qxnce2QbA6+bUsLy5ivecPZfTZ9ewvLmSX724H6UU8VSGlv4Yp8+uYVlTJc3VZfx1U/79/HFdC996eCu/XZ2zVA/G0lSV6VDrmTVB3C4hnj70ztFjWzp5eGM73/3rNu58bq/lJ2rpi1ka26WGMNjTHbH8L6YmsuFgP+ctqufkmVUcNITIY1s6aajwWwEWjZUBS+gDPL6lg0/+Zp31LgtJZ7KEE2mUgtufyQVf7O6O0B9N8qnfvsJvX9bP4u9bOxGBNy5pHKaJ/OyZ3fz8+b2cf0ID6/b3EfS7Wd5cye4RTLZ2ntjaybW3PcdpX/sbrxzoJ5tV/H7tQX5fogZcChMmRIxZwT6Bbvy3oKei3CQiXxWRa4zdLgC2ich29Mxn3zCO7QW+hhZEL6OnAh2uZ09h1uzrY/0ERHHc+JtXuPa25yyBEU9l6DMibX74xMiTCsZTGW55YBNffnAzvy3BqdoX1ULjqpOa2NcT5dFNuveZzmStaw8Y+5hqfpnXPbYmksg1QLu6wjy4vpX71ugPJmE0xH6Pm/kNIUsDuvKkJrxuYWPLoHGONOV+jzWOJJxI2c6vhUh3OEFvOEltyMeKubVcsLiBHz+1i8H48PLtNfwMphYTT2V4cbfWtjqGdIPR0h8jMYqNOydE9OSCbf1xSxMZSqR5cH0rdSEfAa+Le17eT9dQgjl1QZ7Y1knbQCxPS0pnspaZa1dXmPbBOOctauCMebUc7Ivxv4/v5PITp/PCFy9iTl2QRza1Ux30Mr8+N1mliHD9WXPY2j7EhoMD7O+NohTMrQ8iIlyybBrP7Oy27hlyvf5vP7LV6jQMxlNUBnLD1QIelyXsS0Upxf88vp2mqgDZLPzgiZ3UGdFUB/tiHOiN4ve4OGVmNT6Pi93dEcuc1TkURylFa3+MGdVlNNeU0T4YJ53Jsql1gNNnV1tjhKZV+q33pZ+dfq/PjeAINzsfIZ+b+9e20DWUQClFfzTJB8+bx+mzq7n1sR30hBPcv/Ygp8ysZvmMKnoiCcvfcaA3yjcf3sqVJ03nzvefwfM3X8RfP30+Z86tY3fXcJOtnbaBGB+5e7Xld9pwsJ+OoTjxVJYtRnTieDChPhGl1ENKqROUUguUUqaAuMWYPwKl1H1KqUXGPh9SSiVsx96hlFpo/N05keU8VmgbiJHNKgZiKToGE3SHk8NMQaXwyMY2vvbnzcPWpzNZ2gfjDMXTvOf2F9ndFbYaqvkNIR7b0pHngLbz2JYOBmIp5tYF+dIfNxYNU4ynMvzmpf1kszmn9BUnTaepKmD1nLe0DVn2f1MTeWp7FyfOqGRGdaBoI23HbLT8HhebWwf50h83csezWjsyG2m/x2U1xi6BRdPKWTy9wnLqRhJpQn4PQa8bkZE1kd5I0gr9/Oyli+mPpqxrZbO6YQIsZ3XEEHAv7uklkc4yvz5E52DCasTsjtLCKClTCMyr15pI20CMjsE4FX7dAK/d38+ps6o5eWY1z+3UAuo7bz+FrIK3/2gVy/79Ee41NICP/nINH7l7DYC177kL6zlrXi0Abpdwy9XL8LpdfPriEwA4fXbNsAGXFy5pBOCVA/3sMe7RLN+VJzWRTGfztKvOoTjVQS9D8TT/8/gOAAZi2pxlEvC6D9lM+/iWTja2DPLpS07gPWfryQqvXzkHj0to6Y9ysC/GzJoy3C5hbl2Q3V1hDvTmfCKD8TSRZIbm6jJm1gTJZHXk3r6eKIunVVjXmV4ZoD+asspnarrP7+opWi7z23zHilkk01le2tNLOJEmnVXUhXx89rLFtA/GedP3n+VgX5TPX76EpqoASulnBfCHdS0oBV+8cikul1Du91BV5mV+Q4hYKkPbKD6anz29h6yCez6ykpDPze6uiPWe4qmsJQSPlKPtWHcokdb+GG/4zye4b+1BK6IIcr3ckYinMnnOT4D71rRw53N7hn2s3eEkmazig+fOI5LMsGp3j6Va33TJYhor/Nxw9+qizsV7Vx+kubqMP/zz63G7hD+uGz5O4/Etndz8+1dZf7DfEiK1IR/nLarn2Z3dZLKK1fu0wlnu99BvaEC7uyKc1FxFZZl3TMd6JJFGBJZMr+CPr7QwEEtZ5hGzh+v3uJhvNHaza4P4PW6WTK9kR6d26IYNIWJ+tENFfCLd4QS90ZwQWd5cxQWLG7hvzUGUUvz8+b1c8N0n6QknhmkiT2/vwudxcfUpMwgn0hzsixFPZUkY5dzWPsSJ//6o9cHrsutts2rL8LqF1oE47QNxzppfh8+tP+OTZlZx+mxtelnUWM6Z82p5y2nNlPnczKgq42dP72ZHxxCPbenk2R3d2hm/p5cZVQFm1QZZ2lTJ0qZKbr5yCTOqywC4+pQZXHvqDN65wu6i1DRW+KkJetnSNmiVda7xXFfMqaGxws9fNrRZ+3cOJThxRiVnz69jnWF+G4ylqAwUCpFD6yE/sL6Vhgo/bzmtmRvfuIjrV87m+pVzaKoOaE2kL8qsWj178vz6cra0DdE2GMfvcdEXTVkCpak6QLNx308bodOLbEKk0YjWM01aew2T2Oa2waIDTk0hsmS6PkdvJGHV6eqgj3MW1HPuwnraBuJ89rLFnL2gjmlGMEf7gNaQfr/2ICvn1zKzJph37gVGJ2gkk1ZPOMFvXtrPm0+dwazaIPMbytnVFWZvd9Ta59VxioRzhMgE88Mnd/LOn6w64vM8s6OLVEbx3M5udnbmolf2jCFEvvbnzVz/fy/lrdvdFSarhvsMzOiPs+fX4fO42NcTtWz2i6dXcMf7z2AgluIDP3/ZsjmDFnDP7Ojibac3UxPysbSpsmioptm76hhMWB9dXcjPuYsaGIileLVlgNV7+2iuLmNBYzn9sZShtSSoL/dTGfCWYM5KU+7zsKChnFRGlzFhNEqJdAaPS/C4c5qI+THWlfvoi6ZQShExzFkAFQVCxHSyF2oiAJcum87BvhjbO8I8sL6VZDqb10s3/TU7OsMsmV5h9drNBjWRzqKUYm9PhGgywypbDzeWyuB2CX6Pm2mVAdoH4nQMJphZU8Zio5E6ZWY1r5ujhch5i3SgyX//w6k89pnz+dTFi9jRGeYz964HIJnJsnZfHy/t7eUMmwby8L+cx3vPnmtd1+0Sbn3XaVy+fPqwZy0iLG2qZEvbIHu7I9SFfJZAcLmEK09q4sntXVYnpnMwQWNFgIYKPz1h3RAPxtNUluXMWX6v65B9Iuv293Hm3Fq8bhdVQS9fv/YkGir8NFeX0dIXszQRgHkNIVr6YygFp8yqBrDMwk1V2pwFORPqCQWaCGD5ovZ0RywBsaqINmJqzXPq9HvuDictM25NUNebb73tJL527XI++oYFRhn0NdoG4qzd38fenihvO334rMgLGvU5d3UWFyL/8/gO4ukM/3yBPu/8hhC7u7QvyOd2EfS5xy2c2hEiE8zGlgHW7OvLa3Rf3tvLvS8fGOWo4TxrmB3W7OtjR0cYv8eFSxgxrt9kzb4+y6wCkExn2Wf0vHZ05odSmhpGU3WA2bVB9vVErA9melWA5c1VfO7yJWxqHbR6b6BNWUrBW43KflJzFZtaB4bZa00nZtdQPE8TOXdhPSLw06d38eS2Ts6cV0t1mZeBaFILEgX15T4qAp68cNtimKYo0wFdEfBYvfh4KkvAq8eIzKkLUuZ1s6RJNwLVZT6S6SzxVNbQRNzG8d6iPpEOIzqrziZELlqqzTt3rdprObrtQsT01wzFU1SVeWms1NFf6wwfkFI68aNpdrP3FOOpLGVG2WdUlbGjc4hwIm29F9Da0Fnza3ndnBreenr+sKqrjYi0V1sGuOzEabgEfrv6AF1DCc6YWzvqMx2NJdMr2dYxxO6uiKWF5K6pTVqPb+lEKUXXUILGCj+1IR+9kSRKKQZjKcuxDhDwuIkfQjh551Ccg30xTptdPWzbzJog2zqGGIilmFVjaiK5Mq4wBK75rpqryyxNZNWuHjwusQQ9wDRDiHQMxhmIpuiNJLnm1BmEfO68jAcmpiZSV+6jOuilN5K0/Is1wVwwwXtWzrFMhdNtmsj9a1so87q54qSmYeduKPdT4ffkmaSe2NbJU9u7uP2Z3dy1ah/vO3suCxsrjPsup6U/xpb2IWbXBVk2QkfvcHCEyATTF0mRySrLqfaTp3bxDz9Zxefu32A1HmORzSqe39mNz+3iYF+MZ3d2s6ChnOaaslE1kVQmy66ucJ5TdX9vxBJo2zuG6ByM84+3v0Brf8wyXTVVlTGnNmhpIhV+j9UzX96sM9raI7i2tA1SE/Qyp05/qMtnVBFJZthTMALZFCKdQzlNpDropTbkY/mMKh56tZ26cj83XXoC1UEv/bEU3UaPta7cb5izcg16Nqu4a9XevMguUwBcduJ0rj11Bm86eYYlRBLpDH6PrvJet4sHPvF6PnbBQqscAP2xpI7OMu63PJDTRJRSlhDZ2TGEUuRpItMqA5zUXMWvjYio+nIfL+7utUKNTXPWUFxrOmbPdt3+nP8okc5aAQCvtuTWx1IZSwBOrwqwtU13AKZXBvjA6+fN4Hi4AAAgAElEQVRyy5uW0VChtbX7P3aOJVhMAl43152pTVIfv3Ahy5urrNQwZ847fCGytKmCeEoHQ8ytyxcip82qoakqwN82dzAYS5PMZGmo8FNX7iOazNATSZLOqjxzVpnPXZIm8uD6VnZ0DFnPrpgQMUO3gZw5qyEXHGAKzw0HB/AY40ACXjf15T4S6Sxz60P4PLkmcpoh9DsG41bdXtRYwVnz63h2Z/cwP5YpRMzw6Z5Igv6oWe99FKPC7yHkc9PSH+ORje1cvGya9e3ZERHmN5azu1t/h3/e0Mo/3fky77vjJb7+ly1csmwa//amXJYps1P1wu4e5taFWN5cxea2wTF9jKXgCJEJIGWLejDV19aBGOsO9PPNh7dyybJp1IZ8fO+v20s639b2IXoiSd5lNAJb24dYNK2c+fXl7DEqUbFIi73dEVIZRTSZtiq46U/xuoXtHWEeerWN53b28OyObtoH4vg8LkMghNjfG6W1P2b1jiBn/rELkW3tQ5wwrQIR3ZsyG7CNLVobMTWSLkMgdBrmrKoyL17Dnv/us2Zz5rxa7r3hbGbWBKku89IftQsRn2HOyt3LugP93PLAprwBe+FEhnK/h0XTKrj1XadRE/QST5vmrJwmAtpUYX6g1UZvuD+asqKzQGsy4URu7ImpXLUaAre23J/3zC9a2ohSsLSpkkuWTePlfb0oBSI5IRKOp6kIeCwb+2ZbvH8ilbE0kW3tQ5afJJ7MUObTz6qpOkDaKMi0ygCLplXwgXPnMRaffOMi7r3hbE6eWc3K+XVklRaeC20N66Gy1EiTn84qq6EycbmEk5qr2NYxZJkyGysD1If0MzN9RfmO9dKisz5//wY+f/8G1u7vw+sWTpxRNWwf04Rl/21qIiGf2zIDbu8YYlplwMrO22xoLSdMy38uVWVe/B6XFiLGdzevPshFSxvZ1xNlS1u+Zm/mYKsMeKkL+ekJJ60Oj6mJFCIiTK8K8PDGNnojSa4oYkY0WVAfYldnhPUH+vns79azYk4Nd/7TGXzpqqX877tOy8s2bL6bZDrLvPogy5uriCYzvP6bfx/p9CXjCJFxZn9PlLO/+XcrSsd0pLX2x9jerivZl65axj9fsIBnd3YPs6Wu2tXDptZ8NdMMIfzwefMJePUrW9RYzrz6EHu6IjzwSgsnf+WvVl6lHz25i63tg2w1rpdV2gYOubDEcxbUs6NjiKeNqKhtHUO0DcRpqgogIsypCxJNZtjUOpgnRKqDPurLfezq1OfRKSTClm0YdLSTz+NiY8sAN96zjvfeoX0yOU0kTk8k3xR03ZmzufeGs61rVQV9DMZT1jEN5X4qAh6SmazVyD5vPJdt7bmP1zRnmQS8bjJZRSqTJZ7KaSKFVBkfdV80mXcOu2PdFCb2kNTagh7lxUv1WIQrl0/n1FnV1kjwBQ3l1vFD8RQVAS/lhoaXtHUAkkY5AVIZZd1bLJXJM2eZ2N/NWAS8bkvrMCOxVsypPaI09wsby63GqlATAVjQWM6+nogldE1zFuRMsXmOdc/Y0VnpTJZoMsPa/f3cv+Ygy2ZU5XUOTJptQsQ0Z9WEfNQEvcyuC1FvdACyCmZU557jTMOktaixAjsiwrTKAB2DCfZ0RXCJ1nAuP3E6LoG/vJofTDIQS+Fzuwh4XdSV++ixmbPsJrxCmqrK6BhM4PO4OP+EkQdRL2gsp30wztt//Dx1IT8/uv51XLi4kQ+dN58yX/7zsJvl5tSFOGNuDV63WH6hI8ERIuNIOJHmw3etpjucsFI39Md0z6OtP87enig+t4sZ1WVcv3IONUEvv1uT842kMlk++ss1fOa36/NU46d3dLGwsZxZtUFOnqlf+sLGCuY3hIgkM3zlwc3aEbu7hwO9Ub79yFa+//jOvPQRpklrV2eYpqoAp86qZl9v1BJi2zuGaB+IWyaW2YZpqqU/Zq0zMSM9zO3hRJoTbELE63axdHoFf1jXwp83tLH+QD9KKUur6Aon6IskqQkVV+lBawbK5vw3zVmQc1iaaVG2dYwmRHQVjxs9fN8IQqS6TJelayhBOqtsmoh3mBCxf5C1BfewvLmKO99/Bh86b37eB3qS0fPLZBWRZMY6v2kiMUmksnnjRUy/iN2c1WQTHIXvplTOmFdLhd/DhUuOLNNDwOu2evdz64PDtpsBDmZSQ9OcBXZNJF/ojyVEIraxQN3hJKcXMWUBzKzW5Sn3eyxzJejQ5Dcsqre0btANt4kpfOxOdZPplQHDnBVlZo2O7Ksr93POgnr+sqFN+3mM+mmGL4sItSEfPWFtzqoMePC4R256zY7BGxbV59XlQkwT3jWnNPPAJ15PQ4V/xH2DPg8zjPPOqw8xpy7Eq1++jF9+6KwRjykVR4iMI995ZCs7u8JUBjx0hxNGahLdILQOxNjXE2FWrY5XD3jdzG8oz0tx8OLuXgZiKbZ1DLHWsPX2hBM8v6vH6uGazsCFhiYCOsmbS7QT/QVjENsT2zp5xTaK2Rx7sasrzIKGck6YVoFSunFqrPCzrX2ItsGY1UDZe5VNBb3dBTYhYvaU7ZoI6MbUHOQ0lEjTE0lay6Y5q7ABtlMT8lrldbuE6jKvpQEMxnQur7X7+nGJFoCmySycSFtjJwCr4Y2ndA+/WI8Vcj4Rc7SymaSxIuCx/DCmOcruQDYbRDsXLmmkzOdmUWMFQZ+b+nI/jZV+wom0JYjM0fCmszZoXC+RzgmRqjKvNS4nlrQLEd3IVQY8w3qcpVIZ8PL8zW/kujNmH9bxdkyTVjFNxLLFG52Vxgo/dYY5y/Tn2Xvl/iLmrHte2p8XyjpkBDrMqtXP4bTZxWeJmF4VwCXalGWaWgH+652ncvOVS43y6OffZNNETP/J4unDhciCxhBr9vXx9PauvHrwppOb2NsT5X13vswpX/krm1oHdPiyISDryv3axzdG5wly39tlJ45sygJtTdj4lcv43jtPsbSq0TD9QWa5R/oWDhVHiIwjj2/t5OKljZwyq5ouWzgfaHPWnu5I3ofWWOG3RvECPLqpnYBXh9+Z6Sr+vKGNTFbxltN0tM31K+fw/y5bzIKGkCVEzppXyzkL6nl5bx8v7NbZVqPJDM/s6MZjmBqiyQxKKXZ1RVjYWG7Ze31uF9edOZvOoQQtfTGmGw1Uc3UZppVjuq2XBrCgIUSfEZ1iagGLCnptpxq9cDM8ccPBfjJZZQnY7nAiz5xViKkZ7OwMUxvy4XKJZfYYjKdYs6+PZCbLZSdOJ57KcqAvl/cqTxPxmEJEayIjmbNMIdJiRLKFbCG+iXSWZDpraST2d1gzgoMUdHjsmfNqWd5cSbnPQzKdtWzi5r2YmoR5zkQ6YwUAnDyzytJE4ulcdJbZ4B2KKasYFQHvuMzY+K4zZvHh8+YV7TUvMEa5v3KgnzKvm3K/xxK8e4qZswo0ked2dvOF37/Kx3+9zgoIMQXxJy9cxCcuXMjFRlRcIT6Pi6aqMksoFMPsvdtNhG85rZnb3n06CxuH+4q+cMVSzj9Bh6TbI70uO3E6Hpfw9PYulNKDZgfjuciz+nIfSsGersiITnWTk2dWU1/uszqOo1HM6T4Si6drH2DTYWqvI+EIkXHiYJ8eGbtyfh315ToOvi+Si3xo7Y+zrydqxYwDhn1VayLZrOLRTe1ccEIj15wygz9vaGMonuIP61pY2lRp9YpmVJfx8QsXIiI0V5fxLxct4htvWc6KuTVsbR/kqe1dXLx0mqWmm73EWDJDx2CCcCLNgoYQc+tDeN3Cirk1nGqoxVmV6wX5PC5LrZ9eld/LWWB8XDs7w2xrH2JGVSCvIQB486nN/PYjK/nwG7TD1zRnLJtRSVZpM8RoPTLTR7HHGH8AObPHYCzFc7u0gLx+pR6hbPp/wgVCxG+Ys8we/ki9rzKvG5/bZSXfMzWFcuN/OJG2NBFTeFcEPCOax0x+8O7T+cG7TydolMkMmTbPazrXzXMm01kSRijyvPqQJdTiyZxPpC7kw+d2WVrM0eachfX861WF881pqoJe6st9JDNZGiv9iAhBnxu/x5UTIoUhvoYQUUrxnUe3EfC62NI2yO+MEffmWJ2m6gCfvWwxQd/IDen33nkK/++yxSNubzSFSHVOiJT7PVx18vCwWtBa08/eu4LvX3ealdARtK/lZ+9dwe//+RxEdHswYAtfzvmBwiM61U0uWTaNl//14jE1lkPlxjcu4r6PnT3uUz07QmSceHG3HmmthYiP7nAunG9efYht7UPEUpk8u3FDhZ+huDbNvHKwn86hBJctn8Z1Z84mlsrw9h+t4pUD/VxrJAgsRET49CUnsLCxgjPm1qKUHkn9+gV1XLpMq8Km3TSaTFvhgPPqy/G6Xdx8xVJuvGhRfmoHW+92Tq1u2KZX5msiC20RWtvah4qq/T6Pi7Pm1zHb6AVaQqQpF0UzuiaiP7REOmv1Fk1BNRRP8+LuHk6ZVW1pPNuNSKZURlHuzwmKnDkrQ2IUx7qIUBX0DtdEzPxZ8fQwn8ho5TcxnedmmUzzZc6c5c87pxZ2upwVRnixUko71g3TlYhwYnMly2ZUjnn9yYBpRjEbbBGhvtxvme0qbIEKZT6XFU33+BZtkv23Ny1jxZwavvvXbUQSaSsJZym98JXz64r6NkzMulVosh0Nl0u4+pQZwzTBC5c0cvpsPVK/pS+mfSJG/TFNePFUdlTt1cRufhsvqoJelkwf/zrjCJFRSKQzVvpupRQ/e3q31cgU8sLuHqqDXhZPq6C+3E88lbXmJVjaVGFF4BRqIqCjlZ7c1oVL4I1LpnHKrGp+fP3p9MeSeFzCNSMIETunzqq2omRWLqjjnWfMYkZVgNcvrAcgmspYU5aa5oQPnDuPlfPraKoKWH4E+8dkOtcLP7Dm6jL8HhePb+lgd1ckz6leSNDnob7cz/oD2ixzoq3hG80nYlf5zcbabNAHYil2dIQ5cUYlIb+HWbVlbO0YshyuhdFZYJqJsvhHsQPXBL2WJmKPzgJtQrPPM+LzuA6ppxgq0ETMe1naVInP7bLG3yTSGRKpLH6vi4qAl0xWC5BYgT/n3hvO5vOXLSn5+kcTMyzc7vg1333Q57bCvEFrImY03R/WtdBY4eedK2bxkTfMpzucZGv7oKWJ2IXP4TK7LojP7bKit8aD5uoyPeeMTROx+86qx9BEjjUcITIK964+yJv+91n6o0naB+N846Et3L+meArlF/b0cNY8HS5ZZzi5zJQEy5pyDee8Ap8I6MF3u7rCzKoNWpXu8uVNPH7TBTz66TfkRY6MRMjvYVlTJTVBLyc0VvC6OTU8f/NF1gDAWDIzYg9ORFhk+Ejs0T6XLpvGpcumDav0LpewsLGcx7Z04vO4uHJ5cdXfZHZtmZWF9sTm3LMYrRG2h9Gaz9M0Z+3uijCUSFuN0+JplWxvH7LMTfk+ETM6y3Csj2J+qi7zWeU0n1GlzZxlCpHygIeGcn9JmoiJJUQMTcQ8/8r5day75RKrc5E0zG5+T34q+ngyY0WagY6AG2+zxESxwHCum05syDWqhaGuds1xIJZiZk0ZXpvpzhzHA1DuP/LG+B2vm8XDnzrPMp+OB801QQ72xfJSutjrSmFY+LHOkYvyY5h0JotLZMSPcV93hHRW0dIfs/IwmT1VOy39es6CfzpH2//ry3NOYcAyO3hckhePbk+jsK8nMiy6pdzvofwQBoJ94Yol9EdTefcT9OpXHE1mLMdwof8CYPH0Sja2DFoNNsAFixu5YHFxp+W33noyB/uiXLC4ccwIodm1Qdbu145V+z2O1gh73Dlzjhl5UuZ143EJrxzQpjFLiEwv54ltnVYgQ3nR6CxTExlZiNgbEvuIddANeSSRxiW6HF+6aqk1aVUplBcIEbuQDPk9lpktkTajyFyWtjIUT+WNEznWKKaJmOadwrqYC8nOMpRIW8/JyigQTVmaSPk4aCI+j8sq33jRXF3Gnze0olROSFYHfYjo1DbV4+zrONpMaSHynv97iWUzKvPSA9gxTQ96PmMtRA72R4ftt3qv9oeYA7nMRm9HZziv4ZxVG8yLDzc1kY7BBHu7o7xuhFDFUjFNV3bMBj6WTFsfX8g/vDH6+IULuHTZtLxRrqNx0swqTpo5fJRwMUy/SH2Fj4DXTVWZl4FYalRzFmClDTd7rSJCRcDDRmOEtxk+uqixgkw2N9NbcSGi04mY0VpFr2frFZf7CnwiiRRDce20F5Gi+YxGI+Qrbs4yMc1s5jgRuybSF02RzqpjVogsaarA4xJLI4GcJmIfIwK55xBPZYgk0jQbnS4zWq8/lmLIyNQcnKTPo7mmzBpkagoRt0uoDfqMicyOL3PWlBYiW9sHrfj8Ypgpn9sHElYqk4NFNJGNLQP4PC7LwWwKkQN9UZoqA1bkh2laMqkOevG5deRJOJEelsBuPDDvL5rMEE6kdG++yECnmTXBYemmxwszxLLBeC6NFf6ShEhN0MeB3pil2YGO5OmLpgj63JbpzexJmnOYjDTYMD6GJlKdp4no52YKJFMTOZSQSjt2TUSPE8ovh5nO3R7ia/bCzXp4uGNCjjZNVWU8/bkL80ylVsTdME0kJ0TC8bQlfCsCHkT0RGXhRIZyn2fSmvPs6Vbs92eOWi/FsX4sMWV9IulMlr5oKm861ULMXmO7bSrS1v5YXkZe0PMjL5leYTkIzV6WUlqNDXjdLGgIccrM/JG1Ijrp20t7tCZTbLDWkWL2XrUQSY+LCeBQMe39pjmjsdJvjIcZvSy5GPucGcT8KOfVh6xGxNRITOd9MU0kkkyTySr8o2kixsft97gsQWv3S4SPQIgEDaHUORQ3GsT8BtAeihxPZY3oLK91jP1ejkVmVJflNfq1Vth2gRCx+bAitvrqcglVZTopZziROir1uFRm2sKF7T4f856PN8f65H0TE0yvYT+PFqSd/sqDm2isCPDR8+fnhMhg3Ep4l8ooOofilrNbKcXmtsG8RGlet0tnoY2mrArzlxvPy4tCMZlW6bdGp0+EJuIyer2xVIZBI/Hfa41pzjKFyOza4LB5pIthNup2P41ZfrsdO2RkxDXTvNjNdab5yoxMK9QA7JgfvF1Q+D0uvG6xhMhoaShGwzxnVhWPKrL7RBJpHYllHmPmDztWzVnFMDsGlQXPwjK/pjKEk/lC20zKmc5mD1uYvxbYc3bZhaRZj483TWTyvokJpic8XIi09Mf4+fN7WTytgnedMcuarrR9MEEmm0vFcLAvZgmR1oE4/dFUXgQW6I+kP5qyKsxIvUgzYsXtkjw1eDwJ+jxEDZ9IxVH4+Bor/MxvCHFys9bEPn/5kjFnKIScj8LugDc1kUJn6ILGUG4gX5HBhuZUu6NrIvrcdkGh/TA6BX04cfhC2O9x4XYJmawqGlWUM2dlrZH15rXMrAbHsiZSiNkrHyk6S883kv8uq4I++mN64rDJrIkEfR5qgtrsar8/sx4fb0JkypqzzPksoolcY3bvywd00r/uiDUHhNsldBhTkZqpQg725Zzrm4y0FMsKUlHXlai6moPNzFDGiaDM6z6q5iyXS/j7TRfwzjN0KvvqoG/UVBQmK+fX8cYljXmNp+mILUw7Pr8+XzMxMXv45twOo2kipvO2UNuYUR1gb09Ep1QZwwQ3EiKSl4+r2Hafx2WNWPd73IR82g9gChEzFfzxgGnyLQwwMDVHM1mnvb5qTSRpzccymTG1Ebsmcs6COt5wQsMx69saieOnVh4iZiWNGJpIJqv43eoDeN1CMp21RlgvmV5B+2CczsGENfWoPcx3U+sgInpAoR0z/HOsXkdj5fCEh+NN0OcmltSOysn+8dm56uQm7nj/GXnrKkbSRAyh4vO48oSxiOD3uCwhUoomUl4QvXbarBrWHxhgMHZkQrhw7Ekhfo+LRDpDPJ3B73VZc7x3HYeaSHN1GTdetGjYtLumkLeEiK2+1hgm4iPRCF8rZlYHESFP8798eRN3feDMo1iqiWFChYiIXC4i20Rkp4h8ocj22SLyhIisE5ENInKlsd4rIr8QkVdFZIuI3DzeZTPNWWaK9Kd3dNE6EOd9xvzS5hwep8yqZsAIK5xdq+cgOFggRObXh4Y5ic1IpLE0ETPMd27dxERGgRYiepxIalwGaB1NmqoClBl5peyYqTWKmesCXvch+UQKNZHTZlcTTqRpH4wfkRAuTKVSiBYiudxZoM13XYZj/XjyiYgIn7nkhGEaqXnf5veZ5xMJ+uiPJo+JztBJM6uYVxeatBFk48mECRERcQO3AVcAy4DrRKRwQMaXgHuVUqcB7wJ+aKx/B+BXSp0EvA64QUTmjmf5eiK6p5PM6Ayt5jSbNxhJ1cx5Nk62TTM6vcrPzJqyPCGyuXWg6KxqOXNWiZrIBDjVTQJeN7GUHrE+2XtwY3H9yjk88qnzhpkEzKSQxRzfAe+haiKFQiQ3fqfYGJtSKUylUojf4zbGieRyfFUEPPQYptfjzQxSDH+BJmJ/n1VlXgbjaQZik78z9NHzF/Dwp8472sV4TZhITeRMYKdSardSKgncA7y5YB8FmB7pKqDVtj4kIh6gDEgCg4wjZk8HjJQg8RTlfg8NFX7qy/0MxtPUhfJt99MqAoYQ0T6RRDpD60C8aMronDlr9Mq+eFoF1UGvNd/zRKA1kfQxYQYYi4DXnZd/zKSpUmsoxYWI25ocbKQEjKAbd7dhQrIzty5ovccjabzsU+4Ww+9xEU2mySryhIg5cO140kRGYnRNRD/7WCozqR3roH2po3VYjicmUog0AwdsyweNdXa+DFwvIgeBh4BPGuvvAyJAG7Af+K5SqrfwAiLyERFZLSKru7q6Dqlw3TYhEk2lrXmvIWdfn1YZyEu3Pa0qwMyaIC39MbJZZSX8K2bjNgcYjpWue3pVgFduudSal3wiCPo89ISHR7scT7hcwvyGUNEGOuBx5zSRURpiEeHyE6dz1vzaYetNbaTQX3IoBC3HenFB5Cviu6komGvjeKfQsW5/n3bT8NGIMnQoztF2rF8H/FwpNRO4ErhbRFxoLSYDzADmATeJyPzCg5VSP1VKrVBKrWhoOLRpPk1zFujpNu0RH6ZmMb0qkJfueVplgOaaMlIZRVc4UTThn8l5C+u55yMrJ1Q4lEqZz205Zyd7D+5I+Nq1y/miMWOdnYBttrzRNBGA2/7xdN5y2sxh680pWMfDsT7SOfwelzW1qum7KTZw8njG6xbcLilqzjKj5+D4rsfHGhP5JlqAWbblmcY6Ox8ELgdQSq0SkQBQD7wbeEQplQI6ReQ5YAWwe7wK1xNOUu73EE6kiSbTDCVSwwayTasMWPNBgDFXsznPdyxFxrAzFBMiLpewcn7deBX3iAj63NZgyZF6wccDp4+Qe8yufRxuQ3y6EZlnb8gOFbOejByd5abDcKLnNBHbXBtTQIiICAGPi8H48IzT9gSZx6tGfSwykZrIy8AiEZknIj604/xPBfvsBy4CEJGlQADoMta/0VgfAlYCW8ezcL2RpDW4z9REzAbW0kQMU9S0Sr81nsPKpWSb6e5wRzG/VtgdslPRDGAXHGNpIiNx9vw6fvqe13HeouFJLkslNIZPxOdxMWiZ3UyfSC6Bn9d9/Ef6QO59eVyS977yEmQ6msikYcKEiFIqDXwCeBTYgo7C2iQiXxWRa4zdbgI+LCLrgd8A71dKKXRUV7mIbEILozuVUhvGq2zxlB54Z6bjiBX4RJY2VeLzuKzBhWfMrWXFHG0nNytvJJHOTYI0yaNmzHTwMDU/PvscIqMlYBwNEeHSE6cXTV5ZKuVWUseRQ3zNHrjdsQ5aC5mI2e4mI6YQKS/IMWaPdJyKnaHJyoS+CaXUQ2iHuX3dLbbfm4HXFzkujA7znRDMkEkz8iqSyM8r1VDh54WbL7Iicr71tpOtY80Ry5FE2oqameyaiD1T8VQ0AwTGwZw1Hoylifi9Liu5p98aJ6L3nQr+EBN/EX8Q5KdImYqdocnK0XasHxV6DKedqYlEk2mG4qk8f0FtyFe051eY1RU47FQYrxVlU16I2DSRwzRnjQdNVWV4XJI3OZMde0hoThPRdXK0QZLHG2aEVmFddbvEEqpTsR5PVqZOzbRhxqCbQmQgliKRzpakIpu9yUgibSVvPJIBaK8Fdk2k2KyGxztmL14kl+jwaHDpsmk8+f8uyEttb8detkLH+lRwqpsUi0wzMU1aFZN8sOFUYkoKETN80DRndQwOj0kfCVNg2OfcPpbMWZNd4E0EphDxe1xH1a/gcsmoE3/5i2hMpiYyFUarm5j3Wuy7ymVanjrPY7IzuVu/CcL0iTRVBfC4hA4zhXgJvXS/x43P7SKcyOB2mSNTJ7csLvPlerNH4hg+VjEd65N9BLG9HpmCr2IK+kQsc1aRTl1VmXfK1uPJypQUIru7wlQGPAR9boI+tyVESk0JEvK7iSTSuF1C0Df5o2bKvCN/lFMB00k92f0KPs9wTcQ06Uwtc5ZRX4v4GquDvilbjycrU+5tKKV4ansX5y6q13M8+D2HZM4C3RiHE2k8RfIsTUaCo8xjMRXImbMmd0Oc51g3BJ7pw5pKQsSKzipSX9979pwjGqvjMP5MuVZlS9sQHYMJLjihEdANrJmVt1Snc8inhYjXLXn+hsmKaWOeqrH1pgYy2TURv2e4Y73cMmdN7rKPJ5YmUqS+njG3dkKTlTocOlOuVXlyeycA5y/WubaCPg8JYxrcUrWKioCHcDyNz+M6pjSRqWoGMG3sk10T8eX5RPRvt0vPiDiVHOsjhfg6TE6m3Ft6clsXy5oqrey6dk2idJ+Ih95IklTGNekjsyA3Yn2qfpSBY8QnYhdy9nDff75wIafNqj4aRToqBEYxZzlMPib3VzXODMZTrNnXxwWLcxl/7UKg1OSEIb/WRCLJzLAZDScjZi92sk/kM1H4j7HorMJQ5I9fuJBzFk4dP4Dp/zkWOmgOU0wT2dkZJpNVrJiby/ZqaiJ+jyvPnDAaFUb238gXGP4AAB55SURBVHRWHdH8Eq8VPo8Lj0scx/okD8X22YTIVMYKb3aEyDHBlHpLUSNhol3jOJzIpZDfQySRJpNVBI+Riv6FK5Zw1rzJkZr+tSbnWJ/cAt8UHpO9nBONY846tphSbymS1CPM7X4Q0xx1KPNslPs9RJIZUll1zPgZPnTesDm9pgzHiiZijmc53EzDxwvmc5jsOekcNFOqtkYtIZKrnGb6hEPRREzBkUxnj4kQ36mO2bMdbWrcyYDpTJ/svpuJ5vTZ1Zw9v445dSOniHGYPEwpUW8lTCyiiRyKRmFXs48VTWQq4/ccK5qI4xMBWNhYwW8+svJoF8OhRKZUbTV9InY/xuH6RHLHO0JkshM4RsxEjk/E4Vhkcn9V44ypidhTSIQOwydijxpxsolOfizH+iQ3Ex0rGpODg50pVVujyTQBrwu3KxeDHzwMn4hdE3Gcf5OfoM/DyTOrWDaj8mgXZVT8ToivwzHIlGoBI8n0MPNT8DDyStm1D2dA1OTH7RL+9Ilzj3YxxuRYGRTp4GBnSnV5osnMsGiqwwnxtc+q5pizHMYLU3hM9vQsDg52xqytInLYraSIXC4i20Rkp4h8ocj22SLyhIisE5ENInKlbdvJIrJKRDaJyKsiEjjccphEE5lh5qecT8TRRByOLj5HE3E4Bimly7NDRL4jIssO5cSG8LkNuAJYBlxX5BxfAu5VSp0GvAv4oXGsB/gl8FGl1InABUDqUK5fjEgyPSwbalN1AL/HxYLG8pLPYw/xdXwiDuOFJUQcTcThGKKU2noKsB24XUReEJGPiEgpHsozgZ1Kqd1KqSRwD/Dmgn0UYJ6rCmg1fl8KbFBKrQdQSvUopTIlXHNUYsnMMPNTfbmfzV+9/JDmKPB73Hjd2jnvmLMcxgu3S/C5XU6Ir8MxxZhCRCk1pJT6mVLqHODzwL8DbSLyCxFZOMqhzcAB2/JBY52dLwPXi8hB4CHgk8b6EwAlIo+KyFoR+VyxCxgCbbWIrO7q6hrrVkbMumuP1ioVc5ChM07EYTz5zjtO5rozZx/tYjg4lExJPhERuUZE/gDcCnwPmA88iG74j4TrgJ8rpWYCVwJ3i4gLHTV2LvCPxv+3iMhFhQcrpX6qlFqhlFrR0NBQuHkYsWR63NKUhPweyrzuwxJADg4j8eZTm5lXHzraxXBwKJlSutE7gCeA7yilnretv09E3jDKcS3ALNvyTGOdnQ8ClwMopVYZzvN6tNbytFKqG0BEHgJOBx4vobwjMp7zf5T7PcRTR2xhc3BwcDimKcUncrJS6oMFAgQApdSNoxz3MrBIROaJiA/tOP9TwT77gYsARGQpEAC6gEeBk0QkaDjZzwc2l1DWUYkm0nl5s46Ecr/HicxycHCY8pQiRG4TEWtuThGpEZE7xjpIKZUGPoEWCFvQUVibROSrInKNsdtNwIdFZD3wG+D9StMH/BdaEL0CrFVK/eWQ7mx4eYimho8TOVyqgz6qy6bmTIEODg4OJqV0pU9WSvWbC0qpPhE5rZSTK6UeosBvopS6xfZ7M/D6EY79JTrMd1yIp7IoxbhNIvWlq5YSTzvmLAcHh6lNKS2qS0RqDO0AEakt8bhJRbEJqY6EuY7z08HBwaEkYfA9YJWI/A4Q4O3ANya0VBNAzMjg64TkOjg4OIwfY7aoSqm7RGQNcKGx6q2GGeqYwtRExsux7uDg4OBQolnKcIh3oaOnEJHZSqn9E1qycSZiTEhVmPbEwcHBweHwKWWw4TUisgPYAzwF7AUenuByjTumOcsJy3VwcHAYP0oJ8f0asBLYrpSahx7X8cKElmoCGG/HuoODg4NDaUIkpZTqQUdpuZRSTwArJrhc447jWHdwcHAYf0ppUftFpBx4GviViHQCkYkt1vjjONYdHBwcxp9SNJE3A1Hg08AjwC7g6oks1EQQdRzrDg4ODuPOqJqIMbHUn5VSFwJZ4BevSakmgKhjznJwcHAYd0bVRIyJoLIiUvUalWdc+Ozv1vOXDW1566LJNAGvy0nd7uDg4DCOlNItDwOvisjfsPlCxsjge9RQSvGHdS1kleKqk5us9ZFk2tFCHBwcHMaZUlrV3xt/xwSRZIZMVtE1lMhbH02OXwZfBwcHBwdNKWlPjik/SH80CTBciCQyhBxNxMHBwWFcGbNVFZE9gCpcr5SaPyElOkL6oykAusP5QiSSTDuRWQ4ODg7jTCldc/vAwgDwDqB2Yopz5AzGtBDpiSRJZ7J43Dp2IJbMEPI7QsTBwcFhPBlznIhSqsf216KUuhW46jUo22HRbwgRpbQgMYkkM5R5HXOWg4ODw3hSijnrdNuiC62ZTNrW2DRngfaLTKsMABBLph1NxMHBwWGcKXVSKpM0OpvvOyemOEfOQCxfiJhEkhknxNfBwcFhnCklOuvCsfaZTPTHciYsuxCJJtJOiK+Dg4PDOFPKfCL/ISLVtuUaEfn6xBbr8BmIpqgMaNnYORQH9ADEaCrjJF90cHBwGGdKScB4hVKq31xQSvUBV5ZychG5XES2ichOEflCke2zReQJEVknIhtE5Moi28Mi8tlSrgfanDWtMkBlwGNpIvFUFqUg6ExI5eDg4DCulCJE3CLiNxdEpAzwj7K/uZ8buA24AlgGXCciywp2+xJwr1LqNOBdwA8Ltv8XhziLYn80RVWZl4YKP13GWBFnQioHBweHiaGUrvmvgMdF5E5j+Z8oLZvvmcBOpdRuABG5B51WfrNtHwVUGr+rgFZzg4hci3biH9LcJf2xFM3VATxusTQRZ0IqBwcHh4mhlHEi3wa+Diw1/r6mlPrPEs7dDBywLR801tn5MnC9iBwEHgI+CWBMgvV54CujXUBEPiIiq0VkdVdXF6AHG1aV+WisCNA55GgiDg4ODhNJKeNE5gFPKqUeMZbLRGSuUmrvOFz/OuDnSqnvicjZwN0ishwtXP5bKRUWGTl1u1Lqp8BPAVasWKFA586qKvMikovOys0l4ggRBwcHh/GkFPvO74BzbMsZY90ZYxzXAsyyLc801tn5IHA5gFJqlYgEgHrgLODtIvKfQDV6TpO4UuoHo10wlckSSWaoDnrxeVxEkxkiibQ1q2HIcaw7ODg4jCultKoepZQ1+EIplRQRXwnHvQwsMjSZFrTj/N0F++wHLgJ+LiJL0bm5upRS55k7iMiXgfBYAgRyAw2rg14rY2/XUMIyZ5V5HU3EwcHBYTwpJTqrS0SuMRdE5M1A91gHKaXSwCeAR4Et6CisTSLyVdv5bgI+LCLrgd8A71dKDcsYXCpmyhMzOgugK5ywHOuOJuLg4OAwvpTSqn6U/9/evQfLWdd3HH9/ztmT5AhJALmUEmJCiUqsaGgKeEEqSg2pJF46GuqMgoyoFYpWrbE6yFA7HbBqRVEnVhQUiNSKplPkIqJW5ZIEciEJgXARAuGqIUQC5Jzz7R/Pb5PnbPbsbja7zy47n9fMzj7Pb5/L7zzZPN/9Pb8bXCbpa4DIKsvf28jBI+JqsgrzfNo5ueW1wOvqHOPcRs4FO0sikwcH2OdFA1naM9t3lETc2dDMrLUaGfbkHuDY1GKKVNl9UNtz1oSn0pAn+7xoHJMmpCCybfuOOhHPJ2Jm1lqNPM4qKwHvlnQDcHub8rNH8o+zJg9mQWTLs9tzrbP8OMvMrJVq3lVT7/T5ZBXis4CJwNuAX7U/a7tvR8X64AAT0/hZW7YN8czzQ4wv9dHfN3ZzYTMz231jlkQkXQ7cBZwIfBWYBvwhIn4RESPFZG/3lEsikwYHKPX3sde4frY8m9WJuFLdzKz1at1ZZwJ/IGtZtS4ihiU13XKqCE9t287ECaUdJY5JgwNs2bad4Qh3NDQza4MxSyIR8WqyyacmAj+T9GtgYrdWqgNsfW6IibkSx6QJAzsq1h1EzMxar2bFekTcGRGfi4iXA2eTDby4VNJvC8ndbhoeCUr9O/+kSYOlrGJ9u2c1NDNrh4bvrBGxHFgu6ZPAcfW274ShkaCUqzyfPDjAw5uf5UXjwvOrm5m1we408QUgMl3ZOmt4ZGRUC6xJEwZSxfowgwMuiZiZtVpP3VmHhmN0EEkV66U+uSRiZtYGPRVEhkcqgsiEEk8/N8S4Up/rRMzM2qCR+UTGA+8k6yeyY/uIOK992WpOZZ3IpMEBIuDJPz7v1llmZm3QyM/znwBPAcuB59qbnT0zErs+zgKI8OCLZmbt0EgQmRIRc9qekxYYGg5KfbkmvmkQRoBBP84yM2u5Rlpn/VbSK9uekxbYpU5kcGfgcMW6mVnrNfLz/PXAqZLuI3ucJbKWvke2NWdNGBoZYfzA6B7rZa5YNzNrvUburCe1PRctMjwS9Gl0Z8MyV6ybmbVe3cdZEfE7YB/g5PTaJ6V1nV1aZ01wEDEza6e6QUTS2cBlwIHp9X1JZ7U7Y82orBOZOKFEuWDioeDNzFqvkTvr6cAxEfFHAEnnAzeRzTHSVbIBGHcGkb4+sff4Ek8/O8TggEsiZmat1kjrLAHDufXhlFZ/R2mOpPWSNkhaWOXzqZJulHS7pFWS5qb0EyUtl7Q6vZ/QyPmyksjoP6n8SMslETOz1mvkzvod4BZJV6X1twHfrreTpH7gIrKZETeSDSG/JCLW5jb7LHBlRHxD0kzgarKe8U8AJ0fEw5L+HLgWOKTeOSvrRCDrcPjQ5m2uEzEza4O6QSQiviTpF2RNfQFOi4jbGzj20cCGiLgXQNJisvna80EkgElpeTLwcDpn/vhrgEFJ4yOiZo/5ytZZkI2fBa5YNzNrhzGDiKRJEbFF0n7A/elV/my/iPh9nWMfAjyYW98IHFOxzbnAdamifi/gzVWO807gtmoBRNIZwBkAU6dO5U9GRqqWRMD9RMzM2qFWncjl6X05sCz3Kq+3winAdyNiCjAX+J6kHXmS9ArgfOCD1XaOiEURMTsiZh9wwAEMj0B//+ggMnlwgPGlvlGttszMrDXG/HkeEW9N79ObPPZDwKG59SkpLe90YE46z02SJgD7A49JmgJcBbw3Iu5p5ITDVUoiR03dl8ee7upxI83MXrAa6SdyQyNpVSwFZkiaLmkcsABYUrHNA8Cb0jGPACYAj0vaB/hfYGFE/KaBcwFZxXpliePvjpnKpe8/utFDmJnZbhgziEiakOpD9pe0r6T90msaDbSUiogh4EyyllXryFphrZF0nqR5abOPAx+QtBK4Ajg1IiLtdzhwjqQV6XVgvXMOV2mdZWZm7VOrtvmDwEeBPyWrBynfnbcAX2vk4BFxNVmz3XzaObnltcDrquz3eeDzjZwjb2gk6HMQMTMrTK06ka8AX5F0VkR0Xe/0akZcEjEzK1Qj/US+mjr8zSSrsyinX9rOjDVjqEqPdTMza59G5lj/HPBXZEHkarKh4X8NdF0QAVwSMTMrUCM/2/+WrAXVIxFxGvAqst7lXSUie3d/EDOz4jQSRLZFxAgwJGkS8Bij+390hSCLIi6JmJkVp5GxQJalfhvfImultZVsKPiukgoiLomYmRWokYr1v0+L35R0DTApIla1N1tN8OMsM7PC1RqA8ahan0XEbe3JUnPKJRE/zjIzK06tksgX0/sEYDawkqzD4ZFkAzC+pr1Z2z07K9bdxNfMrChj3nEj4o0R8UZgE3BUGi33L4BZ7DqQYhdwxbqZWdEa+dn+sohYXV6JiDuAI9qXpea4ia+ZWfEaaZ21StJ/At9P6+8Buq5i3a2zzMyK10gQOQ34MHB2Wv8V8I225WgPOYiYmRWnkSa+zwJfTq+uFeE6ETOzotVq4ntlRLxL0mp2Pi3aISKObGvOdpMfZ5mZFa9WSaT8+OqtRWRkj6UoUup3EDEzK0qt+UQ2pfffFZed5u0sibifiJlZUWo9znqaKo+xyDocRkRMaluumlCuE+mXSyJmZkWpVRKZWGRGWsV1ImZmxWmkiS8Akg5k9MyGD7QlR03aMXaW60TMzApTtwJB0jxJdwP3Ab8E7gd+2sjBJc2RtF7SBkkLq3w+VdKNkm6XtErS3Nxnn077rZf0lnrnco91M7PiNVIL/S/AscBdETGdbJbDm+vtJKkfuIhsOt2ZwCmSZlZs9lngyoiYBSwAvp72nZnWXwHMAb6ejleD+4mYmRWtkSCyPSKeBPok9UXEjWSj+tZzNLAhIu6NiOeBxcD8im0CKFfQTwYeTsvzgcUR8VxE3AdsSMcbk0siZmbFa6ROZLOkvcmGO7lM0mPAHxvY7xDgwdz6RuCYim3OBa6TdBawF/Dm3L750s7GlDYmdzY0MyteIyWR+cA24GPANcA9wMktOv8pwHcjYgowF/iepIY7ekg6Q9IyScu2bNkC+HGWmVmRavUTuQi4PCJ+k0u+ZDeO/RBwaG59CrvOQ3I6WZ0HEXGTpAnA/g3uS0QsAhYBHD7zVTGEOxuamRWp1h33LuDfJd0v6QJJs3bz2EuBGZKmSxpHVlG+pGKbB8gq6pF0BFkT4sfTdgskjZc0HZgB3FrrZOGKdTOzwtWa2fArEfEa4HjgSeBiSXdK+pykl9Y7cEQMAWcC1wLryFphrZF0nqR5abOPAx+QtBK4Ajg1MmuAK4G1ZI/QPhIRw7VPmL25TsTMrDgqDxfS0MZZaeRi4MiIqNPktliHHXFkjMz/N2795zdx4KQJ9XcwMzMkLY+IRlrcVtVIZ8OSpJMlXUbWyXA98I5mT9gu5VDY55KImVlhalWsn0jWemouWX3EYuCMiGikeW/hPCmVmVnxavUT+TRwOfDxiPhDQfnZY64TMTMrTq1RfE8oMiN7KiIbo77kJr5mZoXpmTuue6ybmRWvZ4LIjulxHUTMzArTM0Gk3NnQrbPMzIrTQ0HEpRAzs6L1TBAhXB9iZla0ngkiLomYmRWvd4JIhEsiZmYF65kgAlDq76k/x8ys6/XMXTeAPrkkYmZWpN4JIuE6ETOzovVMEAG3zjIzK1rPBJGIoNTvIGJmVqTeCSK4JGJmVrSeCSLgOhEzs6L1TBCJcOssM7Oi9U4QwXUiZmZF65kgko2d1Tt/jpnZC0Fb77qS5khaL2mDpIVVPv+ypBXpdZekzbnPLpC0RtI6SRdKtZ9VeewsM7Pi1ZpjfY9I6gcuAk4ENgJLJS2JiLXlbSLiY7ntzwJmpeXXAq8Djkwf/xo4HvjFWOcLj+JrZla4dpZEjgY2RMS9EfE8sBiYX2P7U4Ar0nIAE4BxwHhgAHi03gldEjEzK1Y7g8ghwIO59Y0pbReSXgJMB34OEBE3ATcCm9Lr2ohYV2W/MyQtk7Ts+e3bXRIxMytYt9RELwB+GBHDAJIOB44AppAFnhMkHVe5U0QsiojZETG7VCo5iJiZFaydQeQh4NDc+pSUVs0Cdj7KAng7cHNEbI2IrcBPgdfUOpkr1s3MitfOILIUmCFpuqRxZIFiSeVGkl4O7AvclEt+ADheUknSAFml+i6Ps0ZxxbqZWeHaFkQiYgg4E7iWLABcGRFrJJ0naV5u0wXA4oiIXNoPgXuA1cBKYGVE/E/N8xGU3E/EzKxQbWviCxARVwNXV6SdU7F+bpX9hoEP7u75XBIxMytWz/x0dz8RM7Pi9U4QwUHEzKxovRNEItw6y8ysYD0TRMAlETOzovVMEHE/ETOz4vVOEPFQ8GZmheupu25/T/01Zmbdr2duuxHhkoiZWcF65q7rOhEzs+L1TBABt84yMytaTwURl0TMzIrVU0Gkv99BxMysSL0VROQgYmZWpN4KIn6cZWZWqJ4KIq4TMTMrVk8FkX73NjQzK1RP3XVdEjEzK1ZPBRHXiZiZFau3gohbZ5mZFaqngkjJ/UTMzArV1iAiaY6k9ZI2SFpY5fMvS1qRXndJ2pz7bKqk6yStk7RW0rR65/PjLDOzYpXadWBJ/cBFwInARmCppCURsba8TUR8LLf9WcCs3CEuBf41Iq6XtDcwUu+crlg3MytWO0siRwMbIuLeiHgeWAzMr7H9KcAVAJJmAqWIuB4gIrZGxDP1Tuih4M3MitXOu+4hwIO59Y0pbReSXgJMB36ekl4KbJb0I0m3S/pCKtlU7neGpGWSloFLImZmReuWn+4LgB9GxHBaLwHHAZ8A/hI4DDi1cqeIWBQRsyNiNkCfg4iZWaHaGUQeAg7NrU9JadUsID3KSjYCK9KjsCHgx8BR9U7okoiZWbHaGUSWAjMkTZc0jixQLKncSNLLgX2Bmyr23UfSAWn9BGBt5b6V3DrLzKxYbQsiqQRxJnAtsA64MiLWSDpP0rzcpguAxRERuX2HyR5l3SBpNSDgW/XO6ZKImVmxlLt3v6CNP3hG3HzLrcyaum+ns2Jm9oIhaXm5XrkZ3VKx3hJ+nGVmVqyeKYlIehz4XafzUcf+wBOdzkQDnM/Wcj5by/lsrZdFxMRmd25bj/WiRcQB9bfqLEnL9qTYWBTns7Wcz9ZyPlur3M+uWT31OMvMzIrlIGJmZk1zECnWok5noEHOZ2s5n63lfLbWHuWzZyrWzcyseC6JmJlZ0xxEzMysaQ4ibSDpUEk3phkZ10g6O6WfK+mh3GyOc7sgr/dLWp3ysyyl7Sfpekl3p/eODgMg6WW5a7ZC0hZJH+2W6ynpYkmPSbojl1b1GipzYZrtc5WkugOLtjmfX5B0Z8rLVZL2SenTJG3LXdtvdjifY/5bS/p0up7rJb2lw/n8QS6P90takdI7eT3Huh+15jsaEX61+AUcDByVlicCdwEzgXOBT3Q6fxV5vR/YvyLtAmBhWl4InN/pfOby1g88ArykW64n8AayUabvqHcNgbnAT8nGgzsWuKXD+fxrsgngAM7P5XNafrsuuJ5V/63T/6uVwHiyOYnuAfo7lc+Kz78InNMF13Os+1FLvqMuibRBRGyKiNvS8tNkA1BWnZCrS80HLknLlwBv62BeKr0JuCciumZ0goj4FfD7iuSxruF84NLI3Ew2WvXBncpnRFwX2WCpADeTTdnQUWNcz7HMJxvA9bmIuA/YQDaratvVyqckAe9i9BQXHVHjftSS76iDSJtJmkY2d/wtKenMVES8uNOPiZIArpO0XNIZKe2giNiUlh8BDupM1qqqnHum265n2VjXsOEZPzvg/WS/QMumK5tZ9JeSjutUpnKq/Vt36/U8Dng0Iu7OpXX8elbcj1ryHXUQaSNJewP/DXw0IrYA3wD+DHg1sImsuNtpr4+Io4CTgI9IekP+w8jKt13RDlzZvDTzgP9KSd14PXfRTddwLJI+AwwBl6WkTcDUiJgF/CNwuaRJncofL5B/65xTGP1jp+PXs8r9aIc9+Y46iLSJpAGyf7DLIuJHABHxaEQMR8QI2fwohRS7a4mIh9L7Y8BVZHl6tFx8Te+PdS6Ho5wE3BYRj0J3Xs+csa7h7sz4WQhJpwJvBd6Tbiakx0NPpuXlZHUNL+1UHmv8W3fj9SwB7wB+UE7r9PWsdj+iRd9RB5E2SM9Dvw2si4gv5dLzzxXfDtxRuW+RJO0laWJ5mayS9Q6yGSjflzZ7H/CTzuRwF6N+3XXb9aww1jVcArw3tYA5Fngq90ihcJLmAP8EzIuIZ3LpB0jqT8uHATOAezuTy5r/1kuABZLGS5pOls9bi85fhTcDd0bExnJCJ6/nWPcjWvUd7URrgV5/Aa8nKxquAlak11zge8DqlL4EOLjD+TyMrGXLSmAN8JmU/mLgBuBu4GfAfl1wTfcCngQm59K64nqSBbZNwHay58enj3UNyVq8XET2S3Q1MLvD+dxA9vy7/D39Ztr2nek7sQK4DTi5w/kc898a+Ey6nuuBkzqZz5T+XeBDFdt28nqOdT9qyXfUw56YmVnT/DjLzMya5iBiZmZNcxAxM7OmOYiYmVnTHETMzKxpDiJmdUga1uhRhBe28NjT8qPAmr3QlDqdAbMXgG0R8epOZ8KsG7kkYtakNF/EBcrmY7lV0uEpfZqkn6fBAm+QNDWlH6Rszo6V6fXadKh+Sd9Kcz1cJ2kwbf8PaQ6IVZIWd+jPNKvJQcSsvsGKx1nvzn32VES8Evga8B8p7avAJRFxJNmAhhem9AuBX0bEq8jmoViT0mcAF0XEK4DNZL2bIZvjYVY6zofa9ceZ7Qn3WDerQ9LWiNi7Svr9wAkRcW8a4O6RiHixpCfIhuXYntI3RcT+kh4HpkTEc7ljTAOuj4gZaf1TwEBEfF7SNcBW4MfAjyNia5v/VLPd5pKI2Z6JMZZ3x3O55WF21lX+DdkYRkcBS9PosGZdxUHEbM+8O/d+U1r+LdnkWQDvAf4vLd8AfBhAUr+kyWMdVFIfcGhE3Ah8CpgM7FIaMus0/7Ixq29Q0orc+jURUW7mu6+kVWSliVNS2lnAdyR9EngcOC2lnw0sknQ6WYnjw2SjwFbTD3w/BRoBF0bE5pb9RWYt4joRsyalOpHZEfFEp/Ni1il+nGVmZk1zScTMzJrmkoiZmTXNQcTMzJrmIGJmZk1zEDEzs6Y5iJiZWdP+H/zW/8cnnLv8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Accuracy over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, val_accuracy)\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Accuracy over Range of Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss over Range of Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch where the model's performance degrades based on validation Set:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENT DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.9893 - acc: 0.6311 - val_loss: 0.5642 - val_acc: 0.7907\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.5915 - acc: 0.7857 - val_loss: 0.4893 - val_acc: 0.8274\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.5179 - acc: 0.8128 - val_loss: 0.4457 - val_acc: 0.8308\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.4775 - acc: 0.8303 - val_loss: 0.4329 - val_acc: 0.8438\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.4499 - acc: 0.8392 - val_loss: 0.4124 - val_acc: 0.8519\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.4293 - acc: 0.8475 - val_loss: 0.4197 - val_acc: 0.8428\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.4136 - acc: 0.8514 - val_loss: 0.3798 - val_acc: 0.8629\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.4016 - acc: 0.8581 - val_loss: 0.3710 - val_acc: 0.8619\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3939 - acc: 0.8601 - val_loss: 0.3906 - val_acc: 0.8541\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3816 - acc: 0.8645 - val_loss: 0.3681 - val_acc: 0.8685\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3765 - acc: 0.8682 - val_loss: 0.3523 - val_acc: 0.8717\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3641 - acc: 0.8704 - val_loss: 0.3507 - val_acc: 0.8661\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3633 - acc: 0.8722 - val_loss: 0.4051 - val_acc: 0.8546\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3556 - acc: 0.8750 - val_loss: 0.3855 - val_acc: 0.8387\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3554 - acc: 0.8735 - val_loss: 0.3308 - val_acc: 0.8772\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3486 - acc: 0.8761 - val_loss: 0.3451 - val_acc: 0.8754\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3445 - acc: 0.8785 - val_loss: 0.3531 - val_acc: 0.8679\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3460 - acc: 0.8782 - val_loss: 0.3588 - val_acc: 0.8692\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3343 - acc: 0.8809 - val_loss: 0.3334 - val_acc: 0.8807\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3376 - acc: 0.8804 - val_loss: 0.3433 - val_acc: 0.8799\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3298 - acc: 0.8824 - val_loss: 0.3335 - val_acc: 0.8828\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3306 - acc: 0.8852 - val_loss: 0.3344 - val_acc: 0.8839\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3275 - acc: 0.8842 - val_loss: 0.3302 - val_acc: 0.8795\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3221 - acc: 0.8853 - val_loss: 0.3265 - val_acc: 0.8812\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3237 - acc: 0.8867 - val_loss: 0.3483 - val_acc: 0.8738\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3245 - acc: 0.8862 - val_loss: 0.3269 - val_acc: 0.8845\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3151 - acc: 0.8890 - val_loss: 0.3303 - val_acc: 0.8800\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3184 - acc: 0.8878 - val_loss: 0.3350 - val_acc: 0.8813\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3127 - acc: 0.8907 - val_loss: 0.3595 - val_acc: 0.8685\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3143 - acc: 0.8907 - val_loss: 0.3412 - val_acc: 0.8865\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3127 - acc: 0.8914 - val_loss: 0.3323 - val_acc: 0.8826\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3112 - acc: 0.8906 - val_loss: 0.3488 - val_acc: 0.8845\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3093 - acc: 0.8926 - val_loss: 0.3712 - val_acc: 0.8673\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3144 - acc: 0.8922 - val_loss: 0.3484 - val_acc: 0.8798\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3054 - acc: 0.8930 - val_loss: 0.3359 - val_acc: 0.8850\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3073 - acc: 0.8943 - val_loss: 0.3521 - val_acc: 0.8711\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3066 - acc: 0.8932 - val_loss: 0.3321 - val_acc: 0.8857\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3034 - acc: 0.8937 - val_loss: 0.3453 - val_acc: 0.8833\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3067 - acc: 0.8950 - val_loss: 0.3683 - val_acc: 0.8662\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3011 - acc: 0.8965 - val_loss: 0.3418 - val_acc: 0.8850\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2987 - acc: 0.8965 - val_loss: 0.3442 - val_acc: 0.8815\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2973 - acc: 0.8979 - val_loss: 0.3400 - val_acc: 0.8868\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2974 - acc: 0.8990 - val_loss: 0.3510 - val_acc: 0.8743\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2967 - acc: 0.8987 - val_loss: 0.3474 - val_acc: 0.8850\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2936 - acc: 0.8982 - val_loss: 0.3223 - val_acc: 0.8921\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2982 - acc: 0.8970 - val_loss: 0.3378 - val_acc: 0.8825\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2989 - acc: 0.8974 - val_loss: 0.3226 - val_acc: 0.8915\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2919 - acc: 0.8989 - val_loss: 0.3479 - val_acc: 0.8815\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2933 - acc: 0.9001 - val_loss: 0.3436 - val_acc: 0.8895\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2929 - acc: 0.9003 - val_loss: 0.3396 - val_acc: 0.8889\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2936 - acc: 0.9006 - val_loss: 0.3469 - val_acc: 0.8838\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2933 - acc: 0.9015 - val_loss: 0.3333 - val_acc: 0.8900\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2981 - acc: 0.9003 - val_loss: 0.3420 - val_acc: 0.8915\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2909 - acc: 0.9005 - val_loss: 0.3563 - val_acc: 0.8850\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2925 - acc: 0.9003 - val_loss: 0.3453 - val_acc: 0.8860\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2929 - acc: 0.9011 - val_loss: 0.3293 - val_acc: 0.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2907 - acc: 0.9012 - val_loss: 0.3316 - val_acc: 0.8909\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2931 - acc: 0.9028 - val_loss: 0.3307 - val_acc: 0.8889\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2890 - acc: 0.9032 - val_loss: 0.3344 - val_acc: 0.8893\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2927 - acc: 0.9016 - val_loss: 0.3460 - val_acc: 0.8782\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2900 - acc: 0.9030 - val_loss: 0.3415 - val_acc: 0.8869\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2886 - acc: 0.9036 - val_loss: 0.3448 - val_acc: 0.8840\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2876 - acc: 0.9055 - val_loss: 0.3428 - val_acc: 0.8920\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2871 - acc: 0.9041 - val_loss: 0.3395 - val_acc: 0.8861\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2910 - acc: 0.9036 - val_loss: 0.3417 - val_acc: 0.8904\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2898 - acc: 0.9051 - val_loss: 0.3368 - val_acc: 0.8874\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2830 - acc: 0.9060 - val_loss: 0.3399 - val_acc: 0.8902\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2889 - acc: 0.9039 - val_loss: 0.3324 - val_acc: 0.8914\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2884 - acc: 0.9050 - val_loss: 0.3350 - val_acc: 0.8918\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2890 - acc: 0.9027 - val_loss: 0.3348 - val_acc: 0.8930\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2908 - acc: 0.9055 - val_loss: 0.3491 - val_acc: 0.8866\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2920 - acc: 0.9047 - val_loss: 0.3329 - val_acc: 0.8925\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2834 - acc: 0.9078 - val_loss: 0.3545 - val_acc: 0.8852\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2858 - acc: 0.9068 - val_loss: 0.3484 - val_acc: 0.8876\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2872 - acc: 0.9066 - val_loss: 0.3718 - val_acc: 0.8864\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2907 - acc: 0.9064 - val_loss: 0.3500 - val_acc: 0.8894\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2948 - acc: 0.9052 - val_loss: 0.3534 - val_acc: 0.8898\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2904 - acc: 0.9068 - val_loss: 0.3355 - val_acc: 0.8900\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2861 - acc: 0.9065 - val_loss: 0.3549 - val_acc: 0.8907\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2939 - acc: 0.9067 - val_loss: 0.3476 - val_acc: 0.8933\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2889 - acc: 0.9085 - val_loss: 0.3503 - val_acc: 0.8900\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2904 - acc: 0.9070 - val_loss: 0.3435 - val_acc: 0.8931\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2867 - acc: 0.9075 - val_loss: 0.3448 - val_acc: 0.8904\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2863 - acc: 0.9082 - val_loss: 0.4378 - val_acc: 0.8589\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2971 - acc: 0.9082 - val_loss: 0.3561 - val_acc: 0.8826\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2883 - acc: 0.9070 - val_loss: 0.3344 - val_acc: 0.8955\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2948 - acc: 0.9058 - val_loss: 0.3465 - val_acc: 0.8928\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2860 - acc: 0.9081 - val_loss: 0.3564 - val_acc: 0.8887\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2817 - acc: 0.9088 - val_loss: 0.3523 - val_acc: 0.8880\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2835 - acc: 0.9092 - val_loss: 0.3561 - val_acc: 0.8929\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2939 - acc: 0.9076 - val_loss: 0.3496 - val_acc: 0.8911\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2851 - acc: 0.9082 - val_loss: 0.3722 - val_acc: 0.8885\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2942 - acc: 0.9082 - val_loss: 0.3571 - val_acc: 0.8940\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2926 - acc: 0.9070 - val_loss: 0.3481 - val_acc: 0.8920\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2912 - acc: 0.9079 - val_loss: 0.3513 - val_acc: 0.8913\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2877 - acc: 0.9093 - val_loss: 0.3560 - val_acc: 0.8922\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2856 - acc: 0.9093 - val_loss: 0.3523 - val_acc: 0.8956\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2922 - acc: 0.9095 - val_loss: 0.3633 - val_acc: 0.8888\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2924 - acc: 0.9099 - val_loss: 0.3606 - val_acc: 0.8943\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2935 - acc: 0.9086 - val_loss: 0.3605 - val_acc: 0.8919\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2883 - acc: 0.9113 - val_loss: 0.3612 - val_acc: 0.8913\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2869 - acc: 0.9101 - val_loss: 0.3673 - val_acc: 0.8924\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2795 - acc: 0.9121 - val_loss: 0.3581 - val_acc: 0.8883\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2862 - acc: 0.9108 - val_loss: 0.3685 - val_acc: 0.8901\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2862 - acc: 0.9101 - val_loss: 0.3590 - val_acc: 0.8917\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2864 - acc: 0.9125 - val_loss: 0.3789 - val_acc: 0.8882\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2875 - acc: 0.9107 - val_loss: 0.3465 - val_acc: 0.8922\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.2891 - acc: 0.9100 - val_loss: 0.3864 - val_acc: 0.8865\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2919 - acc: 0.9096 - val_loss: 0.3656 - val_acc: 0.8901\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.2931 - acc: 0.9118 - val_loss: 0.3683 - val_acc: 0.8933\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2939 - acc: 0.9124 - val_loss: 0.3688 - val_acc: 0.8928\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2987 - acc: 0.9113 - val_loss: 0.3686 - val_acc: 0.8954\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2932 - acc: 0.9118 - val_loss: 0.3547 - val_acc: 0.8926\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2815 - acc: 0.9130 - val_loss: 0.3901 - val_acc: 0.8811\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2991 - acc: 0.9115 - val_loss: 0.3863 - val_acc: 0.8924\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2912 - acc: 0.9129 - val_loss: 0.3629 - val_acc: 0.8903\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2947 - acc: 0.9110 - val_loss: 0.3678 - val_acc: 0.8938\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2894 - acc: 0.9132 - val_loss: 0.3795 - val_acc: 0.8873\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2930 - acc: 0.9119 - val_loss: 0.3781 - val_acc: 0.8887\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2903 - acc: 0.9128 - val_loss: 0.3739 - val_acc: 0.8916\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2967 - acc: 0.9119 - val_loss: 0.3693 - val_acc: 0.8960\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2894 - acc: 0.9118 - val_loss: 0.3711 - val_acc: 0.8936\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2989 - acc: 0.9122 - val_loss: 0.3731 - val_acc: 0.8935\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2957 - acc: 0.9126 - val_loss: 0.3735 - val_acc: 0.8952\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3017 - acc: 0.9116 - val_loss: 0.3772 - val_acc: 0.8915\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2998 - acc: 0.9124 - val_loss: 0.3810 - val_acc: 0.8903\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2998 - acc: 0.9131 - val_loss: 0.3762 - val_acc: 0.8930\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3004 - acc: 0.9135 - val_loss: 0.3691 - val_acc: 0.8922\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3011 - acc: 0.9102 - val_loss: 0.3798 - val_acc: 0.8842\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3053 - acc: 0.9108 - val_loss: 0.3792 - val_acc: 0.8907\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2991 - acc: 0.9129 - val_loss: 0.3712 - val_acc: 0.8902\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3072 - acc: 0.9104 - val_loss: 0.3849 - val_acc: 0.8907\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3016 - acc: 0.9119 - val_loss: 0.3916 - val_acc: 0.8903\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3025 - acc: 0.9129 - val_loss: 0.3794 - val_acc: 0.8913\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3066 - acc: 0.9121 - val_loss: 0.4032 - val_acc: 0.8937\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2987 - acc: 0.9128 - val_loss: 0.4249 - val_acc: 0.8810\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3155 - acc: 0.9107 - val_loss: 0.3946 - val_acc: 0.8863\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3188 - acc: 0.9105 - val_loss: 0.3911 - val_acc: 0.8871\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3173 - acc: 0.9116 - val_loss: 0.3939 - val_acc: 0.8879\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3050 - acc: 0.9123 - val_loss: 0.3981 - val_acc: 0.8898\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3147 - acc: 0.9122 - val_loss: 0.3913 - val_acc: 0.8909\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3163 - acc: 0.9125 - val_loss: 0.4099 - val_acc: 0.8815\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3103 - acc: 0.9127 - val_loss: 0.3848 - val_acc: 0.8915\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3117 - acc: 0.9135 - val_loss: 0.3909 - val_acc: 0.8926\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3076 - acc: 0.9110 - val_loss: 0.4152 - val_acc: 0.8864\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3072 - acc: 0.9131 - val_loss: 0.4043 - val_acc: 0.8911\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3142 - acc: 0.9129 - val_loss: 0.3901 - val_acc: 0.8912\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3082 - acc: 0.9128 - val_loss: 0.4030 - val_acc: 0.8873\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3145 - acc: 0.9127 - val_loss: 0.3857 - val_acc: 0.8929\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3095 - acc: 0.9131 - val_loss: 0.3983 - val_acc: 0.8879\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3199 - acc: 0.9140 - val_loss: 0.4065 - val_acc: 0.8949\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3153 - acc: 0.9123 - val_loss: 0.4050 - val_acc: 0.8924\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3129 - acc: 0.9131 - val_loss: 0.3859 - val_acc: 0.8920\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3112 - acc: 0.9153 - val_loss: 0.4278 - val_acc: 0.8914\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3320 - acc: 0.9106 - val_loss: 0.4184 - val_acc: 0.8881\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3233 - acc: 0.9120 - val_loss: 0.4248 - val_acc: 0.8893\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3249 - acc: 0.9136 - val_loss: 0.4059 - val_acc: 0.8910\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3205 - acc: 0.9130 - val_loss: 0.4110 - val_acc: 0.8825\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3204 - acc: 0.9134 - val_loss: 0.4081 - val_acc: 0.8953\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3165 - acc: 0.9135 - val_loss: 0.3972 - val_acc: 0.8923\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3209 - acc: 0.9137 - val_loss: 0.4130 - val_acc: 0.8910\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3292 - acc: 0.9128 - val_loss: 0.4156 - val_acc: 0.8876\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3241 - acc: 0.9131 - val_loss: 0.4088 - val_acc: 0.8940\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3247 - acc: 0.9127 - val_loss: 0.4182 - val_acc: 0.8853\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3426 - acc: 0.9095 - val_loss: 0.4186 - val_acc: 0.8879\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3427 - acc: 0.9122 - val_loss: 0.4301 - val_acc: 0.8904\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3372 - acc: 0.9135 - val_loss: 0.4179 - val_acc: 0.8873\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3347 - acc: 0.9130 - val_loss: 0.4405 - val_acc: 0.8896\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3467 - acc: 0.9110 - val_loss: 0.4193 - val_acc: 0.8906\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3423 - acc: 0.9125 - val_loss: 0.4417 - val_acc: 0.8920\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3479 - acc: 0.9136 - val_loss: 0.4021 - val_acc: 0.8939\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3378 - acc: 0.9122 - val_loss: 0.4144 - val_acc: 0.8936\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3383 - acc: 0.9146 - val_loss: 0.4235 - val_acc: 0.8904\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3319 - acc: 0.9129 - val_loss: 0.4072 - val_acc: 0.8917\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3164 - acc: 0.9150 - val_loss: 0.4102 - val_acc: 0.8945\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3401 - acc: 0.9133 - val_loss: 0.3994 - val_acc: 0.8923\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3273 - acc: 0.9137 - val_loss: 0.4105 - val_acc: 0.8873\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3278 - acc: 0.9140 - val_loss: 0.4329 - val_acc: 0.8920\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3499 - acc: 0.9122 - val_loss: 0.4147 - val_acc: 0.8960\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3468 - acc: 0.9127 - val_loss: 0.4282 - val_acc: 0.8901\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3524 - acc: 0.9109 - val_loss: 0.4132 - val_acc: 0.8898\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3290 - acc: 0.9123 - val_loss: 0.4326 - val_acc: 0.8908\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3527 - acc: 0.9131 - val_loss: 0.4326 - val_acc: 0.8930\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3339 - acc: 0.9137 - val_loss: 0.4352 - val_acc: 0.8883\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3346 - acc: 0.9141 - val_loss: 0.4219 - val_acc: 0.8931\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3448 - acc: 0.9155 - val_loss: 0.4289 - val_acc: 0.8883\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3454 - acc: 0.9108 - val_loss: 0.4298 - val_acc: 0.8881\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3382 - acc: 0.9132 - val_loss: 0.4346 - val_acc: 0.8936\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3472 - acc: 0.9125 - val_loss: 0.4294 - val_acc: 0.8919\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3354 - acc: 0.9156 - val_loss: 0.4367 - val_acc: 0.8920\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3601 - acc: 0.9114 - val_loss: 0.4480 - val_acc: 0.8917\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3549 - acc: 0.9105 - val_loss: 0.4274 - val_acc: 0.8884\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3557 - acc: 0.9104 - val_loss: 0.4376 - val_acc: 0.8886\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3536 - acc: 0.9135 - val_loss: 0.4552 - val_acc: 0.8873\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3528 - acc: 0.9125 - val_loss: 0.4648 - val_acc: 0.8875\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3448 - acc: 0.9141 - val_loss: 0.4414 - val_acc: 0.8910\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3396 - acc: 0.9127 - val_loss: 0.4480 - val_acc: 0.8855\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3472 - acc: 0.9106 - val_loss: 0.4441 - val_acc: 0.8821\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3437 - acc: 0.9129 - val_loss: 0.4145 - val_acc: 0.8916\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3477 - acc: 0.9148 - val_loss: 0.4545 - val_acc: 0.8841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Model with Dropout\n",
    "model_w_dropout = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compile Model\n",
    "model_w_dropout.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_dropout = model_w_dropout.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))\n",
    "\n",
    "#Extract Accuracy and Loss from keras callback history\n",
    "dropout_metrics = track_dropout.history\n",
    "dropout_loss = dropout_metrics['val_loss']\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, dropout_loss, 'b', label = \"dropout\")\n",
    "plt.plot(epochs, val_loss, 'r', label = \"initial\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss over Range of Epochs with Dropout\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph it is evident that between the initial model and the dropout model, the dropout model performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEIGHT REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 14.7034 - acc: 0.5426 - val_loss: 4.1799 - val_acc: 0.6410\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 3.0833 - acc: 0.6513 - val_loss: 2.3541 - val_acc: 0.7074\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 2.1957 - acc: 0.6909 - val_loss: 2.0937 - val_acc: 0.7038\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.8989 - acc: 0.7275 - val_loss: 1.9951 - val_acc: 0.6339\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.7510 - acc: 0.7434 - val_loss: 1.7276 - val_acc: 0.7376\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6427 - acc: 0.7627 - val_loss: 1.6810 - val_acc: 0.7194\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5694 - acc: 0.7743 - val_loss: 1.5386 - val_acc: 0.7733\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5147 - acc: 0.7837 - val_loss: 1.5757 - val_acc: 0.7532\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4794 - acc: 0.7896 - val_loss: 1.4746 - val_acc: 0.7914\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4510 - acc: 0.7952 - val_loss: 1.4567 - val_acc: 0.7765\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4252 - acc: 0.8001 - val_loss: 1.4218 - val_acc: 0.7935\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.4051 - acc: 0.8040 - val_loss: 1.4159 - val_acc: 0.7922\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3881 - acc: 0.8063 - val_loss: 1.3755 - val_acc: 0.8105\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3713 - acc: 0.8096 - val_loss: 1.3850 - val_acc: 0.7957\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3548 - acc: 0.8110 - val_loss: 1.3739 - val_acc: 0.7963\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3461 - acc: 0.8146 - val_loss: 1.3445 - val_acc: 0.8098\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3390 - acc: 0.8152 - val_loss: 1.3217 - val_acc: 0.8210\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3326 - acc: 0.8159 - val_loss: 1.3370 - val_acc: 0.8128\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3256 - acc: 0.8154 - val_loss: 1.3936 - val_acc: 0.7859\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3186 - acc: 0.8207 - val_loss: 1.3465 - val_acc: 0.8076\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3134 - acc: 0.8188 - val_loss: 1.3116 - val_acc: 0.8231\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3068 - acc: 0.8208 - val_loss: 1.3066 - val_acc: 0.8187\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3027 - acc: 0.8214 - val_loss: 1.3144 - val_acc: 0.8134\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3001 - acc: 0.8213 - val_loss: 1.3165 - val_acc: 0.8173\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2925 - acc: 0.8252 - val_loss: 1.3576 - val_acc: 0.8027\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2901 - acc: 0.8235 - val_loss: 1.2887 - val_acc: 0.8211\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.2862 - acc: 0.8275 - val_loss: 1.3035 - val_acc: 0.8175\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2818 - acc: 0.8262 - val_loss: 1.2873 - val_acc: 0.8228\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2774 - acc: 0.8266 - val_loss: 1.2992 - val_acc: 0.8199\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2750 - acc: 0.8266 - val_loss: 1.2593 - val_acc: 0.8329\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2705 - acc: 0.8278 - val_loss: 1.4116 - val_acc: 0.7746\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2670 - acc: 0.8291 - val_loss: 1.4334 - val_acc: 0.7619\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2655 - acc: 0.8298 - val_loss: 1.2535 - val_acc: 0.8333\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2614 - acc: 0.8328 - val_loss: 1.2698 - val_acc: 0.8266\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2579 - acc: 0.8321 - val_loss: 1.2673 - val_acc: 0.8273\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2551 - acc: 0.8334 - val_loss: 1.4277 - val_acc: 0.7657\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2522 - acc: 0.8334 - val_loss: 1.2776 - val_acc: 0.8164\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2499 - acc: 0.8345 - val_loss: 1.3216 - val_acc: 0.8070\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2485 - acc: 0.8346 - val_loss: 1.3189 - val_acc: 0.7992\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2453 - acc: 0.8353 - val_loss: 1.3060 - val_acc: 0.8114\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2467 - acc: 0.8352 - val_loss: 1.3097 - val_acc: 0.8138\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2431 - acc: 0.8357 - val_loss: 1.2692 - val_acc: 0.8219\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2403 - acc: 0.8359 - val_loss: 1.2412 - val_acc: 0.8346\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2363 - acc: 0.8371 - val_loss: 1.2356 - val_acc: 0.8349\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2346 - acc: 0.8375 - val_loss: 1.2480 - val_acc: 0.8305\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.2368 - acc: 0.8362 - val_loss: 1.2822 - val_acc: 0.8151\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2291 - acc: 0.8387 - val_loss: 1.3073 - val_acc: 0.8155\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2321 - acc: 0.8364 - val_loss: 1.2727 - val_acc: 0.8183\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2292 - acc: 0.8385 - val_loss: 1.2663 - val_acc: 0.8257\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2269 - acc: 0.8383 - val_loss: 1.2324 - val_acc: 0.8320\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2264 - acc: 0.8367 - val_loss: 1.2618 - val_acc: 0.8236\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.2234 - acc: 0.8382 - val_loss: 1.2635 - val_acc: 0.8195\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2226 - acc: 0.8387 - val_loss: 1.2224 - val_acc: 0.8351\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2207 - acc: 0.8376 - val_loss: 1.2267 - val_acc: 0.8320\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2195 - acc: 0.8387 - val_loss: 1.2112 - val_acc: 0.8417\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2171 - acc: 0.8411 - val_loss: 1.2329 - val_acc: 0.8318\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2174 - acc: 0.8393 - val_loss: 1.2260 - val_acc: 0.8324\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2148 - acc: 0.8411 - val_loss: 1.2351 - val_acc: 0.8301\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2146 - acc: 0.8407 - val_loss: 1.2171 - val_acc: 0.8367\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2134 - acc: 0.8400 - val_loss: 1.2675 - val_acc: 0.8223\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2089 - acc: 0.8419 - val_loss: 1.2429 - val_acc: 0.8258\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2087 - acc: 0.8419 - val_loss: 1.2076 - val_acc: 0.8398\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2080 - acc: 0.8411 - val_loss: 1.2322 - val_acc: 0.8304\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2096 - acc: 0.8404 - val_loss: 1.2316 - val_acc: 0.8296\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2065 - acc: 0.8420 - val_loss: 1.2301 - val_acc: 0.8286\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2036 - acc: 0.8417 - val_loss: 1.2855 - val_acc: 0.8129\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.2044 - acc: 0.8413 - val_loss: 1.2176 - val_acc: 0.8342\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1989 - acc: 0.8429 - val_loss: 1.2203 - val_acc: 0.8301\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2016 - acc: 0.8422 - val_loss: 1.2590 - val_acc: 0.8212\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1980 - acc: 0.8426 - val_loss: 1.2775 - val_acc: 0.8079\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1990 - acc: 0.8405 - val_loss: 1.2025 - val_acc: 0.8385\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1964 - acc: 0.8431 - val_loss: 1.2384 - val_acc: 0.8268\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1954 - acc: 0.8448 - val_loss: 1.2191 - val_acc: 0.8317\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1953 - acc: 0.8417 - val_loss: 1.2670 - val_acc: 0.8065\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1970 - acc: 0.8432 - val_loss: 1.2367 - val_acc: 0.8281\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1909 - acc: 0.8450 - val_loss: 1.2250 - val_acc: 0.8317\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1934 - acc: 0.8434 - val_loss: 1.1984 - val_acc: 0.8370\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1914 - acc: 0.8445 - val_loss: 1.2155 - val_acc: 0.8311\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1890 - acc: 0.8460 - val_loss: 1.2157 - val_acc: 0.8303\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1934 - acc: 0.8441 - val_loss: 1.2541 - val_acc: 0.8169\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1879 - acc: 0.8450 - val_loss: 1.2711 - val_acc: 0.8148\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1864 - acc: 0.8455 - val_loss: 1.2112 - val_acc: 0.8302\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1886 - acc: 0.8455 - val_loss: 1.2313 - val_acc: 0.8247\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1847 - acc: 0.8458 - val_loss: 1.2868 - val_acc: 0.8007\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1842 - acc: 0.8463 - val_loss: 1.2760 - val_acc: 0.8120\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1820 - acc: 0.8468 - val_loss: 1.2418 - val_acc: 0.8174\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1837 - acc: 0.8463 - val_loss: 1.1908 - val_acc: 0.8397\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1834 - acc: 0.8456 - val_loss: 1.2086 - val_acc: 0.8331\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1828 - acc: 0.8459 - val_loss: 1.2677 - val_acc: 0.8199\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1784 - acc: 0.8475 - val_loss: 1.2332 - val_acc: 0.8240\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1830 - acc: 0.8447 - val_loss: 1.2096 - val_acc: 0.8338\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1768 - acc: 0.8469 - val_loss: 1.2293 - val_acc: 0.8245\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1782 - acc: 0.8464 - val_loss: 1.2203 - val_acc: 0.8298\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1784 - acc: 0.8464 - val_loss: 1.2290 - val_acc: 0.8247\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1770 - acc: 0.8462 - val_loss: 1.1801 - val_acc: 0.8415\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1777 - acc: 0.8479 - val_loss: 1.2145 - val_acc: 0.8281\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1758 - acc: 0.8469 - val_loss: 1.1791 - val_acc: 0.8440\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1727 - acc: 0.8490 - val_loss: 1.1938 - val_acc: 0.8353\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1753 - acc: 0.8477 - val_loss: 1.1961 - val_acc: 0.8368\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1765 - acc: 0.8459 - val_loss: 1.2127 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1719 - acc: 0.8476 - val_loss: 1.2028 - val_acc: 0.8316\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1735 - acc: 0.8472 - val_loss: 1.2050 - val_acc: 0.8319\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1716 - acc: 0.8475 - val_loss: 1.2048 - val_acc: 0.8329\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1684 - acc: 0.8501 - val_loss: 1.1814 - val_acc: 0.8410\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1704 - acc: 0.8494 - val_loss: 1.2123 - val_acc: 0.8320\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1706 - acc: 0.8477 - val_loss: 1.2014 - val_acc: 0.8345\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1703 - acc: 0.8479 - val_loss: 1.1859 - val_acc: 0.8365\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1681 - acc: 0.8482 - val_loss: 1.1805 - val_acc: 0.8414\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1712 - acc: 0.8471 - val_loss: 1.1895 - val_acc: 0.8378\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1679 - acc: 0.8470 - val_loss: 1.1809 - val_acc: 0.8428\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1650 - acc: 0.8487 - val_loss: 1.2522 - val_acc: 0.8157\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1702 - acc: 0.8483 - val_loss: 1.1958 - val_acc: 0.8338\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1697 - acc: 0.8467 - val_loss: 1.1840 - val_acc: 0.8363\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1643 - acc: 0.8491 - val_loss: 1.1987 - val_acc: 0.8343\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1636 - acc: 0.8501 - val_loss: 1.2242 - val_acc: 0.8256\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1650 - acc: 0.8493 - val_loss: 1.1948 - val_acc: 0.8361\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1644 - acc: 0.8499 - val_loss: 1.3175 - val_acc: 0.7949\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1650 - acc: 0.8483 - val_loss: 1.1697 - val_acc: 0.8447\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1644 - acc: 0.8483 - val_loss: 1.2481 - val_acc: 0.8197\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1632 - acc: 0.8485 - val_loss: 1.2047 - val_acc: 0.8254\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1620 - acc: 0.8483 - val_loss: 1.1666 - val_acc: 0.8463\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1634 - acc: 0.8481 - val_loss: 1.2169 - val_acc: 0.8291\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1593 - acc: 0.8503 - val_loss: 1.2370 - val_acc: 0.8212\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1644 - acc: 0.8494 - val_loss: 1.2096 - val_acc: 0.8252\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1602 - acc: 0.8490 - val_loss: 1.1744 - val_acc: 0.8385\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1572 - acc: 0.8500 - val_loss: 1.2386 - val_acc: 0.8097\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1618 - acc: 0.8486 - val_loss: 1.1729 - val_acc: 0.8436\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1601 - acc: 0.8484 - val_loss: 1.1618 - val_acc: 0.8474\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1590 - acc: 0.8491 - val_loss: 1.2396 - val_acc: 0.8205\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1568 - acc: 0.8496 - val_loss: 1.1804 - val_acc: 0.8384\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1585 - acc: 0.8489 - val_loss: 1.2213 - val_acc: 0.8252\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1586 - acc: 0.8489 - val_loss: 1.2937 - val_acc: 0.8047\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1564 - acc: 0.8504 - val_loss: 1.2111 - val_acc: 0.8274\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1616 - acc: 0.8482 - val_loss: 1.1699 - val_acc: 0.8437\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1531 - acc: 0.8501 - val_loss: 1.1843 - val_acc: 0.8380\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1549 - acc: 0.8499 - val_loss: 1.2088 - val_acc: 0.8240\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1582 - acc: 0.8486 - val_loss: 1.2256 - val_acc: 0.8263\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1558 - acc: 0.8500 - val_loss: 1.1673 - val_acc: 0.8419\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1519 - acc: 0.8498 - val_loss: 1.2164 - val_acc: 0.8271\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1545 - acc: 0.8501 - val_loss: 1.1642 - val_acc: 0.8430\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1543 - acc: 0.8514 - val_loss: 1.2059 - val_acc: 0.8315\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1528 - acc: 0.8505 - val_loss: 1.2507 - val_acc: 0.8171\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1535 - acc: 0.8507 - val_loss: 1.2156 - val_acc: 0.8237\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1495 - acc: 0.8525 - val_loss: 1.2034 - val_acc: 0.8284\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1556 - acc: 0.8488 - val_loss: 1.2523 - val_acc: 0.8173\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1490 - acc: 0.8505 - val_loss: 1.1929 - val_acc: 0.8323\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1509 - acc: 0.8513 - val_loss: 1.1794 - val_acc: 0.8392\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1523 - acc: 0.8508 - val_loss: 1.1648 - val_acc: 0.8407\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1474 - acc: 0.8507 - val_loss: 1.1795 - val_acc: 0.8362\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1507 - acc: 0.8495 - val_loss: 1.2105 - val_acc: 0.8282\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1478 - acc: 0.8507 - val_loss: 1.1668 - val_acc: 0.8398\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1458 - acc: 0.8526 - val_loss: 1.1927 - val_acc: 0.8300\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1511 - acc: 0.8497 - val_loss: 1.1751 - val_acc: 0.8438\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1474 - acc: 0.8516 - val_loss: 1.2419 - val_acc: 0.8125\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1476 - acc: 0.8510 - val_loss: 1.1752 - val_acc: 0.8382\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1478 - acc: 0.8499 - val_loss: 1.2458 - val_acc: 0.8149\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1435 - acc: 0.8538 - val_loss: 1.1700 - val_acc: 0.8416\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1501 - acc: 0.8515 - val_loss: 1.1630 - val_acc: 0.8419\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1470 - acc: 0.8510 - val_loss: 1.1694 - val_acc: 0.8435\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1457 - acc: 0.8518 - val_loss: 1.3066 - val_acc: 0.7858\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1485 - acc: 0.8483 - val_loss: 1.2084 - val_acc: 0.8312\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1479 - acc: 0.8499 - val_loss: 1.1729 - val_acc: 0.8376\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1440 - acc: 0.8526 - val_loss: 1.1769 - val_acc: 0.8373\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1461 - acc: 0.8520 - val_loss: 1.1601 - val_acc: 0.8438\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1448 - acc: 0.8521 - val_loss: 1.1682 - val_acc: 0.8439\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1442 - acc: 0.8531 - val_loss: 1.1613 - val_acc: 0.8449\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1430 - acc: 0.8501 - val_loss: 1.2297 - val_acc: 0.8186\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1457 - acc: 0.8512 - val_loss: 1.1558 - val_acc: 0.8450\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1461 - acc: 0.8515 - val_loss: 1.2224 - val_acc: 0.8245\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1419 - acc: 0.8529 - val_loss: 1.1499 - val_acc: 0.8477\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1408 - acc: 0.8513 - val_loss: 1.1718 - val_acc: 0.8409\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1448 - acc: 0.8504 - val_loss: 1.1833 - val_acc: 0.8304\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1414 - acc: 0.8529 - val_loss: 1.1590 - val_acc: 0.8441\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1438 - acc: 0.8517 - val_loss: 1.1952 - val_acc: 0.8309\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1459 - acc: 0.8505 - val_loss: 1.1745 - val_acc: 0.8372\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1424 - acc: 0.8527 - val_loss: 1.1915 - val_acc: 0.8326\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1403 - acc: 0.8528 - val_loss: 1.1869 - val_acc: 0.8324\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1413 - acc: 0.8518 - val_loss: 1.1645 - val_acc: 0.8380\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1408 - acc: 0.8533 - val_loss: 1.1707 - val_acc: 0.8422\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1409 - acc: 0.8528 - val_loss: 1.1942 - val_acc: 0.8308\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1406 - acc: 0.8533 - val_loss: 1.1683 - val_acc: 0.8415\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1385 - acc: 0.8528 - val_loss: 1.1846 - val_acc: 0.8350\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1401 - acc: 0.8513 - val_loss: 1.1870 - val_acc: 0.8321\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1428 - acc: 0.8495 - val_loss: 1.1490 - val_acc: 0.8457\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1394 - acc: 0.8523 - val_loss: 1.1875 - val_acc: 0.8361\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1380 - acc: 0.8534 - val_loss: 1.1866 - val_acc: 0.8309\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1368 - acc: 0.8536 - val_loss: 1.1592 - val_acc: 0.8427\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1416 - acc: 0.8502 - val_loss: 1.1589 - val_acc: 0.8396\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1382 - acc: 0.8529 - val_loss: 1.1879 - val_acc: 0.8342\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1368 - acc: 0.8525 - val_loss: 1.1433 - val_acc: 0.8483\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1367 - acc: 0.8539 - val_loss: 1.2094 - val_acc: 0.8225\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1386 - acc: 0.8512 - val_loss: 1.1581 - val_acc: 0.8434\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1375 - acc: 0.8521 - val_loss: 1.1610 - val_acc: 0.8386\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.1373 - acc: 0.8535 - val_loss: 1.2195 - val_acc: 0.8237\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.1337 - acc: 0.8536 - val_loss: 1.1976 - val_acc: 0.8290\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1375 - acc: 0.8513 - val_loss: 1.1654 - val_acc: 0.8361\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1389 - acc: 0.8525 - val_loss: 1.1985 - val_acc: 0.8256\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1361 - acc: 0.8525 - val_loss: 1.1953 - val_acc: 0.8290\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1374 - acc: 0.8522 - val_loss: 1.1702 - val_acc: 0.8385\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1354 - acc: 0.8533 - val_loss: 1.1708 - val_acc: 0.8370\n"
     ]
    }
   ],
   "source": [
    "# Model with L1 Regularization\n",
    "\n",
    "model_L1 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compile Model\n",
    "model_L1.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_L1 = model_L1.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 2.2128 - acc: 0.6749 - val_loss: 1.6268 - val_acc: 0.7226\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.2209 - acc: 0.7878 - val_loss: 1.0145 - val_acc: 0.7994\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.9159 - acc: 0.8124 - val_loss: 0.8336 - val_acc: 0.8161\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7609 - acc: 0.8272 - val_loss: 0.9182 - val_acc: 0.7547\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.6790 - acc: 0.8339 - val_loss: 0.6880 - val_acc: 0.8257\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.6249 - acc: 0.8421 - val_loss: 0.6593 - val_acc: 0.8233\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.5912 - acc: 0.8485 - val_loss: 0.5507 - val_acc: 0.8586\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.5593 - acc: 0.8504 - val_loss: 0.5765 - val_acc: 0.8422\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.5429 - acc: 0.8547 - val_loss: 0.6041 - val_acc: 0.8311\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5197 - acc: 0.8585 - val_loss: 0.5458 - val_acc: 0.8435\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5098 - acc: 0.8607 - val_loss: 0.6515 - val_acc: 0.8111\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.4989 - acc: 0.8648 - val_loss: 0.5231 - val_acc: 0.8513\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4867 - acc: 0.8664 - val_loss: 0.4675 - val_acc: 0.8690\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4755 - acc: 0.8696 - val_loss: 0.4745 - val_acc: 0.8653\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4678 - acc: 0.8708 - val_loss: 0.5371 - val_acc: 0.8347\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4592 - acc: 0.8711 - val_loss: 0.4982 - val_acc: 0.8587\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4517 - acc: 0.8740 - val_loss: 0.5696 - val_acc: 0.8323\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4463 - acc: 0.8769 - val_loss: 0.5525 - val_acc: 0.8389\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.4404 - acc: 0.8782 - val_loss: 0.5146 - val_acc: 0.8514\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.4379 - acc: 0.8763 - val_loss: 0.4853 - val_acc: 0.8567\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4309 - acc: 0.8792 - val_loss: 0.4631 - val_acc: 0.8600\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4242 - acc: 0.8810 - val_loss: 0.4763 - val_acc: 0.8634\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4198 - acc: 0.8828 - val_loss: 0.4815 - val_acc: 0.8588\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4198 - acc: 0.8818 - val_loss: 0.5294 - val_acc: 0.8439\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4106 - acc: 0.8861 - val_loss: 0.4296 - val_acc: 0.8797\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4115 - acc: 0.8858 - val_loss: 0.4496 - val_acc: 0.8728\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4100 - acc: 0.8867 - val_loss: 0.4528 - val_acc: 0.8688\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4042 - acc: 0.8878 - val_loss: 0.4372 - val_acc: 0.8700\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4023 - acc: 0.8875 - val_loss: 0.4618 - val_acc: 0.8679\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4014 - acc: 0.8884 - val_loss: 0.4265 - val_acc: 0.8773\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3964 - acc: 0.8891 - val_loss: 0.4599 - val_acc: 0.8616\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3961 - acc: 0.8906 - val_loss: 0.4378 - val_acc: 0.8728\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3899 - acc: 0.8922 - val_loss: 0.4190 - val_acc: 0.8824\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3877 - acc: 0.8934 - val_loss: 0.4380 - val_acc: 0.8760\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3869 - acc: 0.8934 - val_loss: 0.4462 - val_acc: 0.8728\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3812 - acc: 0.8946 - val_loss: 0.4753 - val_acc: 0.8638\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3868 - acc: 0.8910 - val_loss: 0.4804 - val_acc: 0.8631\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3832 - acc: 0.8936 - val_loss: 0.4787 - val_acc: 0.8598\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3812 - acc: 0.8949 - val_loss: 0.4144 - val_acc: 0.8836\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3814 - acc: 0.8948 - val_loss: 0.4487 - val_acc: 0.8684\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3775 - acc: 0.8960 - val_loss: 0.4384 - val_acc: 0.8719\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3774 - acc: 0.8961 - val_loss: 0.4680 - val_acc: 0.8646\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3750 - acc: 0.8976 - val_loss: 0.3979 - val_acc: 0.8869\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3759 - acc: 0.8970 - val_loss: 0.4724 - val_acc: 0.8633\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3715 - acc: 0.8987 - val_loss: 0.4157 - val_acc: 0.8860\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3726 - acc: 0.8975 - val_loss: 0.4214 - val_acc: 0.8787\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3677 - acc: 0.8993 - val_loss: 0.4281 - val_acc: 0.8777\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3698 - acc: 0.8979 - val_loss: 0.4524 - val_acc: 0.8720\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3693 - acc: 0.8976 - val_loss: 0.4706 - val_acc: 0.8546\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3676 - acc: 0.9006 - val_loss: 0.4233 - val_acc: 0.8809\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3647 - acc: 0.9006 - val_loss: 0.4464 - val_acc: 0.8732\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3676 - acc: 0.8983 - val_loss: 0.4317 - val_acc: 0.8765\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3628 - acc: 0.9004 - val_loss: 0.4993 - val_acc: 0.8560\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3632 - acc: 0.9016 - val_loss: 0.4414 - val_acc: 0.8699\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3610 - acc: 0.9005 - val_loss: 0.4153 - val_acc: 0.8816\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3615 - acc: 0.9020 - val_loss: 0.5043 - val_acc: 0.8523\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3600 - acc: 0.9022 - val_loss: 0.4202 - val_acc: 0.8795\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3587 - acc: 0.9027 - val_loss: 0.4208 - val_acc: 0.8801\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3610 - acc: 0.9013 - val_loss: 0.4440 - val_acc: 0.8713\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3576 - acc: 0.9021 - val_loss: 0.4573 - val_acc: 0.8667\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3580 - acc: 0.9025 - val_loss: 0.4519 - val_acc: 0.8738\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3584 - acc: 0.9010 - val_loss: 0.4160 - val_acc: 0.8835\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3523 - acc: 0.9053 - val_loss: 0.4020 - val_acc: 0.8837\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3538 - acc: 0.9032 - val_loss: 0.4127 - val_acc: 0.8848\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3550 - acc: 0.9022 - val_loss: 0.4593 - val_acc: 0.8632\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3527 - acc: 0.9038 - val_loss: 0.4297 - val_acc: 0.8797\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3518 - acc: 0.9057 - val_loss: 0.5124 - val_acc: 0.8576\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3513 - acc: 0.9052 - val_loss: 0.4035 - val_acc: 0.8847\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3477 - acc: 0.9059 - val_loss: 0.4373 - val_acc: 0.8774\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3540 - acc: 0.9049 - val_loss: 0.3990 - val_acc: 0.8875\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3494 - acc: 0.9061 - val_loss: 0.4463 - val_acc: 0.8713\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3491 - acc: 0.9054 - val_loss: 0.4915 - val_acc: 0.8566\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3484 - acc: 0.9043 - val_loss: 0.4169 - val_acc: 0.8801\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3492 - acc: 0.9048 - val_loss: 0.4333 - val_acc: 0.8777\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3479 - acc: 0.9055 - val_loss: 0.4507 - val_acc: 0.8650\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3467 - acc: 0.9076 - val_loss: 0.4179 - val_acc: 0.8799\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3447 - acc: 0.9069 - val_loss: 0.4316 - val_acc: 0.8772\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3466 - acc: 0.9067 - val_loss: 0.4631 - val_acc: 0.8687\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3483 - acc: 0.9060 - val_loss: 0.4356 - val_acc: 0.8733\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3426 - acc: 0.9093 - val_loss: 0.4186 - val_acc: 0.8809\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3440 - acc: 0.9069 - val_loss: 0.4446 - val_acc: 0.8780\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3427 - acc: 0.9078 - val_loss: 0.4181 - val_acc: 0.8805\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3408 - acc: 0.9072 - val_loss: 0.4971 - val_acc: 0.8566\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3412 - acc: 0.9093 - val_loss: 0.5285 - val_acc: 0.8534\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3426 - acc: 0.9090 - val_loss: 0.4332 - val_acc: 0.8747\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3391 - acc: 0.9090 - val_loss: 0.5151 - val_acc: 0.8562\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3404 - acc: 0.9080 - val_loss: 0.4343 - val_acc: 0.8790\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3391 - acc: 0.9088 - val_loss: 0.4776 - val_acc: 0.8591\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3410 - acc: 0.9088 - val_loss: 0.4410 - val_acc: 0.8729\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3380 - acc: 0.9099 - val_loss: 0.4425 - val_acc: 0.8745\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3390 - acc: 0.9106 - val_loss: 0.4642 - val_acc: 0.8652\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3349 - acc: 0.9110 - val_loss: 0.5169 - val_acc: 0.8474\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3402 - acc: 0.9090 - val_loss: 0.4288 - val_acc: 0.8792\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3370 - acc: 0.9098 - val_loss: 0.4792 - val_acc: 0.8657\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3362 - acc: 0.9095 - val_loss: 0.4355 - val_acc: 0.8771\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3368 - acc: 0.9094 - val_loss: 0.4464 - val_acc: 0.8714\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3356 - acc: 0.9107 - val_loss: 0.4460 - val_acc: 0.8754\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3342 - acc: 0.9105 - val_loss: 0.4554 - val_acc: 0.8672\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3380 - acc: 0.9084 - val_loss: 0.4108 - val_acc: 0.8868\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3328 - acc: 0.9109 - val_loss: 0.4106 - val_acc: 0.8860\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3374 - acc: 0.9101 - val_loss: 0.4479 - val_acc: 0.8774\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3387 - acc: 0.9094 - val_loss: 0.4118 - val_acc: 0.8822\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3338 - acc: 0.9122 - val_loss: 0.4068 - val_acc: 0.8843\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3325 - acc: 0.9111 - val_loss: 0.4459 - val_acc: 0.8748\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3343 - acc: 0.9108 - val_loss: 0.4578 - val_acc: 0.8710\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3335 - acc: 0.9117 - val_loss: 0.5199 - val_acc: 0.8434\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3360 - acc: 0.9105 - val_loss: 0.4668 - val_acc: 0.8653\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3331 - acc: 0.9114 - val_loss: 0.5086 - val_acc: 0.8467\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3320 - acc: 0.9118 - val_loss: 0.5407 - val_acc: 0.8548\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3308 - acc: 0.9131 - val_loss: 0.4373 - val_acc: 0.8731\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3325 - acc: 0.9119 - val_loss: 0.4863 - val_acc: 0.8629\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3320 - acc: 0.9123 - val_loss: 0.4308 - val_acc: 0.8778\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3328 - acc: 0.9118 - val_loss: 0.4216 - val_acc: 0.8825\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3274 - acc: 0.9130 - val_loss: 0.4385 - val_acc: 0.8774\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3334 - acc: 0.9101 - val_loss: 0.4308 - val_acc: 0.8784\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3328 - acc: 0.9106 - val_loss: 0.4055 - val_acc: 0.8873\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3273 - acc: 0.9155 - val_loss: 0.4363 - val_acc: 0.8738\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3298 - acc: 0.9127 - val_loss: 0.5004 - val_acc: 0.8560\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3297 - acc: 0.9134 - val_loss: 0.4203 - val_acc: 0.8788\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3290 - acc: 0.9143 - val_loss: 0.4806 - val_acc: 0.8572\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3265 - acc: 0.9142 - val_loss: 0.4740 - val_acc: 0.8690\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3283 - acc: 0.9141 - val_loss: 0.5342 - val_acc: 0.8483\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3300 - acc: 0.9128 - val_loss: 0.4770 - val_acc: 0.8598\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3282 - acc: 0.9140 - val_loss: 0.4471 - val_acc: 0.8741\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3262 - acc: 0.9139 - val_loss: 0.6546 - val_acc: 0.8090\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3273 - acc: 0.9143 - val_loss: 0.4535 - val_acc: 0.8720\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3277 - acc: 0.9143 - val_loss: 0.3941 - val_acc: 0.8920\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3257 - acc: 0.9136 - val_loss: 0.4159 - val_acc: 0.8836\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3278 - acc: 0.9135 - val_loss: 0.4431 - val_acc: 0.8770\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3274 - acc: 0.9140 - val_loss: 0.4500 - val_acc: 0.8783\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3231 - acc: 0.9162 - val_loss: 0.4617 - val_acc: 0.8714\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3239 - acc: 0.9146 - val_loss: 0.4106 - val_acc: 0.8860\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3226 - acc: 0.9152 - val_loss: 0.4470 - val_acc: 0.8725\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3304 - acc: 0.9141 - val_loss: 0.4515 - val_acc: 0.8732\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3266 - acc: 0.9131 - val_loss: 0.4392 - val_acc: 0.8760\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3246 - acc: 0.9150 - val_loss: 0.4074 - val_acc: 0.8866\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3239 - acc: 0.9157 - val_loss: 0.4650 - val_acc: 0.8722\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3273 - acc: 0.9142 - val_loss: 0.4426 - val_acc: 0.8785\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.3260 - acc: 0.9147 - val_loss: 0.4204 - val_acc: 0.8804\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3241 - acc: 0.9160 - val_loss: 0.4138 - val_acc: 0.8859\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3205 - acc: 0.9167 - val_loss: 0.3980 - val_acc: 0.8910\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3232 - acc: 0.9171 - val_loss: 0.4363 - val_acc: 0.8802\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3238 - acc: 0.9149 - val_loss: 0.4600 - val_acc: 0.8772\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3260 - acc: 0.9148 - val_loss: 0.4637 - val_acc: 0.8688\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3221 - acc: 0.9157 - val_loss: 0.4475 - val_acc: 0.8785\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3250 - acc: 0.9163 - val_loss: 0.4171 - val_acc: 0.8872\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3212 - acc: 0.9178 - val_loss: 0.4679 - val_acc: 0.8708\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3231 - acc: 0.9155 - val_loss: 0.4158 - val_acc: 0.8832\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3226 - acc: 0.9174 - val_loss: 0.4747 - val_acc: 0.8633\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3226 - acc: 0.9146 - val_loss: 0.4336 - val_acc: 0.8806\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3217 - acc: 0.9163 - val_loss: 0.5135 - val_acc: 0.8521\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3237 - acc: 0.9157 - val_loss: 0.4540 - val_acc: 0.8701\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3201 - acc: 0.9160 - val_loss: 0.4372 - val_acc: 0.8760\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3203 - acc: 0.9167 - val_loss: 0.5101 - val_acc: 0.8567\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3213 - acc: 0.9165 - val_loss: 0.4244 - val_acc: 0.8834\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3201 - acc: 0.9172 - val_loss: 0.4167 - val_acc: 0.8828\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3176 - acc: 0.9169 - val_loss: 0.4950 - val_acc: 0.8626\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3212 - acc: 0.9157 - val_loss: 0.5887 - val_acc: 0.8388\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3201 - acc: 0.9176 - val_loss: 0.4309 - val_acc: 0.8828\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3202 - acc: 0.9168 - val_loss: 0.4640 - val_acc: 0.8754\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3188 - acc: 0.9174 - val_loss: 0.4557 - val_acc: 0.8743\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3193 - acc: 0.9195 - val_loss: 0.4264 - val_acc: 0.8815\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3215 - acc: 0.9162 - val_loss: 0.4107 - val_acc: 0.8886\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.3193 - acc: 0.9176 - val_loss: 0.5753 - val_acc: 0.8346\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3196 - acc: 0.9168 - val_loss: 0.4808 - val_acc: 0.8671\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3209 - acc: 0.9170 - val_loss: 0.4061 - val_acc: 0.8892\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3170 - acc: 0.9181 - val_loss: 0.4608 - val_acc: 0.8760\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3178 - acc: 0.9168 - val_loss: 0.4282 - val_acc: 0.8848\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3172 - acc: 0.9182 - val_loss: 0.5105 - val_acc: 0.8663\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3205 - acc: 0.9162 - val_loss: 0.4135 - val_acc: 0.8877\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3201 - acc: 0.9168 - val_loss: 0.4331 - val_acc: 0.8826\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3179 - acc: 0.9169 - val_loss: 0.4214 - val_acc: 0.8845\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3186 - acc: 0.9182 - val_loss: 0.4151 - val_acc: 0.8848\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3193 - acc: 0.9169 - val_loss: 0.4189 - val_acc: 0.8848\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3177 - acc: 0.9188 - val_loss: 0.4693 - val_acc: 0.8733\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3143 - acc: 0.9186 - val_loss: 0.5471 - val_acc: 0.8284\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3221 - acc: 0.9177 - val_loss: 0.5187 - val_acc: 0.8598\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3201 - acc: 0.9178 - val_loss: 0.4558 - val_acc: 0.8754\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3146 - acc: 0.9183 - val_loss: 0.5219 - val_acc: 0.8513\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3158 - acc: 0.9184 - val_loss: 0.4309 - val_acc: 0.8797\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3170 - acc: 0.9187 - val_loss: 0.4321 - val_acc: 0.8821\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3167 - acc: 0.9177 - val_loss: 0.4224 - val_acc: 0.8804\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3156 - acc: 0.9198 - val_loss: 0.5353 - val_acc: 0.8407\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3152 - acc: 0.9175 - val_loss: 0.4667 - val_acc: 0.8728\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.3134 - acc: 0.9194 - val_loss: 0.4164 - val_acc: 0.8886\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3166 - acc: 0.9181 - val_loss: 0.4319 - val_acc: 0.8829\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3148 - acc: 0.9195 - val_loss: 0.4270 - val_acc: 0.8833\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3157 - acc: 0.9190 - val_loss: 0.4397 - val_acc: 0.8841\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3144 - acc: 0.9184 - val_loss: 0.5189 - val_acc: 0.8640\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3129 - acc: 0.9193 - val_loss: 0.4491 - val_acc: 0.8804\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3144 - acc: 0.9186 - val_loss: 0.4430 - val_acc: 0.8807\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3157 - acc: 0.9185 - val_loss: 0.4736 - val_acc: 0.8728\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3121 - acc: 0.9212 - val_loss: 0.5048 - val_acc: 0.8649\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3141 - acc: 0.9196 - val_loss: 0.4190 - val_acc: 0.8872\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3143 - acc: 0.9198 - val_loss: 0.4957 - val_acc: 0.8626\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3108 - acc: 0.9203 - val_loss: 0.5148 - val_acc: 0.8652\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3126 - acc: 0.9207 - val_loss: 0.4687 - val_acc: 0.8751\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3146 - acc: 0.9196 - val_loss: 0.5103 - val_acc: 0.8573\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3142 - acc: 0.9192 - val_loss: 0.4164 - val_acc: 0.8853\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.3144 - acc: 0.9205 - val_loss: 0.4776 - val_acc: 0.8656\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'l1_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5e3fdaf42e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"initial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l1 reg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l2 reg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l1_loss' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model with L2 Regularization\n",
    "model_L2 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compile Model\n",
    "model_L2.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_L2 = model_L2.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))\n",
    "\n",
    "#Extract Validation Loss from keras callback history\n",
    "L1_metrics = track_L1.history\n",
    "L1_loss = L1_metrics['val_loss']\n",
    "\n",
    "L2_metrics = track_L2.history\n",
    "L2_loss = L2_metrics['val_loss']\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, dropout_loss, 'b', label = \"dropout\")\n",
    "plt.plot(epochs, val_loss, 'r', label = \"initial\")\n",
    "plt.plot(epochs, l1_loss, 'g', label = \"l1 reg\")\n",
    "plt.plot(epochs, l2_loss, 'm', label = \"l2 reg\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss over Range of Epochs with Dropout and Regularization\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison: From all the models, the best performing model is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING: 10 MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.6339 - acc: 0.7767 - val_loss: 0.4856 - val_acc: 0.8203\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.4129 - acc: 0.8477 - val_loss: 0.3978 - val_acc: 0.8498\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.3562 - acc: 0.8673 - val_loss: 0.4341 - val_acc: 0.8412\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.3270 - acc: 0.8783 - val_loss: 0.4366 - val_acc: 0.8355\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.3002 - acc: 0.8882 - val_loss: 0.3763 - val_acc: 0.8644\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2811 - acc: 0.8950 - val_loss: 0.3723 - val_acc: 0.8622\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2685 - acc: 0.8984 - val_loss: 0.3352 - val_acc: 0.8823\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2526 - acc: 0.9050 - val_loss: 0.4166 - val_acc: 0.8538\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2413 - acc: 0.9086 - val_loss: 0.4482 - val_acc: 0.8497\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2286 - acc: 0.9137 - val_loss: 0.3786 - val_acc: 0.8767\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2184 - acc: 0.9172 - val_loss: 0.4541 - val_acc: 0.8516\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2097 - acc: 0.9192 - val_loss: 0.3771 - val_acc: 0.8832\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.2029 - acc: 0.9226 - val_loss: 0.3686 - val_acc: 0.8827\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1943 - acc: 0.9268 - val_loss: 0.3729 - val_acc: 0.8808\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1889 - acc: 0.9286 - val_loss: 0.3669 - val_acc: 0.8801\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1841 - acc: 0.9313 - val_loss: 0.4557 - val_acc: 0.8759\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1772 - acc: 0.9325 - val_loss: 0.3582 - val_acc: 0.8945\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1670 - acc: 0.9367 - val_loss: 0.5034 - val_acc: 0.8675\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1658 - acc: 0.9361 - val_loss: 0.4160 - val_acc: 0.8827\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1615 - acc: 0.9396 - val_loss: 0.3690 - val_acc: 0.8904\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1550 - acc: 0.9412 - val_loss: 0.4781 - val_acc: 0.8732\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1517 - acc: 0.9421 - val_loss: 0.3870 - val_acc: 0.8947\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1480 - acc: 0.9444 - val_loss: 0.4101 - val_acc: 0.8912\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1472 - acc: 0.9459 - val_loss: 0.4263 - val_acc: 0.8925\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1431 - acc: 0.9435 - val_loss: 0.4069 - val_acc: 0.8892\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1389 - acc: 0.9486 - val_loss: 0.4145 - val_acc: 0.8958\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1365 - acc: 0.9487 - val_loss: 0.4208 - val_acc: 0.8955\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1366 - acc: 0.9495 - val_loss: 0.5230 - val_acc: 0.8851\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1312 - acc: 0.9517 - val_loss: 0.5055 - val_acc: 0.8864\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.1295 - acc: 0.9507 - val_loss: 0.5565 - val_acc: 0.8850\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 0.1239 - acc: 0.9537 - val_loss: 0.5274 - val_acc: 0.8803\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1224 - acc: 0.9546 - val_loss: 0.4936 - val_acc: 0.8852\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1218 - acc: 0.9551 - val_loss: 0.4661 - val_acc: 0.8891\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1205 - acc: 0.9568 - val_loss: 0.5313 - val_acc: 0.8950\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1179 - acc: 0.9573 - val_loss: 0.5798 - val_acc: 0.8890\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1149 - acc: 0.9576 - val_loss: 0.4910 - val_acc: 0.8933\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1145 - acc: 0.9581 - val_loss: 0.5268 - val_acc: 0.8916\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1118 - acc: 0.9593 - val_loss: 0.5496 - val_acc: 0.8888\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1146 - acc: 0.9579 - val_loss: 0.4962 - val_acc: 0.8880\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1042 - acc: 0.9618 - val_loss: 0.5698 - val_acc: 0.8927\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1076 - acc: 0.9612 - val_loss: 0.5522 - val_acc: 0.8920\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1024 - acc: 0.9626 - val_loss: 0.5721 - val_acc: 0.8897\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1039 - acc: 0.9613 - val_loss: 0.5743 - val_acc: 0.8949\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1051 - acc: 0.9625 - val_loss: 0.5916 - val_acc: 0.8786\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1045 - acc: 0.9639 - val_loss: 0.6274 - val_acc: 0.8876\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1031 - acc: 0.9633 - val_loss: 0.6169 - val_acc: 0.8873\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0997 - acc: 0.9631 - val_loss: 0.5904 - val_acc: 0.8882\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1023 - acc: 0.9635 - val_loss: 0.6548 - val_acc: 0.8839\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0964 - acc: 0.9656 - val_loss: 0.6174 - val_acc: 0.8843\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0981 - acc: 0.9654 - val_loss: 0.5408 - val_acc: 0.8929\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0972 - acc: 0.9660 - val_loss: 0.6019 - val_acc: 0.8925\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0912 - acc: 0.9667 - val_loss: 0.6455 - val_acc: 0.8867\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0961 - acc: 0.9668 - val_loss: 0.5925 - val_acc: 0.8910\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0890 - acc: 0.9673 - val_loss: 0.7243 - val_acc: 0.8887\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0912 - acc: 0.9682 - val_loss: 0.6948 - val_acc: 0.8841\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0936 - acc: 0.9673 - val_loss: 0.6149 - val_acc: 0.8924\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0899 - acc: 0.9685 - val_loss: 0.6356 - val_acc: 0.8985\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0868 - acc: 0.9694 - val_loss: 0.6630 - val_acc: 0.8928\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0872 - acc: 0.9690 - val_loss: 0.6519 - val_acc: 0.8858\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0907 - acc: 0.9696 - val_loss: 0.6391 - val_acc: 0.8873\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0873 - acc: 0.9696 - val_loss: 0.9477 - val_acc: 0.8716\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0843 - acc: 0.9709 - val_loss: 0.6426 - val_acc: 0.8966\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0792 - acc: 0.9717 - val_loss: 0.6879 - val_acc: 0.8943\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0824 - acc: 0.9712 - val_loss: 0.6226 - val_acc: 0.8987\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0833 - acc: 0.9715 - val_loss: 0.6633 - val_acc: 0.8913\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0802 - acc: 0.9725 - val_loss: 0.7013 - val_acc: 0.8898\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0770 - acc: 0.9733 - val_loss: 0.6792 - val_acc: 0.8903\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0788 - acc: 0.9725 - val_loss: 0.6417 - val_acc: 0.8850\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0816 - acc: 0.9726 - val_loss: 0.7367 - val_acc: 0.8891\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0796 - acc: 0.9732 - val_loss: 0.7429 - val_acc: 0.8906\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0780 - acc: 0.9742 - val_loss: 0.7759 - val_acc: 0.8890\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0780 - acc: 0.9738 - val_loss: 0.8183 - val_acc: 0.8800\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0766 - acc: 0.9749 - val_loss: 0.7810 - val_acc: 0.8859\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0762 - acc: 0.9739 - val_loss: 0.6906 - val_acc: 0.8939\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0756 - acc: 0.9748 - val_loss: 0.7559 - val_acc: 0.8918\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0768 - acc: 0.9750 - val_loss: 0.8203 - val_acc: 0.8891\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0789 - acc: 0.9741 - val_loss: 0.7347 - val_acc: 0.8953\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0739 - acc: 0.9756 - val_loss: 0.8361 - val_acc: 0.8816\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0751 - acc: 0.9760 - val_loss: 0.8239 - val_acc: 0.8878\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0740 - acc: 0.9749 - val_loss: 0.7338 - val_acc: 0.8889\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0722 - acc: 0.9758 - val_loss: 0.7711 - val_acc: 0.8913\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0719 - acc: 0.9759 - val_loss: 0.8320 - val_acc: 0.8923\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0740 - acc: 0.9755 - val_loss: 0.8428 - val_acc: 0.8885\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0674 - acc: 0.9768 - val_loss: 0.7632 - val_acc: 0.8943\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0699 - acc: 0.9774 - val_loss: 0.7212 - val_acc: 0.8971\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0688 - acc: 0.9778 - val_loss: 0.7746 - val_acc: 0.8925\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0656 - acc: 0.9780 - val_loss: 0.7665 - val_acc: 0.8959\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0700 - acc: 0.9769 - val_loss: 0.8455 - val_acc: 0.8869\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0705 - acc: 0.9770 - val_loss: 0.7805 - val_acc: 0.8938\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0657 - acc: 0.9784 - val_loss: 0.8399 - val_acc: 0.8905\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0680 - acc: 0.9776 - val_loss: 0.7610 - val_acc: 0.8918\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0700 - acc: 0.9782 - val_loss: 0.7371 - val_acc: 0.8905\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0652 - acc: 0.9792 - val_loss: 0.8644 - val_acc: 0.8918\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0641 - acc: 0.9794 - val_loss: 0.8035 - val_acc: 0.8871\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0675 - acc: 0.9788 - val_loss: 0.7703 - val_acc: 0.8949\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0633 - acc: 0.9802 - val_loss: 0.7654 - val_acc: 0.8900\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0624 - acc: 0.9802 - val_loss: 0.8337 - val_acc: 0.8947\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0671 - acc: 0.9792 - val_loss: 0.7888 - val_acc: 0.8882\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0675 - acc: 0.9796 - val_loss: 0.7746 - val_acc: 0.8942\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0629 - acc: 0.9805 - val_loss: 0.8340 - val_acc: 0.8890\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0609 - acc: 0.9811 - val_loss: 0.8505 - val_acc: 0.8842\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0608 - acc: 0.9801 - val_loss: 0.8947 - val_acc: 0.8893\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0609 - acc: 0.9808 - val_loss: 0.8207 - val_acc: 0.8913\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0628 - acc: 0.9810 - val_loss: 0.8727 - val_acc: 0.8914\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0648 - acc: 0.9795 - val_loss: 0.8012 - val_acc: 0.8981\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0690 - acc: 0.9795 - val_loss: 0.8638 - val_acc: 0.8766\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0578 - acc: 0.9811 - val_loss: 0.8396 - val_acc: 0.8973\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0585 - acc: 0.9819 - val_loss: 0.7614 - val_acc: 0.8908\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0593 - acc: 0.9821 - val_loss: 0.8699 - val_acc: 0.8872\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0559 - acc: 0.9823 - val_loss: 0.8362 - val_acc: 0.9001\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0584 - acc: 0.9826 - val_loss: 0.9070 - val_acc: 0.8898\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0615 - acc: 0.9824 - val_loss: 0.8331 - val_acc: 0.8891\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0575 - acc: 0.9825 - val_loss: 0.8643 - val_acc: 0.8934\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0549 - acc: 0.9826 - val_loss: 0.9300 - val_acc: 0.8915\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0565 - acc: 0.9830 - val_loss: 0.8573 - val_acc: 0.8859\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0586 - acc: 0.9826 - val_loss: 0.8308 - val_acc: 0.8948\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0623 - acc: 0.9822 - val_loss: 0.7951 - val_acc: 0.8937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0559 - acc: 0.9824 - val_loss: 1.0155 - val_acc: 0.8863\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0542 - acc: 0.9835 - val_loss: 1.1145 - val_acc: 0.8676\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0558 - acc: 0.9836 - val_loss: 0.7818 - val_acc: 0.8958\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0548 - acc: 0.9837 - val_loss: 0.8357 - val_acc: 0.8943\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0553 - acc: 0.9836 - val_loss: 0.9906 - val_acc: 0.8856\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0548 - acc: 0.9834 - val_loss: 0.8501 - val_acc: 0.8990\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0537 - acc: 0.9838 - val_loss: 0.8380 - val_acc: 0.8974\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0535 - acc: 0.9843 - val_loss: 0.8815 - val_acc: 0.8946\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0540 - acc: 0.9843 - val_loss: 1.0210 - val_acc: 0.8854\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0567 - acc: 0.9844 - val_loss: 0.8885 - val_acc: 0.8905\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0554 - acc: 0.9837 - val_loss: 0.8469 - val_acc: 0.8953\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0519 - acc: 0.9842 - val_loss: 1.1242 - val_acc: 0.8835\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0567 - acc: 0.9839 - val_loss: 0.9212 - val_acc: 0.8931\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0550 - acc: 0.9843 - val_loss: 0.8456 - val_acc: 0.8956\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0520 - acc: 0.9848 - val_loss: 0.8836 - val_acc: 0.8980\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0529 - acc: 0.9840 - val_loss: 0.9512 - val_acc: 0.8919\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0522 - acc: 0.9855 - val_loss: 0.9310 - val_acc: 0.8970\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0532 - acc: 0.9843 - val_loss: 0.9703 - val_acc: 0.8904\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0601 - acc: 0.9838 - val_loss: 0.8905 - val_acc: 0.8947\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0503 - acc: 0.9851 - val_loss: 0.8696 - val_acc: 0.8950\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0532 - acc: 0.9849 - val_loss: 0.9203 - val_acc: 0.8847\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0481 - acc: 0.9855 - val_loss: 0.8770 - val_acc: 0.8963\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0500 - acc: 0.9854 - val_loss: 0.9280 - val_acc: 0.8950\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0504 - acc: 0.9856 - val_loss: 0.9222 - val_acc: 0.8928\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0514 - acc: 0.9852 - val_loss: 1.1432 - val_acc: 0.8694\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0541 - acc: 0.9846 - val_loss: 0.9914 - val_acc: 0.8868\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0484 - acc: 0.9858 - val_loss: 0.9355 - val_acc: 0.8950\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0472 - acc: 0.9858 - val_loss: 0.8959 - val_acc: 0.8972\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0515 - acc: 0.9847 - val_loss: 0.9691 - val_acc: 0.8846\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0491 - acc: 0.9858 - val_loss: 0.9134 - val_acc: 0.8948\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0481 - acc: 0.9856 - val_loss: 0.8970 - val_acc: 0.8959\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0469 - acc: 0.9867 - val_loss: 0.9495 - val_acc: 0.8913\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0517 - acc: 0.9866 - val_loss: 0.9532 - val_acc: 0.8899\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0527 - acc: 0.9851 - val_loss: 0.9196 - val_acc: 0.8934\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0514 - acc: 0.9861 - val_loss: 0.9491 - val_acc: 0.8896\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0510 - acc: 0.9857 - val_loss: 0.9288 - val_acc: 0.8939\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0504 - acc: 0.9862 - val_loss: 1.0104 - val_acc: 0.8871\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0489 - acc: 0.9867 - val_loss: 0.9187 - val_acc: 0.8962\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0550 - acc: 0.9856 - val_loss: 0.9930 - val_acc: 0.8924\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0484 - acc: 0.9862 - val_loss: 0.9538 - val_acc: 0.8957\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0460 - acc: 0.9871 - val_loss: 0.8969 - val_acc: 0.8976\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0475 - acc: 0.9863 - val_loss: 1.0338 - val_acc: 0.8832\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0477 - acc: 0.9874 - val_loss: 1.0104 - val_acc: 0.8940\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0500 - acc: 0.9866 - val_loss: 1.1474 - val_acc: 0.8796\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0510 - acc: 0.9858 - val_loss: 0.9664 - val_acc: 0.8914\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0468 - acc: 0.9869 - val_loss: 1.0111 - val_acc: 0.8819\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0448 - acc: 0.9883 - val_loss: 0.9617 - val_acc: 0.8954\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0476 - acc: 0.9867 - val_loss: 0.9666 - val_acc: 0.8947\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0525 - acc: 0.9858 - val_loss: 0.9671 - val_acc: 0.8959\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0459 - acc: 0.9873 - val_loss: 1.0738 - val_acc: 0.8836\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0480 - acc: 0.9872 - val_loss: 1.0095 - val_acc: 0.8970\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0454 - acc: 0.9877 - val_loss: 0.9784 - val_acc: 0.8851\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0437 - acc: 0.9880 - val_loss: 1.1404 - val_acc: 0.8849\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0422 - acc: 0.9880 - val_loss: 0.9587 - val_acc: 0.8944\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0422 - acc: 0.9881 - val_loss: 0.9588 - val_acc: 0.8933\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0464 - acc: 0.9876 - val_loss: 0.9438 - val_acc: 0.8956\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0440 - acc: 0.9882 - val_loss: 0.9754 - val_acc: 0.8970\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0472 - acc: 0.9878 - val_loss: 0.9955 - val_acc: 0.8896\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0477 - acc: 0.9876 - val_loss: 0.9671 - val_acc: 0.8982\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0465 - acc: 0.9872 - val_loss: 0.9788 - val_acc: 0.8902\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0437 - acc: 0.9879 - val_loss: 1.0085 - val_acc: 0.8955\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0435 - acc: 0.9879 - val_loss: 1.0430 - val_acc: 0.8870\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0418 - acc: 0.9881 - val_loss: 1.0313 - val_acc: 0.8953\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0437 - acc: 0.9881 - val_loss: 1.0305 - val_acc: 0.8937\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0428 - acc: 0.9882 - val_loss: 1.0292 - val_acc: 0.8925\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0412 - acc: 0.9891 - val_loss: 1.0462 - val_acc: 0.8946\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0471 - acc: 0.9877 - val_loss: 1.1988 - val_acc: 0.8828\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0468 - acc: 0.9881 - val_loss: 1.0119 - val_acc: 0.8926\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0427 - acc: 0.9889 - val_loss: 0.9952 - val_acc: 0.8950\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0424 - acc: 0.9889 - val_loss: 1.0150 - val_acc: 0.8944\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0446 - acc: 0.9888 - val_loss: 1.1352 - val_acc: 0.8862\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0436 - acc: 0.9889 - val_loss: 1.1208 - val_acc: 0.8905\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0398 - acc: 0.9889 - val_loss: 1.1245 - val_acc: 0.8892\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0433 - acc: 0.9888 - val_loss: 1.0241 - val_acc: 0.8949\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0399 - acc: 0.9885 - val_loss: 1.0045 - val_acc: 0.8953\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0515 - acc: 0.9876 - val_loss: 1.0570 - val_acc: 0.8892\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0471 - acc: 0.9886 - val_loss: 0.9933 - val_acc: 0.8994\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0422 - acc: 0.9886 - val_loss: 1.0399 - val_acc: 0.8908\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0412 - acc: 0.9890 - val_loss: 1.0266 - val_acc: 0.8915\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0498 - acc: 0.9881 - val_loss: 1.0765 - val_acc: 0.8931\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0422 - acc: 0.9899 - val_loss: 1.0278 - val_acc: 0.8955\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0408 - acc: 0.9898 - val_loss: 1.0397 - val_acc: 0.8934\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0449 - acc: 0.9890 - val_loss: 1.0803 - val_acc: 0.8920\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.7252 - acc: 0.7321 - val_loss: 0.5762 - val_acc: 0.8030\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.4501 - acc: 0.8345 - val_loss: 0.4923 - val_acc: 0.7987\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3880 - acc: 0.8568 - val_loss: 0.4510 - val_acc: 0.8392\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3497 - acc: 0.8712 - val_loss: 0.3917 - val_acc: 0.8455\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3240 - acc: 0.8796 - val_loss: 0.3714 - val_acc: 0.8622\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3056 - acc: 0.8864 - val_loss: 0.4454 - val_acc: 0.8516\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2921 - acc: 0.8916 - val_loss: 0.3811 - val_acc: 0.8711\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2827 - acc: 0.8951 - val_loss: 0.4885 - val_acc: 0.8422\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2668 - acc: 0.8993 - val_loss: 0.5293 - val_acc: 0.8569\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2673 - acc: 0.9018 - val_loss: 0.5202 - val_acc: 0.8558\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2584 - acc: 0.9045 - val_loss: 0.3482 - val_acc: 0.8877\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2499 - acc: 0.9058 - val_loss: 0.4541 - val_acc: 0.8609\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2489 - acc: 0.9079 - val_loss: 0.3718 - val_acc: 0.8850\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2397 - acc: 0.9103 - val_loss: 0.3711 - val_acc: 0.8795\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2378 - acc: 0.9119 - val_loss: 0.4400 - val_acc: 0.8577\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2329 - acc: 0.9155 - val_loss: 0.5770 - val_acc: 0.8580\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2306 - acc: 0.9152 - val_loss: 0.4339 - val_acc: 0.8869\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2250 - acc: 0.9174 - val_loss: 0.3983 - val_acc: 0.8829\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2245 - acc: 0.9195 - val_loss: 0.4730 - val_acc: 0.8542\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2248 - acc: 0.9197 - val_loss: 0.4519 - val_acc: 0.8642\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2110 - acc: 0.9227 - val_loss: 0.3788 - val_acc: 0.8942\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2121 - acc: 0.9223 - val_loss: 0.4059 - val_acc: 0.8963\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2099 - acc: 0.9247 - val_loss: 0.3874 - val_acc: 0.8927\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2066 - acc: 0.9262 - val_loss: 0.4078 - val_acc: 0.8928\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2072 - acc: 0.9248 - val_loss: 0.4800 - val_acc: 0.8760\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2004 - acc: 0.9276 - val_loss: 0.4837 - val_acc: 0.8890\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2099 - acc: 0.9284 - val_loss: 0.4462 - val_acc: 0.8870\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1960 - acc: 0.9299 - val_loss: 0.4546 - val_acc: 0.8922\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1998 - acc: 0.9291 - val_loss: 0.3932 - val_acc: 0.8962\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1978 - acc: 0.9300 - val_loss: 0.4259 - val_acc: 0.8833\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1924 - acc: 0.9318 - val_loss: 0.4725 - val_acc: 0.8769\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1960 - acc: 0.9337 - val_loss: 0.4156 - val_acc: 0.8898\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1956 - acc: 0.9334 - val_loss: 0.4799 - val_acc: 0.8887\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1911 - acc: 0.9337 - val_loss: 0.4213 - val_acc: 0.8859\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1849 - acc: 0.9358 - val_loss: 0.4145 - val_acc: 0.8908\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1826 - acc: 0.9357 - val_loss: 0.5882 - val_acc: 0.8743\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1774 - acc: 0.9381 - val_loss: 0.4775 - val_acc: 0.8782\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1816 - acc: 0.9376 - val_loss: 0.4441 - val_acc: 0.8831\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1875 - acc: 0.9384 - val_loss: 0.4468 - val_acc: 0.8867\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1799 - acc: 0.9399 - val_loss: 0.5613 - val_acc: 0.8786\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1708 - acc: 0.9398 - val_loss: 0.5262 - val_acc: 0.8908\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1702 - acc: 0.9401 - val_loss: 0.5981 - val_acc: 0.8632\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1714 - acc: 0.9420 - val_loss: 0.5329 - val_acc: 0.8894\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1737 - acc: 0.9414 - val_loss: 0.4957 - val_acc: 0.8937\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1719 - acc: 0.9430 - val_loss: 0.5236 - val_acc: 0.8815\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1648 - acc: 0.9430 - val_loss: 0.4927 - val_acc: 0.8959\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1725 - acc: 0.9425 - val_loss: 0.5284 - val_acc: 0.8922\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1674 - acc: 0.9449 - val_loss: 0.4728 - val_acc: 0.8930\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1587 - acc: 0.9469 - val_loss: 0.4595 - val_acc: 0.8894\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1661 - acc: 0.9443 - val_loss: 0.4493 - val_acc: 0.8906\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1540 - acc: 0.9452 - val_loss: 0.6618 - val_acc: 0.8731\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1631 - acc: 0.9467 - val_loss: 0.6365 - val_acc: 0.8779\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1541 - acc: 0.9475 - val_loss: 0.6255 - val_acc: 0.8883\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1506 - acc: 0.9489 - val_loss: 0.5635 - val_acc: 0.8933\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1542 - acc: 0.9487 - val_loss: 0.6535 - val_acc: 0.8590\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1580 - acc: 0.9494 - val_loss: 0.5032 - val_acc: 0.8869\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1555 - acc: 0.9493 - val_loss: 0.5936 - val_acc: 0.8849\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1550 - acc: 0.9497 - val_loss: 0.8017 - val_acc: 0.8568\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1563 - acc: 0.9511 - val_loss: 0.5410 - val_acc: 0.8838\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1464 - acc: 0.9506 - val_loss: 0.5163 - val_acc: 0.8985\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1526 - acc: 0.9506 - val_loss: 0.5798 - val_acc: 0.8858\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1530 - acc: 0.9509 - val_loss: 0.6576 - val_acc: 0.8761\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1523 - acc: 0.9511 - val_loss: 0.6634 - val_acc: 0.8823\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1429 - acc: 0.9537 - val_loss: 0.6357 - val_acc: 0.8926\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1509 - acc: 0.9512 - val_loss: 0.6019 - val_acc: 0.8829\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1595 - acc: 0.9526 - val_loss: 0.6892 - val_acc: 0.8916\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1448 - acc: 0.9551 - val_loss: 0.5707 - val_acc: 0.8925\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1536 - acc: 0.9528 - val_loss: 0.6844 - val_acc: 0.8896\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1379 - acc: 0.9550 - val_loss: 0.7316 - val_acc: 0.8838\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1457 - acc: 0.9542 - val_loss: 0.6236 - val_acc: 0.8721\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1536 - acc: 0.9536 - val_loss: 0.7342 - val_acc: 0.8705\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1479 - acc: 0.9552 - val_loss: 0.6326 - val_acc: 0.8855\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1579 - acc: 0.9550 - val_loss: 0.5211 - val_acc: 0.8988\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1466 - acc: 0.9559 - val_loss: 0.7253 - val_acc: 0.8724\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1336 - acc: 0.9559 - val_loss: 0.5838 - val_acc: 0.8906\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1322 - acc: 0.9571 - val_loss: 0.6175 - val_acc: 0.8949\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1346 - acc: 0.9589 - val_loss: 0.6322 - val_acc: 0.8952\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1510 - acc: 0.9570 - val_loss: 0.5705 - val_acc: 0.8951\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1415 - acc: 0.9572 - val_loss: 0.5691 - val_acc: 0.8965\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1436 - acc: 0.9578 - val_loss: 0.5982 - val_acc: 0.8975\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1461 - acc: 0.9595 - val_loss: 0.6662 - val_acc: 0.8895\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1369 - acc: 0.9592 - val_loss: 0.6137 - val_acc: 0.8895\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1351 - acc: 0.9596 - val_loss: 0.6588 - val_acc: 0.8907\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1554 - acc: 0.9576 - val_loss: 0.6248 - val_acc: 0.8925\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1305 - acc: 0.9594 - val_loss: 0.7981 - val_acc: 0.8869\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1361 - acc: 0.9614 - val_loss: 0.6923 - val_acc: 0.8961\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1439 - acc: 0.9592 - val_loss: 0.6515 - val_acc: 0.8738\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1328 - acc: 0.9630 - val_loss: 0.6200 - val_acc: 0.8900\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1354 - acc: 0.9604 - val_loss: 0.5930 - val_acc: 0.8989\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1402 - acc: 0.9620 - val_loss: 0.7136 - val_acc: 0.8876\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1384 - acc: 0.9606 - val_loss: 0.6122 - val_acc: 0.8975\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1252 - acc: 0.9623 - val_loss: 0.6628 - val_acc: 0.8922\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1305 - acc: 0.9627 - val_loss: 0.6306 - val_acc: 0.8952\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1342 - acc: 0.9619 - val_loss: 0.6523 - val_acc: 0.8798\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1305 - acc: 0.9632 - val_loss: 0.6203 - val_acc: 0.8968\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1221 - acc: 0.9635 - val_loss: 0.6568 - val_acc: 0.8899\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1452 - acc: 0.9608 - val_loss: 0.6106 - val_acc: 0.8935\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1349 - acc: 0.9637 - val_loss: 0.8660 - val_acc: 0.8748\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1300 - acc: 0.9626 - val_loss: 0.6031 - val_acc: 0.8945\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1253 - acc: 0.9635 - val_loss: 0.7722 - val_acc: 0.8817\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1432 - acc: 0.9622 - val_loss: 0.6756 - val_acc: 0.8781\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1320 - acc: 0.9644 - val_loss: 0.7201 - val_acc: 0.8922\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1322 - acc: 0.9649 - val_loss: 0.6319 - val_acc: 0.8956\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1462 - acc: 0.9631 - val_loss: 0.6855 - val_acc: 0.8874\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1230 - acc: 0.9641 - val_loss: 0.6556 - val_acc: 0.8979\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1242 - acc: 0.9648 - val_loss: 0.8174 - val_acc: 0.8799\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1297 - acc: 0.9650 - val_loss: 0.6533 - val_acc: 0.8927\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1294 - acc: 0.9655 - val_loss: 0.6954 - val_acc: 0.8961\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1282 - acc: 0.9658 - val_loss: 0.6566 - val_acc: 0.8945\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1196 - acc: 0.9661 - val_loss: 0.6709 - val_acc: 0.8934\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1266 - acc: 0.9668 - val_loss: 0.6964 - val_acc: 0.8893\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1189 - acc: 0.9662 - val_loss: 0.6439 - val_acc: 0.9001\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1196 - acc: 0.9665 - val_loss: 0.8348 - val_acc: 0.8853\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1288 - acc: 0.9653 - val_loss: 0.6714 - val_acc: 0.8930\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1276 - acc: 0.9656 - val_loss: 0.7356 - val_acc: 0.8716\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1314 - acc: 0.9654 - val_loss: 0.8513 - val_acc: 0.8727\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1328 - acc: 0.9657 - val_loss: 0.6380 - val_acc: 0.8987\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1335 - acc: 0.9665 - val_loss: 0.8831 - val_acc: 0.8770\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1316 - acc: 0.9662 - val_loss: 0.6957 - val_acc: 0.8992\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1333 - acc: 0.9663 - val_loss: 0.7619 - val_acc: 0.8853\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1237 - acc: 0.9680 - val_loss: 0.9669 - val_acc: 0.8676\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1301 - acc: 0.9685 - val_loss: 0.6338 - val_acc: 0.8766\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1138 - acc: 0.9686 - val_loss: 0.8270 - val_acc: 0.8872\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1209 - acc: 0.9694 - val_loss: 0.6571 - val_acc: 0.8959\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1073 - acc: 0.9705 - val_loss: 0.7257 - val_acc: 0.8912\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1054 - acc: 0.9695 - val_loss: 0.8864 - val_acc: 0.8803\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1167 - acc: 0.9701 - val_loss: 0.7396 - val_acc: 0.8973\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1201 - acc: 0.9692 - val_loss: 0.7210 - val_acc: 0.8926\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1070 - acc: 0.9713 - val_loss: 0.9020 - val_acc: 0.8785\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1204 - acc: 0.9674 - val_loss: 0.6754 - val_acc: 0.8942\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1168 - acc: 0.9725 - val_loss: 0.7114 - val_acc: 0.8923\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1171 - acc: 0.9700 - val_loss: 0.7878 - val_acc: 0.8901\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1073 - acc: 0.9711 - val_loss: 0.8477 - val_acc: 0.8918\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1066 - acc: 0.9717 - val_loss: 0.9319 - val_acc: 0.8838\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1061 - acc: 0.9709 - val_loss: 0.9128 - val_acc: 0.8861\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1284 - acc: 0.9698 - val_loss: 0.7675 - val_acc: 0.8917\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1101 - acc: 0.9714 - val_loss: 0.8249 - val_acc: 0.8714\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1188 - acc: 0.9695 - val_loss: 0.9051 - val_acc: 0.8871\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1145 - acc: 0.9715 - val_loss: 0.8439 - val_acc: 0.8819\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1036 - acc: 0.9733 - val_loss: 0.7941 - val_acc: 0.8948\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1160 - acc: 0.9724 - val_loss: 0.7807 - val_acc: 0.8914\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1099 - acc: 0.9728 - val_loss: 0.7686 - val_acc: 0.8970\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1121 - acc: 0.9711 - val_loss: 0.8216 - val_acc: 0.8873\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1063 - acc: 0.9722 - val_loss: 0.7484 - val_acc: 0.8958\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1013 - acc: 0.9720 - val_loss: 0.7688 - val_acc: 0.8954\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1088 - acc: 0.9730 - val_loss: 0.9482 - val_acc: 0.8787\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1107 - acc: 0.9730 - val_loss: 0.7753 - val_acc: 0.8953\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.0942 - acc: 0.9748 - val_loss: 0.7882 - val_acc: 0.8994\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1102 - acc: 0.9730 - val_loss: 0.7265 - val_acc: 0.8952\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1310 - acc: 0.9704 - val_loss: 0.7706 - val_acc: 0.8979\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1157 - acc: 0.9731 - val_loss: 0.8169 - val_acc: 0.8824\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1101 - acc: 0.9728 - val_loss: 0.8843 - val_acc: 0.8885\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1043 - acc: 0.9741 - val_loss: 0.7981 - val_acc: 0.8967\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0970 - acc: 0.9747 - val_loss: 0.7826 - val_acc: 0.8924\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.0889 - acc: 0.9767 - val_loss: 0.7756 - val_acc: 0.8911\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1040 - acc: 0.9744 - val_loss: 0.8423 - val_acc: 0.8861\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1007 - acc: 0.9740 - val_loss: 0.7728 - val_acc: 0.8978\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1108 - acc: 0.9742 - val_loss: 0.7734 - val_acc: 0.8864\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1194 - acc: 0.9726 - val_loss: 0.8112 - val_acc: 0.8951\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1070 - acc: 0.9749 - val_loss: 0.8048 - val_acc: 0.8882\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0996 - acc: 0.9751 - val_loss: 0.7607 - val_acc: 0.8959\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0993 - acc: 0.9758 - val_loss: 0.9114 - val_acc: 0.8788\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1076 - acc: 0.9752 - val_loss: 0.9628 - val_acc: 0.8916\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1153 - acc: 0.9729 - val_loss: 0.7986 - val_acc: 0.8985\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1001 - acc: 0.9751 - val_loss: 0.8672 - val_acc: 0.8816\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0986 - acc: 0.9762 - val_loss: 0.7547 - val_acc: 0.8922\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0968 - acc: 0.9756 - val_loss: 0.8353 - val_acc: 0.8927\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1091 - acc: 0.9754 - val_loss: 0.9748 - val_acc: 0.8887\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1215 - acc: 0.9749 - val_loss: 0.8115 - val_acc: 0.8836\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1242 - acc: 0.9731 - val_loss: 0.9023 - val_acc: 0.8764\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1119 - acc: 0.9748 - val_loss: 0.7872 - val_acc: 0.8909\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1096 - acc: 0.9755 - val_loss: 0.9751 - val_acc: 0.8768\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1076 - acc: 0.9752 - val_loss: 0.8777 - val_acc: 0.8924\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1038 - acc: 0.9771 - val_loss: 1.1500 - val_acc: 0.8684\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1059 - acc: 0.9770 - val_loss: 0.8288 - val_acc: 0.8946\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0960 - acc: 0.9776 - val_loss: 0.9334 - val_acc: 0.8749\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0974 - acc: 0.9779 - val_loss: 1.0487 - val_acc: 0.8894\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1319 - acc: 0.9726 - val_loss: 0.9272 - val_acc: 0.8874\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1037 - acc: 0.9770 - val_loss: 0.8385 - val_acc: 0.8939\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0998 - acc: 0.9768 - val_loss: 0.9080 - val_acc: 0.8820\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0946 - acc: 0.9782 - val_loss: 0.7849 - val_acc: 0.8947\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1030 - acc: 0.9784 - val_loss: 0.9043 - val_acc: 0.8959\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1245 - acc: 0.9755 - val_loss: 0.8815 - val_acc: 0.8906\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1073 - acc: 0.9771 - val_loss: 0.9725 - val_acc: 0.8728\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0932 - acc: 0.9781 - val_loss: 0.9313 - val_acc: 0.8871\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1066 - acc: 0.9782 - val_loss: 0.8407 - val_acc: 0.8882\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1160 - acc: 0.9773 - val_loss: 1.0237 - val_acc: 0.8857\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1129 - acc: 0.9762 - val_loss: 0.8783 - val_acc: 0.8858\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0993 - acc: 0.9780 - val_loss: 0.8451 - val_acc: 0.8960\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1109 - acc: 0.9773 - val_loss: 0.8857 - val_acc: 0.8936\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1100 - acc: 0.9785 - val_loss: 0.8216 - val_acc: 0.8882\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1084 - acc: 0.9777 - val_loss: 0.8255 - val_acc: 0.8941\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1066 - acc: 0.9779 - val_loss: 0.8223 - val_acc: 0.8950\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1135 - acc: 0.9781 - val_loss: 0.8496 - val_acc: 0.8885\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0974 - acc: 0.9780 - val_loss: 0.8223 - val_acc: 0.8930\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1065 - acc: 0.9782 - val_loss: 1.0159 - val_acc: 0.8817\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1192 - acc: 0.9762 - val_loss: 0.8364 - val_acc: 0.8940\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.0960 - acc: 0.9792 - val_loss: 0.9805 - val_acc: 0.8916\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1043 - acc: 0.9776 - val_loss: 1.0594 - val_acc: 0.8680\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1043 - acc: 0.9783 - val_loss: 0.8650 - val_acc: 0.8992\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.8476 - acc: 0.6853 - val_loss: 0.8296 - val_acc: 0.7286\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.5070 - acc: 0.8156 - val_loss: 0.5272 - val_acc: 0.8071\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.4219 - acc: 0.8453 - val_loss: 0.4329 - val_acc: 0.8355\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3851 - acc: 0.8587 - val_loss: 0.4655 - val_acc: 0.8482\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3539 - acc: 0.8721 - val_loss: 0.5222 - val_acc: 0.8149\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3404 - acc: 0.8791 - val_loss: 0.4902 - val_acc: 0.8198\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3183 - acc: 0.8852 - val_loss: 0.5834 - val_acc: 0.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3112 - acc: 0.8875 - val_loss: 0.4238 - val_acc: 0.8701\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3011 - acc: 0.8903 - val_loss: 0.3532 - val_acc: 0.8760\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3009 - acc: 0.8955 - val_loss: 0.3287 - val_acc: 0.8848\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2838 - acc: 0.8982 - val_loss: 0.4667 - val_acc: 0.8524\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2852 - acc: 0.8985 - val_loss: 0.4008 - val_acc: 0.8634\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2775 - acc: 0.9019 - val_loss: 0.3713 - val_acc: 0.8804\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2751 - acc: 0.9009 - val_loss: 0.4283 - val_acc: 0.8510\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2773 - acc: 0.9026 - val_loss: 0.4352 - val_acc: 0.8656\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2686 - acc: 0.9074 - val_loss: 0.5011 - val_acc: 0.8432\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2668 - acc: 0.9068 - val_loss: 0.3889 - val_acc: 0.8738\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2620 - acc: 0.9072 - val_loss: 0.3603 - val_acc: 0.8895\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2603 - acc: 0.9096 - val_loss: 0.8839 - val_acc: 0.8596\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2644 - acc: 0.9101 - val_loss: 0.4879 - val_acc: 0.8691\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2520 - acc: 0.9112 - val_loss: 0.4961 - val_acc: 0.8593\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2564 - acc: 0.9124 - val_loss: 0.4554 - val_acc: 0.8741\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2463 - acc: 0.9133 - val_loss: 0.4407 - val_acc: 0.8756\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2457 - acc: 0.9161 - val_loss: 0.4365 - val_acc: 0.8696\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2410 - acc: 0.9159 - val_loss: 0.5030 - val_acc: 0.8533\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2430 - acc: 0.9161 - val_loss: 0.4719 - val_acc: 0.8785\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2430 - acc: 0.9185 - val_loss: 0.4798 - val_acc: 0.8818\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2443 - acc: 0.9188 - val_loss: 0.5673 - val_acc: 0.8758\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2433 - acc: 0.9205 - val_loss: 0.4006 - val_acc: 0.8856\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2390 - acc: 0.9210 - val_loss: 0.4460 - val_acc: 0.8865\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2374 - acc: 0.9223 - val_loss: 0.4806 - val_acc: 0.8831\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2417 - acc: 0.9222 - val_loss: 0.4477 - val_acc: 0.8771\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2535 - acc: 0.9226 - val_loss: 0.4953 - val_acc: 0.8738\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2299 - acc: 0.9244 - val_loss: 0.5935 - val_acc: 0.8718\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.2326 - acc: 0.9255 - val_loss: 0.4773 - val_acc: 0.8879\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2396 - acc: 0.9265 - val_loss: 0.4930 - val_acc: 0.8895\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2410 - acc: 0.9253 - val_loss: 0.4435 - val_acc: 0.8949\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2236 - acc: 0.9293 - val_loss: 0.5354 - val_acc: 0.8693\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2267 - acc: 0.9271 - val_loss: 0.5449 - val_acc: 0.8324\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2487 - acc: 0.9292 - val_loss: 0.4517 - val_acc: 0.8905\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2119 - acc: 0.9319 - val_loss: 0.5253 - val_acc: 0.8842\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2281 - acc: 0.9296 - val_loss: 0.6178 - val_acc: 0.8526\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2208 - acc: 0.9307 - val_loss: 0.4547 - val_acc: 0.8869\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2151 - acc: 0.9319 - val_loss: 0.7324 - val_acc: 0.8596\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2161 - acc: 0.9330 - val_loss: 0.4499 - val_acc: 0.8910\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2245 - acc: 0.9329 - val_loss: 0.4771 - val_acc: 0.8833\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2155 - acc: 0.9337 - val_loss: 0.5343 - val_acc: 0.8792\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2160 - acc: 0.9333 - val_loss: 0.4564 - val_acc: 0.8818\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2105 - acc: 0.9341 - val_loss: 0.5290 - val_acc: 0.8875\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2076 - acc: 0.9368 - val_loss: 0.8101 - val_acc: 0.8677\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2191 - acc: 0.9364 - val_loss: 0.5438 - val_acc: 0.8961\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2199 - acc: 0.9374 - val_loss: 0.6356 - val_acc: 0.8753\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2448 - acc: 0.9343 - val_loss: 0.6150 - val_acc: 0.8831\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2395 - acc: 0.9358 - val_loss: 0.9109 - val_acc: 0.8317\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2179 - acc: 0.9357 - val_loss: 0.6023 - val_acc: 0.8813\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2178 - acc: 0.9358 - val_loss: 0.5053 - val_acc: 0.8828\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1961 - acc: 0.9397 - val_loss: 0.5583 - val_acc: 0.8891\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2039 - acc: 0.9395 - val_loss: 0.5037 - val_acc: 0.8866\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1945 - acc: 0.9410 - val_loss: 0.5614 - val_acc: 0.8718\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1994 - acc: 0.9411 - val_loss: 0.5436 - val_acc: 0.8902\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2441 - acc: 0.9359 - val_loss: 0.6929 - val_acc: 0.8626\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2065 - acc: 0.9387 - val_loss: 0.6114 - val_acc: 0.8922\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1900 - acc: 0.9404 - val_loss: 1.0135 - val_acc: 0.8429\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2003 - acc: 0.9432 - val_loss: 0.6164 - val_acc: 0.8883\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1978 - acc: 0.9398 - val_loss: 0.5606 - val_acc: 0.8899\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1890 - acc: 0.9435 - val_loss: 0.5984 - val_acc: 0.8909\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1893 - acc: 0.9438 - val_loss: 0.7666 - val_acc: 0.8788\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1944 - acc: 0.9432 - val_loss: 0.6582 - val_acc: 0.8904\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2524 - acc: 0.9416 - val_loss: 0.4827 - val_acc: 0.8918\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2050 - acc: 0.9457 - val_loss: 0.6983 - val_acc: 0.8663\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2095 - acc: 0.9445 - val_loss: 0.8538 - val_acc: 0.8629\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2208 - acc: 0.9434 - val_loss: 0.7431 - val_acc: 0.8575\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1938 - acc: 0.9458 - val_loss: 0.5558 - val_acc: 0.8968\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2594 - acc: 0.9421 - val_loss: 0.6132 - val_acc: 0.8936\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2080 - acc: 0.9451 - val_loss: 0.7295 - val_acc: 0.8719\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1865 - acc: 0.9483 - val_loss: 0.5885 - val_acc: 0.8823\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1816 - acc: 0.9483 - val_loss: 0.7235 - val_acc: 0.8793\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1778 - acc: 0.9478 - val_loss: 0.7839 - val_acc: 0.8749\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1768 - acc: 0.9499 - val_loss: 0.5864 - val_acc: 0.8948\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1905 - acc: 0.9461 - val_loss: 0.6621 - val_acc: 0.8876\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1813 - acc: 0.9505 - val_loss: 0.7056 - val_acc: 0.8331\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1789 - acc: 0.9495 - val_loss: 0.5719 - val_acc: 0.8959\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1729 - acc: 0.9513 - val_loss: 0.6182 - val_acc: 0.8856\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1807 - acc: 0.9485 - val_loss: 0.7773 - val_acc: 0.8805\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1786 - acc: 0.9494 - val_loss: 0.6478 - val_acc: 0.8911\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2006 - acc: 0.9488 - val_loss: 0.6016 - val_acc: 0.8796\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1867 - acc: 0.9493 - val_loss: 0.8555 - val_acc: 0.8700\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1926 - acc: 0.9513 - val_loss: 0.7488 - val_acc: 0.8916\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1979 - acc: 0.9521 - val_loss: 0.6680 - val_acc: 0.8876\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2452 - acc: 0.9489 - val_loss: 0.6826 - val_acc: 0.8897\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2134 - acc: 0.9502 - val_loss: 0.6838 - val_acc: 0.8857\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2555 - acc: 0.9456 - val_loss: 0.8004 - val_acc: 0.8836\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2194 - acc: 0.9461 - val_loss: 0.6567 - val_acc: 0.8787\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1995 - acc: 0.9482 - val_loss: 0.6683 - val_acc: 0.8893\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1860 - acc: 0.9523 - val_loss: 0.6493 - val_acc: 0.8908\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2118 - acc: 0.9515 - val_loss: 0.8829 - val_acc: 0.8384\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2015 - acc: 0.9506 - val_loss: 0.6684 - val_acc: 0.8857\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2007 - acc: 0.9504 - val_loss: 0.6747 - val_acc: 0.8933\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2050 - acc: 0.9515 - val_loss: 0.6206 - val_acc: 0.8903\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2401 - acc: 0.9492 - val_loss: 0.6737 - val_acc: 0.8882\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1868 - acc: 0.9516 - val_loss: 0.8136 - val_acc: 0.8802\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2407 - acc: 0.9498 - val_loss: 0.6345 - val_acc: 0.8901\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1785 - acc: 0.9553 - val_loss: 0.8075 - val_acc: 0.8737\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2288 - acc: 0.9513 - val_loss: 0.7713 - val_acc: 0.8742\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1976 - acc: 0.9541 - val_loss: 0.8333 - val_acc: 0.8902\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1988 - acc: 0.9545 - val_loss: 0.9992 - val_acc: 0.8546\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2172 - acc: 0.9537 - val_loss: 0.7379 - val_acc: 0.8889\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2328 - acc: 0.9528 - val_loss: 0.8209 - val_acc: 0.8868\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2292 - acc: 0.9509 - val_loss: 0.6804 - val_acc: 0.8945\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1932 - acc: 0.9552 - val_loss: 0.6875 - val_acc: 0.8892\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2839 - acc: 0.9515 - val_loss: 0.9952 - val_acc: 0.8418\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2072 - acc: 0.9553 - val_loss: 0.7841 - val_acc: 0.8920\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2397 - acc: 0.9515 - val_loss: 0.9847 - val_acc: 0.8622\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2428 - acc: 0.9511 - val_loss: 0.7871 - val_acc: 0.8873\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2312 - acc: 0.9533 - val_loss: 0.8514 - val_acc: 0.8685\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1853 - acc: 0.9562 - val_loss: 0.6933 - val_acc: 0.8976\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2183 - acc: 0.9542 - val_loss: 0.8116 - val_acc: 0.8872\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1990 - acc: 0.9558 - val_loss: 0.7613 - val_acc: 0.8863\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1992 - acc: 0.9573 - val_loss: 0.9298 - val_acc: 0.8875\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2271 - acc: 0.9537 - val_loss: 0.9499 - val_acc: 0.8745\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2146 - acc: 0.9560 - val_loss: 0.7140 - val_acc: 0.8877\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2022 - acc: 0.9562 - val_loss: 0.8503 - val_acc: 0.8803\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1944 - acc: 0.9589 - val_loss: 0.8765 - val_acc: 0.8751\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1903 - acc: 0.9586 - val_loss: 0.9445 - val_acc: 0.8662\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2166 - acc: 0.9579 - val_loss: 0.9609 - val_acc: 0.8789\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2167 - acc: 0.9567 - val_loss: 0.6640 - val_acc: 0.8880\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2120 - acc: 0.9580 - val_loss: 0.8648 - val_acc: 0.8855\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2055 - acc: 0.9567 - val_loss: 0.7997 - val_acc: 0.8852\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1981 - acc: 0.9602 - val_loss: 0.8235 - val_acc: 0.8935\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1980 - acc: 0.9592 - val_loss: 0.8297 - val_acc: 0.8944\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2046 - acc: 0.9571 - val_loss: 0.8088 - val_acc: 0.8810\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2026 - acc: 0.9584 - val_loss: 0.8474 - val_acc: 0.8911\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2066 - acc: 0.9596 - val_loss: 0.8938 - val_acc: 0.8815\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3100 - acc: 0.9506 - val_loss: 0.8704 - val_acc: 0.8911\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2422 - acc: 0.9564 - val_loss: 0.8290 - val_acc: 0.8736\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2574 - acc: 0.9563 - val_loss: 0.7695 - val_acc: 0.8879\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2497 - acc: 0.9541 - val_loss: 0.8971 - val_acc: 0.8814\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2320 - acc: 0.9575 - val_loss: 0.8542 - val_acc: 0.8822\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2396 - acc: 0.9550 - val_loss: 0.7512 - val_acc: 0.8920\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3292 - acc: 0.9526 - val_loss: 0.8901 - val_acc: 0.8865\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2672 - acc: 0.9554 - val_loss: 0.9201 - val_acc: 0.8902\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2848 - acc: 0.9559 - val_loss: 0.9948 - val_acc: 0.8768\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3616 - acc: 0.9476 - val_loss: 0.9350 - val_acc: 0.8838\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3013 - acc: 0.9505 - val_loss: 0.9332 - val_acc: 0.8733\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2901 - acc: 0.9542 - val_loss: 0.9545 - val_acc: 0.8741\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3178 - acc: 0.9525 - val_loss: 0.9935 - val_acc: 0.8776\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2795 - acc: 0.9537 - val_loss: 0.8693 - val_acc: 0.8891\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2610 - acc: 0.9548 - val_loss: 1.1826 - val_acc: 0.8705\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3425 - acc: 0.9489 - val_loss: 0.9200 - val_acc: 0.8868\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2867 - acc: 0.9527 - val_loss: 0.9249 - val_acc: 0.8825\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3132 - acc: 0.9533 - val_loss: 1.0507 - val_acc: 0.8757\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3163 - acc: 0.9530 - val_loss: 1.0743 - val_acc: 0.8427\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3089 - acc: 0.9509 - val_loss: 1.1254 - val_acc: 0.8580\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3184 - acc: 0.9522 - val_loss: 0.7628 - val_acc: 0.8796\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3064 - acc: 0.9547 - val_loss: 1.0975 - val_acc: 0.8760\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3736 - acc: 0.9501 - val_loss: 0.9501 - val_acc: 0.8769\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3281 - acc: 0.9539 - val_loss: 1.0432 - val_acc: 0.8772\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2967 - acc: 0.9536 - val_loss: 0.9095 - val_acc: 0.8781\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3119 - acc: 0.9549 - val_loss: 0.9755 - val_acc: 0.8834\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3919 - acc: 0.9502 - val_loss: 0.9674 - val_acc: 0.8852\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3642 - acc: 0.9483 - val_loss: 0.9211 - val_acc: 0.8864\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2961 - acc: 0.9552 - val_loss: 0.9135 - val_acc: 0.8336\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2725 - acc: 0.9574 - val_loss: 1.1500 - val_acc: 0.8704\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3000 - acc: 0.9541 - val_loss: 0.8844 - val_acc: 0.8837\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.2526 - acc: 0.9594 - val_loss: 0.9369 - val_acc: 0.8837\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3027 - acc: 0.9560 - val_loss: 0.8625 - val_acc: 0.8848\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3963 - acc: 0.9491 - val_loss: 0.8852 - val_acc: 0.8852\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.2628 - acc: 0.9594 - val_loss: 1.2544 - val_acc: 0.8581\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2861 - acc: 0.9556 - val_loss: 0.8384 - val_acc: 0.8907\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3022 - acc: 0.9529 - val_loss: 0.9803 - val_acc: 0.8570\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2839 - acc: 0.9567 - val_loss: 0.8328 - val_acc: 0.8819\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3069 - acc: 0.9543 - val_loss: 1.0226 - val_acc: 0.8767\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3481 - acc: 0.9514 - val_loss: 1.0975 - val_acc: 0.8778\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3770 - acc: 0.9498 - val_loss: 0.9942 - val_acc: 0.8794\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3323 - acc: 0.9529 - val_loss: 0.9616 - val_acc: 0.8634\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2984 - acc: 0.9540 - val_loss: 1.0633 - val_acc: 0.8579\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3565 - acc: 0.9513 - val_loss: 0.9032 - val_acc: 0.8774\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3134 - acc: 0.9565 - val_loss: 0.8413 - val_acc: 0.8893\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2667 - acc: 0.9602 - val_loss: 0.9678 - val_acc: 0.8689\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3013 - acc: 0.9569 - val_loss: 0.9913 - val_acc: 0.8806\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2488 - acc: 0.9583 - val_loss: 1.7570 - val_acc: 0.8423\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3160 - acc: 0.9559 - val_loss: 0.9932 - val_acc: 0.8854\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2157 - acc: 0.9631 - val_loss: 0.9254 - val_acc: 0.8764\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3202 - acc: 0.9561 - val_loss: 0.9009 - val_acc: 0.8874\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2366 - acc: 0.9621 - val_loss: 0.8860 - val_acc: 0.8816\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2582 - acc: 0.9598 - val_loss: 0.8063 - val_acc: 0.8808\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2504 - acc: 0.9625 - val_loss: 0.9548 - val_acc: 0.8819\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2934 - acc: 0.9572 - val_loss: 1.2933 - val_acc: 0.8638\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3716 - acc: 0.9472 - val_loss: 0.8008 - val_acc: 0.8845\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3209 - acc: 0.9570 - val_loss: 0.8575 - val_acc: 0.8859\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3674 - acc: 0.9544 - val_loss: 0.8786 - val_acc: 0.8916\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3525 - acc: 0.9537 - val_loss: 0.9641 - val_acc: 0.8688\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3081 - acc: 0.9536 - val_loss: 0.9193 - val_acc: 0.8765\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3465 - acc: 0.9519 - val_loss: 1.1659 - val_acc: 0.8797\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.4459 - acc: 0.9511 - val_loss: 1.2212 - val_acc: 0.8818\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3059 - acc: 0.9527 - val_loss: 0.8940 - val_acc: 0.8713\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3161 - acc: 0.9538 - val_loss: 0.9014 - val_acc: 0.8737\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3054 - acc: 0.9547 - val_loss: 0.8830 - val_acc: 0.8804\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.4131 - acc: 0.9512 - val_loss: 1.1283 - val_acc: 0.8568\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3252 - acc: 0.9505 - val_loss: 1.2567 - val_acc: 0.8531\n"
     ]
    }
   ],
   "source": [
    "#Alter the number of layers on batch size 256\n",
    "# 3 Layers\n",
    "model_layer3 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# 5 Layers \n",
    "model_layer5 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# 7 Layers\n",
    "model_layer7 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compile Model\n",
    "model_layer3.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_layer5.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_layer7.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_layer3 = model_layer3.fit(X_train, Y_train, batch_size = 256, epochs=200, validation_data = (X_val, Y_val))\n",
    "track_layer5 = model_layer5.fit(X_train, Y_train, batch_size = 256, epochs=200, validation_data = (X_val, Y_val))\n",
    "track_layer7 = model_layer7.fit(X_train, Y_train, batch_size = 256, epochs=200, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Validation Loss from keras callback history\n",
    "layer3_metrics = track_layer3.history\n",
    "layer3_loss = layer3_metrics['val_loss']\n",
    "\n",
    "layer5_metrics = track_layer5.history\n",
    "layer5_loss = layer5_metrics['val_loss']\n",
    "\n",
    "layer7_metrics = track_layer.history\n",
    "layer7_loss = layer7_metrics['val_loss']\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, layer3_loss, 'b', label = \"3 layers\")\n",
    "plt.plot(epochs, layer5_loss, 'r', label = \"5 layers\")\n",
    "plt.plot(epochs, layer7_loss, 'g', label = \"7 layers\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss for Varying Layers with batch size 256\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_estimate(metric_list):\n",
    "    min_val = min(metric_list)\n",
    "    best_iter = metric_list.index(min_val)\n",
    "    return (min_val, best_iter + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Best Estimate of Each Model\n",
    "(layer3_min, layer3_best) = best_estimate(layer3_loss)\n",
    "(layer5_min, layer5_best) = best_estimate(layer5_loss)\n",
    "(layer7_min, layer7_best) = best_estimate(layer7_loss)\n",
    "\n",
    "print(layer3_min, layer5_min, layer7_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare 5 layers with batch size 512 vs batch size 256\n",
    "\n",
    "Of the varying layers 3, 5, 7: the best model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Varying Dropout Rate: constant 0.5, constant 0.8, varying from 0.9 - 0.3\n",
    "model_DRpt5 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_DRpt8 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model_DRvar = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dropout(0.9),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.8),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.7),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "model_DRpt5.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_DRpt8.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_DRvar.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_DRpt5 = model_DRpt5.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))\n",
    "track_DRpt8 = model_DRpt8.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))\n",
    "track_DRvar = model_DRvar.fit(X_train, Y_train, batch_size = 512, epochs=200, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Validation Loss from keras callback history\n",
    "DRpt5_metrics = track_DRpt5.history\n",
    "DRpt5_loss = DRpt5_metrics['val_loss']\n",
    "\n",
    "DRpt8_metrics = track_DRpt8.history\n",
    "DRpt8_loss = DRpt8_metrics['val_loss']\n",
    "\n",
    "DRvar_metrics = track_DRvar.history\n",
    "DRvar_loss = DRvar_metrics['val_loss']\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, DRpt5_loss, 'b', label = \"dropout rate of 0.5\")\n",
    "plt.plot(epochs, DRpt8_loss, 'r', label = \"dropout rate of 0.8\")\n",
    "plt.plot(epochs, DRvar_loss, 'g', label = \"dropout rate 0.9 to 0.4\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss for Varying Dropout Rate with batch size 512\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Best Estimate of Each Model\n",
    "(pt5_min, pt5_best) = best_estimate(DRpt5_loss)\n",
    "(pt8_min, pt8_best) = best_estimate(DRpt8_loss)\n",
    "(var_min, var_best) = best_estimate(DRvar_loss)\n",
    "\n",
    "print(pt5_min, pt8_min, var_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison: Of the threee models that vary the dropout rate by 0.5, 0.8 and range 0.9 to 0.4 on seven layered model with batch size 512 and epochs 200, the best performing model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying Epochs - 100, 300, 500 on Initial Model\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(28 * 28,)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_ep100 = model.fit(X_train, Y_train, batch_size = 512, epochs=100, validation_data = (X_val, Y_val))\n",
    "track_ep300 = model.fit(X_train, Y_train, batch_size = 512, epochs=300, validation_data = (X_val, Y_val))\n",
    "track_ep500 = model.fit(X_train, Y_train, batch_size = 512, epochs=500, validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Accuracy and Loss from keras callback history\n",
    "ep100_metrics = track_ep100.history\n",
    "ep100_loss = ep100_metrics['val_loss']\n",
    "epochs_100 = numpy.arange(1, len(ep100_loss)+1)\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs_100, ep100_loss, 'b', label = \"Epoch = 100\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss with 100 Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "ep300_metrics = track_ep300.history\n",
    "ep300_loss = ep300_metrics['val_loss']\n",
    "epochs_300 = numpy.arange(1, len(ep300_loss)+1)\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs_300, ep300_loss, 'r', label = \"Epoch = 300\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss with 300 Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "ep500_metrics = track_ep500.history\n",
    "ep500_loss = ep500_metrics['val_loss']\n",
    "epochs_500 = numpy.arange(1, len(ep500_loss)+1)\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs_500, ep500_loss, 'g', label = \"Epoch = 500\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss with 500 Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Best Estimate of Each Model\n",
    "(ep100_min, ep100_best) = best_estimate(ep100_loss)\n",
    "(ep300_min, ep300_best) = best_estimate(ep300_loss)\n",
    "(ep500_min, ep500_best) = best_estimate(ep500_loss)\n",
    "\n",
    "print(ep100_min, ep300_min, ep500_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Weight - L2 with lower number of epochs\n",
    "model_L2 = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer = regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#Compile Model\n",
    "model_L2.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_L2 = model_L2.fit(X_train, Y_train, batch_size = 512, epochs=50, validation_data = (X_val, Y_val))\n",
    "\n",
    "#Extract Validation Loss from keras callback history\n",
    "L1_metrics = track_L1.history\n",
    "L1_loss = L1_metrics['val_loss']\n",
    "\n",
    "L2_metrics = track_L2.history\n",
    "L2_loss = L2_metrics['val_loss']\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, dropout_loss, 'b', label = \"dropout\")\n",
    "plt.plot(epochs, val_loss, 'r', label = \"initial\")\n",
    "plt.plot(epochs, l1_loss, 'g', label = \"l1 reg\")\n",
    "plt.plot(epochs, l2_loss, 'm', label = \"l2 reg\")\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss over Range of Epochs with Dropout and Regularization\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternate models were compared by varying epoch, layers, changing dropout and adding weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "model_final.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train Model and Track Accuracy\n",
    "track_final = model_final.fit(x_train_full, y_train_full, batch_size = 512, epochs=200, validation_data = (x_test_final, Y_test_final))\n",
    "\n",
    "#Evaluate Best Model\n",
    "model_final.evaluate(x_final_test, y_final_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
