{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10) (50000, 784) (50000, 10) (10000, 784) (10000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#transform image data into 2d-tensor\n",
    "x_train = x_train.reshape((60000, 28*28))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "x_test = x_test.reshape((10000, 28*28))\n",
    "x_test = x_test.astype('float32')/ 255\n",
    "\n",
    "#make y categorical type\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#split train set into train sand validation\n",
    "x_train_50000, x_val, y_train_50000, y_val = train_test_split(x_train, y_train, test_size = 1/6, random_state = 1)\n",
    "\n",
    "#check shapes\n",
    "print(x_train.shape, y_train.shape, \n",
    "      x_train_50000.shape, y_train_50000.shape,\n",
    "      x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 \n",
    "\n",
    "#initialize sequential models with 5 layers + 512 hidden units for each layer\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_1.add(layers.Dense(512, activation = 'relu'))\n",
    "model_1.add(layers.Dense(512, activation = 'relu'))\n",
    "model_1.add(layers.Dense(512, activation = 'relu'))\n",
    "model_1.add(layers.Dense(512, activation = 'relu'))\n",
    "model_1.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_1.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_1 = model_1.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_2.add(layers.Dense(512, activation = 'relu'))\n",
    "model_2.add(layers.Dense(512, activation = 'relu'))\n",
    "model_2.add(layers.Dense(512, activation = 'relu'))\n",
    "model_2.add(layers.Dense(512, activation = 'relu'))\n",
    "model_2.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_2.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_3.add(layers.Dense(512, activation = 'relu'))\n",
    "model_3.add(layers.Dense(512, activation = 'relu'))\n",
    "model_3.add(layers.Dense(512, activation = 'relu'))\n",
    "model_3.add(layers.Dense(512, activation = 'relu'))\n",
    "model_3.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_3.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_3 = model_3.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4\n",
    "model_4 = models.Sequential()\n",
    "model_4.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_4.add(layers.Dense(512, activation = 'relu'))\n",
    "model_4.add(layers.Dense(512, activation = 'relu'))\n",
    "model_4.add(layers.Dense(512, activation = 'relu'))\n",
    "model_4.add(layers.Dense(512, activation = 'relu'))\n",
    "model_4.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_4.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_4 = model_4.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5\n",
    "model_5 = models.Sequential()\n",
    "model_5.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_5.add(layers.Dense(512, activation = 'relu'))\n",
    "model_5.add(layers.Dense(512, activation = 'relu'))\n",
    "model_5.add(layers.Dense(512, activation = 'relu'))\n",
    "model_5.add(layers.Dense(512, activation = 'relu'))\n",
    "model_5.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_5.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_5 = model_5.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6\n",
    "model_6 = models.Sequential()\n",
    "model_6.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_6.add(layers.Dense(512, activation = 'relu'))\n",
    "model_6.add(layers.Dense(512, activation = 'relu'))\n",
    "model_6.add(layers.Dense(512, activation = 'relu'))\n",
    "model_6.add(layers.Dense(512, activation = 'relu'))\n",
    "model_6.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_6.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_6 = model_6.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 7\n",
    "model_7 = models.Sequential()\n",
    "model_7.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_7.add(layers.Dense(512, activation = 'relu'))\n",
    "model_7.add(layers.Dense(512, activation = 'relu'))\n",
    "model_7.add(layers.Dense(512, activation = 'relu'))\n",
    "model_7.add(layers.Dense(512, activation = 'relu'))\n",
    "model_7.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_7.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_7 = model_7.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8\n",
    "model_8 = models.Sequential()\n",
    "model_8.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_8.add(layers.Dense(512, activation = 'relu'))\n",
    "model_8.add(layers.Dense(512, activation = 'relu'))\n",
    "model_8.add(layers.Dense(512, activation = 'relu'))\n",
    "model_8.add(layers.Dense(512, activation = 'relu'))\n",
    "model_8.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_8.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_8 = model_8.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 9\n",
    "model_9 = models.Sequential()\n",
    "model_9.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_9.add(layers.Dense(512, activation = 'relu'))\n",
    "model_9.add(layers.Dense(512, activation = 'relu'))\n",
    "model_9.add(layers.Dense(512, activation = 'relu'))\n",
    "model_9.add(layers.Dense(512, activation = 'relu'))\n",
    "model_9.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_9.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_9 = model_9.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 10\n",
    "model_10 = models.Sequential()\n",
    "model_10.add(layers.Dense(512, activation = 'relu', input_shape=(784,)))\n",
    "model_10.add(layers.Dense(512, activation = 'relu'))\n",
    "model_10.add(layers.Dense(512, activation = 'relu'))\n",
    "model_10.add(layers.Dense(512, activation = 'relu'))\n",
    "model_10.add(layers.Dense(512, activation = 'relu'))\n",
    "model_10.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model_10.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_10 = model_10.fit(x_train_50000, y_train_50000, \n",
    "                    batch_size = 512, epochs = 200,\n",
    "                    validation_data = (x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
