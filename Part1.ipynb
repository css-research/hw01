{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspectives on Research\n",
    "## Homework 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Deep Learning\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import regularizers\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "#Tensor Flow\n",
    "import tensorflow as tf\n",
    "                    \n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Seed\n",
    "SEED= 1234\n",
    "import random\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# preprocess data to 2D tensors\n",
    "# convert to float and make the values between 0 and 1\n",
    "X_train = X_train.reshape([60000, 28*28]).astype('float32') / 255\n",
    "X_test = X_test.reshape([10000, 28*28]).astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#Splitting Training Data into Validation and Training\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=10000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Model\n",
    "baseline_model = Sequential()\n",
    "#Setting up 5 models\n",
    "baseline_model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "baseline_model.add(Dense(512, activation='relu'))\n",
    "baseline_model.add(Dense(512, activation='relu'))\n",
    "baseline_model.add(Dense(512, activation='relu'))\n",
    "baseline_model.add(Dense(10, activation='softmax'))\n",
    "baseline_model.compile(optimizer='rmsprop', \n",
    "                       loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.8692 - acc: 0.6823 - val_loss: 0.5185 - val_acc: 0.8104\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.5148 - acc: 0.8078 - val_loss: 0.5295 - val_acc: 0.8093\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.4360 - acc: 0.8377 - val_loss: 0.4083 - val_acc: 0.8464\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.3891 - acc: 0.8558 - val_loss: 0.4050 - val_acc: 0.8514\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.3517 - acc: 0.8690 - val_loss: 0.3546 - val_acc: 0.8652\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3320 - acc: 0.8745 - val_loss: 0.3437 - val_acc: 0.8719\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3082 - acc: 0.8837 - val_loss: 0.3503 - val_acc: 0.8699\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.2966 - acc: 0.8895 - val_loss: 0.3624 - val_acc: 0.8725\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.2822 - acc: 0.8917 - val_loss: 0.3609 - val_acc: 0.8703\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.2667 - acc: 0.8992 - val_loss: 0.3821 - val_acc: 0.8655\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2564 - acc: 0.9016 - val_loss: 0.3629 - val_acc: 0.8723\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.2507 - acc: 0.9040 - val_loss: 0.3232 - val_acc: 0.8856\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.2365 - acc: 0.9098 - val_loss: 0.4986 - val_acc: 0.8453\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.2298 - acc: 0.9135 - val_loss: 0.3398 - val_acc: 0.8874\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.2227 - acc: 0.9136 - val_loss: 0.3620 - val_acc: 0.8840\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2145 - acc: 0.9169 - val_loss: 0.3429 - val_acc: 0.8873\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.2159 - acc: 0.9175 - val_loss: 0.3352 - val_acc: 0.8847\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.2020 - acc: 0.9234 - val_loss: 0.3425 - val_acc: 0.8941\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2009 - acc: 0.9245 - val_loss: 0.3732 - val_acc: 0.8880\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.1915 - acc: 0.9267 - val_loss: 0.3739 - val_acc: 0.8931\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.1840 - acc: 0.9276 - val_loss: 0.4032 - val_acc: 0.8878\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1815 - acc: 0.9306 - val_loss: 0.3747 - val_acc: 0.8949\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.1857 - acc: 0.9305 - val_loss: 0.3881 - val_acc: 0.8963\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.1740 - acc: 0.9347 - val_loss: 0.3500 - val_acc: 0.8892\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.1704 - acc: 0.9348 - val_loss: 0.3981 - val_acc: 0.8914\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.1686 - acc: 0.9372 - val_loss: 0.4069 - val_acc: 0.8883\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.1637 - acc: 0.9379 - val_loss: 0.4263 - val_acc: 0.8950\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.1609 - acc: 0.9394 - val_loss: 0.4168 - val_acc: 0.8888\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.1598 - acc: 0.9402 - val_loss: 0.5195 - val_acc: 0.8704\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.1558 - acc: 0.9404 - val_loss: 0.4933 - val_acc: 0.8812\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.1582 - acc: 0.9402 - val_loss: 0.4013 - val_acc: 0.8966\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1555 - acc: 0.9427 - val_loss: 0.3862 - val_acc: 0.8975\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.1510 - acc: 0.9437 - val_loss: 0.4952 - val_acc: 0.8883\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.1444 - acc: 0.9454 - val_loss: 0.4583 - val_acc: 0.8906\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.1417 - acc: 0.9463 - val_loss: 0.4942 - val_acc: 0.8896\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.1467 - acc: 0.9456 - val_loss: 0.4415 - val_acc: 0.89720.1473 -\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.1407 - acc: 0.9472 - val_loss: 0.4598 - val_acc: 0.8960\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.1359 - acc: 0.9490 - val_loss: 0.4552 - val_acc: 0.8943\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1364 - acc: 0.9485 - val_loss: 0.4302 - val_acc: 0.8967\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.1332 - acc: 0.9505 - val_loss: 0.5084 - val_acc: 0.8715\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.1415 - acc: 0.9495 - val_loss: 0.5144 - val_acc: 0.8831\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.1241 - acc: 0.9526 - val_loss: 0.5349 - val_acc: 0.8937\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.1383 - acc: 0.9493 - val_loss: 0.4235 - val_acc: 0.8932\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.1360 - acc: 0.9516 - val_loss: 0.5789 - val_acc: 0.8921\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.1321 - acc: 0.9517 - val_loss: 0.4478 - val_acc: 0.8950\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.1376 - acc: 0.9505 - val_loss: 0.4292 - val_acc: 0.8971\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.1161 - acc: 0.9573 - val_loss: 0.5999 - val_acc: 0.8962\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.1280 - acc: 0.9543 - val_loss: 0.5662 - val_acc: 0.8986\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.1236 - acc: 0.9572 - val_loss: 0.6359 - val_acc: 0.8877\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.1253 - acc: 0.9546 - val_loss: 0.6085 - val_acc: 0.8811\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.1241 - acc: 0.9560 - val_loss: 0.4671 - val_acc: 0.8966\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.1209 - acc: 0.9557 - val_loss: 0.5483 - val_acc: 0.8948\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.1259 - acc: 0.9577 - val_loss: 0.5046 - val_acc: 0.8806\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.1150 - acc: 0.9580 - val_loss: 0.5830 - val_acc: 0.8980\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.1138 - acc: 0.9584 - val_loss: 0.5329 - val_acc: 0.8871\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.1172 - acc: 0.9602 - val_loss: 0.5614 - val_acc: 0.8915\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.1150 - acc: 0.9600 - val_loss: 0.5672 - val_acc: 0.8848\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.1169 - acc: 0.9603 - val_loss: 0.5544 - val_acc: 0.9010\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.1195 - acc: 0.9592 - val_loss: 0.4613 - val_acc: 0.8964\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.1064 - acc: 0.9621 - val_loss: 0.6457 - val_acc: 0.8815\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.1079 - acc: 0.9610 - val_loss: 0.6528 - val_acc: 0.8875\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.1116 - acc: 0.9606 - val_loss: 0.5118 - val_acc: 0.8951\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.1096 - acc: 0.9618 - val_loss: 0.5112 - val_acc: 0.9002\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.1055 - acc: 0.9620 - val_loss: 0.5933 - val_acc: 0.8956\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.1128 - acc: 0.9610 - val_loss: 0.6537 - val_acc: 0.8892\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.1082 - acc: 0.9629 - val_loss: 0.6424 - val_acc: 0.8909\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.1065 - acc: 0.9639 - val_loss: 0.6198 - val_acc: 0.8944\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.1126 - acc: 0.9624 - val_loss: 0.5434 - val_acc: 0.8950\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.1047 - acc: 0.9651 - val_loss: 0.5671 - val_acc: 0.9018\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0983 - acc: 0.9660 - val_loss: 0.7840 - val_acc: 0.8702\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1022 - acc: 0.9664 - val_loss: 0.6434 - val_acc: 0.8954\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.1036 - acc: 0.9649 - val_loss: 0.7157 - val_acc: 0.8810\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.1004 - acc: 0.9663 - val_loss: 0.6526 - val_acc: 0.8923\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.0983 - acc: 0.9660 - val_loss: 0.6222 - val_acc: 0.8971\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0952 - acc: 0.9662 - val_loss: 0.6538 - val_acc: 0.8893\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.1000 - acc: 0.9651 - val_loss: 0.5588 - val_acc: 0.8995\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0985 - acc: 0.9675 - val_loss: 0.5957 - val_acc: 0.8907\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0931 - acc: 0.9682 - val_loss: 0.5975 - val_acc: 0.8999\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.0869 - acc: 0.9693 - val_loss: 0.6779 - val_acc: 0.8979\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0988 - acc: 0.9674 - val_loss: 0.5798 - val_acc: 0.8952\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0861 - acc: 0.9706 - val_loss: 0.7406 - val_acc: 0.8942\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.0910 - acc: 0.9679 - val_loss: 0.6756 - val_acc: 0.8915\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.0983 - acc: 0.9678 - val_loss: 0.6652 - val_acc: 0.8759\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.0904 - acc: 0.9706 - val_loss: 0.7381 - val_acc: 0.8972\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.0944 - acc: 0.9693 - val_loss: 0.5762 - val_acc: 0.8977\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.0913 - acc: 0.9701 - val_loss: 0.6592 - val_acc: 0.8927\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.0863 - acc: 0.9710 - val_loss: 0.8559 - val_acc: 0.8879\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.0824 - acc: 0.9720 - val_loss: 0.7040 - val_acc: 0.8951\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.0955 - acc: 0.9700 - val_loss: 0.5787 - val_acc: 0.9013\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.0824 - acc: 0.9732 - val_loss: 0.5536 - val_acc: 0.8828\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.0851 - acc: 0.9706 - val_loss: 0.6640 - val_acc: 0.8975\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.0845 - acc: 0.9724 - val_loss: 0.6226 - val_acc: 0.8957\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.0922 - acc: 0.9709 - val_loss: 0.9151 - val_acc: 0.8851\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0904 - acc: 0.9725 - val_loss: 0.7462 - val_acc: 0.8945\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.0934 - acc: 0.9710 - val_loss: 0.7523 - val_acc: 0.8829\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.0814 - acc: 0.9738 - val_loss: 0.6775 - val_acc: 0.8935\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.0848 - acc: 0.9716 - val_loss: 0.6017 - val_acc: 0.8986\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.0834 - acc: 0.9732 - val_loss: 0.6626 - val_acc: 0.8933\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.0870 - acc: 0.9744 - val_loss: 0.6555 - val_acc: 0.8986\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.0895 - acc: 0.9737 - val_loss: 0.6900 - val_acc: 0.8921\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.0825 - acc: 0.9737 - val_loss: 0.7136 - val_acc: 0.8980\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0891 - acc: 0.9740 - val_loss: 0.7136 - val_acc: 0.8969\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.0835 - acc: 0.9756 - val_loss: 0.6919 - val_acc: 0.8986\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0814 - acc: 0.9745 - val_loss: 0.7320 - val_acc: 0.8948\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0789 - acc: 0.9762 - val_loss: 0.7817 - val_acc: 0.8929\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0887 - acc: 0.9733 - val_loss: 0.6806 - val_acc: 0.8872\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0824 - acc: 0.9752 - val_loss: 0.6940 - val_acc: 0.8967\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.0785 - acc: 0.9756 - val_loss: 0.6578 - val_acc: 0.8990\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.0763 - acc: 0.9755 - val_loss: 0.7541 - val_acc: 0.8984\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.0729 - acc: 0.9770 - val_loss: 0.6212 - val_acc: 0.8961\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.0772 - acc: 0.9760 - val_loss: 0.7067 - val_acc: 0.8971 1s - loss: 0.0771 - acc: 0.975 - ETA: \n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.0836 - acc: 0.9767 - val_loss: 0.8638 - val_acc: 0.8802\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.0810 - acc: 0.9766 - val_loss: 0.7058 - val_acc: 0.8929\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.0767 - acc: 0.9766 - val_loss: 0.7826 - val_acc: 0.8923\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.0833 - acc: 0.9767 - val_loss: 0.7117 - val_acc: 0.9060\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.0782 - acc: 0.9769 - val_loss: 0.7548 - val_acc: 0.8832\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.0688 - acc: 0.9782 - val_loss: 0.8243 - val_acc: 0.8862\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.0798 - acc: 0.9765 - val_loss: 0.6372 - val_acc: 0.8968\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.0771 - acc: 0.9774 - val_loss: 0.7640 - val_acc: 0.8997\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.0767 - acc: 0.9771 - val_loss: 0.6512 - val_acc: 0.9003\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.0738 - acc: 0.9773 - val_loss: 0.7346 - val_acc: 0.9009\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.0700 - acc: 0.9788 - val_loss: 0.7367 - val_acc: 0.8956\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.0764 - acc: 0.9776 - val_loss: 0.7315 - val_acc: 0.8998\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.0778 - acc: 0.9778 - val_loss: 0.6773 - val_acc: 0.9005\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.0743 - acc: 0.9777 - val_loss: 0.7693 - val_acc: 0.8976\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.0828 - acc: 0.9776 - val_loss: 0.6528 - val_acc: 0.8996\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.0709 - acc: 0.9813 - val_loss: 0.7815 - val_acc: 0.9018\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.0780 - acc: 0.9777 - val_loss: 0.7942 - val_acc: 0.8838\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.0686 - acc: 0.9785 - val_loss: 0.6774 - val_acc: 0.9014\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.0728 - acc: 0.9795 - val_loss: 0.7370 - val_acc: 0.8987\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.0748 - acc: 0.9796 - val_loss: 0.7316 - val_acc: 0.8833\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.0718 - acc: 0.9814 - val_loss: 0.8412 - val_acc: 0.8951\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0691 - acc: 0.9794 - val_loss: 0.7884 - val_acc: 0.8985\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.0795 - acc: 0.9783 - val_loss: 0.7575 - val_acc: 0.8997\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.0771 - acc: 0.9784 - val_loss: 0.6969 - val_acc: 0.8987\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.0683 - acc: 0.9806 - val_loss: 0.8504 - val_acc: 0.8984\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.0731 - acc: 0.9791 - val_loss: 0.7943 - val_acc: 0.8962\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.0879 - acc: 0.9778 - val_loss: 0.7149 - val_acc: 0.8951\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.0772 - acc: 0.9807 - val_loss: 0.8701 - val_acc: 0.8970\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.0769 - acc: 0.9794 - val_loss: 0.7590 - val_acc: 0.8984\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0695 - acc: 0.9808 - val_loss: 0.7883 - val_acc: 0.8954\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.0738 - acc: 0.9802 - val_loss: 0.7550 - val_acc: 0.8873\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.0720 - acc: 0.9805 - val_loss: 0.7006 - val_acc: 0.8872\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.0653 - acc: 0.9823 - val_loss: 0.7897 - val_acc: 0.9002\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.0706 - acc: 0.9805 - val_loss: 0.8702 - val_acc: 0.8892\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.0719 - acc: 0.9801 - val_loss: 0.7765 - val_acc: 0.9004\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.0730 - acc: 0.9797 - val_loss: 0.7749 - val_acc: 0.8967\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.0734 - acc: 0.9809 - val_loss: 0.7284 - val_acc: 0.8970\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.0693 - acc: 0.9831 - val_loss: 1.0188 - val_acc: 0.8784\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.0692 - acc: 0.9821 - val_loss: 0.8001 - val_acc: 0.8943\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.0661 - acc: 0.9819 - val_loss: 1.2260 - val_acc: 0.8682\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.0703 - acc: 0.9827 - val_loss: 0.9844 - val_acc: 0.8752\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.0708 - acc: 0.9808 - val_loss: 0.8092 - val_acc: 0.8945\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.0588 - acc: 0.9834 - val_loss: 0.7416 - val_acc: 0.8964\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0666 - acc: 0.9823 - val_loss: 0.6689 - val_acc: 0.8952\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0621 - acc: 0.9834 - val_loss: 0.9042 - val_acc: 0.8834\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.0772 - acc: 0.9812 - val_loss: 0.7597 - val_acc: 0.8957\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.0730 - acc: 0.9809 - val_loss: 0.8083 - val_acc: 0.8966\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.0628 - acc: 0.9831 - val_loss: 0.7788 - val_acc: 0.9028\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.0613 - acc: 0.9830 - val_loss: 0.9594 - val_acc: 0.8878\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.0677 - acc: 0.9818 - val_loss: 0.8562 - val_acc: 0.8913\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.0782 - acc: 0.9818 - val_loss: 0.7711 - val_acc: 0.8988\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.0718 - acc: 0.9824 - val_loss: 0.7471 - val_acc: 0.9012\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.0665 - acc: 0.9841 - val_loss: 0.7812 - val_acc: 0.8987\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.0647 - acc: 0.9827 - val_loss: 0.8730 - val_acc: 0.8951- loss: 0.0496 -\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.0686 - acc: 0.9836 - val_loss: 0.8328 - val_acc: 0.8976\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.0679 - acc: 0.9832 - val_loss: 0.9832 - val_acc: 0.8703\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.0674 - acc: 0.9826 - val_loss: 0.8053 - val_acc: 0.8995\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.0610 - acc: 0.9838 - val_loss: 0.8997 - val_acc: 0.8968\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.0671 - acc: 0.9829 - val_loss: 0.8398 - val_acc: 0.8952\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.0623 - acc: 0.9835 - val_loss: 0.9403 - val_acc: 0.8863\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.0777 - acc: 0.9834 - val_loss: 0.9000 - val_acc: 0.8939\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.0765 - acc: 0.9829 - val_loss: 0.8457 - val_acc: 0.8912\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.0586 - acc: 0.9846 - val_loss: 0.7666 - val_acc: 0.8971\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.0592 - acc: 0.9846 - val_loss: 0.8717 - val_acc: 0.8923\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.0664 - acc: 0.9829 - val_loss: 0.7573 - val_acc: 0.8911\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.0775 - acc: 0.9820 - val_loss: 0.7622 - val_acc: 0.8893\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.0690 - acc: 0.9830 - val_loss: 0.8428 - val_acc: 0.8939\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.0649 - acc: 0.9843 - val_loss: 0.8295 - val_acc: 0.8859\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.0624 - acc: 0.9853 - val_loss: 0.8332 - val_acc: 0.9012\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.0682 - acc: 0.9849 - val_loss: 0.8049 - val_acc: 0.9011\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.0611 - acc: 0.9859 - val_loss: 0.8114 - val_acc: 0.8975\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.0725 - acc: 0.9827 - val_loss: 0.8383 - val_acc: 0.8827\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.0591 - acc: 0.9853 - val_loss: 0.9944 - val_acc: 0.8899\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.0669 - acc: 0.9845 - val_loss: 0.7888 - val_acc: 0.8954\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.0546 - acc: 0.9859 - val_loss: 0.8080 - val_acc: 0.8973\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.0619 - acc: 0.9850 - val_loss: 0.8053 - val_acc: 0.8947\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.0593 - acc: 0.9863 - val_loss: 0.7882 - val_acc: 0.8992\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.0547 - acc: 0.9864 - val_loss: 0.8994 - val_acc: 0.8947\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.0531 - acc: 0.9863 - val_loss: 0.8176 - val_acc: 0.8975\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.0585 - acc: 0.9850 - val_loss: 0.8193 - val_acc: 0.9002\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.0614 - acc: 0.9855 - val_loss: 0.8289 - val_acc: 0.9015\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.0582 - acc: 0.9860 - val_loss: 0.8868 - val_acc: 0.8970\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.0574 - acc: 0.9863 - val_loss: 0.8552 - val_acc: 0.8971\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.0747 - acc: 0.9854 - val_loss: 0.8739 - val_acc: 0.8941\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.0598 - acc: 0.9856 - val_loss: 0.8490 - val_acc: 0.8961\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.0560 - acc: 0.9864 - val_loss: 0.8527 - val_acc: 0.8950\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.0672 - acc: 0.9857 - val_loss: 0.8614 - val_acc: 0.8947\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.0675 - acc: 0.9855 - val_loss: 0.8222 - val_acc: 0.8982\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.0559 - acc: 0.9865 - val_loss: 0.9155 - val_acc: 0.8992\n"
     ]
    }
   ],
   "source": [
    "baseline_history = baseline_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = baseline_history.history['val_acc']\n",
    "val_loss = baseline_history.history['val_loss']\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['val_acc', 'val_loss'])\n",
    "plt.title('The validation set accuracy versus loss over 200 epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with Drop\n",
    "dropout_model = Sequential()\n",
    "dropout_model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(512, activation='relu'))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(512, activation='relu'))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(512, activation='relu'))\n",
    "dropout_model.add(Dropout(0.5))\n",
    "dropout_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "dropout_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "result_dropout = dropout_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc_dropout = result_dropout.history['val_acc']\n",
    "val_loss_dropout = result_dropout.history['val_loss']\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.plot(val_acc_dropout)\n",
    "plt.plot(val_loss_dropout)\n",
    "plt.legend(['val_acc', 'val_loss', 'val_acc_dropout', 'val_loss_dropout'])\n",
    "plt.title('Comparison of Baseline and Dropout Model for Loss & Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the accuracy on the validation set is almost identical for both the model with and without the dropout option. However, the dropout model fares far better on loss, which rises much less over epochs than for the baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 14.6816 - acc: 0.5417 - val_loss: 4.1789 - val_acc: 0.6272\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 3.0972 - acc: 0.6509 - val_loss: 2.4645 - val_acc: 0.6545\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 2.2172 - acc: 0.7005 - val_loss: 2.0203 - val_acc: 0.7165\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.9076 - acc: 0.7309 - val_loss: 1.8268 - val_acc: 0.7154\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 1.7521 - acc: 0.7500 - val_loss: 1.7095 - val_acc: 0.7593\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.6682 - acc: 0.7626 - val_loss: 1.5987 - val_acc: 0.7757\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.6041 - acc: 0.7724 - val_loss: 1.5787 - val_acc: 0.7767\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.5563 - acc: 0.7789 - val_loss: 1.5629 - val_acc: 0.7760\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.5131 - acc: 0.7870 - val_loss: 1.5830 - val_acc: 0.7670\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.4845 - acc: 0.7914 - val_loss: 1.4475 - val_acc: 0.7993\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.4565 - acc: 0.7959 - val_loss: 1.4542 - val_acc: 0.7917\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.4331 - acc: 0.7988 - val_loss: 1.4283 - val_acc: 0.7949\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.4058 - acc: 0.8046 - val_loss: 1.4412 - val_acc: 0.7913\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.3915 - acc: 0.8050 - val_loss: 1.3954 - val_acc: 0.8009\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.3745 - acc: 0.8087 - val_loss: 1.3669 - val_acc: 0.8111\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.3587 - acc: 0.8113 - val_loss: 1.4140 - val_acc: 0.8018\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.3470 - acc: 0.8142 - val_loss: 1.3340 - val_acc: 0.8194s - los\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.3354 - acc: 0.8179 - val_loss: 1.3821 - val_acc: 0.8018\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 1.3255 - acc: 0.8185 - val_loss: 1.3299 - val_acc: 0.8138\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.3156 - acc: 0.8209 - val_loss: 1.3728 - val_acc: 0.7956\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.3075 - acc: 0.8214 - val_loss: 1.2965 - val_acc: 0.8270\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.3023 - acc: 0.8212 - val_loss: 1.3393 - val_acc: 0.8045\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.2968 - acc: 0.8228 - val_loss: 1.2964 - val_acc: 0.8248\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 1.2873 - acc: 0.8264 - val_loss: 1.3250 - val_acc: 0.8069\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.2872 - acc: 0.8248 - val_loss: 1.2736 - val_acc: 0.8293\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.2809 - acc: 0.8260 - val_loss: 1.2694 - val_acc: 0.8323\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.2793 - acc: 0.8274 - val_loss: 1.2730 - val_acc: 0.8284\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2736 - acc: 0.8290 - val_loss: 1.3192 - val_acc: 0.8155\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2696 - acc: 0.8294 - val_loss: 1.2677 - val_acc: 0.8326\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.2660 - acc: 0.8310 - val_loss: 1.2910 - val_acc: 0.8202\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2631 - acc: 0.8308 - val_loss: 1.2837 - val_acc: 0.8233\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2601 - acc: 0.8307 - val_loss: 1.2967 - val_acc: 0.8160\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.2578 - acc: 0.8317 - val_loss: 1.3057 - val_acc: 0.8126\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.2534 - acc: 0.8331 - val_loss: 1.2474 - val_acc: 0.8377\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2521 - acc: 0.8336 - val_loss: 1.2751 - val_acc: 0.8237\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2489 - acc: 0.8335 - val_loss: 1.2588 - val_acc: 0.8271\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.2485 - acc: 0.8319 - val_loss: 1.2629 - val_acc: 0.8286\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.2450 - acc: 0.8343 - val_loss: 1.3020 - val_acc: 0.8058\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 1.2424 - acc: 0.8351 - val_loss: 1.2579 - val_acc: 0.8272\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2433 - acc: 0.8338 - val_loss: 1.2913 - val_acc: 0.8129\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.2395 - acc: 0.8341 - val_loss: 1.3108 - val_acc: 0.7956\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2370 - acc: 0.8361 - val_loss: 1.2416 - val_acc: 0.8362\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2371 - acc: 0.8364 - val_loss: 1.2974 - val_acc: 0.8081\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2327 - acc: 0.8365 - val_loss: 1.2753 - val_acc: 0.8119\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2338 - acc: 0.8354 - val_loss: 1.2416 - val_acc: 0.8336\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2295 - acc: 0.8357 - val_loss: 1.2821 - val_acc: 0.8094\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2276 - acc: 0.8383 - val_loss: 1.2700 - val_acc: 0.8260\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2257 - acc: 0.8353 - val_loss: 1.2485 - val_acc: 0.8327\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2244 - acc: 0.8376 - val_loss: 1.3009 - val_acc: 0.8140\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2251 - acc: 0.8377 - val_loss: 1.2474 - val_acc: 0.8278\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2225 - acc: 0.8395 - val_loss: 1.2370 - val_acc: 0.8307\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2234 - acc: 0.8381 - val_loss: 1.2554 - val_acc: 0.8256\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2200 - acc: 0.8384 - val_loss: 1.2307 - val_acc: 0.8348\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2168 - acc: 0.8406 - val_loss: 1.2453 - val_acc: 0.8328\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.2165 - acc: 0.8395 - val_loss: 1.2460 - val_acc: 0.8281\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2176 - acc: 0.8374 - val_loss: 1.2598 - val_acc: 0.8249\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.2138 - acc: 0.8404 - val_loss: 1.3200 - val_acc: 0.8046\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.2171 - acc: 0.8387 - val_loss: 1.2394 - val_acc: 0.8325\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.2148 - acc: 0.8380 - val_loss: 1.2355 - val_acc: 0.8336\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.2148 - acc: 0.8389 - val_loss: 1.2257 - val_acc: 0.8357\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.2127 - acc: 0.8415 - val_loss: 1.2720 - val_acc: 0.8118\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.2100 - acc: 0.8412 - val_loss: 1.2637 - val_acc: 0.8183\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2096 - acc: 0.8402 - val_loss: 1.2587 - val_acc: 0.8222\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2080 - acc: 0.8399 - val_loss: 1.2151 - val_acc: 0.8437\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.2070 - acc: 0.8409 - val_loss: 1.2674 - val_acc: 0.8191\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2054 - acc: 0.8409 - val_loss: 1.2486 - val_acc: 0.8194\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.2058 - acc: 0.8410 - val_loss: 1.2555 - val_acc: 0.8236\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.2043 - acc: 0.8415 - val_loss: 1.2265 - val_acc: 0.8328\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.2020 - acc: 0.8431 - val_loss: 1.2403 - val_acc: 0.8277\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2047 - acc: 0.8402 - val_loss: 1.2371 - val_acc: 0.8281\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2029 - acc: 0.8408 - val_loss: 1.2517 - val_acc: 0.8249\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.2015 - acc: 0.8413 - val_loss: 1.2768 - val_acc: 0.8176\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1978 - acc: 0.8462 - val_loss: 1.2322 - val_acc: 0.8298\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1999 - acc: 0.8437 - val_loss: 1.2226 - val_acc: 0.8341\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.1992 - acc: 0.8422 - val_loss: 1.2423 - val_acc: 0.8239\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 1.1978 - acc: 0.8421 - val_loss: 1.2009 - val_acc: 0.8452\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.1976 - acc: 0.8436 - val_loss: 1.2035 - val_acc: 0.8419\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1953 - acc: 0.8431 - val_loss: 1.2079 - val_acc: 0.8387\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1933 - acc: 0.8436 - val_loss: 1.2252 - val_acc: 0.8338\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1962 - acc: 0.8422 - val_loss: 1.2235 - val_acc: 0.8308\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.1927 - acc: 0.8431 - val_loss: 1.2356 - val_acc: 0.8290\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1889 - acc: 0.8441 - val_loss: 1.2584 - val_acc: 0.8165\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1936 - acc: 0.8422 - val_loss: 1.3738 - val_acc: 0.7654\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1883 - acc: 0.8438 - val_loss: 1.2119 - val_acc: 0.8345\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1893 - acc: 0.8438 - val_loss: 1.2495 - val_acc: 0.8194\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1900 - acc: 0.8441 - val_loss: 1.2337 - val_acc: 0.8265\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1866 - acc: 0.8453 - val_loss: 1.2502 - val_acc: 0.8235\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1887 - acc: 0.8435 - val_loss: 1.2771 - val_acc: 0.8097\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1842 - acc: 0.8457 - val_loss: 1.1915 - val_acc: 0.8465\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1867 - acc: 0.8446 - val_loss: 1.3608 - val_acc: 0.7771\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1855 - acc: 0.8442 - val_loss: 1.2398 - val_acc: 0.8231\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.1838 - acc: 0.8441 - val_loss: 1.2079 - val_acc: 0.8388\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1864 - acc: 0.8438 - val_loss: 1.2092 - val_acc: 0.8383\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.1825 - acc: 0.8469 - val_loss: 1.1945 - val_acc: 0.8421\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1830 - acc: 0.8450 - val_loss: 1.1975 - val_acc: 0.8408\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1817 - acc: 0.8453 - val_loss: 1.2339 - val_acc: 0.8294\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1798 - acc: 0.8455 - val_loss: 1.2181 - val_acc: 0.8282\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1815 - acc: 0.8438 - val_loss: 1.2008 - val_acc: 0.8359\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1812 - acc: 0.8455 - val_loss: 1.1928 - val_acc: 0.8445\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1792 - acc: 0.8450 - val_loss: 1.2237 - val_acc: 0.8301\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1789 - acc: 0.8461 - val_loss: 1.2348 - val_acc: 0.8218\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1781 - acc: 0.8463 - val_loss: 1.2588 - val_acc: 0.8131\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.1738 - acc: 0.8461 - val_loss: 1.2570 - val_acc: 0.8138\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1751 - acc: 0.8465 - val_loss: 1.2239 - val_acc: 0.8302\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1736 - acc: 0.8481 - val_loss: 1.2007 - val_acc: 0.8373\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1758 - acc: 0.8447 - val_loss: 1.1924 - val_acc: 0.8395\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1734 - acc: 0.8469 - val_loss: 1.1961 - val_acc: 0.8398\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1740 - acc: 0.8471 - val_loss: 1.2152 - val_acc: 0.8301\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1723 - acc: 0.8466 - val_loss: 1.2502 - val_acc: 0.8195\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1742 - acc: 0.8467 - val_loss: 1.2022 - val_acc: 0.8359\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1701 - acc: 0.8473 - val_loss: 1.1956 - val_acc: 0.8396\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1737 - acc: 0.8470 - val_loss: 1.1984 - val_acc: 0.8342\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1708 - acc: 0.8462 - val_loss: 1.1743 - val_acc: 0.8454\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.1695 - acc: 0.8468 - val_loss: 1.1829 - val_acc: 0.8448\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1677 - acc: 0.8480 - val_loss: 1.1934 - val_acc: 0.8393\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1680 - acc: 0.8484 - val_loss: 1.2569 - val_acc: 0.8123\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.1632 - acc: 0.8495 - val_loss: 1.2827 - val_acc: 0.8103\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1684 - acc: 0.8452 - val_loss: 1.1990 - val_acc: 0.8334\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1635 - acc: 0.8484 - val_loss: 1.2021 - val_acc: 0.8351\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1660 - acc: 0.8481 - val_loss: 1.1837 - val_acc: 0.8388\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1656 - acc: 0.8486 - val_loss: 1.1838 - val_acc: 0.8383\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1639 - acc: 0.8481 - val_loss: 1.1778 - val_acc: 0.8440\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.1626 - acc: 0.8467 - val_loss: 1.2199 - val_acc: 0.8282\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.1633 - acc: 0.8473 - val_loss: 1.1951 - val_acc: 0.8386\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.1590 - acc: 0.8503 - val_loss: 1.2053 - val_acc: 0.8370\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.1604 - acc: 0.8502 - val_loss: 1.2609 - val_acc: 0.8043\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1616 - acc: 0.8480 - val_loss: 1.1929 - val_acc: 0.8371\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1593 - acc: 0.8500 - val_loss: 1.2019 - val_acc: 0.8302\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1610 - acc: 0.8482 - val_loss: 1.1924 - val_acc: 0.8342\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1594 - acc: 0.8474 - val_loss: 1.2236 - val_acc: 0.8287\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1602 - acc: 0.8483 - val_loss: 1.2104 - val_acc: 0.8272\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1563 - acc: 0.8496 - val_loss: 1.2953 - val_acc: 0.8003\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.1606 - acc: 0.8478 - val_loss: 1.1905 - val_acc: 0.8371\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1575 - acc: 0.8483 - val_loss: 1.3134 - val_acc: 0.7852\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1585 - acc: 0.8477 - val_loss: 1.1943 - val_acc: 0.8379\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.1563 - acc: 0.8493 - val_loss: 1.2319 - val_acc: 0.8167\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1574 - acc: 0.8486 - val_loss: 1.2119 - val_acc: 0.8286\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.1595 - acc: 0.8491 - val_loss: 1.1679 - val_acc: 0.8493\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.1585 - acc: 0.8478 - val_loss: 1.2061 - val_acc: 0.8326\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1568 - acc: 0.8491 - val_loss: 1.2324 - val_acc: 0.8213\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1555 - acc: 0.8493 - val_loss: 1.1826 - val_acc: 0.8344\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.1580 - acc: 0.8472 - val_loss: 1.1858 - val_acc: 0.8389\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1553 - acc: 0.8499 - val_loss: 1.1765 - val_acc: 0.8388\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1533 - acc: 0.8490 - val_loss: 1.1697 - val_acc: 0.8439\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1568 - acc: 0.8471 - val_loss: 1.2130 - val_acc: 0.8227\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1530 - acc: 0.8510 - val_loss: 1.2126 - val_acc: 0.8291\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.1530 - acc: 0.8500 - val_loss: 1.1736 - val_acc: 0.8399\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.1538 - acc: 0.8488 - val_loss: 1.2009 - val_acc: 0.8313\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1550 - acc: 0.8485 - val_loss: 1.1856 - val_acc: 0.8366\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1490 - acc: 0.8506 - val_loss: 1.1807 - val_acc: 0.8388\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1556 - acc: 0.8493 - val_loss: 1.2191 - val_acc: 0.8241\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.1523 - acc: 0.8500 - val_loss: 1.1774 - val_acc: 0.8394\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1516 - acc: 0.8487 - val_loss: 1.1873 - val_acc: 0.8371\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1510 - acc: 0.8512 - val_loss: 1.1856 - val_acc: 0.8364\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1514 - acc: 0.8497 - val_loss: 1.1835 - val_acc: 0.8357\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1529 - acc: 0.8493 - val_loss: 1.2409 - val_acc: 0.8194\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1479 - acc: 0.8499 - val_loss: 1.1967 - val_acc: 0.8325\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1503 - acc: 0.8504 - val_loss: 1.1727 - val_acc: 0.8431\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1499 - acc: 0.8500 - val_loss: 1.2076 - val_acc: 0.8258\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1510 - acc: 0.8484 - val_loss: 1.1578 - val_acc: 0.8473\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1516 - acc: 0.8485 - val_loss: 1.2262 - val_acc: 0.8232\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1479 - acc: 0.8497 - val_loss: 1.1866 - val_acc: 0.8321\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1493 - acc: 0.8514 - val_loss: 1.1801 - val_acc: 0.8383\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1472 - acc: 0.8496 - val_loss: 1.1679 - val_acc: 0.8468\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.1487 - acc: 0.8498 - val_loss: 1.2033 - val_acc: 0.8275\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1490 - acc: 0.8493 - val_loss: 1.1774 - val_acc: 0.8383\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.1472 - acc: 0.8507 - val_loss: 1.1672 - val_acc: 0.8464\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1467 - acc: 0.8502 - val_loss: 1.2451 - val_acc: 0.8083\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1491 - acc: 0.8492 - val_loss: 1.1542 - val_acc: 0.8494\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1485 - acc: 0.8495 - val_loss: 1.1841 - val_acc: 0.8356\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1464 - acc: 0.8506 - val_loss: 1.2113 - val_acc: 0.8265\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1458 - acc: 0.8500 - val_loss: 1.1752 - val_acc: 0.8416\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.1456 - acc: 0.8516 - val_loss: 1.1906 - val_acc: 0.8322\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1483 - acc: 0.8492 - val_loss: 1.1697 - val_acc: 0.8454\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1450 - acc: 0.8496 - val_loss: 1.1756 - val_acc: 0.8395\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1439 - acc: 0.8504 - val_loss: 1.1761 - val_acc: 0.8389\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1466 - acc: 0.8500 - val_loss: 1.2452 - val_acc: 0.8079\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.1489 - acc: 0.8484 - val_loss: 1.1784 - val_acc: 0.8356\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.1443 - acc: 0.8516 - val_loss: 1.1825 - val_acc: 0.8378\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1450 - acc: 0.8502 - val_loss: 1.1605 - val_acc: 0.8452\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1449 - acc: 0.8515 - val_loss: 1.1701 - val_acc: 0.8422\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.1419 - acc: 0.8507 - val_loss: 1.1794 - val_acc: 0.8390\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.1431 - acc: 0.8512 - val_loss: 1.2327 - val_acc: 0.8185\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1441 - acc: 0.8482 - val_loss: 1.1888 - val_acc: 0.8325\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.1442 - acc: 0.8518 - val_loss: 1.1589 - val_acc: 0.8433\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.1424 - acc: 0.8500 - val_loss: 1.1587 - val_acc: 0.8452\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.1427 - acc: 0.8519 - val_loss: 1.2155 - val_acc: 0.8231\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1426 - acc: 0.8506 - val_loss: 1.1659 - val_acc: 0.8410\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1434 - acc: 0.8501 - val_loss: 1.1691 - val_acc: 0.8389\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1399 - acc: 0.8512 - val_loss: 1.2495 - val_acc: 0.8119\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1445 - acc: 0.8508 - val_loss: 1.1538 - val_acc: 0.8473\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1422 - acc: 0.8504 - val_loss: 1.1527 - val_acc: 0.8479\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1420 - acc: 0.8493 - val_loss: 1.2462 - val_acc: 0.8126\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1435 - acc: 0.8494 - val_loss: 1.2091 - val_acc: 0.8261\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1400 - acc: 0.8532 - val_loss: 1.1544 - val_acc: 0.8447\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1405 - acc: 0.8516 - val_loss: 1.2297 - val_acc: 0.8195\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1410 - acc: 0.8524 - val_loss: 1.1795 - val_acc: 0.8380\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.1425 - acc: 0.8510 - val_loss: 1.1629 - val_acc: 0.8440\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1382 - acc: 0.8512 - val_loss: 1.2215 - val_acc: 0.8246\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.1386 - acc: 0.8519 - val_loss: 1.1727 - val_acc: 0.8401\n"
     ]
    }
   ],
   "source": [
    "#L1 Regularization\n",
    "model_L1 = Sequential()\n",
    "model_L1.add(Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_L1.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_L1.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_L1.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_L1.add(Dense(10, activation='softmax'))\n",
    "model_L1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_L1 = model_L1.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=200, batch_size=512)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.9753 - acc: 0.6346 - val_loss: 0.6064 - val_acc: 0.7676\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.5936 - acc: 0.7858 - val_loss: 0.5043 - val_acc: 0.8190\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.5176 - acc: 0.8135 - val_loss: 0.4379 - val_acc: 0.8374\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.4762 - acc: 0.8285 - val_loss: 0.4244 - val_acc: 0.8391\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.4508 - acc: 0.8403 - val_loss: 0.4156 - val_acc: 0.8521\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.4315 - acc: 0.8466 - val_loss: 0.3712 - val_acc: 0.8643\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.4144 - acc: 0.8528 - val_loss: 0.3831 - val_acc: 0.8562\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.4004 - acc: 0.8594 - val_loss: 0.4009 - val_acc: 0.8503\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 0.3936 - acc: 0.8610 - val_loss: 0.3648 - val_acc: 0.8662\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3825 - acc: 0.8642 - val_loss: 0.3519 - val_acc: 0.8701\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3734 - acc: 0.8683 - val_loss: 0.3481 - val_acc: 0.8725\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3719 - acc: 0.8673 - val_loss: 0.3671 - val_acc: 0.8699\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3623 - acc: 0.8704 - val_loss: 0.3553 - val_acc: 0.8662\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3588 - acc: 0.8737 - val_loss: 0.3777 - val_acc: 0.8615\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.3551 - acc: 0.8735 - val_loss: 0.3747 - val_acc: 0.8592\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3496 - acc: 0.8770 - val_loss: 0.3353 - val_acc: 0.8754\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3487 - acc: 0.8754 - val_loss: 0.3503 - val_acc: 0.8739\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3410 - acc: 0.8783 - val_loss: 0.3495 - val_acc: 0.8784\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3347 - acc: 0.8817 - val_loss: 0.3440 - val_acc: 0.8719\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3358 - acc: 0.8822 - val_loss: 0.3375 - val_acc: 0.8794\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3320 - acc: 0.8833 - val_loss: 0.3279 - val_acc: 0.8754\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3323 - acc: 0.8819 - val_loss: 0.3381 - val_acc: 0.8782\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3229 - acc: 0.8874 - val_loss: 0.3431 - val_acc: 0.8748\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.3275 - acc: 0.8853 - val_loss: 0.3265 - val_acc: 0.8772\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3184 - acc: 0.8867 - val_loss: 0.3416 - val_acc: 0.8772\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3201 - acc: 0.8886 - val_loss: 0.3337 - val_acc: 0.8814\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3209 - acc: 0.8871 - val_loss: 0.3331 - val_acc: 0.8792\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3159 - acc: 0.8908 - val_loss: 0.3352 - val_acc: 0.8742\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3180 - acc: 0.8889 - val_loss: 0.3604 - val_acc: 0.8782\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3135 - acc: 0.8902 - val_loss: 0.3300 - val_acc: 0.8801\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3110 - acc: 0.8897 - val_loss: 0.3287 - val_acc: 0.8869\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 0.3118 - acc: 0.8918 - val_loss: 0.3310 - val_acc: 0.8844\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 15s 302us/step - loss: 0.3088 - acc: 0.8926 - val_loss: 0.3161 - val_acc: 0.8905\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 0.3053 - acc: 0.8929 - val_loss: 0.3398 - val_acc: 0.8812\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 0.3026 - acc: 0.8936 - val_loss: 0.3415 - val_acc: 0.8804\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 0.3098 - acc: 0.8931 - val_loss: 0.3367 - val_acc: 0.8875\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.3018 - acc: 0.8940 - val_loss: 0.3355 - val_acc: 0.8830\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 0.3026 - acc: 0.8948 - val_loss: 0.3225 - val_acc: 0.8889\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.3010 - acc: 0.8975 - val_loss: 0.3316 - val_acc: 0.8831\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.2985 - acc: 0.8961 - val_loss: 0.3287 - val_acc: 0.8840\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.2991 - acc: 0.8964 - val_loss: 0.3443 - val_acc: 0.8793\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.2984 - acc: 0.8970 - val_loss: 0.3342 - val_acc: 0.8891\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.2981 - acc: 0.8978 - val_loss: 0.3304 - val_acc: 0.8858\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.2962 - acc: 0.8976 - val_loss: 0.3439 - val_acc: 0.8835\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.3008 - acc: 0.8985 - val_loss: 0.3291 - val_acc: 0.8892\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 0.2960 - acc: 0.8985 - val_loss: 0.3413 - val_acc: 0.8839\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.2961 - acc: 0.8966 - val_loss: 0.3630 - val_acc: 0.8805\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 0.2965 - acc: 0.8978 - val_loss: 0.3285 - val_acc: 0.8907\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.2973 - acc: 0.8974 - val_loss: 0.3298 - val_acc: 0.8847\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 0.2875 - acc: 0.9016 - val_loss: 0.3175 - val_acc: 0.8905\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.2954 - acc: 0.9014 - val_loss: 0.3481 - val_acc: 0.8808\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.2919 - acc: 0.8999 - val_loss: 0.3219 - val_acc: 0.8895\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.2920 - acc: 0.9009 - val_loss: 0.3237 - val_acc: 0.8907\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.2902 - acc: 0.9011 - val_loss: 0.3403 - val_acc: 0.8851\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.2938 - acc: 0.8994 - val_loss: 0.3293 - val_acc: 0.8877\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.2905 - acc: 0.9013 - val_loss: 0.3278 - val_acc: 0.8917\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.2907 - acc: 0.9024 - val_loss: 0.3570 - val_acc: 0.8842\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.2902 - acc: 0.8998 - val_loss: 0.3539 - val_acc: 0.8839\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.2852 - acc: 0.9039 - val_loss: 0.3403 - val_acc: 0.8893\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.2945 - acc: 0.9012 - val_loss: 0.3324 - val_acc: 0.8877\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.2884 - acc: 0.9011 - val_loss: 0.3454 - val_acc: 0.8909\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.2933 - acc: 0.9025 - val_loss: 0.3438 - val_acc: 0.8877\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.2916 - acc: 0.9035 - val_loss: 0.3295 - val_acc: 0.8901\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.2875 - acc: 0.9054 - val_loss: 0.3449 - val_acc: 0.8893\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.2916 - acc: 0.9024 - val_loss: 0.3496 - val_acc: 0.8880\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.2889 - acc: 0.9040 - val_loss: 0.3477 - val_acc: 0.8846\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.2938 - acc: 0.9036 - val_loss: 0.3615 - val_acc: 0.8839\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.2873 - acc: 0.9025 - val_loss: 0.3337 - val_acc: 0.8916\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2908 - acc: 0.9059 - val_loss: 0.3489 - val_acc: 0.8818\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2865 - acc: 0.9042 - val_loss: 0.3436 - val_acc: 0.8891\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.2894 - acc: 0.9050 - val_loss: 0.3531 - val_acc: 0.8897\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 11s 225us/step - loss: 0.2873 - acc: 0.9060 - val_loss: 0.3510 - val_acc: 0.8908\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.2861 - acc: 0.9066 - val_loss: 0.3612 - val_acc: 0.8808\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.2922 - acc: 0.9040 - val_loss: 0.3548 - val_acc: 0.8853\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.2744 - acc: 0.9091 - val_loss: 0.3555 - val_acc: 0.8906\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.2842 - acc: 0.9067 - val_loss: 0.3434 - val_acc: 0.8935\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2841 - acc: 0.9058 - val_loss: 0.3413 - val_acc: 0.8925\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2880 - acc: 0.9062 - val_loss: 0.3501 - val_acc: 0.8922\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2922 - acc: 0.9078 - val_loss: 0.3502 - val_acc: 0.8919\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2855 - acc: 0.9065 - val_loss: 0.3371 - val_acc: 0.8928\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2875 - acc: 0.9073 - val_loss: 0.3815 - val_acc: 0.8750\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2978 - acc: 0.9058 - val_loss: 0.3506 - val_acc: 0.8881\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2932 - acc: 0.9053 - val_loss: 0.3363 - val_acc: 0.8922\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.2857 - acc: 0.9073 - val_loss: 0.3429 - val_acc: 0.8923\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.2978 - acc: 0.9066 - val_loss: 0.3595 - val_acc: 0.8911\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.2919 - acc: 0.9074 - val_loss: 0.3620 - val_acc: 0.8903\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.2934 - acc: 0.9077 - val_loss: 0.3635 - val_acc: 0.8844\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2877 - acc: 0.9066 - val_loss: 0.3529 - val_acc: 0.8918\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2895 - acc: 0.9078 - val_loss: 0.3621 - val_acc: 0.8930\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 0.2893 - acc: 0.9100 - val_loss: 0.3660 - val_acc: 0.8852\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.2869 - acc: 0.9077 - val_loss: 0.3606 - val_acc: 0.8937\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.2926 - acc: 0.9084 - val_loss: 0.3601 - val_acc: 0.8886\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2919 - acc: 0.9086 - val_loss: 0.3416 - val_acc: 0.8930\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.2942 - acc: 0.9080 - val_loss: 0.3522 - val_acc: 0.8922\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 0.2931 - acc: 0.9087 - val_loss: 0.3423 - val_acc: 0.8927\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2996 - acc: 0.9072 - val_loss: 0.3647 - val_acc: 0.8887\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.2857 - acc: 0.9078 - val_loss: 0.3641 - val_acc: 0.8897\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.2995 - acc: 0.9089 - val_loss: 0.3505 - val_acc: 0.8912\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2875 - acc: 0.9075 - val_loss: 0.3493 - val_acc: 0.8923\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2892 - acc: 0.9068 - val_loss: 0.3713 - val_acc: 0.8877\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2930 - acc: 0.9094 - val_loss: 0.3538 - val_acc: 0.8939\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.2886 - acc: 0.9091 - val_loss: 0.3555 - val_acc: 0.8944\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.2903 - acc: 0.9102 - val_loss: 0.3704 - val_acc: 0.8891\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 0.2929 - acc: 0.9091 - val_loss: 0.3764 - val_acc: 0.8901\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3000 - acc: 0.9095 - val_loss: 0.3560 - val_acc: 0.8891\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.2799 - acc: 0.9124 - val_loss: 0.3688 - val_acc: 0.8828\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.2959 - acc: 0.9083 - val_loss: 0.3684 - val_acc: 0.8924\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.2999 - acc: 0.9087 - val_loss: 0.3748 - val_acc: 0.8922\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.2946 - acc: 0.9081 - val_loss: 0.3685 - val_acc: 0.8945\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2998 - acc: 0.9088 - val_loss: 0.3773 - val_acc: 0.8898\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2924 - acc: 0.9107 - val_loss: 0.3819 - val_acc: 0.8914\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3033 - acc: 0.9086 - val_loss: 0.3621 - val_acc: 0.8925\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.2950 - acc: 0.9080 - val_loss: 0.3788 - val_acc: 0.8888\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2980 - acc: 0.9105 - val_loss: 0.3619 - val_acc: 0.8932\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.2969 - acc: 0.9119 - val_loss: 0.3820 - val_acc: 0.8872\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3041 - acc: 0.9098 - val_loss: 0.3801 - val_acc: 0.8888\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3051 - acc: 0.9102 - val_loss: 0.3684 - val_acc: 0.8934\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3071 - acc: 0.9096 - val_loss: 0.3767 - val_acc: 0.8917\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3111 - acc: 0.9069 - val_loss: 0.3672 - val_acc: 0.8921\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2918 - acc: 0.9108 - val_loss: 0.3721 - val_acc: 0.8925\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3067 - acc: 0.9096 - val_loss: 0.3836 - val_acc: 0.8865\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.3153 - acc: 0.9095 - val_loss: 0.3754 - val_acc: 0.8884\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3105 - acc: 0.9085 - val_loss: 0.3733 - val_acc: 0.8893\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3087 - acc: 0.9096 - val_loss: 0.3779 - val_acc: 0.8941\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3126 - acc: 0.9094 - val_loss: 0.3820 - val_acc: 0.8905 5s - los\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3057 - acc: 0.9098 - val_loss: 0.3863 - val_acc: 0.8809\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3172 - acc: 0.9089 - val_loss: 0.3938 - val_acc: 0.8898\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3153 - acc: 0.9092 - val_loss: 0.3878 - val_acc: 0.8889\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.3041 - acc: 0.9100 - val_loss: 0.3924 - val_acc: 0.8895\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3068 - acc: 0.9109 - val_loss: 0.3707 - val_acc: 0.8948\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3065 - acc: 0.9105 - val_loss: 0.3907 - val_acc: 0.8953\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3189 - acc: 0.9101 - val_loss: 0.4044 - val_acc: 0.8810\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3181 - acc: 0.9097 - val_loss: 0.3871 - val_acc: 0.8897\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3106 - acc: 0.9104 - val_loss: 0.4067 - val_acc: 0.8852\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3174 - acc: 0.9106 - val_loss: 0.3890 - val_acc: 0.8900\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3083 - acc: 0.9115 - val_loss: 0.4028 - val_acc: 0.8883\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3232 - acc: 0.9098 - val_loss: 0.3831 - val_acc: 0.8866\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3144 - acc: 0.9108 - val_loss: 0.3857 - val_acc: 0.8907\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3139 - acc: 0.9103 - val_loss: 0.3982 - val_acc: 0.8919\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3198 - acc: 0.9105 - val_loss: 0.3841 - val_acc: 0.8924\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3152 - acc: 0.9114 - val_loss: 0.3746 - val_acc: 0.8917\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.3159 - acc: 0.9113 - val_loss: 0.4066 - val_acc: 0.8874\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.3192 - acc: 0.9107 - val_loss: 0.3769 - val_acc: 0.8941\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.3194 - acc: 0.9097 - val_loss: 0.3821 - val_acc: 0.8921\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.3084 - acc: 0.9121 - val_loss: 0.3801 - val_acc: 0.8920\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.3135 - acc: 0.9129 - val_loss: 0.4013 - val_acc: 0.8847\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3078 - acc: 0.9107 - val_loss: 0.4036 - val_acc: 0.8859\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.3141 - acc: 0.9098 - val_loss: 0.3978 - val_acc: 0.8924\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3007 - acc: 0.9114 - val_loss: 0.4025 - val_acc: 0.8870\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.3127 - acc: 0.9103 - val_loss: 0.3986 - val_acc: 0.8927\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.3340 - acc: 0.9102 - val_loss: 0.4052 - val_acc: 0.8928\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.3218 - acc: 0.9118 - val_loss: 0.3857 - val_acc: 0.8936\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.3116 - acc: 0.9127 - val_loss: 0.4090 - val_acc: 0.8974\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3269 - acc: 0.9120 - val_loss: 0.4168 - val_acc: 0.8926\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.3372 - acc: 0.9115 - val_loss: 0.4167 - val_acc: 0.8936\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 0.3436 - acc: 0.9108 - val_loss: 0.4204 - val_acc: 0.8925\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.3385 - acc: 0.9107 - val_loss: 0.3957 - val_acc: 0.8957\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.3251 - acc: 0.9124 - val_loss: 0.4043 - val_acc: 0.8913\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3250 - acc: 0.9130 - val_loss: 0.4056 - val_acc: 0.8917\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3306 - acc: 0.9123 - val_loss: 0.4206 - val_acc: 0.8876\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3294 - acc: 0.9122 - val_loss: 0.4081 - val_acc: 0.8925\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3273 - acc: 0.9118 - val_loss: 0.4140 - val_acc: 0.8936\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3245 - acc: 0.9138 - val_loss: 0.4213 - val_acc: 0.8909\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3273 - acc: 0.9136 - val_loss: 0.4064 - val_acc: 0.8932\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3297 - acc: 0.9127 - val_loss: 0.4163 - val_acc: 0.8934\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3589 - acc: 0.9088 - val_loss: 0.4142 - val_acc: 0.8915\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3408 - acc: 0.9115 - val_loss: 0.4228 - val_acc: 0.8910\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3423 - acc: 0.9103 - val_loss: 0.4049 - val_acc: 0.8908\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.3454 - acc: 0.9110 - val_loss: 0.4180 - val_acc: 0.8890\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.3369 - acc: 0.9106 - val_loss: 0.4199 - val_acc: 0.8908\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.3366 - acc: 0.9113 - val_loss: 0.4320 - val_acc: 0.8906\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3347 - acc: 0.9101 - val_loss: 0.4044 - val_acc: 0.8975\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.3373 - acc: 0.9116 - val_loss: 0.4043 - val_acc: 0.8943\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3283 - acc: 0.9131 - val_loss: 0.4355 - val_acc: 0.8913\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3566 - acc: 0.9093 - val_loss: 0.4225 - val_acc: 0.8919\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.3302 - acc: 0.9108 - val_loss: 0.4169 - val_acc: 0.8928\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3435 - acc: 0.9110 - val_loss: 0.4266 - val_acc: 0.8915\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3473 - acc: 0.9110 - val_loss: 0.4048 - val_acc: 0.8944\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.3521 - acc: 0.9132 - val_loss: 0.4300 - val_acc: 0.8825\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3472 - acc: 0.9131 - val_loss: 0.4230 - val_acc: 0.8926\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3433 - acc: 0.9100 - val_loss: 0.4138 - val_acc: 0.8932\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3482 - acc: 0.9113 - val_loss: 0.4172 - val_acc: 0.8912\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.3488 - acc: 0.9103 - val_loss: 0.4285 - val_acc: 0.8936\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3351 - acc: 0.9119 - val_loss: 0.4128 - val_acc: 0.8955\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.3404 - acc: 0.9113 - val_loss: 0.4089 - val_acc: 0.8882\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.3495 - acc: 0.9110 - val_loss: 0.4447 - val_acc: 0.8865\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.3365 - acc: 0.9127 - val_loss: 0.4348 - val_acc: 0.8892\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.3491 - acc: 0.9111 - val_loss: 0.4345 - val_acc: 0.8903\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3497 - acc: 0.9122 - val_loss: 0.4257 - val_acc: 0.8903\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.3512 - acc: 0.9106 - val_loss: 0.4483 - val_acc: 0.8894\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.3669 - acc: 0.9088 - val_loss: 0.4287 - val_acc: 0.8904\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3532 - acc: 0.9101 - val_loss: 0.4410 - val_acc: 0.8905\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.3585 - acc: 0.9104 - val_loss: 0.4650 - val_acc: 0.8900\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3593 - acc: 0.9109 - val_loss: 0.4290 - val_acc: 0.8911\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.3429 - acc: 0.9121 - val_loss: 0.4191 - val_acc: 0.8914\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3589 - acc: 0.9122 - val_loss: 0.4416 - val_acc: 0.8869\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.3529 - acc: 0.9117 - val_loss: 0.4531 - val_acc: 0.8906\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3662 - acc: 0.9117 - val_loss: 0.4460 - val_acc: 0.8903\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3598 - acc: 0.9122 - val_loss: 0.4389 - val_acc: 0.8915\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.3705 - acc: 0.9115 - val_loss: 0.4459 - val_acc: 0.8888\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 2.1672 - acc: 0.6712 - val_loss: 1.4058 - val_acc: 0.7653\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.1873 - acc: 0.7877 - val_loss: 1.1427 - val_acc: 0.7661\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.8929 - acc: 0.8143 - val_loss: 1.0313 - val_acc: 0.7682\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.7471 - acc: 0.8283 - val_loss: 0.8378 - val_acc: 0.8068\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.6756 - acc: 0.8330 - val_loss: 0.6692 - val_acc: 0.8295\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.6222 - acc: 0.8411 - val_loss: 0.6090 - val_acc: 0.8403\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.5835 - acc: 0.8473 - val_loss: 0.8098 - val_acc: 0.7625\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.5600 - acc: 0.8509 - val_loss: 0.6000 - val_acc: 0.8380\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.5382 - acc: 0.8553 - val_loss: 0.5676 - val_acc: 0.8374\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.5226 - acc: 0.8580 - val_loss: 0.5020 - val_acc: 0.8623\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.5074 - acc: 0.8623 - val_loss: 0.5118 - val_acc: 0.8553\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.4956 - acc: 0.8636 - val_loss: 0.5336 - val_acc: 0.8455\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.4847 - acc: 0.8662 - val_loss: 0.5248 - val_acc: 0.8427\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.4792 - acc: 0.8664 - val_loss: 0.5554 - val_acc: 0.8373\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.4687 - acc: 0.8690 - val_loss: 0.5720 - val_acc: 0.8277\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.4614 - acc: 0.8706 - val_loss: 0.5017 - val_acc: 0.8567\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.4541 - acc: 0.8729 - val_loss: 0.4800 - val_acc: 0.8645\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.4449 - acc: 0.8761 - val_loss: 0.4543 - val_acc: 0.8712\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.4382 - acc: 0.8787 - val_loss: 0.4985 - val_acc: 0.8517\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.4354 - acc: 0.8784 - val_loss: 0.5302 - val_acc: 0.8364\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.4344 - acc: 0.8767 - val_loss: 0.4591 - val_acc: 0.8659\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.4275 - acc: 0.8814 - val_loss: 0.4518 - val_acc: 0.8735\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.4217 - acc: 0.8813 - val_loss: 0.4303 - val_acc: 0.8784\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.4222 - acc: 0.8807 - val_loss: 0.5079 - val_acc: 0.8494\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.4166 - acc: 0.8834 - val_loss: 0.4807 - val_acc: 0.8580\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.4146 - acc: 0.8844 - val_loss: 0.4868 - val_acc: 0.8574\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.4092 - acc: 0.8855 - val_loss: 0.4857 - val_acc: 0.8606\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.4070 - acc: 0.8859 - val_loss: 0.5045 - val_acc: 0.8467\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.4064 - acc: 0.8856 - val_loss: 0.4623 - val_acc: 0.8648\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.3982 - acc: 0.8894 - val_loss: 0.4929 - val_acc: 0.8563\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.4042 - acc: 0.8866 - val_loss: 0.4401 - val_acc: 0.8689\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.3938 - acc: 0.8902 - val_loss: 0.6078 - val_acc: 0.8267\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.3941 - acc: 0.8911 - val_loss: 0.4791 - val_acc: 0.8557\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3928 - acc: 0.8899 - val_loss: 0.4582 - val_acc: 0.8647\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3887 - acc: 0.8915 - val_loss: 0.4792 - val_acc: 0.8622\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3871 - acc: 0.8919 - val_loss: 0.5081 - val_acc: 0.8556\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3867 - acc: 0.8913 - val_loss: 0.4284 - val_acc: 0.8767\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.3828 - acc: 0.8932 - val_loss: 0.4324 - val_acc: 0.8777\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.3847 - acc: 0.8917 - val_loss: 0.4574 - val_acc: 0.8644\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.3792 - acc: 0.8950 - val_loss: 0.4609 - val_acc: 0.8596\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.3804 - acc: 0.8945 - val_loss: 0.4412 - val_acc: 0.8755\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.3773 - acc: 0.8959 - val_loss: 0.4500 - val_acc: 0.8626\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3790 - acc: 0.8944 - val_loss: 0.4719 - val_acc: 0.8623\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3768 - acc: 0.8958 - val_loss: 0.4177 - val_acc: 0.8824\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3724 - acc: 0.8965 - val_loss: 0.4441 - val_acc: 0.8723\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3713 - acc: 0.8975 - val_loss: 0.4297 - val_acc: 0.8781\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3742 - acc: 0.8955 - val_loss: 0.5250 - val_acc: 0.8458\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.3734 - acc: 0.8966 - val_loss: 0.5188 - val_acc: 0.8512\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3698 - acc: 0.8973 - val_loss: 0.4746 - val_acc: 0.8552\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3696 - acc: 0.8968 - val_loss: 0.5216 - val_acc: 0.8455\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3652 - acc: 0.8997 - val_loss: 0.4250 - val_acc: 0.8786\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3652 - acc: 0.9002 - val_loss: 0.4102 - val_acc: 0.8851\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3668 - acc: 0.8984 - val_loss: 0.4801 - val_acc: 0.8610\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.3630 - acc: 0.9010 - val_loss: 0.4134 - val_acc: 0.8795\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3633 - acc: 0.8998 - val_loss: 0.4390 - val_acc: 0.8753\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.3660 - acc: 0.9010 - val_loss: 0.4648 - val_acc: 0.8698\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.3606 - acc: 0.9013 - val_loss: 0.4551 - val_acc: 0.8655\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3602 - acc: 0.9025 - val_loss: 0.4228 - val_acc: 0.8810\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3594 - acc: 0.9022 - val_loss: 0.5077 - val_acc: 0.8511\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3601 - acc: 0.9018 - val_loss: 0.4123 - val_acc: 0.8841\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3587 - acc: 0.9036 - val_loss: 0.5160 - val_acc: 0.8483\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3593 - acc: 0.9023 - val_loss: 0.4317 - val_acc: 0.8749\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3541 - acc: 0.9050 - val_loss: 0.5058 - val_acc: 0.8560\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3559 - acc: 0.9027 - val_loss: 0.4652 - val_acc: 0.8650\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3548 - acc: 0.9031 - val_loss: 0.4103 - val_acc: 0.8851\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3591 - acc: 0.9010 - val_loss: 0.4637 - val_acc: 0.8684\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3515 - acc: 0.9049 - val_loss: 0.4127 - val_acc: 0.8859\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3541 - acc: 0.9015 - val_loss: 0.4309 - val_acc: 0.8764\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3571 - acc: 0.9032 - val_loss: 0.4356 - val_acc: 0.8806\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3503 - acc: 0.9042 - val_loss: 0.4291 - val_acc: 0.8769\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.3496 - acc: 0.9050 - val_loss: 0.5785 - val_acc: 0.8335\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3481 - acc: 0.9065 - val_loss: 0.4422 - val_acc: 0.8770\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.3480 - acc: 0.9064 - val_loss: 0.4578 - val_acc: 0.8661\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3467 - acc: 0.9062 - val_loss: 0.4679 - val_acc: 0.8649\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3499 - acc: 0.9049 - val_loss: 0.6368 - val_acc: 0.8107\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3474 - acc: 0.9069 - val_loss: 0.4729 - val_acc: 0.8689\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3462 - acc: 0.9080 - val_loss: 0.4647 - val_acc: 0.8646\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3458 - acc: 0.9069 - val_loss: 0.4728 - val_acc: 0.8569\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3469 - acc: 0.9071 - val_loss: 0.4233 - val_acc: 0.8834\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3459 - acc: 0.9076 - val_loss: 0.4390 - val_acc: 0.8772\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3490 - acc: 0.9046 - val_loss: 0.4000 - val_acc: 0.8890\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3441 - acc: 0.9073 - val_loss: 0.4445 - val_acc: 0.8765\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3409 - acc: 0.9086 - val_loss: 0.4281 - val_acc: 0.8789\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3425 - acc: 0.9085 - val_loss: 0.4599 - val_acc: 0.8673\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3427 - acc: 0.9075 - val_loss: 0.4248 - val_acc: 0.8768\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3430 - acc: 0.9080 - val_loss: 0.4335 - val_acc: 0.8809\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3422 - acc: 0.9090 - val_loss: 0.4452 - val_acc: 0.8773\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3424 - acc: 0.9085 - val_loss: 0.4087 - val_acc: 0.8863\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3378 - acc: 0.9090 - val_loss: 0.4957 - val_acc: 0.8541\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3420 - acc: 0.9087 - val_loss: 0.4079 - val_acc: 0.8860\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.3413 - acc: 0.9088 - val_loss: 0.4557 - val_acc: 0.8662\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3422 - acc: 0.9076 - val_loss: 0.5186 - val_acc: 0.8523\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3370 - acc: 0.9121 - val_loss: 0.4989 - val_acc: 0.8556\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3391 - acc: 0.9090 - val_loss: 0.4298 - val_acc: 0.8778\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3376 - acc: 0.9102 - val_loss: 0.4751 - val_acc: 0.8662\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3346 - acc: 0.9117 - val_loss: 0.5044 - val_acc: 0.8537\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3383 - acc: 0.9097 - val_loss: 0.4283 - val_acc: 0.8785\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3348 - acc: 0.9116 - val_loss: 0.6564 - val_acc: 0.8054: 0s - loss: 0.3349 - acc: 0.911\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3371 - acc: 0.9097 - val_loss: 0.4956 - val_acc: 0.8566\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.3365 - acc: 0.9108 - val_loss: 0.5275 - val_acc: 0.8500\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.3328 - acc: 0.9124 - val_loss: 0.4334 - val_acc: 0.8799\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3376 - acc: 0.9095 - val_loss: 0.4428 - val_acc: 0.8772\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3331 - acc: 0.9112 - val_loss: 0.5159 - val_acc: 0.8535\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3306 - acc: 0.9121 - val_loss: 0.4098 - val_acc: 0.8905\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3330 - acc: 0.9119 - val_loss: 0.4501 - val_acc: 0.8747\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3348 - acc: 0.9115 - val_loss: 0.4847 - val_acc: 0.8634\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.3335 - acc: 0.9124 - val_loss: 0.3999 - val_acc: 0.8887\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.3279 - acc: 0.9139 - val_loss: 0.4485 - val_acc: 0.8776\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.3325 - acc: 0.9131 - val_loss: 0.4489 - val_acc: 0.8755\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3280 - acc: 0.9140 - val_loss: 0.4304 - val_acc: 0.8799\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3316 - acc: 0.9115 - val_loss: 0.5495 - val_acc: 0.8492\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3321 - acc: 0.9120 - val_loss: 0.4666 - val_acc: 0.8695\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3300 - acc: 0.9135 - val_loss: 0.4231 - val_acc: 0.8852\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3311 - acc: 0.9122 - val_loss: 0.4814 - val_acc: 0.8602\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3312 - acc: 0.9117 - val_loss: 0.4343 - val_acc: 0.8820\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3294 - acc: 0.9129 - val_loss: 0.4709 - val_acc: 0.8685\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3280 - acc: 0.9131 - val_loss: 0.4221 - val_acc: 0.8811\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3303 - acc: 0.9128 - val_loss: 0.4457 - val_acc: 0.8814\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.3313 - acc: 0.9118 - val_loss: 0.4652 - val_acc: 0.8730\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3270 - acc: 0.9156 - val_loss: 0.4072 - val_acc: 0.8896\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3276 - acc: 0.9141 - val_loss: 0.5834 - val_acc: 0.8260\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3292 - acc: 0.9138 - val_loss: 0.4083 - val_acc: 0.8888\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3228 - acc: 0.9154 - val_loss: 0.4851 - val_acc: 0.8562\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3278 - acc: 0.9136 - val_loss: 0.4328 - val_acc: 0.8765\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.3262 - acc: 0.9138 - val_loss: 0.4311 - val_acc: 0.8853\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.3252 - acc: 0.9149 - val_loss: 0.4496 - val_acc: 0.8752\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.3256 - acc: 0.9143 - val_loss: 0.4581 - val_acc: 0.8739\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.3244 - acc: 0.9158 - val_loss: 0.4939 - val_acc: 0.8638\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3251 - acc: 0.9154 - val_loss: 0.4647 - val_acc: 0.8687\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3242 - acc: 0.9164 - val_loss: 0.4097 - val_acc: 0.8919\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3217 - acc: 0.9161 - val_loss: 0.4809 - val_acc: 0.8630\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3246 - acc: 0.9153 - val_loss: 0.4310 - val_acc: 0.8769\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3239 - acc: 0.9160 - val_loss: 0.4352 - val_acc: 0.8800\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3216 - acc: 0.9164 - val_loss: 0.4421 - val_acc: 0.8740\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3230 - acc: 0.9171 - val_loss: 0.4353 - val_acc: 0.8803\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3248 - acc: 0.9153 - val_loss: 0.5106 - val_acc: 0.8561\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3241 - acc: 0.9149 - val_loss: 0.4158 - val_acc: 0.8891\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3249 - acc: 0.9153 - val_loss: 0.4842 - val_acc: 0.8662\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3232 - acc: 0.9162 - val_loss: 0.5412 - val_acc: 0.8538\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3218 - acc: 0.9164 - val_loss: 0.4435 - val_acc: 0.8730\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3229 - acc: 0.9175 - val_loss: 0.4178 - val_acc: 0.8885\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.3204 - acc: 0.9168 - val_loss: 0.4477 - val_acc: 0.8752\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.3229 - acc: 0.9159 - val_loss: 0.4235 - val_acc: 0.8855\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.3250 - acc: 0.9151 - val_loss: 0.4383 - val_acc: 0.8765\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3164 - acc: 0.9175 - val_loss: 0.4347 - val_acc: 0.8841\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3234 - acc: 0.9164 - val_loss: 0.4640 - val_acc: 0.8753\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3259 - acc: 0.9136 - val_loss: 0.4092 - val_acc: 0.8896\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3189 - acc: 0.9185 - val_loss: 0.4908 - val_acc: 0.8674\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3192 - acc: 0.9170 - val_loss: 0.7031 - val_acc: 0.8214\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3226 - acc: 0.9166 - val_loss: 0.4371 - val_acc: 0.8773\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.3210 - acc: 0.9159 - val_loss: 0.4512 - val_acc: 0.8743\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.3194 - acc: 0.9165 - val_loss: 0.4314 - val_acc: 0.8841\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.3202 - acc: 0.9159 - val_loss: 0.4286 - val_acc: 0.8845\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3197 - acc: 0.9178 - val_loss: 0.4812 - val_acc: 0.8700\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.3202 - acc: 0.9172 - val_loss: 0.4815 - val_acc: 0.8691\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.3179 - acc: 0.9178 - val_loss: 0.4804 - val_acc: 0.8701\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.3189 - acc: 0.9175 - val_loss: 0.4258 - val_acc: 0.8838\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3210 - acc: 0.9171 - val_loss: 0.4401 - val_acc: 0.8774\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.3172 - acc: 0.9174 - val_loss: 0.4187 - val_acc: 0.8908\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3186 - acc: 0.9171 - val_loss: 0.4930 - val_acc: 0.8662\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.3202 - acc: 0.9158 - val_loss: 0.4522 - val_acc: 0.8739\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3167 - acc: 0.9179 - val_loss: 0.4532 - val_acc: 0.8747\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3192 - acc: 0.9173 - val_loss: 0.4112 - val_acc: 0.8907\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3203 - acc: 0.9174 - val_loss: 0.4142 - val_acc: 0.8877\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.3173 - acc: 0.9186 - val_loss: 0.4534 - val_acc: 0.8781\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.3149 - acc: 0.9184 - val_loss: 0.4220 - val_acc: 0.8818\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.3168 - acc: 0.9172 - val_loss: 0.4845 - val_acc: 0.8658\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.3187 - acc: 0.9179 - val_loss: 0.4614 - val_acc: 0.8731\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.3169 - acc: 0.9184 - val_loss: 0.4819 - val_acc: 0.8687\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.3154 - acc: 0.9184 - val_loss: 0.4275 - val_acc: 0.8849\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.3178 - acc: 0.9177 - val_loss: 0.4099 - val_acc: 0.8898\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3183 - acc: 0.9178 - val_loss: 0.4421 - val_acc: 0.8769\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3141 - acc: 0.9189 - val_loss: 0.4631 - val_acc: 0.8695\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.3142 - acc: 0.9196 - val_loss: 0.4716 - val_acc: 0.8767\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.3168 - acc: 0.9188 - val_loss: 0.4294 - val_acc: 0.8874\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.3139 - acc: 0.9199 - val_loss: 0.5010 - val_acc: 0.8610\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3163 - acc: 0.9187 - val_loss: 0.4718 - val_acc: 0.8701\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3154 - acc: 0.9202 - val_loss: 0.4971 - val_acc: 0.8647\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3140 - acc: 0.9196 - val_loss: 0.4243 - val_acc: 0.8832\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.3142 - acc: 0.9198 - val_loss: 0.5312 - val_acc: 0.8634\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3155 - acc: 0.9184 - val_loss: 0.5144 - val_acc: 0.8568\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.3144 - acc: 0.9200 - val_loss: 0.4831 - val_acc: 0.8584\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.3139 - acc: 0.9197 - val_loss: 0.4800 - val_acc: 0.8632\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3138 - acc: 0.9187 - val_loss: 0.4246 - val_acc: 0.8858\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3133 - acc: 0.9202 - val_loss: 0.4955 - val_acc: 0.8683\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.3105 - acc: 0.9205 - val_loss: 0.4544 - val_acc: 0.8772\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3162 - acc: 0.9193 - val_loss: 0.4394 - val_acc: 0.8793\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3114 - acc: 0.9200 - val_loss: 0.4548 - val_acc: 0.8770\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3153 - acc: 0.9200 - val_loss: 0.5455 - val_acc: 0.8419\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.3152 - acc: 0.9194 - val_loss: 0.4208 - val_acc: 0.8863\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.3086 - acc: 0.9211 - val_loss: 0.5400 - val_acc: 0.8523\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.3152 - acc: 0.9188 - val_loss: 0.4338 - val_acc: 0.8842\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.3099 - acc: 0.9208 - val_loss: 0.4651 - val_acc: 0.8699\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3104 - acc: 0.9213 - val_loss: 0.4784 - val_acc: 0.8678\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.3127 - acc: 0.9196 - val_loss: 0.5185 - val_acc: 0.8616\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3135 - acc: 0.9203 - val_loss: 0.4460 - val_acc: 0.8811\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3070 - acc: 0.9224 - val_loss: 0.4902 - val_acc: 0.8648\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3107 - acc: 0.9206 - val_loss: 0.5170 - val_acc: 0.8490\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.3095 - acc: 0.9207 - val_loss: 0.4705 - val_acc: 0.8744\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.3199 - acc: 0.9185 - val_loss: 0.4650 - val_acc: 0.8756\n"
     ]
    }
   ],
   "source": [
    "model_L2 = Sequential()\n",
    "model_L2.add(Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_L2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_L2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_L2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_L2.add(Dense(10, activation='softmax'))\n",
    "model_L2.compile(optimizer='rmsprop', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "result_L2 = model_L2.fit(X_train, y_train, \n",
    "                         validation_data=(X_valid, y_valid), \n",
    "                         epochs=200, batch_size=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss = baseline_history.history['val_loss']\n",
    "val_loss_dropout = result_dropout.history['val_loss']\n",
    "val_loss_L1 = result_L1.history['val_loss']\n",
    "val_loss_L2 = result_L2.history['val_loss']\n",
    "plt.plot(val_loss)\n",
    "plt.plot(val_loss_dropout)\n",
    "plt.plot(val_loss_L1)\n",
    "plt.plot(val_loss_L2)\n",
    "plt.legend(['val_loss', 'val_loss_dropout', 'val_loss_L1', 'val_loss_L2'])\n",
    "plt.title('The validation loss for the initial/dropout/L1/L2 model over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Models\n",
    "We will use 12 alternative models, focusing on the number of layers as our key parameter:\n",
    "1) Varying the number of layers for all the 4 models explored above- baseline, dropout, using L1 & L2\n",
    "a) With 4 layers (less than baseline)\n",
    "b) With 3 layers (less than baseline)\n",
    "c) With 6 layers (more than baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep adding the history\n",
    "alt_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(model):\n",
    "    legend_titles = []\n",
    "    \n",
    "    plt.plot(model.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in alt_models:\n",
    "    plot_loss(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models (no dropout or regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.7446 - acc: 0.7344 - val_loss: 0.5947 - val_acc: 0.7725\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.4719 - acc: 0.8257 - val_loss: 0.4371 - val_acc: 0.8320\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.4012 - acc: 0.8531 - val_loss: 0.4376 - val_acc: 0.8414\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 0.3618 - acc: 0.8649 - val_loss: 0.3646 - val_acc: 0.8634\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.3318 - acc: 0.8768 - val_loss: 0.3850 - val_acc: 0.8614\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.3143 - acc: 0.8820 - val_loss: 0.3409 - val_acc: 0.8714\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2937 - acc: 0.8881 - val_loss: 0.3593 - val_acc: 0.8694\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.2758 - acc: 0.8956 - val_loss: 0.3664 - val_acc: 0.8663\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.2609 - acc: 0.9023 - val_loss: 0.3792 - val_acc: 0.8597\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.2500 - acc: 0.9053 - val_loss: 0.3499 - val_acc: 0.8791\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.2404 - acc: 0.9089 - val_loss: 0.3467 - val_acc: 0.8763\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2285 - acc: 0.9137 - val_loss: 0.3269 - val_acc: 0.8804\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2193 - acc: 0.9157 - val_loss: 0.3355 - val_acc: 0.8828\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2108 - acc: 0.9190 - val_loss: 0.3184 - val_acc: 0.8895\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.2031 - acc: 0.9229 - val_loss: 0.3381 - val_acc: 0.8853\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1971 - acc: 0.9236 - val_loss: 0.3491 - val_acc: 0.8857\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.1887 - acc: 0.9290 - val_loss: 0.3345 - val_acc: 0.8848\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.1799 - acc: 0.9319 - val_loss: 0.3850 - val_acc: 0.8823\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.1759 - acc: 0.9336 - val_loss: 0.3671 - val_acc: 0.8851\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.1694 - acc: 0.9352 - val_loss: 0.3966 - val_acc: 0.8844\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.1635 - acc: 0.9374 - val_loss: 0.3339 - val_acc: 0.8936\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1573 - acc: 0.9391 - val_loss: 0.3440 - val_acc: 0.8954\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1541 - acc: 0.9409 - val_loss: 0.3608 - val_acc: 0.8946\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1455 - acc: 0.9451 - val_loss: 0.3582 - val_acc: 0.8916\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.1416 - acc: 0.9462 - val_loss: 0.3585 - val_acc: 0.8910\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.1355 - acc: 0.9482 - val_loss: 0.3855 - val_acc: 0.8893\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.1340 - acc: 0.9487 - val_loss: 0.3756 - val_acc: 0.8956\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.1298 - acc: 0.9509 - val_loss: 0.4196 - val_acc: 0.8867\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.1234 - acc: 0.9520 - val_loss: 0.3883 - val_acc: 0.8922\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.1214 - acc: 0.9540 - val_loss: 0.3702 - val_acc: 0.8890\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1174 - acc: 0.9549 - val_loss: 0.4537 - val_acc: 0.8831\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1138 - acc: 0.9566 - val_loss: 0.4553 - val_acc: 0.8865\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.1134 - acc: 0.9574 - val_loss: 0.4007 - val_acc: 0.8963\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.1049 - acc: 0.9601 - val_loss: 0.4462 - val_acc: 0.8871\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.1062 - acc: 0.9592 - val_loss: 0.4188 - val_acc: 0.8899\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.1009 - acc: 0.9629 - val_loss: 0.4354 - val_acc: 0.8946\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.0973 - acc: 0.9625 - val_loss: 0.4559 - val_acc: 0.8930\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.0965 - acc: 0.9641 - val_loss: 0.4465 - val_acc: 0.8964\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0916 - acc: 0.9654 - val_loss: 0.4901 - val_acc: 0.8895\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.0943 - acc: 0.9652 - val_loss: 0.4788 - val_acc: 0.8951\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0891 - acc: 0.9667 - val_loss: 0.4780 - val_acc: 0.8964\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0888 - acc: 0.9669 - val_loss: 0.4354 - val_acc: 0.8983\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0835 - acc: 0.9680 - val_loss: 0.4944 - val_acc: 0.8916\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0841 - acc: 0.9684 - val_loss: 0.4900 - val_acc: 0.8930\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0795 - acc: 0.9696 - val_loss: 0.4574 - val_acc: 0.8958\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.0788 - acc: 0.9710 - val_loss: 0.4600 - val_acc: 0.8965\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0756 - acc: 0.9712 - val_loss: 0.5461 - val_acc: 0.8825\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.0738 - acc: 0.9713 - val_loss: 0.4875 - val_acc: 0.8938\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0760 - acc: 0.9728 - val_loss: 0.5614 - val_acc: 0.8882\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0707 - acc: 0.9742 - val_loss: 0.5895 - val_acc: 0.8821\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0733 - acc: 0.9733 - val_loss: 0.5115 - val_acc: 0.9001\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0686 - acc: 0.9751 - val_loss: 0.5995 - val_acc: 0.8812\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.0695 - acc: 0.9748 - val_loss: 0.5328 - val_acc: 0.8923\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0669 - acc: 0.9759 - val_loss: 0.5696 - val_acc: 0.8988\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.0634 - acc: 0.9765 - val_loss: 0.6210 - val_acc: 0.8936\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0636 - acc: 0.9764 - val_loss: 0.5399 - val_acc: 0.8929\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0591 - acc: 0.9789 - val_loss: 0.5840 - val_acc: 0.8915\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.0653 - acc: 0.9764 - val_loss: 0.5054 - val_acc: 0.8972\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0554 - acc: 0.9795 - val_loss: 0.6259 - val_acc: 0.8849\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0627 - acc: 0.9784 - val_loss: 0.5392 - val_acc: 0.8943\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.0572 - acc: 0.9790 - val_loss: 0.6416 - val_acc: 0.8910\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.0550 - acc: 0.9803 - val_loss: 0.5716 - val_acc: 0.8975\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0560 - acc: 0.9800 - val_loss: 0.5883 - val_acc: 0.8919\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.0590 - acc: 0.9797 - val_loss: 0.5736 - val_acc: 0.8859\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.0573 - acc: 0.9803 - val_loss: 0.5566 - val_acc: 0.9003\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.0497 - acc: 0.9820 - val_loss: 0.6250 - val_acc: 0.8910\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.0590 - acc: 0.9799 - val_loss: 0.5774 - val_acc: 0.8929\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.0510 - acc: 0.9825 - val_loss: 0.5812 - val_acc: 0.8995\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0528 - acc: 0.9827 - val_loss: 0.6722 - val_acc: 0.8921\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.0522 - acc: 0.9818 - val_loss: 0.7134 - val_acc: 0.8818\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.0487 - acc: 0.9827 - val_loss: 0.6265 - val_acc: 0.8978\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0494 - acc: 0.9829 - val_loss: 0.6710 - val_acc: 0.8902\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.0473 - acc: 0.9833 - val_loss: 0.6458 - val_acc: 0.8897\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0467 - acc: 0.9829 - val_loss: 0.6916 - val_acc: 0.8877\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0459 - acc: 0.9846 - val_loss: 0.6773 - val_acc: 0.8902\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.0526 - acc: 0.9822 - val_loss: 0.6552 - val_acc: 0.8960\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0456 - acc: 0.9848 - val_loss: 0.5961 - val_acc: 0.9000\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.0433 - acc: 0.9855 - val_loss: 0.6385 - val_acc: 0.9006\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.0469 - acc: 0.9844 - val_loss: 0.6260 - val_acc: 0.8920\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.0420 - acc: 0.9852 - val_loss: 0.7067 - val_acc: 0.8965\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.0490 - acc: 0.9845 - val_loss: 0.7123 - val_acc: 0.8945\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.0426 - acc: 0.9861 - val_loss: 0.6680 - val_acc: 0.8985\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.0433 - acc: 0.9858 - val_loss: 0.6613 - val_acc: 0.8916\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.0413 - acc: 0.9860 - val_loss: 0.7239 - val_acc: 0.8951\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.0407 - acc: 0.9855 - val_loss: 0.7020 - val_acc: 0.8977\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.0453 - acc: 0.9859 - val_loss: 0.6627 - val_acc: 0.8957\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.0411 - acc: 0.9862 - val_loss: 0.7161 - val_acc: 0.8964\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.0423 - acc: 0.9861 - val_loss: 0.8417 - val_acc: 0.8810\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.0441 - acc: 0.9861 - val_loss: 0.6565 - val_acc: 0.9010\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.0419 - acc: 0.9871 - val_loss: 0.9824 - val_acc: 0.8601\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.0437 - acc: 0.9861 - val_loss: 0.6552 - val_acc: 0.9000\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.0386 - acc: 0.9874 - val_loss: 0.8449 - val_acc: 0.8879\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.0405 - acc: 0.9870 - val_loss: 0.7176 - val_acc: 0.9001\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0410 - acc: 0.9871 - val_loss: 0.8322 - val_acc: 0.8866. - ETA: 1s - loss: 0.0\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.0418 - acc: 0.9873 - val_loss: 0.7585 - val_acc: 0.8948\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.0383 - acc: 0.9875 - val_loss: 0.7326 - val_acc: 0.8999\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.0360 - acc: 0.9875 - val_loss: 0.7775 - val_acc: 0.8953\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.0426 - acc: 0.9865 - val_loss: 0.6915 - val_acc: 0.8986\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.0392 - acc: 0.9878 - val_loss: 0.7257 - val_acc: 0.8976\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.0356 - acc: 0.9891 - val_loss: 0.7816 - val_acc: 0.8941\n"
     ]
    }
   ],
   "source": [
    "# 3 layers\n",
    "alt_model_baseline3 = Sequential()\n",
    "alt_model_baseline3.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "alt_model_baseline3.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline3.add(Dense(10, activation='softmax'))\n",
    "alt_model_baseline3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_3 = alt_model_baseline3.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.7839 - acc: 0.7205 - val_loss: 0.5695 - val_acc: 0.7790\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.4955 - acc: 0.8150 - val_loss: 0.4314 - val_acc: 0.8356\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.4155 - acc: 0.8425 - val_loss: 0.4224 - val_acc: 0.8430\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.3691 - acc: 0.8606 - val_loss: 0.4423 - val_acc: 0.8321\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3454 - acc: 0.8710 - val_loss: 0.4433 - val_acc: 0.8277\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3184 - acc: 0.8800 - val_loss: 0.3869 - val_acc: 0.8603\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.3032 - acc: 0.8848 - val_loss: 0.3430 - val_acc: 0.8739\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.2833 - acc: 0.8944 - val_loss: 0.3924 - val_acc: 0.8588\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2699 - acc: 0.8976 - val_loss: 0.4494 - val_acc: 0.8444\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.2573 - acc: 0.9009 - val_loss: 0.3308 - val_acc: 0.8824\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.2421 - acc: 0.9073 - val_loss: 0.3491 - val_acc: 0.8806\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2357 - acc: 0.9094 - val_loss: 0.3845 - val_acc: 0.8717\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2258 - acc: 0.9137 - val_loss: 0.3248 - val_acc: 0.8907\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.2148 - acc: 0.9170 - val_loss: 0.3352 - val_acc: 0.8803\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.2091 - acc: 0.9192 - val_loss: 0.3707 - val_acc: 0.8742\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.2017 - acc: 0.9218 - val_loss: 0.3848 - val_acc: 0.8749\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1937 - acc: 0.9255 - val_loss: 0.3381 - val_acc: 0.8916\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1861 - acc: 0.9281 - val_loss: 0.3768 - val_acc: 0.8906\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.1798 - acc: 0.9304 - val_loss: 0.3559 - val_acc: 0.8893\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.1770 - acc: 0.9324 - val_loss: 0.4284 - val_acc: 0.8662\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.1714 - acc: 0.9339 - val_loss: 0.4092 - val_acc: 0.8793\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.1639 - acc: 0.9355 - val_loss: 0.4434 - val_acc: 0.8754\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.1621 - acc: 0.9360 - val_loss: 0.3708 - val_acc: 0.8947s: 0.1624 - a\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.1555 - acc: 0.9400 - val_loss: 0.4154 - val_acc: 0.8910\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1527 - acc: 0.9407 - val_loss: 0.4018 - val_acc: 0.8908\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.1498 - acc: 0.9420 - val_loss: 0.4140 - val_acc: 0.8865\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.1430 - acc: 0.9455 - val_loss: 0.4908 - val_acc: 0.8858\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1364 - acc: 0.9471 - val_loss: 0.5043 - val_acc: 0.8925\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1352 - acc: 0.9474 - val_loss: 0.4009 - val_acc: 0.8942\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1352 - acc: 0.9489 - val_loss: 0.4379 - val_acc: 0.8931\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1299 - acc: 0.9523 - val_loss: 0.4523 - val_acc: 0.8898\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.1228 - acc: 0.9528 - val_loss: 0.4198 - val_acc: 0.8965\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.1222 - acc: 0.9530 - val_loss: 0.5402 - val_acc: 0.8835\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1229 - acc: 0.9529 - val_loss: 0.4718 - val_acc: 0.8966\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.1193 - acc: 0.9560 - val_loss: 0.4549 - val_acc: 0.8825\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1138 - acc: 0.9565 - val_loss: 0.4539 - val_acc: 0.8982\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1139 - acc: 0.9573 - val_loss: 0.5025 - val_acc: 0.8924\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.1120 - acc: 0.9585 - val_loss: 0.4772 - val_acc: 0.8950\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1114 - acc: 0.9578 - val_loss: 0.4697 - val_acc: 0.8940\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1050 - acc: 0.9595 - val_loss: 0.5132 - val_acc: 0.8978\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1028 - acc: 0.9599 - val_loss: 0.4747 - val_acc: 0.8967\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1016 - acc: 0.9618 - val_loss: 0.4932 - val_acc: 0.8971\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0996 - acc: 0.9627 - val_loss: 0.4950 - val_acc: 0.8956\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0968 - acc: 0.9624 - val_loss: 0.5448 - val_acc: 0.8936\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1004 - acc: 0.9637 - val_loss: 0.4827 - val_acc: 0.8965\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0893 - acc: 0.9668 - val_loss: 0.5640 - val_acc: 0.8960\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0949 - acc: 0.9657 - val_loss: 0.5241 - val_acc: 0.8917\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0931 - acc: 0.9653 - val_loss: 0.5377 - val_acc: 0.8868\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0951 - acc: 0.9662 - val_loss: 0.5332 - val_acc: 0.8945\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.0850 - acc: 0.9685 - val_loss: 0.5733 - val_acc: 0.8954\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0905 - acc: 0.9673 - val_loss: 0.6028 - val_acc: 0.8861\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.0849 - acc: 0.9697 - val_loss: 0.5705 - val_acc: 0.8961\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.0829 - acc: 0.9687 - val_loss: 0.8365 - val_acc: 0.8726\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0863 - acc: 0.9696 - val_loss: 0.5483 - val_acc: 0.8951\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0848 - acc: 0.9688 - val_loss: 0.6267 - val_acc: 0.8745\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.0768 - acc: 0.9722 - val_loss: 0.5987 - val_acc: 0.8931\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.0805 - acc: 0.9708 - val_loss: 0.6671 - val_acc: 0.8972\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0835 - acc: 0.9706 - val_loss: 0.6598 - val_acc: 0.8913\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.0790 - acc: 0.9728 - val_loss: 0.6441 - val_acc: 0.9000\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0769 - acc: 0.9717 - val_loss: 0.6288 - val_acc: 0.8934\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.0830 - acc: 0.9732 - val_loss: 0.6103 - val_acc: 0.8983\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0771 - acc: 0.9731 - val_loss: 0.6564 - val_acc: 0.8967\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.0755 - acc: 0.9737 - val_loss: 0.6161 - val_acc: 0.8843\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0741 - acc: 0.9745 - val_loss: 0.5946 - val_acc: 0.8980\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.0728 - acc: 0.9754 - val_loss: 0.6511 - val_acc: 0.8901\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.0763 - acc: 0.9734 - val_loss: 0.6688 - val_acc: 0.8934\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.0697 - acc: 0.9762 - val_loss: 0.6041 - val_acc: 0.8873\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0766 - acc: 0.9741 - val_loss: 0.6589 - val_acc: 0.8913\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.0705 - acc: 0.9761 - val_loss: 0.6341 - val_acc: 0.8933\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.0693 - acc: 0.9757 - val_loss: 0.6101 - val_acc: 0.8984\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.0701 - acc: 0.9766 - val_loss: 0.6536 - val_acc: 0.9014\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0718 - acc: 0.9761 - val_loss: 0.7170 - val_acc: 0.8990\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0728 - acc: 0.9757 - val_loss: 0.6509 - val_acc: 0.8976\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.0683 - acc: 0.9765 - val_loss: 0.6814 - val_acc: 0.8983\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.0703 - acc: 0.9765 - val_loss: 0.7440 - val_acc: 0.8928\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.0693 - acc: 0.9783 - val_loss: 0.7146 - val_acc: 0.8784\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.0681 - acc: 0.9776 - val_loss: 0.6805 - val_acc: 0.9001 1s - loss: 0.0674 - acc: 0.977 - ETA: 1s - loss: 0.0\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.0715 - acc: 0.9772 - val_loss: 0.7203 - val_acc: 0.8935\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.0594 - acc: 0.9791 - val_loss: 0.7969 - val_acc: 0.8917\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0669 - acc: 0.9780 - val_loss: 0.7468 - val_acc: 0.8955\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.0640 - acc: 0.9795 - val_loss: 0.6402 - val_acc: 0.9020\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.0621 - acc: 0.9797 - val_loss: 0.8103 - val_acc: 0.8820: 5s - l - ETA: 1s - \n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.0677 - acc: 0.9781 - val_loss: 0.6825 - val_acc: 0.8978\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.0607 - acc: 0.9800 - val_loss: 0.6884 - val_acc: 0.8984\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.0689 - acc: 0.9776 - val_loss: 0.6594 - val_acc: 0.8907\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.0627 - acc: 0.9805 - val_loss: 0.6613 - val_acc: 0.8980\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.0573 - acc: 0.9812 - val_loss: 0.7030 - val_acc: 0.9016\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.0628 - acc: 0.9805 - val_loss: 0.7952 - val_acc: 0.8806\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.0608 - acc: 0.9798 - val_loss: 0.7497 - val_acc: 0.8968\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.0655 - acc: 0.9788 - val_loss: 0.7021 - val_acc: 0.8962\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.0635 - acc: 0.9808 - val_loss: 0.8095 - val_acc: 0.8958\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.0602 - acc: 0.9807 - val_loss: 0.8027 - val_acc: 0.8962\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.0638 - acc: 0.9812 - val_loss: 0.7491 - val_acc: 0.8938\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.0548 - acc: 0.9824 - val_loss: 0.8049 - val_acc: 0.8915\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.0647 - acc: 0.9793 - val_loss: 0.7244 - val_acc: 0.8844\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.0560 - acc: 0.9822 - val_loss: 0.7536 - val_acc: 0.8916\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.0586 - acc: 0.9819 - val_loss: 0.8640 - val_acc: 0.8922\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.0616 - acc: 0.9818 - val_loss: 0.7949 - val_acc: 0.8877\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.0641 - acc: 0.9806 - val_loss: 0.7543 - val_acc: 0.8937\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.0541 - acc: 0.9834 - val_loss: 0.7982 - val_acc: 0.8970\n"
     ]
    }
   ],
   "source": [
    "# 4 Layers\n",
    "alt_model_baseline4 = Sequential()\n",
    "alt_model_baseline4.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "alt_model_baseline4.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline4.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline4.add(Dense(10, activation='softmax'))\n",
    "alt_model_baseline4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_4 = alt_model_baseline4.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.9460 - acc: 0.6572 - val_loss: 0.5244 - val_acc: 0.7910\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.5533 - acc: 0.7983 - val_loss: 0.4589 - val_acc: 0.8311\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.4501 - acc: 0.8315 - val_loss: 0.5013 - val_acc: 0.8053\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.4044 - acc: 0.8490 - val_loss: 0.4452 - val_acc: 0.8237\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3693 - acc: 0.8636 - val_loss: 0.3958 - val_acc: 0.8530\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.3440 - acc: 0.8716 - val_loss: 0.4776 - val_acc: 0.8405\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.3313 - acc: 0.8768 - val_loss: 0.3665 - val_acc: 0.8698\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3079 - acc: 0.8843 - val_loss: 0.3641 - val_acc: 0.8655\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.2916 - acc: 0.8908 - val_loss: 0.3209 - val_acc: 0.8851\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.2821 - acc: 0.8943 - val_loss: 0.3308 - val_acc: 0.8799\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.2687 - acc: 0.8985 - val_loss: 0.3689 - val_acc: 0.8753\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.2593 - acc: 0.9026 - val_loss: 0.3993 - val_acc: 0.8647\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.2513 - acc: 0.9048 - val_loss: 0.3549 - val_acc: 0.8804\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.2420 - acc: 0.9085 - val_loss: 0.3746 - val_acc: 0.8756\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.2383 - acc: 0.9112 - val_loss: 0.3881 - val_acc: 0.8795\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2265 - acc: 0.9143 - val_loss: 0.3848 - val_acc: 0.8730\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.2234 - acc: 0.9153 - val_loss: 0.4279 - val_acc: 0.8726\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.2191 - acc: 0.9174 - val_loss: 0.4137 - val_acc: 0.8806\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.2100 - acc: 0.9211 - val_loss: 0.3410 - val_acc: 0.8909\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2076 - acc: 0.9226 - val_loss: 0.3990 - val_acc: 0.89042s - loss:\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2082 - acc: 0.9223 - val_loss: 0.4107 - val_acc: 0.8703\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.2030 - acc: 0.9241 - val_loss: 0.4448 - val_acc: 0.8727\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1951 - acc: 0.9258 - val_loss: 0.3707 - val_acc: 0.8873\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1897 - acc: 0.9303 - val_loss: 0.4083 - val_acc: 0.8765\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1893 - acc: 0.9288 - val_loss: 0.4276 - val_acc: 0.8898\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1888 - acc: 0.9285 - val_loss: 0.3746 - val_acc: 0.8942: 0.\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1870 - acc: 0.9313 - val_loss: 0.4575 - val_acc: 0.8749\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1776 - acc: 0.9335 - val_loss: 0.4365 - val_acc: 0.8935\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1855 - acc: 0.9336 - val_loss: 0.3663 - val_acc: 0.8974\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 0.1777 - acc: 0.9361 - val_loss: 0.4523 - val_acc: 0.8924\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 0.1694 - acc: 0.9360 - val_loss: 0.4349 - val_acc: 0.8842\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.1725 - acc: 0.9358 - val_loss: 0.3872 - val_acc: 0.8921\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.1702 - acc: 0.9390 - val_loss: 0.3841 - val_acc: 0.8859\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1672 - acc: 0.9373 - val_loss: 0.4524 - val_acc: 0.8928\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1662 - acc: 0.9399 - val_loss: 0.4013 - val_acc: 0.8880\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1678 - acc: 0.9399 - val_loss: 0.4181 - val_acc: 0.9001\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1665 - acc: 0.9398 - val_loss: 0.3860 - val_acc: 0.8962\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.1632 - acc: 0.9408 - val_loss: 0.4879 - val_acc: 0.8779\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1689 - acc: 0.9411 - val_loss: 0.4098 - val_acc: 0.8933\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1564 - acc: 0.9440 - val_loss: 0.4773 - val_acc: 0.8933\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.1594 - acc: 0.9448 - val_loss: 0.4456 - val_acc: 0.8944\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1555 - acc: 0.9440 - val_loss: 0.4471 - val_acc: 0.8973\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1594 - acc: 0.9441 - val_loss: 0.4030 - val_acc: 0.8968\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.1480 - acc: 0.9461 - val_loss: 0.4413 - val_acc: 0.8962\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.1463 - acc: 0.9477 - val_loss: 0.4441 - val_acc: 0.8887\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1445 - acc: 0.9478 - val_loss: 0.5342 - val_acc: 0.8898\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1477 - acc: 0.9483 - val_loss: 0.5827 - val_acc: 0.8805\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.1432 - acc: 0.9476 - val_loss: 0.4366 - val_acc: 0.8944\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1455 - acc: 0.9487 - val_loss: 0.4694 - val_acc: 0.8884\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.1400 - acc: 0.9504 - val_loss: 0.4711 - val_acc: 0.8973\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.1377 - acc: 0.9511 - val_loss: 0.4943 - val_acc: 0.8896\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.1406 - acc: 0.9507 - val_loss: 0.5518 - val_acc: 0.8756\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1464 - acc: 0.9515 - val_loss: 0.4759 - val_acc: 0.8921\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1239 - acc: 0.9551 - val_loss: 0.4968 - val_acc: 0.8942\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1368 - acc: 0.9521 - val_loss: 0.5210 - val_acc: 0.8847\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1253 - acc: 0.9559 - val_loss: 0.5022 - val_acc: 0.8987\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1345 - acc: 0.9549 - val_loss: 0.4833 - val_acc: 0.8924\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.1316 - acc: 0.9558 - val_loss: 0.5321 - val_acc: 0.8989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.1310 - acc: 0.9550 - val_loss: 0.4800 - val_acc: 0.8995\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.1219 - acc: 0.9569 - val_loss: 0.5116 - val_acc: 0.8990\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1263 - acc: 0.9576 - val_loss: 0.5568 - val_acc: 0.8945\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.1187 - acc: 0.9572 - val_loss: 0.5382 - val_acc: 0.8994\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.1248 - acc: 0.9570 - val_loss: 0.5351 - val_acc: 0.8672\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.1309 - acc: 0.9574 - val_loss: 0.4861 - val_acc: 0.9002\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.1305 - acc: 0.9574 - val_loss: 0.4555 - val_acc: 0.8971\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1181 - acc: 0.9590 - val_loss: 0.5373 - val_acc: 0.9019\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1267 - acc: 0.9595 - val_loss: 0.5237 - val_acc: 0.8986\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.1134 - acc: 0.9609 - val_loss: 0.6100 - val_acc: 0.8791\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1320 - acc: 0.9599 - val_loss: 0.4832 - val_acc: 0.8968\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1117 - acc: 0.9615 - val_loss: 0.5810 - val_acc: 0.8955\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.1058 - acc: 0.9630 - val_loss: 0.6261 - val_acc: 0.8672\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.1151 - acc: 0.9607 - val_loss: 0.5032 - val_acc: 0.8974\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.1083 - acc: 0.9614 - val_loss: 0.5415 - val_acc: 0.8870\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.1061 - acc: 0.9639 - val_loss: 0.5992 - val_acc: 0.8976\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.1171 - acc: 0.9608 - val_loss: 0.5342 - val_acc: 0.8932\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.1087 - acc: 0.9637 - val_loss: 0.6610 - val_acc: 0.8968\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.1152 - acc: 0.9622 - val_loss: 0.5505 - val_acc: 0.8929\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.1038 - acc: 0.9641 - val_loss: 0.5820 - val_acc: 0.9000\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.1080 - acc: 0.9639 - val_loss: 0.6474 - val_acc: 0.9008\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.1198 - acc: 0.9632 - val_loss: 0.5550 - val_acc: 0.9003\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.1102 - acc: 0.9655 - val_loss: 0.5817 - val_acc: 0.8942\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1024 - acc: 0.9655 - val_loss: 0.6007 - val_acc: 0.8991\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1123 - acc: 0.9657 - val_loss: 0.5493 - val_acc: 0.8984\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.0952 - acc: 0.9679 - val_loss: 0.7325 - val_acc: 0.8814\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.1063 - acc: 0.9653 - val_loss: 0.6672 - val_acc: 0.8859\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1059 - acc: 0.9659 - val_loss: 0.5693 - val_acc: 0.9030\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.0992 - acc: 0.9688 - val_loss: 0.6449 - val_acc: 0.8968\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.1035 - acc: 0.9667 - val_loss: 0.6453 - val_acc: 0.8844\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.0961 - acc: 0.9676 - val_loss: 0.6213 - val_acc: 0.8927\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.1005 - acc: 0.9663 - val_loss: 0.6231 - val_acc: 0.8953\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1073 - acc: 0.9658 - val_loss: 0.6231 - val_acc: 0.9029\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.0976 - acc: 0.9678 - val_loss: 0.7110 - val_acc: 0.8910\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0905 - acc: 0.9710 - val_loss: 0.6735 - val_acc: 0.8929\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1028 - acc: 0.9705 - val_loss: 0.5602 - val_acc: 0.8963\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.0855 - acc: 0.9703 - val_loss: 0.7097 - val_acc: 0.8832\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0951 - acc: 0.9700 - val_loss: 0.6117 - val_acc: 0.8994\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.0909 - acc: 0.9705 - val_loss: 0.6070 - val_acc: 0.9022\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.0874 - acc: 0.9705 - val_loss: 0.7258 - val_acc: 0.8907\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0971 - acc: 0.9734 - val_loss: 0.5726 - val_acc: 0.8940\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0871 - acc: 0.9722 - val_loss: 0.5868 - val_acc: 0.8942\n"
     ]
    }
   ],
   "source": [
    "# 6 layers\n",
    "alt_model_baseline6 = Sequential()\n",
    "alt_model_baseline6.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "alt_model_baseline6.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline6.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline6.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline6.add(Dense(512, activation='relu'))\n",
    "alt_model_baseline6.add(Dense(10, activation='softmax'))\n",
    "alt_model_baseline6.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_6 = alt_model_baseline6.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.7985 - acc: 0.7114 - val_loss: 0.5148 - val_acc: 0.8026\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.5182 - acc: 0.8124 - val_loss: 0.4492 - val_acc: 0.8335\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.4596 - acc: 0.8331 - val_loss: 0.4204 - val_acc: 0.8428\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.4234 - acc: 0.8454 - val_loss: 0.3960 - val_acc: 0.8523\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.4020 - acc: 0.8539 - val_loss: 0.3898 - val_acc: 0.8536\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.3804 - acc: 0.8621 - val_loss: 0.3596 - val_acc: 0.8670\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.3717 - acc: 0.8648 - val_loss: 0.4389 - val_acc: 0.8320\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.3566 - acc: 0.8709 - val_loss: 0.3458 - val_acc: 0.8724\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.3452 - acc: 0.8736 - val_loss: 0.3932 - val_acc: 0.8520\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.3405 - acc: 0.8749 - val_loss: 0.3299 - val_acc: 0.8827\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.3333 - acc: 0.8792 - val_loss: 0.3584 - val_acc: 0.8660\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.3280 - acc: 0.8788 - val_loss: 0.3310 - val_acc: 0.8771\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.3191 - acc: 0.8825 - val_loss: 0.3471 - val_acc: 0.8725\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.3160 - acc: 0.8840 - val_loss: 0.3366 - val_acc: 0.8798\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.3105 - acc: 0.8863 - val_loss: 0.3422 - val_acc: 0.8773\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.3044 - acc: 0.8882 - val_loss: 0.3450 - val_acc: 0.8685\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.3007 - acc: 0.8873 - val_loss: 0.3459 - val_acc: 0.8722\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.2969 - acc: 0.8910 - val_loss: 0.3320 - val_acc: 0.8764\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.2942 - acc: 0.8913 - val_loss: 0.3185 - val_acc: 0.8850\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.2865 - acc: 0.8947 - val_loss: 0.3212 - val_acc: 0.8836\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.2860 - acc: 0.8942 - val_loss: 0.3192 - val_acc: 0.8861\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.2815 - acc: 0.8965 - val_loss: 0.3261 - val_acc: 0.8812\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.2818 - acc: 0.8971 - val_loss: 0.3134 - val_acc: 0.8906\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.2798 - acc: 0.8969 - val_loss: 0.3126 - val_acc: 0.8906\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2738 - acc: 0.8991 - val_loss: 0.3187 - val_acc: 0.8898\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.2710 - acc: 0.9001 - val_loss: 0.3085 - val_acc: 0.8920\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.2674 - acc: 0.9010 - val_loss: 0.3231 - val_acc: 0.8854\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.2637 - acc: 0.9033 - val_loss: 0.3294 - val_acc: 0.8830\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.2644 - acc: 0.9025 - val_loss: 0.3292 - val_acc: 0.8842\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.2618 - acc: 0.9025 - val_loss: 0.3139 - val_acc: 0.8929\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.2574 - acc: 0.9035 - val_loss: 0.3189 - val_acc: 0.8909\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2578 - acc: 0.9038 - val_loss: 0.3275 - val_acc: 0.8882\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.2567 - acc: 0.9044 - val_loss: 0.3128 - val_acc: 0.8954\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2541 - acc: 0.9062 - val_loss: 0.3195 - val_acc: 0.8926\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2482 - acc: 0.9081 - val_loss: 0.3609 - val_acc: 0.8816\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.2488 - acc: 0.9089 - val_loss: 0.3118 - val_acc: 0.8908\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.2479 - acc: 0.9083 - val_loss: 0.3302 - val_acc: 0.8904\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2448 - acc: 0.9092 - val_loss: 0.3189 - val_acc: 0.8911\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2445 - acc: 0.9100 - val_loss: 0.3297 - val_acc: 0.8944\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.2434 - acc: 0.9101 - val_loss: 0.3196 - val_acc: 0.8915\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.2416 - acc: 0.9112 - val_loss: 0.3192 - val_acc: 0.8952\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.2410 - acc: 0.9124 - val_loss: 0.3240 - val_acc: 0.8905\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2392 - acc: 0.9111 - val_loss: 0.3189 - val_acc: 0.8942\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2366 - acc: 0.9118 - val_loss: 0.3264 - val_acc: 0.8953\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2365 - acc: 0.9127 - val_loss: 0.3507 - val_acc: 0.8882\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.2330 - acc: 0.9152 - val_loss: 0.3098 - val_acc: 0.8932\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2312 - acc: 0.9147 - val_loss: 0.3401 - val_acc: 0.8845\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.2275 - acc: 0.9155 - val_loss: 0.3417 - val_acc: 0.8930\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.2306 - acc: 0.9161 - val_loss: 0.3364 - val_acc: 0.8954\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.2259 - acc: 0.9155 - val_loss: 0.3248 - val_acc: 0.8912\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2227 - acc: 0.9174 - val_loss: 0.3340 - val_acc: 0.8946\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.2263 - acc: 0.9155 - val_loss: 0.3303 - val_acc: 0.8922\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.2280 - acc: 0.9172 - val_loss: 0.3307 - val_acc: 0.8920\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.2238 - acc: 0.9192 - val_loss: 0.3385 - val_acc: 0.8919\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2220 - acc: 0.9181 - val_loss: 0.3443 - val_acc: 0.8939\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.2206 - acc: 0.9200 - val_loss: 0.3317 - val_acc: 0.8963\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.2192 - acc: 0.9186 - val_loss: 0.3385 - val_acc: 0.8974\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.2153 - acc: 0.9201 - val_loss: 0.3632 - val_acc: 0.8900\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2190 - acc: 0.9192 - val_loss: 0.3292 - val_acc: 0.8968\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.2160 - acc: 0.9204 - val_loss: 0.3322 - val_acc: 0.8987\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.2154 - acc: 0.9212 - val_loss: 0.3405 - val_acc: 0.8969\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.2130 - acc: 0.9227 - val_loss: 0.3669 - val_acc: 0.8916\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.2117 - acc: 0.9233 - val_loss: 0.3409 - val_acc: 0.8972\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.2139 - acc: 0.9223 - val_loss: 0.3450 - val_acc: 0.8953\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.2089 - acc: 0.9229 - val_loss: 0.3490 - val_acc: 0.8966\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.2127 - acc: 0.9210 - val_loss: 0.3367 - val_acc: 0.8963\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.2075 - acc: 0.9244 - val_loss: 0.3382 - val_acc: 0.8965\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.2090 - acc: 0.9225 - val_loss: 0.3593 - val_acc: 0.8882\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.2102 - acc: 0.9221 - val_loss: 0.3346 - val_acc: 0.8963\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.2047 - acc: 0.9255 - val_loss: 0.3466 - val_acc: 0.8960\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.2039 - acc: 0.9247 - val_loss: 0.3420 - val_acc: 0.8949\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.2022 - acc: 0.9253 - val_loss: 0.3532 - val_acc: 0.8985\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.2015 - acc: 0.9267 - val_loss: 0.3649 - val_acc: 0.8952\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.2031 - acc: 0.9264 - val_loss: 0.3374 - val_acc: 0.8977\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.2048 - acc: 0.9249 - val_loss: 0.3490 - val_acc: 0.8940\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.2023 - acc: 0.9261 - val_loss: 0.3533 - val_acc: 0.8985\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.2008 - acc: 0.9255 - val_loss: 0.3435 - val_acc: 0.8971\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.2009 - acc: 0.9268 - val_loss: 0.3615 - val_acc: 0.8986\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.1976 - acc: 0.9270 - val_loss: 0.3637 - val_acc: 0.8962\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.1999 - acc: 0.9272 - val_loss: 0.3594 - val_acc: 0.8949\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.1965 - acc: 0.9279 - val_loss: 0.3686 - val_acc: 0.8899\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1948 - acc: 0.9284 - val_loss: 0.3683 - val_acc: 0.8938\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1981 - acc: 0.9289 - val_loss: 0.3897 - val_acc: 0.8901\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.1958 - acc: 0.9278 - val_loss: 0.3716 - val_acc: 0.8985\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.1915 - acc: 0.9297 - val_loss: 0.3537 - val_acc: 0.8957\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.1948 - acc: 0.9295 - val_loss: 0.3659 - val_acc: 0.8967\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.1938 - acc: 0.9293 - val_loss: 0.3608 - val_acc: 0.8993\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.1894 - acc: 0.9311 - val_loss: 0.3790 - val_acc: 0.8930\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.1954 - acc: 0.9295 - val_loss: 0.3632 - val_acc: 0.8998\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.1884 - acc: 0.9317 - val_loss: 0.3621 - val_acc: 0.8999\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.1891 - acc: 0.9309 - val_loss: 0.3714 - val_acc: 0.8946\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.1912 - acc: 0.9313 - val_loss: 0.3630 - val_acc: 0.8970\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1854 - acc: 0.9322 - val_loss: 0.3705 - val_acc: 0.8970\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1899 - acc: 0.9311 - val_loss: 0.3604 - val_acc: 0.8992\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1843 - acc: 0.9341 - val_loss: 0.3656 - val_acc: 0.9004\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1903 - acc: 0.9290 - val_loss: 0.3791 - val_acc: 0.8954\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.1855 - acc: 0.9328 - val_loss: 0.3915 - val_acc: 0.8937\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.1864 - acc: 0.9327 - val_loss: 0.3765 - val_acc: 0.8921\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.1879 - acc: 0.9326 - val_loss: 0.3731 - val_acc: 0.9002\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.1845 - acc: 0.9345 - val_loss: 0.4000 - val_acc: 0.8944\n"
     ]
    }
   ],
   "source": [
    "alt_model_drop3 = Sequential()\n",
    "alt_model_drop3.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "alt_model_drop3.add(Dropout(0.5))\n",
    "alt_model_drop3.add(Dense(512, activation='relu'))\n",
    "alt_model_drop3.add(Dropout(0.5))\n",
    "alt_model_drop3.add(Dense(10, activation='softmax'))\n",
    "alt_model_drop3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "result_drop3 = alt_model_drop3.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)\n",
    "alt_models.append(result_drop3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.8703 - acc: 0.6815 - val_loss: 0.6119 - val_acc: 0.7660\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.5487 - acc: 0.8007 - val_loss: 0.5201 - val_acc: 0.7899\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.4844 - acc: 0.8247 - val_loss: 0.4267 - val_acc: 0.8400\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.4468 - acc: 0.8388 - val_loss: 0.3995 - val_acc: 0.8561\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.4231 - acc: 0.8477 - val_loss: 0.4142 - val_acc: 0.8376\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.4049 - acc: 0.8525 - val_loss: 0.3994 - val_acc: 0.8502\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.3922 - acc: 0.8574 - val_loss: 0.3718 - val_acc: 0.8622\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.3802 - acc: 0.8626 - val_loss: 0.3695 - val_acc: 0.8670\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.3710 - acc: 0.8648 - val_loss: 0.3507 - val_acc: 0.8671\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.3569 - acc: 0.8710 - val_loss: 0.3615 - val_acc: 0.8638\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3560 - acc: 0.8724 - val_loss: 0.3506 - val_acc: 0.8723\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.3478 - acc: 0.8731 - val_loss: 0.3754 - val_acc: 0.8642\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.3427 - acc: 0.8747 - val_loss: 0.3472 - val_acc: 0.8766\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.3336 - acc: 0.8777 - val_loss: 0.3405 - val_acc: 0.8692\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3348 - acc: 0.8789 - val_loss: 0.3255 - val_acc: 0.8809\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.3269 - acc: 0.8814 - val_loss: 0.3391 - val_acc: 0.8770\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.3207 - acc: 0.8830 - val_loss: 0.3257 - val_acc: 0.8800\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3201 - acc: 0.8850 - val_loss: 0.3437 - val_acc: 0.8728\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.3161 - acc: 0.8836 - val_loss: 0.3181 - val_acc: 0.8854\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.3123 - acc: 0.8861 - val_loss: 0.3656 - val_acc: 0.8592\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.3109 - acc: 0.8872 - val_loss: 0.3505 - val_acc: 0.8684\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.3062 - acc: 0.8874 - val_loss: 0.3264 - val_acc: 0.8834\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.3037 - acc: 0.8900 - val_loss: 0.3547 - val_acc: 0.8723\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.3018 - acc: 0.8916 - val_loss: 0.3500 - val_acc: 0.8717\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3014 - acc: 0.8901 - val_loss: 0.3164 - val_acc: 0.8866\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.2998 - acc: 0.8920 - val_loss: 0.3197 - val_acc: 0.8859\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.2918 - acc: 0.8935 - val_loss: 0.3417 - val_acc: 0.8825\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.2905 - acc: 0.8955 - val_loss: 0.3186 - val_acc: 0.8878\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2876 - acc: 0.8949 - val_loss: 0.3190 - val_acc: 0.8844\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2867 - acc: 0.8964 - val_loss: 0.3180 - val_acc: 0.8883\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2855 - acc: 0.8963 - val_loss: 0.3348 - val_acc: 0.8792\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.2824 - acc: 0.8981 - val_loss: 0.3317 - val_acc: 0.8824\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2807 - acc: 0.8986 - val_loss: 0.3223 - val_acc: 0.8867\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.2846 - acc: 0.8963 - val_loss: 0.3377 - val_acc: 0.8773\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.2792 - acc: 0.9000 - val_loss: 0.3270 - val_acc: 0.8831\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2774 - acc: 0.8994 - val_loss: 0.3208 - val_acc: 0.8866\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2756 - acc: 0.9016 - val_loss: 0.3171 - val_acc: 0.8889\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.2740 - acc: 0.8995 - val_loss: 0.3299 - val_acc: 0.8846\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2715 - acc: 0.9016 - val_loss: 0.3518 - val_acc: 0.8843\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.2741 - acc: 0.9022 - val_loss: 0.3220 - val_acc: 0.8896\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2716 - acc: 0.9025 - val_loss: 0.3297 - val_acc: 0.8910\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.2702 - acc: 0.9025 - val_loss: 0.3198 - val_acc: 0.8907\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2681 - acc: 0.9031 - val_loss: 0.3266 - val_acc: 0.8879\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2662 - acc: 0.9055 - val_loss: 0.3271 - val_acc: 0.8895\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2674 - acc: 0.9048 - val_loss: 0.3342 - val_acc: 0.8898\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.2638 - acc: 0.9049 - val_loss: 0.3161 - val_acc: 0.8901\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2609 - acc: 0.9044 - val_loss: 0.3191 - val_acc: 0.8917\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.2613 - acc: 0.9069 - val_loss: 0.3313 - val_acc: 0.8873\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.2567 - acc: 0.9062 - val_loss: 0.3168 - val_acc: 0.8942\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.2567 - acc: 0.9090 - val_loss: 0.3423 - val_acc: 0.8881\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.2609 - acc: 0.9071 - val_loss: 0.3226 - val_acc: 0.8940\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2553 - acc: 0.9081 - val_loss: 0.3254 - val_acc: 0.8902\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.2554 - acc: 0.9089 - val_loss: 0.3231 - val_acc: 0.8908\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2543 - acc: 0.9092 - val_loss: 0.3134 - val_acc: 0.8937\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.2552 - acc: 0.9103 - val_loss: 0.3309 - val_acc: 0.8917\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2528 - acc: 0.9100 - val_loss: 0.3315 - val_acc: 0.8907\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.2504 - acc: 0.9093 - val_loss: 0.3348 - val_acc: 0.8931\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.2544 - acc: 0.9097 - val_loss: 0.3297 - val_acc: 0.8900\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.2535 - acc: 0.9123 - val_loss: 0.3234 - val_acc: 0.8914\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2466 - acc: 0.9113 - val_loss: 0.3284 - val_acc: 0.8910\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.2505 - acc: 0.9112 - val_loss: 0.3514 - val_acc: 0.8824\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2474 - acc: 0.9114 - val_loss: 0.3287 - val_acc: 0.8937\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.2456 - acc: 0.9135 - val_loss: 0.3592 - val_acc: 0.8830\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2466 - acc: 0.9130 - val_loss: 0.3327 - val_acc: 0.8902\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.2430 - acc: 0.9144 - val_loss: 0.3339 - val_acc: 0.8963\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2422 - acc: 0.9146 - val_loss: 0.3404 - val_acc: 0.8929\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.2432 - acc: 0.9139 - val_loss: 0.3260 - val_acc: 0.8934\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2421 - acc: 0.9145 - val_loss: 0.3319 - val_acc: 0.8895\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.2455 - acc: 0.9138 - val_loss: 0.3380 - val_acc: 0.8921\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.2399 - acc: 0.9145 - val_loss: 0.3498 - val_acc: 0.8890\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.2351 - acc: 0.9164 - val_loss: 0.3606 - val_acc: 0.8888\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2408 - acc: 0.9140 - val_loss: 0.3534 - val_acc: 0.8953\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2428 - acc: 0.9143 - val_loss: 0.3788 - val_acc: 0.8814\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.2376 - acc: 0.9142 - val_loss: 0.3418 - val_acc: 0.8924\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.2360 - acc: 0.9158 - val_loss: 0.3424 - val_acc: 0.8921\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.2298 - acc: 0.9180 - val_loss: 0.3415 - val_acc: 0.8944\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.2392 - acc: 0.9171 - val_loss: 0.3601 - val_acc: 0.8908\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.2356 - acc: 0.9176 - val_loss: 0.3628 - val_acc: 0.8895\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2329 - acc: 0.9161 - val_loss: 0.3410 - val_acc: 0.8907\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.2297 - acc: 0.9176 - val_loss: 0.3498 - val_acc: 0.8932\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 0.2366 - acc: 0.9177 - val_loss: 0.3624 - val_acc: 0.8893\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.2305 - acc: 0.9193 - val_loss: 0.3442 - val_acc: 0.8932\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.2304 - acc: 0.9186 - val_loss: 0.3473 - val_acc: 0.8928\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 0.2323 - acc: 0.9195 - val_loss: 0.3564 - val_acc: 0.8929\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.2281 - acc: 0.9201 - val_loss: 0.3362 - val_acc: 0.8957\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.2263 - acc: 0.9196 - val_loss: 0.3466 - val_acc: 0.8880\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.2313 - acc: 0.9182 - val_loss: 0.3334 - val_acc: 0.8972\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.2263 - acc: 0.9215 - val_loss: 0.3511 - val_acc: 0.8964\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.2282 - acc: 0.9196 - val_loss: 0.3330 - val_acc: 0.8951\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.2247 - acc: 0.9202 - val_loss: 0.3595 - val_acc: 0.8915\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 0.2263 - acc: 0.9208 - val_loss: 0.3453 - val_acc: 0.8934\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.2238 - acc: 0.9221 - val_loss: 0.3368 - val_acc: 0.8959\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.2279 - acc: 0.9215 - val_loss: 0.3571 - val_acc: 0.8829\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.2276 - acc: 0.9206 - val_loss: 0.3467 - val_acc: 0.8950\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.2232 - acc: 0.9226 - val_loss: 0.3441 - val_acc: 0.8972\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.2232 - acc: 0.9220 - val_loss: 0.3542 - val_acc: 0.8950\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2262 - acc: 0.9218 - val_loss: 0.3599 - val_acc: 0.8939\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2226 - acc: 0.9234 - val_loss: 0.3436 - val_acc: 0.8991\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.2274 - acc: 0.9229 - val_loss: 0.3488 - val_acc: 0.8963\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.2252 - acc: 0.9223 - val_loss: 0.3739 - val_acc: 0.8906\n"
     ]
    }
   ],
   "source": [
    "alt_model_drop4 = Sequential()\n",
    "alt_model_drop4.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "alt_model_drop4.add(Dropout(0.5))\n",
    "alt_model_drop4.add(Dense(512, activation='relu'))\n",
    "alt_model_drop4.add(Dropout(0.5))\n",
    "alt_model_drop4.add(Dense(512, activation='relu'))\n",
    "alt_model_drop4.add(Dropout(0.5))\n",
    "alt_model_drop4.add(Dense(10, activation='softmax'))\n",
    "alt_model_drop4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_drop4 = alt_model_drop4.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_models.append(result_drop4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.9816 - acc: 0.6343 - val_loss: 0.6116 - val_acc: 0.7708\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.5967 - acc: 0.7867 - val_loss: 0.4691 - val_acc: 0.8256\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.5055 - acc: 0.8208 - val_loss: 0.4689 - val_acc: 0.8278\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.4814 - acc: 0.8301 - val_loss: 0.4303 - val_acc: 0.8364\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.4426 - acc: 0.8422 - val_loss: 0.4218 - val_acc: 0.8377\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.4352 - acc: 0.8450 - val_loss: 0.4277 - val_acc: 0.8384\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.4114 - acc: 0.8517 - val_loss: 0.3937 - val_acc: 0.8553\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.4033 - acc: 0.8577 - val_loss: 0.3767 - val_acc: 0.8548\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.3978 - acc: 0.8599 - val_loss: 0.3873 - val_acc: 0.8552\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.3823 - acc: 0.8641 - val_loss: 0.3668 - val_acc: 0.8630\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.3786 - acc: 0.8663 - val_loss: 0.3447 - val_acc: 0.8727\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3697 - acc: 0.8686 - val_loss: 0.3395 - val_acc: 0.8749\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3637 - acc: 0.8710 - val_loss: 0.3672 - val_acc: 0.8693\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3599 - acc: 0.8712 - val_loss: 0.3944 - val_acc: 0.8569\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.3529 - acc: 0.8755 - val_loss: 0.3530 - val_acc: 0.8709\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3503 - acc: 0.8767 - val_loss: 0.3677 - val_acc: 0.8591\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3455 - acc: 0.8790 - val_loss: 0.3341 - val_acc: 0.8825\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.3428 - acc: 0.8795 - val_loss: 0.3653 - val_acc: 0.8689\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3365 - acc: 0.8823 - val_loss: 0.3478 - val_acc: 0.8727\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3352 - acc: 0.8820 - val_loss: 0.3368 - val_acc: 0.8772\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3304 - acc: 0.8825 - val_loss: 0.3363 - val_acc: 0.8783\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3281 - acc: 0.8837 - val_loss: 0.3544 - val_acc: 0.8728\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.3240 - acc: 0.8847 - val_loss: 0.3424 - val_acc: 0.8795\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.3220 - acc: 0.8868 - val_loss: 0.3283 - val_acc: 0.8844\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3211 - acc: 0.8869 - val_loss: 0.3334 - val_acc: 0.8840\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.3184 - acc: 0.8873 - val_loss: 0.3228 - val_acc: 0.8857\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.3154 - acc: 0.8883 - val_loss: 0.3414 - val_acc: 0.8755\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.3189 - acc: 0.8893 - val_loss: 0.3395 - val_acc: 0.8891\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.3107 - acc: 0.8902 - val_loss: 0.3354 - val_acc: 0.8822\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.3142 - acc: 0.8910 - val_loss: 0.3621 - val_acc: 0.8748\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3127 - acc: 0.8915 - val_loss: 0.3241 - val_acc: 0.8874\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3119 - acc: 0.8911 - val_loss: 0.3625 - val_acc: 0.8694\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.3105 - acc: 0.8921 - val_loss: 0.3525 - val_acc: 0.8755\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.3073 - acc: 0.8928 - val_loss: 0.3358 - val_acc: 0.8827\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3090 - acc: 0.8940 - val_loss: 0.3391 - val_acc: 0.8808\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3048 - acc: 0.8954 - val_loss: 0.3333 - val_acc: 0.8869\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3059 - acc: 0.8936 - val_loss: 0.3383 - val_acc: 0.8831\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3069 - acc: 0.8940 - val_loss: 0.3530 - val_acc: 0.8798\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.3014 - acc: 0.8973 - val_loss: 0.3376 - val_acc: 0.8792\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3002 - acc: 0.8949 - val_loss: 0.3399 - val_acc: 0.8792\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3002 - acc: 0.8963 - val_loss: 0.3357 - val_acc: 0.8876\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2987 - acc: 0.8956 - val_loss: 0.3362 - val_acc: 0.8863\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.2951 - acc: 0.8973 - val_loss: 0.3412 - val_acc: 0.8851\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2970 - acc: 0.8968 - val_loss: 0.3430 - val_acc: 0.8867\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2967 - acc: 0.8964 - val_loss: 0.3531 - val_acc: 0.8833\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.2949 - acc: 0.8974 - val_loss: 0.3573 - val_acc: 0.8780\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2938 - acc: 0.8979 - val_loss: 0.3539 - val_acc: 0.8824\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3002 - acc: 0.8970 - val_loss: 0.3409 - val_acc: 0.8835\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2978 - acc: 0.8986 - val_loss: 0.3372 - val_acc: 0.8883\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2926 - acc: 0.8990 - val_loss: 0.3330 - val_acc: 0.8897\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2947 - acc: 0.8999 - val_loss: 0.3250 - val_acc: 0.8898\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3005 - acc: 0.8987 - val_loss: 0.3499 - val_acc: 0.8817\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.2959 - acc: 0.9007 - val_loss: 0.3481 - val_acc: 0.8869\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.2945 - acc: 0.8996 - val_loss: 0.3490 - val_acc: 0.8826\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2934 - acc: 0.9005 - val_loss: 0.3606 - val_acc: 0.8792\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2889 - acc: 0.9025 - val_loss: 0.3400 - val_acc: 0.8912\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2921 - acc: 0.9014 - val_loss: 0.3522 - val_acc: 0.8877\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2918 - acc: 0.9023 - val_loss: 0.3428 - val_acc: 0.8884\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.2992 - acc: 0.9013 - val_loss: 0.3432 - val_acc: 0.8894\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2871 - acc: 0.9020 - val_loss: 0.3531 - val_acc: 0.8867\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2919 - acc: 0.9031 - val_loss: 0.3428 - val_acc: 0.8927c: 0 - ETA: 3s - loss: 0.2941 - acc: - ETA:\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2972 - acc: 0.8999 - val_loss: 0.3367 - val_acc: 0.8878\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.2894 - acc: 0.9025 - val_loss: 0.3334 - val_acc: 0.8880\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2857 - acc: 0.9051 - val_loss: 0.3548 - val_acc: 0.8807\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2897 - acc: 0.9031 - val_loss: 0.3424 - val_acc: 0.8870\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.2885 - acc: 0.9044 - val_loss: 0.3395 - val_acc: 0.8878\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.2889 - acc: 0.9031 - val_loss: 0.3525 - val_acc: 0.8870\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2910 - acc: 0.9041 - val_loss: 0.3517 - val_acc: 0.8862\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.2905 - acc: 0.9044 - val_loss: 0.3496 - val_acc: 0.8862\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.2871 - acc: 0.9039 - val_loss: 0.3499 - val_acc: 0.8918\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2907 - acc: 0.9052 - val_loss: 0.3466 - val_acc: 0.8916\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.2923 - acc: 0.9049 - val_loss: 0.3427 - val_acc: 0.8911\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.2882 - acc: 0.9034 - val_loss: 0.3442 - val_acc: 0.8875\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.2879 - acc: 0.9031 - val_loss: 0.3646 - val_acc: 0.8922\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2960 - acc: 0.9033 - val_loss: 0.3432 - val_acc: 0.8883\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.2860 - acc: 0.9074 - val_loss: 0.3740 - val_acc: 0.8906\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2977 - acc: 0.9041 - val_loss: 0.3454 - val_acc: 0.8901\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2937 - acc: 0.9058 - val_loss: 0.3502 - val_acc: 0.8913\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.2941 - acc: 0.9058 - val_loss: 0.3508 - val_acc: 0.8874\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2914 - acc: 0.9042 - val_loss: 0.3663 - val_acc: 0.8904\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2986 - acc: 0.9048 - val_loss: 0.3513 - val_acc: 0.8909\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.2860 - acc: 0.9077 - val_loss: 0.3464 - val_acc: 0.8865\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2915 - acc: 0.9056 - val_loss: 0.3554 - val_acc: 0.8918\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.2971 - acc: 0.9040 - val_loss: 0.3733 - val_acc: 0.8850\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.2951 - acc: 0.9064 - val_loss: 0.3621 - val_acc: 0.8868\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.3010 - acc: 0.9045 - val_loss: 0.4028 - val_acc: 0.8811\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2966 - acc: 0.9057 - val_loss: 0.3655 - val_acc: 0.8888\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2903 - acc: 0.9077 - val_loss: 0.3638 - val_acc: 0.8925\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2935 - acc: 0.9074 - val_loss: 0.3942 - val_acc: 0.8673\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2984 - acc: 0.9070 - val_loss: 0.3605 - val_acc: 0.8875\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.2959 - acc: 0.9069 - val_loss: 0.3482 - val_acc: 0.8917\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2897 - acc: 0.9075 - val_loss: 0.3503 - val_acc: 0.8938\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2958 - acc: 0.9071 - val_loss: 0.3715 - val_acc: 0.8860\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.2948 - acc: 0.9076 - val_loss: 0.3680 - val_acc: 0.8934\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3026 - acc: 0.9061 - val_loss: 0.3543 - val_acc: 0.8917\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2983 - acc: 0.9077 - val_loss: 0.3553 - val_acc: 0.8889\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.2904 - acc: 0.9088 - val_loss: 0.3607 - val_acc: 0.8925\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.2947 - acc: 0.9086 - val_loss: 0.3667 - val_acc: 0.8950\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3006 - acc: 0.9077 - val_loss: 0.3632 - val_acc: 0.8922\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.2929 - acc: 0.9104 - val_loss: 0.3660 - val_acc: 0.8910\n"
     ]
    }
   ],
   "source": [
    "alt_model_drop6 = Sequential()\n",
    "alt_model_drop6.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "alt_model_drop6.add(Dropout(0.5))\n",
    "alt_model_drop6.add(Dense(512, activation='relu'))\n",
    "alt_model_drop6.add(Dropout(0.5))\n",
    "alt_model_drop6.add(Dense(512, activation='relu'))\n",
    "alt_model_drop6.add(Dropout(0.5))\n",
    "alt_model_drop6.add(Dense(512, activation='relu'))\n",
    "alt_model_drop6.add(Dropout(0.5))\n",
    "alt_model_drop6.add(Dense(10, activation='softmax'))\n",
    "alt_model_drop6.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "result_drop6 = alt_model_drop6.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)\n",
    "alt_models.append(result_drop6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 8.9630 - acc: 0.6667 - val_loss: 2.8797 - val_acc: 0.7259\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 2.1294 - acc: 0.7438 - val_loss: 1.6557 - val_acc: 0.7697\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4966 - acc: 0.7732 - val_loss: 1.4091 - val_acc: 0.7774\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.3126 - acc: 0.7868 - val_loss: 1.2530 - val_acc: 0.7973\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.2121 - acc: 0.7997 - val_loss: 1.2197 - val_acc: 0.7855\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.1471 - acc: 0.8087 - val_loss: 1.1889 - val_acc: 0.7767\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.1018 - acc: 0.8152 - val_loss: 1.1162 - val_acc: 0.8153\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.0736 - acc: 0.8212 - val_loss: 1.0637 - val_acc: 0.8200\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.0531 - acc: 0.8239 - val_loss: 1.0634 - val_acc: 0.8221\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.0377 - acc: 0.8259 - val_loss: 1.0608 - val_acc: 0.8175\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.0241 - acc: 0.8282 - val_loss: 1.0621 - val_acc: 0.8122\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 1.0122 - acc: 0.8308 - val_loss: 1.0345 - val_acc: 0.8203\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.0010 - acc: 0.8319 - val_loss: 1.0094 - val_acc: 0.8277\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.9928 - acc: 0.8337 - val_loss: 1.0093 - val_acc: 0.8240\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9848 - acc: 0.8337 - val_loss: 1.0039 - val_acc: 0.8236\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9789 - acc: 0.8341 - val_loss: 1.0042 - val_acc: 0.8166\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.9709 - acc: 0.8372 - val_loss: 1.0289 - val_acc: 0.8093\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.9677 - acc: 0.8376 - val_loss: 0.9670 - val_acc: 0.8368\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9598 - acc: 0.8382 - val_loss: 0.9835 - val_acc: 0.8274\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9539 - acc: 0.8391 - val_loss: 0.9762 - val_acc: 0.8292\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9521 - acc: 0.8395 - val_loss: 1.0211 - val_acc: 0.8005\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9485 - acc: 0.8406 - val_loss: 0.9681 - val_acc: 0.8305\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.9471 - acc: 0.8389 - val_loss: 0.9678 - val_acc: 0.8310\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.9408 - acc: 0.8417 - val_loss: 0.9495 - val_acc: 0.8357\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.9392 - acc: 0.8413 - val_loss: 0.9316 - val_acc: 0.8432\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.9358 - acc: 0.8404 - val_loss: 0.9501 - val_acc: 0.8334\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9323 - acc: 0.8439 - val_loss: 0.9482 - val_acc: 0.8333\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9291 - acc: 0.8422 - val_loss: 0.9525 - val_acc: 0.8327\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.9247 - acc: 0.8439 - val_loss: 0.9621 - val_acc: 0.8314\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9226 - acc: 0.8450 - val_loss: 0.9256 - val_acc: 0.8412\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9195 - acc: 0.8448 - val_loss: 0.9504 - val_acc: 0.8320\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9211 - acc: 0.8433 - val_loss: 0.9809 - val_acc: 0.8232\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9151 - acc: 0.8453 - val_loss: 0.9423 - val_acc: 0.8350\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9144 - acc: 0.8448 - val_loss: 0.9226 - val_acc: 0.8425\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9134 - acc: 0.8440 - val_loss: 0.9155 - val_acc: 0.8419\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9101 - acc: 0.8461 - val_loss: 0.9445 - val_acc: 0.8332\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9082 - acc: 0.8440 - val_loss: 0.9166 - val_acc: 0.8404\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.9060 - acc: 0.8456 - val_loss: 0.9142 - val_acc: 0.8446\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9048 - acc: 0.8464 - val_loss: 0.9265 - val_acc: 0.8372\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9051 - acc: 0.8470 - val_loss: 0.9245 - val_acc: 0.8391\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.9024 - acc: 0.8479 - val_loss: 0.9310 - val_acc: 0.8344\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.9008 - acc: 0.8468 - val_loss: 0.9209 - val_acc: 0.8353\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.8980 - acc: 0.8471 - val_loss: 0.9482 - val_acc: 0.8296\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8956 - acc: 0.8482 - val_loss: 0.9132 - val_acc: 0.8397\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8967 - acc: 0.8476 - val_loss: 0.9246 - val_acc: 0.8329\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.8951 - acc: 0.8476 - val_loss: 0.9118 - val_acc: 0.8401\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8913 - acc: 0.8490 - val_loss: 0.9146 - val_acc: 0.8389\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.8918 - acc: 0.8494 - val_loss: 0.9639 - val_acc: 0.8184\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.8913 - acc: 0.8480 - val_loss: 0.9121 - val_acc: 0.8395\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.8900 - acc: 0.8486 - val_loss: 0.9066 - val_acc: 0.8405\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.8877 - acc: 0.8483 - val_loss: 0.9262 - val_acc: 0.8334\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8872 - acc: 0.8495 - val_loss: 0.8962 - val_acc: 0.8453\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.8854 - acc: 0.8487 - val_loss: 0.9295 - val_acc: 0.8344\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8854 - acc: 0.8482 - val_loss: 0.9318 - val_acc: 0.8309\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8817 - acc: 0.8507 - val_loss: 0.9053 - val_acc: 0.8394\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.8845 - acc: 0.8496 - val_loss: 0.8975 - val_acc: 0.8441\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8843 - acc: 0.8489 - val_loss: 0.9241 - val_acc: 0.8339\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.8826 - acc: 0.8494 - val_loss: 0.9112 - val_acc: 0.8343\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8799 - acc: 0.8516 - val_loss: 0.8987 - val_acc: 0.8420\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.8812 - acc: 0.8494 - val_loss: 0.9720 - val_acc: 0.8183\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.8766 - acc: 0.8510 - val_loss: 0.9114 - val_acc: 0.8347\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.8791 - acc: 0.8519 - val_loss: 0.9571 - val_acc: 0.8118\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.8800 - acc: 0.8501 - val_loss: 0.8973 - val_acc: 0.8418\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.8775 - acc: 0.8520 - val_loss: 0.8961 - val_acc: 0.8411\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8756 - acc: 0.8519 - val_loss: 0.9152 - val_acc: 0.8360\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.8766 - acc: 0.8513 - val_loss: 0.9108 - val_acc: 0.8375\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.8725 - acc: 0.8524 - val_loss: 0.9139 - val_acc: 0.8352\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.8757 - acc: 0.8528 - val_loss: 0.9123 - val_acc: 0.8327\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8737 - acc: 0.8517 - val_loss: 0.9398 - val_acc: 0.8212\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8739 - acc: 0.8514 - val_loss: 0.9413 - val_acc: 0.8272\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8725 - acc: 0.8518 - val_loss: 0.9007 - val_acc: 0.8447\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.8732 - acc: 0.8522 - val_loss: 0.8920 - val_acc: 0.8422\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.8688 - acc: 0.8536 - val_loss: 0.9393 - val_acc: 0.8217\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.8684 - acc: 0.8543 - val_loss: 0.9230 - val_acc: 0.8361\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.8708 - acc: 0.8537 - val_loss: 0.9053 - val_acc: 0.8356\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.8675 - acc: 0.8535 - val_loss: 0.9284 - val_acc: 0.8283\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.8698 - acc: 0.8533 - val_loss: 0.9132 - val_acc: 0.8358\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.8663 - acc: 0.8535 - val_loss: 0.9438 - val_acc: 0.8233\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.8684 - acc: 0.8530 - val_loss: 0.9610 - val_acc: 0.8157\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8680 - acc: 0.8513 - val_loss: 0.8983 - val_acc: 0.8386\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8658 - acc: 0.8548 - val_loss: 0.8924 - val_acc: 0.8454\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.8650 - acc: 0.8540 - val_loss: 0.9104 - val_acc: 0.8351\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.8655 - acc: 0.8520 - val_loss: 0.9469 - val_acc: 0.8228\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.8631 - acc: 0.8531 - val_loss: 0.9174 - val_acc: 0.8318\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.8642 - acc: 0.8539 - val_loss: 0.8795 - val_acc: 0.8466\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.8653 - acc: 0.8533 - val_loss: 0.8978 - val_acc: 0.8405\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.8650 - acc: 0.8523 - val_loss: 0.9021 - val_acc: 0.8361\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.8628 - acc: 0.8534 - val_loss: 0.8899 - val_acc: 0.8407\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.8649 - acc: 0.8531 - val_loss: 0.9062 - val_acc: 0.8362\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.8614 - acc: 0.8557 - val_loss: 0.8781 - val_acc: 0.8474\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.8634 - acc: 0.8548 - val_loss: 0.9208 - val_acc: 0.8329\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8638 - acc: 0.8530 - val_loss: 0.8805 - val_acc: 0.8455\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.8612 - acc: 0.8542 - val_loss: 0.9236 - val_acc: 0.8199\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.8601 - acc: 0.8553 - val_loss: 0.8719 - val_acc: 0.8499\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.8604 - acc: 0.8535 - val_loss: 0.8755 - val_acc: 0.8473\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.8610 - acc: 0.8530 - val_loss: 0.8797 - val_acc: 0.8440\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8614 - acc: 0.8538 - val_loss: 0.8862 - val_acc: 0.8462\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8598 - acc: 0.8551 - val_loss: 0.9084 - val_acc: 0.8351\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.8584 - acc: 0.8547 - val_loss: 0.9030 - val_acc: 0.8350\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.8608 - acc: 0.8522 - val_loss: 0.9024 - val_acc: 0.8347\n"
     ]
    }
   ],
   "source": [
    "alt_model_l1_3 = Sequential()\n",
    "alt_model_l1_3.add(Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l1_3.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l1_3.add(Dense(10, activation='softmax'))\n",
    "alt_model_l1_3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l1_3 = alt_model_l1_3.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)\n",
    "alt_models.append(result_l1_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 11.9363 - acc: 0.6170 - val_loss: 3.7567 - val_acc: 0.5999\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 2.6937 - acc: 0.6931 - val_loss: 2.1918 - val_acc: 0.6692\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.9394 - acc: 0.7241 - val_loss: 1.7878 - val_acc: 0.7155\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.6841 - acc: 0.7469 - val_loss: 1.7366 - val_acc: 0.6877\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5469 - acc: 0.7606 - val_loss: 1.4918 - val_acc: 0.7784\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4693 - acc: 0.7726 - val_loss: 1.4258 - val_acc: 0.7884\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4145 - acc: 0.7813 - val_loss: 1.4162 - val_acc: 0.7762\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3701 - acc: 0.7881 - val_loss: 1.4645 - val_acc: 0.7558\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3361 - acc: 0.7970 - val_loss: 1.3157 - val_acc: 0.7977\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.3163 - acc: 0.7954 - val_loss: 1.3007 - val_acc: 0.8024\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.2928 - acc: 0.8037 - val_loss: 1.2890 - val_acc: 0.8008\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.2762 - acc: 0.8044 - val_loss: 1.2617 - val_acc: 0.8087\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.2568 - acc: 0.8078 - val_loss: 1.3987 - val_acc: 0.7606\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.2414 - acc: 0.8098 - val_loss: 1.2506 - val_acc: 0.8083\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.2281 - acc: 0.8140 - val_loss: 1.2244 - val_acc: 0.8164\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2142 - acc: 0.8158 - val_loss: 1.2914 - val_acc: 0.7674\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.2051 - acc: 0.8171 - val_loss: 1.2465 - val_acc: 0.8022\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.1957 - acc: 0.8191 - val_loss: 1.2506 - val_acc: 0.7983\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.1837 - acc: 0.8218 - val_loss: 1.2190 - val_acc: 0.8088\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.1751 - acc: 0.8238 - val_loss: 1.2331 - val_acc: 0.8056\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.1683 - acc: 0.8233 - val_loss: 1.2146 - val_acc: 0.8046\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.1593 - acc: 0.8270 - val_loss: 1.1570 - val_acc: 0.8243\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.1545 - acc: 0.8270 - val_loss: 1.1447 - val_acc: 0.8310\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.1457 - acc: 0.8271 - val_loss: 1.1524 - val_acc: 0.8209\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.1473 - acc: 0.8286 - val_loss: 1.1802 - val_acc: 0.8169\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.1368 - acc: 0.8312 - val_loss: 1.1790 - val_acc: 0.8119\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.1355 - acc: 0.8309 - val_loss: 1.1549 - val_acc: 0.8158\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.1345 - acc: 0.8297 - val_loss: 1.1362 - val_acc: 0.8265\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.1298 - acc: 0.8315 - val_loss: 1.1543 - val_acc: 0.8217\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1222 - acc: 0.8329 - val_loss: 1.1749 - val_acc: 0.8112\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.1178 - acc: 0.8346 - val_loss: 1.1501 - val_acc: 0.8201\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.1175 - acc: 0.8338 - val_loss: 1.1365 - val_acc: 0.8200\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.1122 - acc: 0.8351 - val_loss: 1.1160 - val_acc: 0.8342\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1125 - acc: 0.8331 - val_loss: 1.1503 - val_acc: 0.8187\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.1062 - acc: 0.8348 - val_loss: 1.1246 - val_acc: 0.8279\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1052 - acc: 0.8355 - val_loss: 1.0898 - val_acc: 0.8385\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.0999 - acc: 0.8366 - val_loss: 1.1107 - val_acc: 0.8333\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.0960 - acc: 0.8384 - val_loss: 1.1162 - val_acc: 0.8251\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.0954 - acc: 0.8373 - val_loss: 1.1433 - val_acc: 0.8184\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.0894 - acc: 0.8385 - val_loss: 1.1168 - val_acc: 0.8244\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.0903 - acc: 0.8359 - val_loss: 1.1599 - val_acc: 0.8127\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.0843 - acc: 0.8394 - val_loss: 1.0804 - val_acc: 0.8398\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.0831 - acc: 0.8403 - val_loss: 1.1557 - val_acc: 0.8129\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.0833 - acc: 0.8381 - val_loss: 1.1181 - val_acc: 0.8244\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.0795 - acc: 0.8392 - val_loss: 1.0877 - val_acc: 0.8314\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.0775 - acc: 0.8404 - val_loss: 1.1649 - val_acc: 0.8058\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.0750 - acc: 0.8415 - val_loss: 1.1319 - val_acc: 0.8115\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0749 - acc: 0.8414 - val_loss: 1.0831 - val_acc: 0.8388\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.0716 - acc: 0.8411 - val_loss: 1.1139 - val_acc: 0.8241\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.0694 - acc: 0.8426 - val_loss: 1.1626 - val_acc: 0.8113\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.0646 - acc: 0.8435 - val_loss: 1.0735 - val_acc: 0.83821.0646 - ac\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.0673 - acc: 0.8427 - val_loss: 1.1431 - val_acc: 0.8090\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.0643 - acc: 0.8422 - val_loss: 1.0689 - val_acc: 0.8347\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0660 - acc: 0.8409 - val_loss: 1.0767 - val_acc: 0.8332\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.0608 - acc: 0.8418 - val_loss: 1.0999 - val_acc: 0.8283\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.0612 - acc: 0.8429 - val_loss: 1.1208 - val_acc: 0.8224\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0612 - acc: 0.8436 - val_loss: 1.0721 - val_acc: 0.8374\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.0583 - acc: 0.8430 - val_loss: 1.0814 - val_acc: 0.8335\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.0598 - acc: 0.8426 - val_loss: 1.0715 - val_acc: 0.8379\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.0548 - acc: 0.8446 - val_loss: 1.0812 - val_acc: 0.8337\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.0542 - acc: 0.8431 - val_loss: 1.0970 - val_acc: 0.8285\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0486 - acc: 0.8456 - val_loss: 1.0701 - val_acc: 0.8368\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.0526 - acc: 0.8446 - val_loss: 1.0741 - val_acc: 0.8369\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.0504 - acc: 0.8464 - val_loss: 1.0981 - val_acc: 0.8260\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.0474 - acc: 0.8470 - val_loss: 1.0734 - val_acc: 0.8370\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0485 - acc: 0.8451 - val_loss: 1.1023 - val_acc: 0.8235\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.0462 - acc: 0.8471 - val_loss: 1.0939 - val_acc: 0.8263\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.0481 - acc: 0.8452 - val_loss: 1.1335 - val_acc: 0.8098\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.0433 - acc: 0.8471 - val_loss: 1.0694 - val_acc: 0.8337\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.0450 - acc: 0.8460 - val_loss: 1.1290 - val_acc: 0.8156\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0395 - acc: 0.8483 - val_loss: 1.1272 - val_acc: 0.7991\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.0427 - acc: 0.8466 - val_loss: 1.1320 - val_acc: 0.8149\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.0430 - acc: 0.8478 - val_loss: 1.0467 - val_acc: 0.8448\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.0410 - acc: 0.8470 - val_loss: 1.0704 - val_acc: 0.8330\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.0398 - acc: 0.8477 - val_loss: 1.0753 - val_acc: 0.8273\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.0401 - acc: 0.8472 - val_loss: 1.0589 - val_acc: 0.8405\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.0360 - acc: 0.8495 - val_loss: 1.0476 - val_acc: 0.8406\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.0402 - acc: 0.8466 - val_loss: 1.1589 - val_acc: 0.8027\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.0348 - acc: 0.8491 - val_loss: 1.0709 - val_acc: 0.8324\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0357 - acc: 0.8496 - val_loss: 1.0870 - val_acc: 0.8257\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.0368 - acc: 0.8486 - val_loss: 1.0864 - val_acc: 0.8283\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.0342 - acc: 0.8481 - val_loss: 1.0382 - val_acc: 0.8469\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.0353 - acc: 0.8481 - val_loss: 1.1267 - val_acc: 0.8127\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0331 - acc: 0.8476 - val_loss: 1.1020 - val_acc: 0.8221\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0324 - acc: 0.8503 - val_loss: 1.0634 - val_acc: 0.8356\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.0355 - acc: 0.8481 - val_loss: 1.0531 - val_acc: 0.8411\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.0324 - acc: 0.8484 - val_loss: 1.1059 - val_acc: 0.8205\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.0288 - acc: 0.8503 - val_loss: 1.0458 - val_acc: 0.8416\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0277 - acc: 0.8514 - val_loss: 1.1118 - val_acc: 0.8182\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.0268 - acc: 0.8513 - val_loss: 1.0717 - val_acc: 0.8275\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.0262 - acc: 0.8513 - val_loss: 1.0859 - val_acc: 0.8299\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.0284 - acc: 0.8497 - val_loss: 1.0455 - val_acc: 0.8418\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0278 - acc: 0.8496 - val_loss: 1.0708 - val_acc: 0.8318\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.0263 - acc: 0.8498 - val_loss: 1.0544 - val_acc: 0.8377\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0262 - acc: 0.8487 - val_loss: 1.0570 - val_acc: 0.8354\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.0252 - acc: 0.8515 - val_loss: 1.0310 - val_acc: 0.8480\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.0230 - acc: 0.8503 - val_loss: 1.1019 - val_acc: 0.8163\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.0260 - acc: 0.8500 - val_loss: 1.0415 - val_acc: 0.8445\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.0232 - acc: 0.8505 - val_loss: 1.0467 - val_acc: 0.8363\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.0258 - acc: 0.8497 - val_loss: 1.1489 - val_acc: 0.7924\n"
     ]
    }
   ],
   "source": [
    "alt_model_l1_4 = Sequential()\n",
    "alt_model_l1_4.add(Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l1_4.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l1_4.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l1_4.add(Dense(10, activation='softmax'))\n",
    "alt_model_l1_4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l1_4 = alt_model_l1_4.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)\n",
    "alt_models.append(result_l1_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 6.1360 - acc: 0.6835 - val_loss: 2.6970 - val_acc: 0.6857\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.9051 - acc: 0.7443 - val_loss: 1.4130 - val_acc: 0.7855\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3121 - acc: 0.7726 - val_loss: 1.1747 - val_acc: 0.7916\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.0903 - acc: 0.7939 - val_loss: 1.0357 - val_acc: 0.7991\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.9935 - acc: 0.8045 - val_loss: 1.0188 - val_acc: 0.7871\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.9301 - acc: 0.8149 - val_loss: 1.0276 - val_acc: 0.7772\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.8923 - acc: 0.8199 - val_loss: 0.8721 - val_acc: 0.8182\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.8570 - acc: 0.8261 - val_loss: 0.8591 - val_acc: 0.8161\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.8331 - acc: 0.8300 - val_loss: 0.8400 - val_acc: 0.8282\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.8093 - acc: 0.8352 - val_loss: 0.8129 - val_acc: 0.8322\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.7955 - acc: 0.8375 - val_loss: 0.8168 - val_acc: 0.8200\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.7870 - acc: 0.8389 - val_loss: 0.8015 - val_acc: 0.8326\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.7783 - acc: 0.8413 - val_loss: 0.7629 - val_acc: 0.8434\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.7684 - acc: 0.8430 - val_loss: 0.7850 - val_acc: 0.8344\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.7663 - acc: 0.8421 - val_loss: 0.7827 - val_acc: 0.8315\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.7561 - acc: 0.8450 - val_loss: 0.7887 - val_acc: 0.8338\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.7544 - acc: 0.8457 - val_loss: 0.7600 - val_acc: 0.8440\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.7490 - acc: 0.8451 - val_loss: 0.7597 - val_acc: 0.8393\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.7434 - acc: 0.8468 - val_loss: 0.8055 - val_acc: 0.8265- loss: 0 - ETA: 1s - loss: 0.7\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.7416 - acc: 0.8487 - val_loss: 0.7868 - val_acc: 0.8289\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.7394 - acc: 0.8469 - val_loss: 0.7502 - val_acc: 0.8411\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.7341 - acc: 0.8488 - val_loss: 0.7686 - val_acc: 0.8373\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.7312 - acc: 0.8514 - val_loss: 0.7784 - val_acc: 0.8327\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.7310 - acc: 0.8492 - val_loss: 0.7546 - val_acc: 0.8365\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.7296 - acc: 0.8507 - val_loss: 0.7789 - val_acc: 0.8327\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.7256 - acc: 0.8515 - val_loss: 0.7478 - val_acc: 0.8425\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.7239 - acc: 0.8515 - val_loss: 0.8371 - val_acc: 0.8104\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.7202 - acc: 0.8525 - val_loss: 0.7583 - val_acc: 0.8349\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.7183 - acc: 0.8538 - val_loss: 0.7590 - val_acc: 0.8339\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.7201 - acc: 0.8518 - val_loss: 0.7254 - val_acc: 0.8515\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.7131 - acc: 0.8541 - val_loss: 0.7952 - val_acc: 0.8215\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.7144 - acc: 0.8559 - val_loss: 0.7435 - val_acc: 0.8381\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 0.7135 - acc: 0.8555 - val_loss: 0.7201 - val_acc: 0.8485\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.7105 - acc: 0.8546 - val_loss: 0.8257 - val_acc: 0.8211\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.7091 - acc: 0.8570 - val_loss: 0.7939 - val_acc: 0.8232\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.7096 - acc: 0.8561 - val_loss: 0.7983 - val_acc: 0.8310\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.7070 - acc: 0.8566 - val_loss: 0.8244 - val_acc: 0.8098\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.7089 - acc: 0.8548 - val_loss: 0.7266 - val_acc: 0.8469\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.7086 - acc: 0.8558 - val_loss: 0.7704 - val_acc: 0.8281\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.7041 - acc: 0.8576 - val_loss: 0.7844 - val_acc: 0.8298\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.7029 - acc: 0.8575 - val_loss: 0.8043 - val_acc: 0.8215\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 0.7023 - acc: 0.8584 - val_loss: 0.7528 - val_acc: 0.8326\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.7039 - acc: 0.8574 - val_loss: 0.7786 - val_acc: 0.8294\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.7007 - acc: 0.8597 - val_loss: 0.7099 - val_acc: 0.8552\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.7011 - acc: 0.8574 - val_loss: 0.7179 - val_acc: 0.8505\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.7009 - acc: 0.8586 - val_loss: 0.7895 - val_acc: 0.8227\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.6993 - acc: 0.8588 - val_loss: 0.8384 - val_acc: 0.8218\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.6965 - acc: 0.8599 - val_loss: 0.7660 - val_acc: 0.8320\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.7010 - acc: 0.8570 - val_loss: 0.7424 - val_acc: 0.8400\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 0.6974 - acc: 0.8569 - val_loss: 0.7151 - val_acc: 0.8501\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.6995 - acc: 0.8587 - val_loss: 0.7395 - val_acc: 0.8431\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.6974 - acc: 0.8585 - val_loss: 0.8346 - val_acc: 0.8160\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.6977 - acc: 0.8589 - val_loss: 0.7744 - val_acc: 0.8298\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 0.6952 - acc: 0.8599 - val_loss: 0.7078 - val_acc: 0.8528\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6925 - acc: 0.8611 - val_loss: 0.7329 - val_acc: 0.8479\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.6919 - acc: 0.8606 - val_loss: 0.7187 - val_acc: 0.8510\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6942 - acc: 0.8602 - val_loss: 0.7541 - val_acc: 0.8355\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.6930 - acc: 0.8611 - val_loss: 0.7214 - val_acc: 0.8517\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.6914 - acc: 0.8612 - val_loss: 0.7475 - val_acc: 0.8423\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.6906 - acc: 0.8613 - val_loss: 0.7540 - val_acc: 0.8385\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.6907 - acc: 0.8608 - val_loss: 0.8002 - val_acc: 0.8273\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 0.6902 - acc: 0.8615 - val_loss: 0.7245 - val_acc: 0.8474\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 0.6912 - acc: 0.8622 - val_loss: 0.7552 - val_acc: 0.8379\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.6891 - acc: 0.8619 - val_loss: 0.7280 - val_acc: 0.8497\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6889 - acc: 0.8615 - val_loss: 0.7158 - val_acc: 0.8518\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 0.6907 - acc: 0.8613 - val_loss: 0.7203 - val_acc: 0.8504\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.6891 - acc: 0.8613 - val_loss: 0.7313 - val_acc: 0.8409\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 0.6893 - acc: 0.8626 - val_loss: 0.7252 - val_acc: 0.8488\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.6844 - acc: 0.8636 - val_loss: 0.6958 - val_acc: 0.8558\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6841 - acc: 0.8633 - val_loss: 0.7812 - val_acc: 0.8273\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.6865 - acc: 0.8628 - val_loss: 0.7197 - val_acc: 0.8489\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.6845 - acc: 0.8633 - val_loss: 0.8058 - val_acc: 0.8265\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 0.6849 - acc: 0.8638 - val_loss: 0.7592 - val_acc: 0.8354\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.6857 - acc: 0.8635 - val_loss: 0.7006 - val_acc: 0.8585\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.6808 - acc: 0.8649 - val_loss: 0.7053 - val_acc: 0.8489\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.6841 - acc: 0.8635 - val_loss: 0.7287 - val_acc: 0.8473\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 0.6829 - acc: 0.8637 - val_loss: 0.7324 - val_acc: 0.8438\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.6814 - acc: 0.8654 - val_loss: 0.7101 - val_acc: 0.8574\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 0.6820 - acc: 0.8655 - val_loss: 0.7161 - val_acc: 0.8500\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 0.6801 - acc: 0.8646 - val_loss: 0.7102 - val_acc: 0.8485\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.6805 - acc: 0.8644 - val_loss: 0.7326 - val_acc: 0.8423\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.6811 - acc: 0.8641 - val_loss: 0.6945 - val_acc: 0.8581\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.6782 - acc: 0.8657 - val_loss: 0.7556 - val_acc: 0.8319\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.6773 - acc: 0.8667 - val_loss: 0.7600 - val_acc: 0.8361\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 0.6805 - acc: 0.8645 - val_loss: 0.6973 - val_acc: 0.8598\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 0.6771 - acc: 0.8665 - val_loss: 0.7200 - val_acc: 0.8491\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.6775 - acc: 0.8668 - val_loss: 0.7238 - val_acc: 0.8482\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.6786 - acc: 0.8664 - val_loss: 0.8109 - val_acc: 0.8044\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.6749 - acc: 0.8668 - val_loss: 0.7171 - val_acc: 0.8466\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 0.6759 - acc: 0.8642 - val_loss: 0.7262 - val_acc: 0.8524\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.6769 - acc: 0.8644 - val_loss: 0.7061 - val_acc: 0.8552\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.6748 - acc: 0.8668 - val_loss: 0.6925 - val_acc: 0.8607\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 0.6764 - acc: 0.8650 - val_loss: 0.7333 - val_acc: 0.8414\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 0.6746 - acc: 0.8662 - val_loss: 0.7001 - val_acc: 0.8564\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.6764 - acc: 0.8653 - val_loss: 0.7034 - val_acc: 0.8545\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 0.6738 - acc: 0.8661 - val_loss: 0.7059 - val_acc: 0.8540\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 0.6738 - acc: 0.8665 - val_loss: 0.7892 - val_acc: 0.8233\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 0.6717 - acc: 0.8680 - val_loss: 0.7168 - val_acc: 0.8492\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.6760 - acc: 0.8649 - val_loss: 0.7261 - val_acc: 0.8468\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 0.6740 - acc: 0.8676 - val_loss: 0.7488 - val_acc: 0.8329\n"
     ]
    }
   ],
   "source": [
    "# 3 layers\n",
    "#The Regularization is not applied in the first layer\n",
    "alt_model_l2_3 = Sequential()\n",
    "alt_model_l2_3.add(Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l2_3.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "alt_model_l2_3.add(Dense(10, activation='softmax'))\n",
    "alt_model_l2_3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l2_3 = alt_model_l2_3.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)\n",
    "alt_models.append(result_l2_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 6.5859 - acc: 0.6472 - val_loss: 3.0104 - val_acc: 0.6892oss: 7.371\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 2.2347 - acc: 0.7286 - val_loss: 1.6474 - val_acc: 0.7722\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.5287 - acc: 0.7578 - val_loss: 1.3409 - val_acc: 0.7563\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.2200 - acc: 0.7805 - val_loss: 1.1504 - val_acc: 0.7838\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0703 - acc: 0.7957 - val_loss: 1.1171 - val_acc: 0.7662\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.9858 - acc: 0.8062 - val_loss: 0.9550 - val_acc: 0.8112\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.9321 - acc: 0.8112 - val_loss: 0.9029 - val_acc: 0.8125\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.9001 - acc: 0.8163 - val_loss: 0.9130 - val_acc: 0.8138\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.8698 - acc: 0.8212 - val_loss: 0.9969 - val_acc: 0.7842\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.8615 - acc: 0.8220 - val_loss: 0.9844 - val_acc: 0.7848\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.8499 - acc: 0.8243 - val_loss: 0.8887 - val_acc: 0.8076\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.8297 - acc: 0.8288 - val_loss: 0.8326 - val_acc: 0.8299\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.8311 - acc: 0.8278 - val_loss: 0.8050 - val_acc: 0.8300\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.8194 - acc: 0.8310 - val_loss: 0.8521 - val_acc: 0.8174\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.8138 - acc: 0.8337 - val_loss: 0.8832 - val_acc: 0.8065\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.8043 - acc: 0.8337 - val_loss: 0.9672 - val_acc: 0.7726\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.7998 - acc: 0.8346 - val_loss: 0.8529 - val_acc: 0.8114\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.7895 - acc: 0.8379 - val_loss: 0.8243 - val_acc: 0.8212\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.7850 - acc: 0.8389 - val_loss: 0.7901 - val_acc: 0.8330\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.7782 - acc: 0.8414 - val_loss: 0.8997 - val_acc: 0.7982\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.7736 - acc: 0.8404 - val_loss: 0.7763 - val_acc: 0.8403\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.7712 - acc: 0.8419 - val_loss: 0.8393 - val_acc: 0.8100\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.7682 - acc: 0.8431 - val_loss: 0.8443 - val_acc: 0.8062 - loss: 0.7686 - acc: 0.84\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.7639 - acc: 0.8418 - val_loss: 0.8144 - val_acc: 0.82232s - loss: 0.7641 - acc: - ETA\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.7615 - acc: 0.8433 - val_loss: 0.8432 - val_acc: 0.8143\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.7585 - acc: 0.8433 - val_loss: 0.8120 - val_acc: 0.8219\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7529 - acc: 0.8456 - val_loss: 0.7898 - val_acc: 0.8282\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7545 - acc: 0.8439 - val_loss: 0.8224 - val_acc: 0.8179\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.7527 - acc: 0.8447 - val_loss: 0.7531 - val_acc: 0.8424\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.7469 - acc: 0.8473 - val_loss: 0.7421 - val_acc: 0.8441\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.7475 - acc: 0.8478 - val_loss: 0.7575 - val_acc: 0.8378\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7457 - acc: 0.8478 - val_loss: 0.9285 - val_acc: 0.7837\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7437 - acc: 0.8476 - val_loss: 0.7832 - val_acc: 0.8350\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.7436 - acc: 0.8474 - val_loss: 0.8172 - val_acc: 0.8187\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.7380 - acc: 0.8511 - val_loss: 0.8352 - val_acc: 0.8119\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7445 - acc: 0.8476 - val_loss: 0.7529 - val_acc: 0.8395\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7354 - acc: 0.8497 - val_loss: 0.7901 - val_acc: 0.8263\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.7352 - acc: 0.8511 - val_loss: 0.8065 - val_acc: 0.8229\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.7368 - acc: 0.8503 - val_loss: 0.7571 - val_acc: 0.8383\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.7327 - acc: 0.8516 - val_loss: 0.7426 - val_acc: 0.8443\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.7324 - acc: 0.8513 - val_loss: 0.7187 - val_acc: 0.8539\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.7319 - acc: 0.8512 - val_loss: 0.7290 - val_acc: 0.8506\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7309 - acc: 0.8512 - val_loss: 0.7456 - val_acc: 0.8404\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 0.7285 - acc: 0.8523 - val_loss: 0.7947 - val_acc: 0.8282\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7300 - acc: 0.8511 - val_loss: 0.7701 - val_acc: 0.8384\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.7285 - acc: 0.8533 - val_loss: 0.7794 - val_acc: 0.8297\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.7255 - acc: 0.8531 - val_loss: 0.7754 - val_acc: 0.8312\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.7259 - acc: 0.8540 - val_loss: 0.7515 - val_acc: 0.8415\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.7232 - acc: 0.8541 - val_loss: 0.7529 - val_acc: 0.8413\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.7222 - acc: 0.8553 - val_loss: 0.7309 - val_acc: 0.8479\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.7229 - acc: 0.8544 - val_loss: 0.7367 - val_acc: 0.8487\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.7174 - acc: 0.8562 - val_loss: 0.7214 - val_acc: 0.8495\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.7194 - acc: 0.8549 - val_loss: 0.7233 - val_acc: 0.8496\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.7204 - acc: 0.8556 - val_loss: 0.7518 - val_acc: 0.8389\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.7190 - acc: 0.8563 - val_loss: 0.7540 - val_acc: 0.8392: 0s - loss: 0.7216 - \n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.7197 - acc: 0.8552 - val_loss: 0.7522 - val_acc: 0.8397\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.7176 - acc: 0.8556 - val_loss: 0.7195 - val_acc: 0.8557\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 143us/step - loss: 0.7181 - acc: 0.8555 - val_loss: 0.7200 - val_acc: 0.8528\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.7162 - acc: 0.8566 - val_loss: 0.7069 - val_acc: 0.8576\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 0.7138 - acc: 0.8570 - val_loss: 0.8140 - val_acc: 0.8228\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.7149 - acc: 0.8570 - val_loss: 0.7563 - val_acc: 0.8379\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.7130 - acc: 0.8571 - val_loss: 0.7720 - val_acc: 0.8360\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.7135 - acc: 0.8579 - val_loss: 0.7488 - val_acc: 0.8413\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7137 - acc: 0.8576 - val_loss: 0.7407 - val_acc: 0.8463\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7127 - acc: 0.8576 - val_loss: 0.7392 - val_acc: 0.8488\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.7105 - acc: 0.8587 - val_loss: 0.7291 - val_acc: 0.8496\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 0.7094 - acc: 0.8590 - val_loss: 0.7546 - val_acc: 0.8385\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7102 - acc: 0.8577 - val_loss: 0.7395 - val_acc: 0.8432\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.7070 - acc: 0.8614 - val_loss: 0.7315 - val_acc: 0.8479\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.7093 - acc: 0.8589 - val_loss: 0.7319 - val_acc: 0.8532: 0s - loss: 0.7092 - acc: 0.85\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.7083 - acc: 0.8581 - val_loss: 0.7217 - val_acc: 0.8485\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.7074 - acc: 0.8590 - val_loss: 0.7503 - val_acc: 0.8383\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.7071 - acc: 0.8605 - val_loss: 0.8529 - val_acc: 0.8177\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.7067 - acc: 0.8602 - val_loss: 0.8224 - val_acc: 0.8189\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.7032 - acc: 0.8624 - val_loss: 0.7662 - val_acc: 0.8294\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.7050 - acc: 0.8594 - val_loss: 0.7093 - val_acc: 0.8568\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.7044 - acc: 0.8599 - val_loss: 0.7688 - val_acc: 0.8356\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.7035 - acc: 0.8606 - val_loss: 0.7208 - val_acc: 0.8521\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.7012 - acc: 0.8614 - val_loss: 0.7158 - val_acc: 0.8524\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.7003 - acc: 0.8620 - val_loss: 0.7491 - val_acc: 0.8414\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6985 - acc: 0.8621 - val_loss: 0.7028 - val_acc: 0.8591\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6993 - acc: 0.8622 - val_loss: 0.7526 - val_acc: 0.8406: \n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.7007 - acc: 0.8603 - val_loss: 0.7412 - val_acc: 0.8367\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.7016 - acc: 0.8615 - val_loss: 0.7432 - val_acc: 0.8442\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.6946 - acc: 0.8630 - val_loss: 0.7375 - val_acc: 0.8466\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6965 - acc: 0.8618 - val_loss: 0.7838 - val_acc: 0.8299\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.6980 - acc: 0.8619 - val_loss: 0.7929 - val_acc: 0.8255\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.6961 - acc: 0.8625 - val_loss: 0.7711 - val_acc: 0.8211\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.6956 - acc: 0.8611 - val_loss: 0.7335 - val_acc: 0.8481\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.6936 - acc: 0.8634 - val_loss: 0.7199 - val_acc: 0.8524\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.6940 - acc: 0.8633 - val_loss: 0.7081 - val_acc: 0.8526\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.6947 - acc: 0.8634 - val_loss: 0.7225 - val_acc: 0.8494\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.6939 - acc: 0.8634 - val_loss: 0.7222 - val_acc: 0.8503\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.6933 - acc: 0.8635 - val_loss: 0.7070 - val_acc: 0.8550\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6925 - acc: 0.8651 - val_loss: 0.7627 - val_acc: 0.8390\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 0.6908 - acc: 0.8647 - val_loss: 0.7300 - val_acc: 0.8478\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.6892 - acc: 0.8639 - val_loss: 0.7769 - val_acc: 0.8333\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6901 - acc: 0.8647 - val_loss: 0.7608 - val_acc: 0.8349\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.6905 - acc: 0.8632 - val_loss: 0.7411 - val_acc: 0.8433\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 0.6937 - acc: 0.8637 - val_loss: 0.6953 - val_acc: 0.8596\n"
     ]
    }
   ],
   "source": [
    "#4 layers\n",
    "#The Regularization is not applied in the first layer\n",
    "alt_model_l2_4 = Sequential()\n",
    "alt_model_l2_4.add(Dense(512, activation='relu', input_shape=(28 * 28,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "alt_model_l2_4.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "alt_model_l2_4.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "alt_model_l2_4.add(Dense(10, activation='softmax'))\n",
    "alt_model_l2_4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result_l2_4 = alt_model_l2_4.fit(X_train, y_train,validation_data=(X_valid,y_valid), epochs=100, batch_size=512)\n",
    "alt_models.append(result_l2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_models.append(result_3)\n",
    "alt_models.append(result_4)\n",
    "alt_models.append(result_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alt_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in alt_models:\n",
    "    plot_loss(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
