{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspectives on Computational Research -- HW 01\n",
    "\n",
    "## Author: Sanittawan Tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_all_train, y_all_train), (x_final_test, y_final_test) = fashion_mnist.load_data()\n",
    "\n",
    "# preprocess data to 2D tensors\n",
    "# convert to float and make the values between 0 and 1\n",
    "x_all_train = x_all_train.reshape((60000, 28 * 28))\n",
    "x_all_train = x_all_train.astype('float32') / 255\n",
    "\n",
    "x_final_test = x_final_test.reshape((10000, 28 * 28))\n",
    "x_final_test = x_final_test.astype('float32') / 255\n",
    "\n",
    "y_all_train = keras.utils.to_categorical(y_all_train)\n",
    "y_final_test = keras.utils.to_categorical(y_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x_all_train, y_all_train, \n",
    "                                                      test_size=10000, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, 201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement a series of neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__i. Initial test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model = models.Sequential()\n",
    "init_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "init_model.add(layers.Dense(512, activation='relu'))\n",
    "init_model.add(layers.Dense(512, activation='relu'))\n",
    "init_model.add(layers.Dense(512, activation='relu'))\n",
    "init_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "init_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.8780 - acc: 0.6841 - val_loss: 0.5736 - val_acc: 0.7840\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5273 - acc: 0.8038 - val_loss: 0.4982 - val_acc: 0.8257\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.4344 - acc: 0.8373 - val_loss: 0.5239 - val_acc: 0.7996\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3928 - acc: 0.8533 - val_loss: 0.4409 - val_acc: 0.8367\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3582 - acc: 0.8650 - val_loss: 0.3428 - val_acc: 0.8706\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3377 - acc: 0.8738 - val_loss: 0.4392 - val_acc: 0.8465\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3145 - acc: 0.8798 - val_loss: 0.3423 - val_acc: 0.8786\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2964 - acc: 0.8871 - val_loss: 0.3299 - val_acc: 0.8824\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2845 - acc: 0.8917 - val_loss: 0.4238 - val_acc: 0.8529\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2685 - acc: 0.8976 - val_loss: 0.3656 - val_acc: 0.8744\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2577 - acc: 0.9016 - val_loss: 0.3621 - val_acc: 0.8819\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2487 - acc: 0.9046 - val_loss: 0.3930 - val_acc: 0.8733\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2380 - acc: 0.9079 - val_loss: 0.3425 - val_acc: 0.8843\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2304 - acc: 0.9113 - val_loss: 0.3394 - val_acc: 0.8912\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2206 - acc: 0.9162 - val_loss: 0.3472 - val_acc: 0.8817\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2135 - acc: 0.9172 - val_loss: 0.3345 - val_acc: 0.8900\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2056 - acc: 0.9209 - val_loss: 0.3838 - val_acc: 0.8750\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2024 - acc: 0.9228 - val_loss: 0.3659 - val_acc: 0.8847\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1919 - acc: 0.9256 - val_loss: 0.3790 - val_acc: 0.8844\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1871 - acc: 0.9276 - val_loss: 0.3804 - val_acc: 0.8846\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1839 - acc: 0.9302 - val_loss: 0.3998 - val_acc: 0.8833\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1776 - acc: 0.9307 - val_loss: 0.4010 - val_acc: 0.8862\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1776 - acc: 0.9319 - val_loss: 0.3840 - val_acc: 0.8865\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1750 - acc: 0.9340 - val_loss: 0.4095 - val_acc: 0.8815\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1745 - acc: 0.9349 - val_loss: 0.3954 - val_acc: 0.8871\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1614 - acc: 0.9392 - val_loss: 0.5535 - val_acc: 0.8803\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1677 - acc: 0.9376 - val_loss: 0.4414 - val_acc: 0.8775\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1579 - acc: 0.9408 - val_loss: 0.4630 - val_acc: 0.8805\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1558 - acc: 0.9409 - val_loss: 0.4183 - val_acc: 0.8903\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1476 - acc: 0.9437 - val_loss: 0.4638 - val_acc: 0.8847\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1578 - acc: 0.9420 - val_loss: 0.4294 - val_acc: 0.8909\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1462 - acc: 0.9450 - val_loss: 0.4773 - val_acc: 0.8892\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1426 - acc: 0.9449 - val_loss: 0.4821 - val_acc: 0.8850\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1392 - acc: 0.9481 - val_loss: 0.4475 - val_acc: 0.8956\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1448 - acc: 0.9465 - val_loss: 0.4539 - val_acc: 0.8949\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1468 - acc: 0.9468 - val_loss: 0.4780 - val_acc: 0.8892\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1371 - acc: 0.9498 - val_loss: 0.4688 - val_acc: 0.8900\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1344 - acc: 0.9489 - val_loss: 0.4922 - val_acc: 0.8964\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1357 - acc: 0.9509 - val_loss: 0.4125 - val_acc: 0.8952\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1312 - acc: 0.9532 - val_loss: 0.6325 - val_acc: 0.8824\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1303 - acc: 0.9524 - val_loss: 0.5232 - val_acc: 0.8884\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1314 - acc: 0.9517 - val_loss: 0.5499 - val_acc: 0.8885\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1287 - acc: 0.9527 - val_loss: 0.5320 - val_acc: 0.8925\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1263 - acc: 0.9540 - val_loss: 0.5775 - val_acc: 0.8914\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1251 - acc: 0.9539 - val_loss: 0.4538 - val_acc: 0.8958\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1249 - acc: 0.9554 - val_loss: 0.5843 - val_acc: 0.8887\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1251 - acc: 0.9556 - val_loss: 0.5150 - val_acc: 0.8929\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1211 - acc: 0.9570 - val_loss: 0.5132 - val_acc: 0.8988\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1211 - acc: 0.9558 - val_loss: 0.5448 - val_acc: 0.8955\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1208 - acc: 0.9555 - val_loss: 0.5170 - val_acc: 0.8951\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1197 - acc: 0.9566 - val_loss: 0.5047 - val_acc: 0.8927\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1190 - acc: 0.9592 - val_loss: 0.5378 - val_acc: 0.8851\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1247 - acc: 0.9558 - val_loss: 0.4484 - val_acc: 0.8948\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1178 - acc: 0.9589 - val_loss: 0.4659 - val_acc: 0.8812\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1174 - acc: 0.9582 - val_loss: 0.4726 - val_acc: 0.8971\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1164 - acc: 0.9601 - val_loss: 0.5600 - val_acc: 0.8989\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1122 - acc: 0.9604 - val_loss: 0.7786 - val_acc: 0.8808\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1128 - acc: 0.9609 - val_loss: 0.4985 - val_acc: 0.8946\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1140 - acc: 0.9611 - val_loss: 0.5073 - val_acc: 0.8934\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1127 - acc: 0.9606 - val_loss: 0.5675 - val_acc: 0.8900\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1063 - acc: 0.9613 - val_loss: 0.6537 - val_acc: 0.8835\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1123 - acc: 0.9627 - val_loss: 0.5409 - val_acc: 0.8953\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.1093 - acc: 0.9620 - val_loss: 0.5653 - val_acc: 0.8988\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1094 - acc: 0.9616 - val_loss: 0.5917 - val_acc: 0.8835\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1083 - acc: 0.9629 - val_loss: 0.5857 - val_acc: 0.8915\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1122 - acc: 0.9631 - val_loss: 0.5549 - val_acc: 0.8976\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1003 - acc: 0.9651 - val_loss: 0.5102 - val_acc: 0.8949\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1084 - acc: 0.9644 - val_loss: 0.6326 - val_acc: 0.8876\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1075 - acc: 0.9634 - val_loss: 0.6400 - val_acc: 0.8918\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1128 - acc: 0.9622 - val_loss: 0.4887 - val_acc: 0.8894\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1005 - acc: 0.9658 - val_loss: 0.7240 - val_acc: 0.8823\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1090 - acc: 0.9630 - val_loss: 0.6347 - val_acc: 0.8907\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1003 - acc: 0.9668 - val_loss: 0.5920 - val_acc: 0.9012\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1045 - acc: 0.9663 - val_loss: 0.5715 - val_acc: 0.8961\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0975 - acc: 0.9670 - val_loss: 0.6649 - val_acc: 0.8724\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0996 - acc: 0.9663 - val_loss: 0.5853 - val_acc: 0.9004\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0983 - acc: 0.9679 - val_loss: 0.5779 - val_acc: 0.8972\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0975 - acc: 0.9675 - val_loss: 0.5435 - val_acc: 0.8932\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0928 - acc: 0.9698 - val_loss: 0.6246 - val_acc: 0.8953\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0987 - acc: 0.9675 - val_loss: 0.5484 - val_acc: 0.9011\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0977 - acc: 0.9691 - val_loss: 0.5795 - val_acc: 0.8967\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0843 - acc: 0.9706 - val_loss: 0.6551 - val_acc: 0.8930\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0871 - acc: 0.9712 - val_loss: 0.7025 - val_acc: 0.8971\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0904 - acc: 0.9692 - val_loss: 0.6290 - val_acc: 0.8896\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0939 - acc: 0.9697 - val_loss: 0.6241 - val_acc: 0.8989\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1029 - acc: 0.9674 - val_loss: 0.6032 - val_acc: 0.8998\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0860 - acc: 0.9711 - val_loss: 0.7137 - val_acc: 0.8974\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1007 - acc: 0.9706 - val_loss: 0.7659 - val_acc: 0.8892\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0868 - acc: 0.9712 - val_loss: 0.6017 - val_acc: 0.9007\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0885 - acc: 0.9718 - val_loss: 0.6515 - val_acc: 0.8998\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0904 - acc: 0.9712 - val_loss: 0.6530 - val_acc: 0.9020\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0937 - acc: 0.9709 - val_loss: 0.5440 - val_acc: 0.8995\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0787 - acc: 0.9729 - val_loss: 0.5565 - val_acc: 0.8899\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0824 - acc: 0.9731 - val_loss: 0.7163 - val_acc: 0.8910\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0847 - acc: 0.9728 - val_loss: 0.6528 - val_acc: 0.8985\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0845 - acc: 0.9739 - val_loss: 0.6956 - val_acc: 0.8946\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0837 - acc: 0.9734 - val_loss: 0.6635 - val_acc: 0.8967\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0931 - acc: 0.9718 - val_loss: 0.6332 - val_acc: 0.8961\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0890 - acc: 0.9735 - val_loss: 0.6847 - val_acc: 0.8955\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0809 - acc: 0.9736 - val_loss: 0.8531 - val_acc: 0.8867\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0884 - acc: 0.9743 - val_loss: 0.7682 - val_acc: 0.8829\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0928 - acc: 0.9734 - val_loss: 1.0041 - val_acc: 0.8695\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0783 - acc: 0.9743 - val_loss: 0.6142 - val_acc: 0.8936\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0841 - acc: 0.9744 - val_loss: 0.5577 - val_acc: 0.8984\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0726 - acc: 0.9761 - val_loss: 0.8038 - val_acc: 0.8974\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0802 - acc: 0.9749 - val_loss: 0.7365 - val_acc: 0.9012\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0829 - acc: 0.9760 - val_loss: 0.6900 - val_acc: 0.8979\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0751 - acc: 0.9758 - val_loss: 0.7676 - val_acc: 0.8926\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0861 - acc: 0.9742 - val_loss: 0.6515 - val_acc: 0.9004\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0803 - acc: 0.9761 - val_loss: 0.6761 - val_acc: 0.9019\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0911 - acc: 0.9745 - val_loss: 0.6463 - val_acc: 0.8991\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0831 - acc: 0.9750 - val_loss: 0.8510 - val_acc: 0.8701\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0759 - acc: 0.9770 - val_loss: 0.7138 - val_acc: 0.8907\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0743 - acc: 0.9763 - val_loss: 0.7537 - val_acc: 0.8970\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0699 - acc: 0.9777 - val_loss: 0.6832 - val_acc: 0.8949\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0805 - acc: 0.9761 - val_loss: 0.6733 - val_acc: 0.8963\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0738 - acc: 0.9780 - val_loss: 0.7380 - val_acc: 0.8917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0722 - acc: 0.9777 - val_loss: 0.8062 - val_acc: 0.8965\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0797 - acc: 0.9768 - val_loss: 0.6845 - val_acc: 0.8967\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0770 - acc: 0.9771 - val_loss: 0.7136 - val_acc: 0.8890\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0795 - acc: 0.9786 - val_loss: 0.6951 - val_acc: 0.8996\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0781 - acc: 0.9756 - val_loss: 0.6708 - val_acc: 0.8988\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0804 - acc: 0.9774 - val_loss: 0.7564 - val_acc: 0.8963\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0758 - acc: 0.9766 - val_loss: 0.7804 - val_acc: 0.8923\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0817 - acc: 0.9773 - val_loss: 0.6890 - val_acc: 0.8983\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0704 - acc: 0.9784 - val_loss: 0.8193 - val_acc: 0.8962\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0765 - acc: 0.9780 - val_loss: 0.7466 - val_acc: 0.8974\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0843 - acc: 0.9775 - val_loss: 0.7715 - val_acc: 0.9023\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0781 - acc: 0.9786 - val_loss: 0.7121 - val_acc: 0.8960\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0776 - acc: 0.9788 - val_loss: 1.1291 - val_acc: 0.8685\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0810 - acc: 0.9774 - val_loss: 0.6742 - val_acc: 0.9018\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0699 - acc: 0.9792 - val_loss: 0.7490 - val_acc: 0.9010\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0852 - acc: 0.9770 - val_loss: 0.6063 - val_acc: 0.8991\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0640 - acc: 0.9809 - val_loss: 0.7141 - val_acc: 0.9002\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0693 - acc: 0.9799 - val_loss: 0.7581 - val_acc: 0.8912\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0739 - acc: 0.9794 - val_loss: 0.7008 - val_acc: 0.8942\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0707 - acc: 0.9786 - val_loss: 0.7270 - val_acc: 0.8990\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0716 - acc: 0.9788 - val_loss: 0.6913 - val_acc: 0.8954\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0612 - acc: 0.9807 - val_loss: 0.8251 - val_acc: 0.8871\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0745 - acc: 0.9787 - val_loss: 0.7481 - val_acc: 0.8943\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0729 - acc: 0.9790 - val_loss: 0.7411 - val_acc: 0.8870\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0701 - acc: 0.9792 - val_loss: 0.6805 - val_acc: 0.9024\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0685 - acc: 0.9797 - val_loss: 0.7473 - val_acc: 0.8950\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0715 - acc: 0.9800 - val_loss: 0.7790 - val_acc: 0.8983\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0910 - acc: 0.9773 - val_loss: 0.7375 - val_acc: 0.9008\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0686 - acc: 0.9821 - val_loss: 0.7997 - val_acc: 0.8968\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0757 - acc: 0.9798 - val_loss: 0.6922 - val_acc: 0.9003\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0636 - acc: 0.9825 - val_loss: 0.7395 - val_acc: 0.8955\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0743 - acc: 0.9812 - val_loss: 0.7735 - val_acc: 0.8943\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0786 - acc: 0.9794 - val_loss: 0.7377 - val_acc: 0.8999\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0603 - acc: 0.9825 - val_loss: 0.8418 - val_acc: 0.8981\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0712 - acc: 0.9808 - val_loss: 0.9177 - val_acc: 0.8883\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0707 - acc: 0.9816 - val_loss: 0.8215 - val_acc: 0.8969\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0713 - acc: 0.9806 - val_loss: 0.7732 - val_acc: 0.8998\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0770 - acc: 0.9816 - val_loss: 0.7859 - val_acc: 0.8922\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0676 - acc: 0.9835 - val_loss: 0.8596 - val_acc: 0.8929\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0900 - acc: 0.9792 - val_loss: 0.7462 - val_acc: 0.8959\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0706 - acc: 0.9817 - val_loss: 0.8161 - val_acc: 0.8973\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0709 - acc: 0.9815 - val_loss: 0.7769 - val_acc: 0.9006\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0685 - acc: 0.9820 - val_loss: 0.9367 - val_acc: 0.8932\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0639 - acc: 0.9822 - val_loss: 0.9573 - val_acc: 0.8873\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0651 - acc: 0.9825 - val_loss: 0.8664 - val_acc: 0.8904\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0614 - acc: 0.9825 - val_loss: 0.8162 - val_acc: 0.9004\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0645 - acc: 0.9821 - val_loss: 0.6622 - val_acc: 0.8892\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0591 - acc: 0.9836 - val_loss: 0.9413 - val_acc: 0.8816\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0654 - acc: 0.9816 - val_loss: 0.7596 - val_acc: 0.9000\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0584 - acc: 0.9836 - val_loss: 1.0568 - val_acc: 0.8884\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0778 - acc: 0.9810 - val_loss: 0.7418 - val_acc: 0.8899\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0864 - acc: 0.9806 - val_loss: 0.7892 - val_acc: 0.8986\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0606 - acc: 0.9836 - val_loss: 0.7962 - val_acc: 0.8949\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0665 - acc: 0.9830 - val_loss: 0.8342 - val_acc: 0.8993\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0621 - acc: 0.9833 - val_loss: 0.8150 - val_acc: 0.8977\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0658 - acc: 0.9830 - val_loss: 0.8608 - val_acc: 0.8954\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0744 - acc: 0.9826 - val_loss: 0.8460 - val_acc: 0.8992\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0577 - acc: 0.9839 - val_loss: 0.8673 - val_acc: 0.8968\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0756 - acc: 0.9816 - val_loss: 0.6877 - val_acc: 0.8950\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0670 - acc: 0.9837 - val_loss: 0.8056 - val_acc: 0.8983\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0615 - acc: 0.9836 - val_loss: 0.8029 - val_acc: 0.9010\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0752 - acc: 0.9839 - val_loss: 0.7971 - val_acc: 0.8957\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0657 - acc: 0.9831 - val_loss: 0.8149 - val_acc: 0.8989\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0559 - acc: 0.9860 - val_loss: 0.8644 - val_acc: 0.8920\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0709 - acc: 0.9818 - val_loss: 0.7903 - val_acc: 0.9014\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0570 - acc: 0.9851 - val_loss: 0.9307 - val_acc: 0.8809\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0708 - acc: 0.9834 - val_loss: 0.8317 - val_acc: 0.9019\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0611 - acc: 0.9851 - val_loss: 0.8625 - val_acc: 0.8981\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0664 - acc: 0.9827 - val_loss: 0.9547 - val_acc: 0.8816\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0610 - acc: 0.9849 - val_loss: 0.7622 - val_acc: 0.8928\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0594 - acc: 0.9853 - val_loss: 0.8417 - val_acc: 0.8981\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0645 - acc: 0.9842 - val_loss: 0.8507 - val_acc: 0.8982\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0642 - acc: 0.9847 - val_loss: 0.7710 - val_acc: 0.8958\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0696 - acc: 0.9844 - val_loss: 0.9092 - val_acc: 0.8839\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0553 - acc: 0.9850 - val_loss: 0.8006 - val_acc: 0.8942\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0641 - acc: 0.9834 - val_loss: 0.8861 - val_acc: 0.8978\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0658 - acc: 0.9830 - val_loss: 0.8612 - val_acc: 0.9028\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0687 - acc: 0.9843 - val_loss: 0.8324 - val_acc: 0.8965\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0647 - acc: 0.9851 - val_loss: 0.8152 - val_acc: 0.8947\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0732 - acc: 0.9839 - val_loss: 0.8421 - val_acc: 0.9008\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0783 - acc: 0.9823 - val_loss: 0.7896 - val_acc: 0.8978\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0756 - acc: 0.9842 - val_loss: 0.8404 - val_acc: 0.8987\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0655 - acc: 0.9855 - val_loss: 0.8943 - val_acc: 0.8963\n"
     ]
    }
   ],
   "source": [
    "init_history = init_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_history_dict = init_history.history\n",
    "init_val_acc = init_history_dict['val_acc'] \n",
    "init_val_loss = init_history_dict['val_loss']\n",
    "max_accu_epoch = init_val_acc.index(max(init_val_acc))\n",
    "min_loss_epoch = init_val_loss.index(min(init_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGDCAYAAAAyM4nNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXecXFXZ+L/PzGzN1uymZ5NNI5DQJBgCGEVAacEGKkVFVLD78lreV3wVO/r6ij98X0UpIlWpilRpEgglbLIhCSQhpO1mN3V7yZZp5/fHuXfmzuy03exkdmbP9/OZz5R7597nnHvvec5TzjmilMJgMBgMBkP248q0AAaDwWAwGEYHo9QNBoPBYMgRjFI3GAwGgyFHMErdYDAYDIYcwSh1g8FgMBhyBKPUDQaDwWDIEYxSNyRFRJ4SkSsSbP+jiPwgxWOtFJEvjJ50qSEiZ4hIc4r7/khE7kmDDHeIyM+sz8tFZGsq+47wXL0iMnek/zeMHiLyWRF5Oc62WhFRIuI50nIZchOj1McpItIgImensq9S6jyl1J3W/4Y0UEqpLymlfpoOOXMVpdQqpdTC0ThWrI6SUqpEKbVzNI5vGL8k6pAYxiZGqRsMhqxANKbNGiWMdyA3MQ+IIdQbF5Ffi0iHiOwSkfMc21eKyBdE5Bjgj8Cplnu309rudCtXisjjItJiHetxEZmZohw/EpEHReQeEekRkTdF5CgRuVZEDopIk4h80LH/dBF5VETaRWS7iFzl2FZkydUhIpuBd0eda7qIPGzJuUtEvpGijFtEZIXju8c6xknW9wdFZL+IdInISyKyOM5xIsIBIvIuEVlnlft+oNCxLW6disjPgeXA76xr8jvrdyUi863P5SJyl/X/RhH5vq0ck137GHJ/V0R2WHJuFpGPRm2/yqoje7tdLzUi8jdLhjaHnBGhjmh3tHXv/VxEXgH6gLkicqXjHDtF5ItRMnxYRNaLSLcl67ki8nERqY/a75si8o845Yx7Dvvaici3rPtyn4hc6dheZd2X3SJSB8yLV58xzpvonl4qImut4x4Qkd9Yvxdaz0ybiHSKyBoRmRLn+A0i8p8ishE4ZN2/Ma+pxH/eC6z7Zbclxx9FpMjaVm3dn51WGVaJ6YgdUUxlG2xOAbYC1cCvgD+JiDh3UEptAb4EvGa5dytiHMcF/BmYDcwC+oHfDUOOC4G7gUrgDeBp65gzgJ8ANzv2vQ9oBqYDFwPXi8iZ1rYfohvTecA5QCgnwGpkHgM2WMc9C7hGRM5JQb6/Apc6vp8DtCql1lnfnwIWAJOBdcC9yQ4oIvnAI1a5JwIPAhc5dolbp0qp/wJWAV+zrsnXYpzi/4ByYC7wPuAzwJWO7UmvvYMd6E5EOfBj4B4RmWaV4+PAj6zjlwEfAtpExA08DjQCteg6vy9ZvTj4NHA1UGod4yCwwjrHlcD/c3QelgJ3Ad8BKoD3Ag3Ao8AcS1E5j3tXnHPGPYfFVKsOZgCfB34vIpXWtt8DA8A04HPWK1US3dO/BX6rlCpD39cPWL9fYclSA1Shn9H+BOe4FLgAqFBK+YlzTRM8778EjgJOBOZbdXCdte1blvyTgCnA9wAzF/mRRCllXuPwhW7ozrY+fxbY7thWjH4Qp1rfVwJfcOz7ctSx7gB+Fuc8JwIdju+hY8XY90fAs47vFwK9gNv6XmrJVYFuwAJAqWP/XwB3WJ93Auc6tl0NNFufTwF2R537WuDPDjnuiSPjfKAHKLa+3wtcF2ffCkve8uh6As5wyPNeYC8gjv++ejh1ap13PuAGvMAix7YvAitTufYp3EfrgQ9bn58G/i3GPqcCLYAnzjW/x/G91jq/x1G2nySR4RH7vOhO3/+Ls98fgJ9bnxcDHUBBiuV0nuMMtNL0OLYfBJZZ9e0DjnZsu56oZyZWeUl+T7+EVrrVUcf4nHW/HJ9CORqAzw3jmn7WKTsgwCFgXtT13WV9/gnwD2B+KvVqXqP/Mpa6wWa//UEp1Wd9LBnuQUSkWERutty83eiGqMKy1lLhgONzP9oKDji+23JNB9qVUj2O/RvRVgPW9qaobTazgemWi7DTcit+D21ZJEQptR3YAlwoIsVoa/QvACLiFpFfWq7MbnQDCtoCTsR0YI+yWsVoeQ+zTquBPCLL76wnGMa1F5HPWK5tu96OJVy+GrTVF00N0Ki0VTgSnNcRETlPRFZb7t1O4PwUZAC4E7jM8kJ8GnhAKTUYa8ck5wBoiypPH7rOJqEVdLx7LxHJ7unPoy3kty0Xux0GuhvdobpPRPaKyK9EJC/BeaLrM9E1jWYSuuNX79j/n9bvAP8DbAeescIW302l4IbRwyh1w3BJ5kr7FrAQOEVpN+F7rd/juXNHyl5gooiUOn6bBeyxPu9DN/DObTZNaMuiwvEqVUqdn+K5bRf8h4HNlqIHuMz67Wy0K7PW+j1Z2fcBM6Jc3k55k9VpomvSirYcZ0cde0/s3eMjIrOBW4GvAVVKu2PfcsjRROz4cRMwS2InZh1CKwmbqTH2CZVPRAqAh4FfA1MsGZ5MQQaUUqvRXovl6Gt1d6z9UjhHIloAP/HvvUQkvKeVUtuUUpeiQzv/DTwkIhOUUj6l1I+VUouA09Bhg88kOI+zPpNd0+h7qxXduV7seHbKlVIllow9SqlvKaXmoju83xSRs1Isv2EUMErdMFwOADOtOHAsStEPfaeITETHtkcdpVQT2uX4CytR6Hi0JWMnXT0AXCs6yWwm8HXH3+uAHithqMiysI8VkYhkugTcB3wQ+DKWlW5RCgwCbWhFdX2Kx3sNrQi+ISJ5IvIxYGnUcRPV6QF0vHwIlpfjAeDnIlJqNeLfJFxPw2ECupFvAZ1MhrbqbG4Dvi0iS0Qz3zpfHbrj8ksRmWBdr9Ot/6wH3isis0SkHB0GSUQ+UGDJ4Bed1PdBx/Y/AVeKyFki4hKRGSJytGP7Xeh8BJ9SKt5QrWTniItV338DfmR5WBbhyOdI8t+E97SIfEpEJimlgkCn9begiLxfRI6zPDfd6E5cMJVzkvyaRjzv1rlvRecYTLb+M8PORxGRFdZ1F6ALHU5IVRbDKGCUumG4/AvYBOwXkdYY228EitA9+tVo11y6uBRtDe8F/g78UCn1nLXtx2jX5S7gGRxWmdXwrkDHpndZst6Gtq6TopTah1bEpwH3OzbdZZ1zD7AZXf5UjucFPoaOX7YDn0QrBptkdfpb4GLR2ev/G+MUX0dbxDuBl9EdkdtTkS1Kzs3ADeiyHwCOA15xbH8Q+Ll1/B50HHqiVd8XomP8u9GJVJ+0/vMsug43AvXohLpEMvQA30B3VDrQFvejju11WIltaKXyIpFeirvRSitupybZOVLga2hX/H50HsWfh/HfRPf0ucAmEelFX/NLlFL9aO/GQ2iFvgVd5pheiGiSXVNiP+//iXaxr7bCQc+hPUmgk0SfQ+fCvAbcpJR6YRjlNxwmEhnGMxgMhtxF9NCrg8BJSqltmZbHYBhtjKVuMBjGE18G1hiFbshVzIxCBoNhXCAiDegEsI9kWBSDIW0Y97vBYDAYDDmCcb8bDAaDwZAjGKVuMBgMBkOOkHUx9erqalVbW5tpMSBoDb10mX6RwWAw5CpBq613Zbitr6+vb1VKTUq2X9Yp9draWtauXZtpMQwGg8FgOGKISErTDRszc6TcdJN+GQwGgyFnuemmm7gpi9p6o9RHygMP6JfBYDAYcpYHHniAB7KorTdK3WAwGAyGHMEodYPBYDAYcgSj1A0Gg8FgyBGMUjcYDAaDIUfIuiFtY4aVKzMtgcFgMBjSzMosa+uNpW4wGAwGQ45glPpI+fWv9ctgMBgMOcuvf/1rfp1Fbb1R6iPl8cf1y2AwGAw5y+OPP87jWdTWG6VuMBgMsWiqg1U36HeDIUswiXIGg8EQTVMd3LkCAn5w58MVj0LN0kxLZTAkxVjqBoPBEM3mf4B/EFQAAl5oWJVpiQyGlDCW+kgpKsq0BAaDIV1MWqjfxaUt9drlmZXHkDGKsqytN0p9pDz1VKYlMBgM6WLS0fp98cfglC8a1/s45qksa+uN+91gMBiiCQb0+8LzjEI3ZBVGqY+Un/5UvwwGQ+6hLKWugpmVw5BxfvrTn/LTLGrrjVIfKc8/r18GgyH3CPoj3w3jlueff57ns6itN0rdYDAYorHd7/a7wZAlGKVuMBgM0djKXBmlbsgu0qbUReR2ETkoIm/F2X60iLwmIoMi8u10yWEwGAzDRhlL3ZCdpHNI2x3A74C74mxvB74BfCSNMqSPqqpMS2AwGNJF0CTKGTRVWdbWp02pK6VeEpHaBNsPAgdF5IJ0yZBWHn440xIYDIZ0EUqUM5b6eOfhLGvrsyKmLiJXi8haEVnb0tKSaXEMBkOuo0xM3ZCdZIVSV0rdopQ6WSl18qRJkzItjubaa/XLYDDkHkHL7W4s9XHPtddey7VZ1NabaWJHymuvZVoCg8GQLmz3u7HUxz2vZVlbnxWWusFgMBxRTPa7IUtJm6UuIn8FzgCqRaQZ+CGQB6CU+qOITAXWAmVAUESuARYppbrTJZPBYDCkhEmUM2Qp6cx+vzTJ9v3AzHSd32AwGEaMmXzGkKWYmPpImWn6IwZDzqJMopxBMzPL2nqj1EfKPfdkWgKDwZAuTKKcweKeLGvrTaKcwWAwRGMWdDFkKUapj5RrrtEvg8GQe5j11A0W11xzDddkUVtv3O8jZf36TEtgMBjShcl+N1isz7K23ljqBoPBEI09o5yJqRuyDKPUDQaDIRpjqRuyFKPUDQaDIRqzoIshSzEx9ZFy1FGZlsBgMKQLk/0+PJrqoGEV1C6HmqWZlmZUOSrL2nqj1EfKLbdkWgKDwZAujPs9dZrq4M4VEPCBuwCueDSnFPstWdbWG/e7wWAwRKNMolzKNKwC/6Cus4BXfzdkDKPUR8rVV+uXwWDIPYz7PXVql4NYqsSdr7/nEFdffTVXZ1Fbb9zvI+WddzItgcFgSBdmmtjUqVkKVUfBYCd84u6ccr0DvJNlbb1R6gaDwRCNWU99eOQVgLs65xR6NmKUusFgMEQTstTNNLEpEfCH68yQUYxSNxgMhmiCZunVYRH0mboaIxilPlJOPDHTEhgMhnRhJp8ZHsHctdRPzLK23ij1kXLjjZmWwGAwpAszTn14BPw52wG6McvaeqPUDQaDIZqgsdSHRdBn8g/GCEapj5RPfUq/33NPZuUwGAyjj8l+Hx5Bf87W1aestv6eLGnrjVIfKc3NmZbAYDCkCzP5zPAI+ECpTEuRFpqzrK03St1gMBiiMe734RH0G/f7GMEodYPBYIjGJMoNj4APyE1LPdswSt1gMBiiMUPahoex1McMRqmPlFNPzbQEBoMhXZiYeuoo5UgsDIIrt9YJOzXL2nqj1EfKL36RaQkMBkO6CMXUjfWZlIAv/DnoA1dB5mRJA7/IsrY+t7pUBoPBMBqYIW2pE3Qq9dycVS6bMEp9pFx0kX4ZDIbcw2S/p45TkTut9hzhoosu4qIsauvTptRF5HYROSgib8XZLiLyvyKyXUQ2ishJ6ZIlLbS16ZfBMN5oqoNVN+j3XMVkv6dOwKHUc7C+2traaMuitj6dMfU7gN8Bd8XZfh6wwHqdAvzBejcYDGOVpjq480LwD4CnEK54LDfX0DbZ76kT9MX+bMgIabPUlVIvAe0JdvkwcJfSrAYqRGRauuQxGAyjQMMq8Hv154BXf89FTPZ76gRMTH0skcmY+gygyfG92fptCCJytYisFZG1LS0tR0Q4g8EQg9rl4LYcfK48/T0XMUo9dXI8pp5tZMWQNqXULcAtACeffPLYmLborLMyLYHBcOSpWQrv+Sa8+Es45/rcdL2Dcb8Ph2Bux9TPyrK2PpNKfQ9Q4/g+0/otO/jBDzItgcGQGSqsx7Z6QWblSCcmUS51osep5xg/yLK2PpPu90eBz1hZ8MuALqXUvgzKYzAYUsFuxHM5fmqGtKVOhKWew/dElpA2S11E/gqcAVSLSDPwQyAPQCn1R+BJ4HxgO9AHXJkuWdLCeefp96eeyqwcBsORxlbquTzbml22YA6XcbTI8clnzrPa+qeypK1Pm1JXSl2aZLsCvpqu86ed/v5MS2AwZIaAlf2egw14CLtsxlJPjnOceiD37on+LGvrzYxyBoNheISUeg4rPJP9njo5bqlnG0apGwyG4TEuYurGUk+ZiJh67iXKZRtGqRsMhuExHtzvZkGX1AmYRLmxRFaMUx+TrFiRaQkMhsxgK/VcTpSzE+RUQK8XLpJZecYyTus8B2PqK7KsrTdKfaR8+9uZlsBgyAzjyf0OuvMi7szJMtbJ8Wliv51lbb1xvxsMhuExHhLlnLH0XC7naGBi6mMKo9RHyhln6JfBMN4YDzH1YCBsnZtkucTk+OQzZ5xxBmdkUVtvlLrBYBgeue5+V0orcne+/m4s9cQEcjumnm0YpW4wGIZHrifK2eXyWEp9PFrqTXWw6gb9nowct9SzDZMoZzAYhkeuu9/tco1XS72pDu44X5fbXQBXPJp4Nb7gGF/QpakOGlbpZYJzdVVBB0apGwyG4RFyv+eosrPL5S7Q77nqkYjH1qfC1zjg1QoxkTIcy+PUm+rgz+db4ZQUOig5gFHqI+UTn8i0BAZDZsh1S912t7vz9Huudl7iYXdmEO2tqF2eeP+xPE5954th+VLpoMTgE1nW1hulPlK+8pVMS2AwZIact9QtxeSxLfUcLWc8upr0++Sj4cL/Ta4Ex3JMffq7rA8pdlBi8JUsa+tNotxI6evTL4NhvBFKlMtRZWfPJjceY+pKwc6V+nPJlNSs2sAYHqdeNU+/zzx5xK73vr4++rKorTeW+kg5/3z9vnJlRsUwGI4448b9biv1HC1nLNq2Q3ez/jzQHX8/Z/LZWF6lbaBLv09eNOJY+vlWW78yS9p6o9QNBsPwyPVx6tHZ7+MpUc620qe/K6wQo2mqgzsu0Ba6pwAWfRjEpetprHk1Bq2OiX8ws3IcQZK630XkVyJSJiJ5IvK8iLSIyKeOhHAGg2EMkuvTxNrl8oxD9/umv0NhOZROCyvEaBpWWfdAUL93NuoOkLgjJ6IZC9jehoBR6k4+qJTqBlYADcB84DvpFMpgMIxhcl6pR1vqOVrOaHa/Do2vaAt92zPQ3xl7v9rlgLVqnTtfdwBceeDyjD3vje1t8HszK8cRJBWlbrvoLwAeVErF8ckYDIZxgW2N5aqyU+M0UW7nC+HPwYCOlfsGhu5Xs1Qn0VXM1slnxVXg9ughgJlU6rFmwQu532OUI0dJJab+uIi8DfQDXxaRScD4qaF4fPazmZbAYMgMuZ4oF4xKlMvVzks0M062Pohldfu0UswrHLqvyw0TqrWCX3+v3l8FM3dPNK6GOy/QMjgnmQm530duqX82y9r6pEpdKfVdEfkV0KWUCojIIeDD6RdtjJNlF9pgGDXGW6LceLHUpyzS70efD1OOhxd/od3XJZOH7hvwhZPPgn7tflcqczH1rU+Er5tzkplRSJTLNqWeSqLcxwGfpdC/D9wDTE+7ZGOd1lb9MhjGG7keU1dRiXLjJfvd16/fj/kQzLAmbYk3rC3oUOoBv3a/ZzKmPvU460PUJDMDVl7AYbjfW1tbac2itj6VmPoPlFI9IvIe4GzgT8Af0itWFnDxxfplMIw3cl2pR7vfc7Wc0diKz1OoM+AhrBSjCfgdlrpPW+qZjKnbk8zMPi1ykplRcL9ffPHFXJxFbX0qSt2+oy8AblFKPQHkp08kg8EwZgkGwpZsrsaahyzokiXlHM5yqbGwk+LyiqCgTH+ON6wt6At3AoJ+baW73JlT6raXYfIxkZPMjMNx6qkkyu0RkZuBDwD/LSIFmOllDYbxSWAMzx42WkS737PBUm+qgztXaOXlKYQrHhv+DGp+SzF6CqHQUurxJqAJRLvf83SYIlMxdVupD/ZE/j4w/pR6Ksr5E8DTwDlKqU5gImacusEwPnG6MXNVqQ9JlMuCcjasCo/FthPFhktM93sMS10p3fEJON3vGY6p+6y52aPltTslZvKZMEqpPmAHcI6IfA2YrJR6Ju2SGQyGsUeEpZ4FFuxIyMYhbbXLtVIF/T6C1cjC7vdCyC/RU7/GstTte8A/EM54d2d48pl4lnrI/Z5CTP1wwxdjhKTudxH5N+Aq4G/WT/eIyC1Kqf9Lq2RjnS9/OdMSGAxHnghLPQuU3UgYsqBLFmS/1yyF4y6GDX+F9313ZIuXhCz1IhDRcfVYMfWI9dO94Zi6ewxY6tHyDqQ4+UxTHfz5fH1Pewoiku2+nGVtfSru988DpyilrlNKXQcsQyv5pIjIuSKyVUS2i8h3Y2yfbc0nv1FEVorIzOGJn0E++Un9MhjGE06lng0W7EjI1mli84r0e+mUkf3ftnbtyWYKy2K7353eGv+AI1HOM7Zi6r4B7XZ35+uOSKLOWcMqq7MSHBK+mL/sg7ROXkJ9Y0d6ZB9lUkmUE8IZ8FifJemfRNzA79EJds3AGhF5VCm12bHbr4G7lFJ3isiZwC+AT6cqfEZpatLvNTWZlcMwJqhv7GD1zjaWza1iyezKpL+n8t/DlWG0jhtBiolyyeqjsjifjj7v6Mp2GNQ3dvDSOwd571GTWWI3/lai3PYDXTy9d/sQmQ+3fl/b0cqahnZOnz8p4T2T8r3V1643JFoyNUH5ezc38T7QljrouLrlfo84V3VYHWxoOMiUjh6KSisp94z+kLZUnx/f1maWAQz2hP7znmlBTgCYMAm692hl7YoxOx445rNXEePc6xs7+PgNj+EPBCmeOIV7v7AsJEdanq9RIBWl/mfgdRH5u/X9I+ix6slYCmxXSu0EEJH70DPROZX6IuCb1ucXgEdSEXpM8Gmr75Ela+yORUbjoRjpMQ5HCcc61qW3rsbrD1LgcfGXq5aFGuPLb1vNoC9Inlv4+Mk1fOykmRHHfeHtA3zhrnqUUuR7XBGNRqzzvLK9hWAQFDClrDCkZAAuueU1/AGFywW1Eyewo/UQAG6Bi5bM5JPvnnXYZY2XKOdU1q9ub+HJt/ajFBHltmX0BVTofx638MkY9TJS1jS088LbB5lRUURnvy/p9a1v7ODhdU3cX9dMQCluWrmDp849xHwIWeo3/HMLTwVLAd3se9zCKXMmsnpnO8EY1y1VRXT5ba8TVHDTCzu496plADy4tomH6psJBBUFeS6uW7GYHz+2CV8gGHEe+97y+oN4XLqO/7OjhTIIWatKKf751n52th6KK0t9Ywf3r9nNw+v28DlXM+/zwBv7+nnXAqCgHAa79f19y2r8QS3DA5fN4Xjr//92z2r+z9VLW3ceJ00rpCzfH7eeY3XmEj2HD69r4oE1zfiDashzZf+ne8DH5+9Yw7fce1jmgUB/Fxf/4VUU8A/3fp7Jg0N5E5nAHm215xXGkWUpFE/UeQSX/AVqllLf2MFPH9/M3kf+B4Dpl/+S1TvbQjJceutqfP7ws714evmY6KimMk3sb0RkJfAe66crlVJvpHDsGUCT43szcErUPhuAjwG/BT4KlIpIlVKqzbmTiFwNXA0wa9asFE5tGAnJrKiRWlmxHtz6xo5QA+9xCZ98d+KHIvoYD65t4vaXd/H2/h5ECDV4QMIGtb6xg7tea+CxDXtRCgryIhvKy25djS8QbihTUTard7bi9WvrbtAf5L//uYX/PPcYVu9sY9AXRAHegOLe13fz8Lrm0PleeqeFr/3lDQJBreQGfEFufO4drjn7KJbMruSZTft550APp86rxh8IcumtqwmqyHMLugwrjp8WUpaBICGFDhBQ8MDaZh7dsDeirHb957mFT5xcw+JpZbT0DjKpVHcWYl7nCKWuy/zkxn18/a9vEFBRwlnl/otV7qW1EyMUOoA/Rr0ArNrWwtqGjlDHJZYyeG1HKyUFHnoH/Zw6rxqAS25ZHapPALcLPnFyDRcv0R61y25dzaClCN+/cDIr3zkYIZMvoHhqYxNfB3Z1+JgDuAi7bZW1z8vbw02Uzx8MNfZPb9rPl+6pD3VoPhHnHnp28/7QtRzwB/nxo5vYtK87QvYBX5BfPf02g9a9NeALcuOz73DNB47ile2tDPiCoTq+9/XdXF6wh0UCB1oOcsNDG3hlRxt7OvpD90h0x+P+Nbv527o9+K1zFoi+tqt3H9JKvbAcOht5+q39eAPBUFnXN7SElLoEBvG4gviCLjoHFWWewJB7a/n8ala+0xIqr6Dr5j0Lqlm5Vf/uEvjQCdNZOqeKt/Z28cCappBcYD1XT21hakURj23Yi6Cf+ZkVxQQVFKJldysfefjwkkdhUD8Da1vdvE8A/yD1De188pbVoWPbsnz85Bp+7PfhKSoPKfToDmhQwbYDPfzl9d08VN8Ueubt+o91z2VCucdV6iIy0fG1wXqFtiml2kfh/N8GficinwVeAvYQ6eoHQCl1C3ALwMknnzy05TAcNrFudmdD8NqO1pBlEWt7xLEcChjC1llhXljx/vAfb4UeGH8w8qGIbgzrG9q59NbXQ5bCl947jxuf3xbaXynd2Dy8rpmH65vjKuVYD6qzQX58w95QAxpLCcfDJZHRqLpdHVx+62quu3AxLpcMaaj/WtfIbS/t5J+b9hN9M6/a1srqnW3UVBaxs1Un/xTmbefoqWVDFDpYSsYf5O39PaHrEu8BGfSFy/rkm/tC9eCLapSiKXReZ4f7vbd/gF8+8hYPrm2KqdCdMg76gryyvRWxZAxGyRqtGL94d33MYxV4XHz3vKP56eObI+qj0LOdcxZPjahr0B2cv9Y18WB9MwsmlYSurz+oeHbLgYh9bXk27+mEfLjxhQZ+6wY3QVyWzLFwu1wsm1vFw/XNXPu3jdhV4Yu6hwZ9AdY2dnD6/GoODUY2cxv3xB4P3tkXGaNetb2VV3e2MnHC0Pm/ytH3wItv7uABb3Pod7v+b3zuHc47dhrPbdnPC2+3DLlPCsWLX7lo7vZT39jBEiumvmlvWDa3y8VJM0vgdf29AB8eAvjFQ/mEIgh28kTUvfWvrS0R57E7uf96O/x7UMEj6/fyyPq9MesBoK6hA+iIKNP2ll4AiggPWSuhnw7yKBP9/LQEy8ANGxsO8NVHD0R0Fpwd7h8W9OFHeHXbyhAOAAAgAElEQVRrC995aEOoDAIU5buB5DICLFdvMG/d3fx63Sl8+6rPHnHFnshSr0eX2W6x7Jqw7/25SY69B3AGnGdav4VQSu1FW+qISAlwkTUWPufQiq6VZXOr0xfvTHjuxK6w+6J6xs6G4NzFU7nxuXciGlFbmdgNsfNctlvK7RIqivNCD8egTyveh9Y2h3r+sZRQqDGsb+beq5Zxy6qdEZbCw+uaiSbP46J/0D9EKT+4timk3J/dvH+IpehyCcvmVvH0pv3ct6ZpyHG9VhkHfQFe3NbC7IkTIizGNQ3t/OnlXVRNyOeYaWW8sr3VaiiCdPR5OWpyCS29g3T3+/EFtNX+UP2eSBmAmonFNLb3hcpvK3TQHYENTZ2IgKihClEBW/f3sGhaKSfOqtTu24Cu/zMWTmbl1ha81rl3tfZy56u7+JtVh4k6ATbOzoBtqSvxsP1AJ/fsbtT17xYCAUUQbXV5rHO/sFVbwgrtMQh5BaaX89beLu6r201Q6eu3bG4Vq7a18O/3r48viz/I9U9uGdLBGfAH2binM1Sf0XXkDyi27I8a7mThtNa6+nywSd9D/UE3uKEkH771voVUFufz1t6uiPot8LjJcwvf//ubcY/v8+uO3MP1e1DATS9sZ0pZIQsmlzC1rJBV21uHyHLMtDI2NnehrPLMqiqmoU3fE4EgtPR4cQucdcyU0PWtQCu4YtUXqgeXS/AHdf2v2tbKqm1D5zC3zzm5QDHgzw95Vl48toDKQx28cqCN9y6o5o3dnUyckM/GxoMca/03Hx95EqAwv4CyCUX0HdzPY+v3hI57OBZYrLoQq0wBq0yg77dCCXuQlkx1M2n2LLrW6p5Hu1QA8O9/qWN/cGpM2dwEyBc/AW8vV9zxOkpJ6NgiQmlhHi4h4r4T4PiZ5WzZ34PfHyQInCTvcGv+b8iTAJ9Sz/H4G7NZMvtjh1ELwyeuUldKzTnMY68BFojIHLQyvwS4zLmDiFQD7UqpIHAtcPthnnNM8vrOtpDrtDBvO9etWMyPHtVxsnjWbjyGmwz18vZWrri9LhSz/doZ87nh2XciHoh8j4uqCfkRVhQQsyFwPgy2QrQ7LGWFedy2alfILeUPKlp7ww+bAp58c19IQbuA46IeCufxB/xBXnrnIKt3hl2deR4XvYN+/bBZAgWC8P0LFvFm81Brx2lxn2zVj610AN49pwp/IMiX7q5HoRuR9zuUUVDBC28f5H+e3hpRB3a884ePvhVyM55/3DTWNrQz4A/iEh13vemF7Vy8ZCYfOnEGq3e28VZzF09t2h9xrPw8F1983zx+8vimkLs+GgXkucIK0XZJ3/zSDhrb+ggGFNtbDvHTjxzHRSfNHHKP/OnlnTz55n4eqt8T6lS4XXDW0Vop+AOR9R/daXhnv05AWmINZ/K6ChD7Ogp8/OQaZlQUxXST//yJzazbrRVuMKiYXlHEZafoMFq+W7jj1UZ+f9lJAFxxe12ENyhaFiDCgnL+vqu1j9PnVXHa/OoIBezzh+vU2RDbivnjUV6huzZpKzro0tbwzIoCvvL++aHzOOv3zeZOfvTYZtodFrV9X2/e1x26h57ZdCDivm5s7+Pzp9dy/vHTWdPYHuoEO/MPLr/Nitl6XFz93tj3xwk1FXzxffN48o0GJqzX1moZfaHn+roVi/nL6428tXdo8pyzM/Oxk2aS99RDDOzLD3Xon9/ZzyW+XoQgdbva+cDiKTy2YR/3vNrIZZajYE6Fmypc1PcGqWvspqKvhxavN+LeCgTDZbM7c0M6nu+0hNoA+/mMVxfXrVjMXa81hLxTEGmpnz23iE9+6DhWDjwDW+H4hfNhG3iUN3R9Tl9QzXnHTuOtvV08uLaJAmtyGjcB8pWPQfL1fvOr2TxNz653yOPC6wvLmO9xcd2FiwFCRlLVGy/i3qfvHw8BTnVvxrJbjxipJMqNCKWU35qs5mnADdyulNokIj8B1iqlHgXOAH4hIgrtfv9quuQZdb71rZR2q2/s4Jr714caKq8/yCPrmyMsT1tpOa3n6MZxTUM7f35lF89uOkDAUtB2Eo3XH79z8Lt/bQu5JAd9QW58fltEoxBU2hLc0znARe+awdzJJVQW5/PA2ibWN0U6TeyH4dzFU/mfZ7YypayQQDDIJbfEjvUqx/+OnVHGm3u6Q+7EeA9FdEN87+u76er38/6Fk3hhawufObWWW17ayVffP4/ifA/Hzyznc3esobHtEKu2tXDCzHIWzygf0ph7/UFe39XO8gXVLJtbxbK5Vfxj/R7uX9PEf//z7dB+waAKNZQ3rdzG81taWBs1lEVZx3t0w56QggkGFR19Xu69ahlfuqeeaWWFVE7I55A3wLEzylkyuzKk5F545+CQRnzJ7EoWTi3VngxHgzd/cgmb9/WEzuFUiAB7O/v53QvbAQgE9L301ffPj7gPlsyuZPXOcp56M8rdr8JKIda9V1mcT92uNh5Zv5d/bNjL05v389i5/SwAXPnFeHy68cr3uLgoTu7BktmV/NcFiyIaZTssA3DO4mnc8WojHreLF985GLqPnA2vLctTb+3j5W2tIevV3v7mnk7uq2tCAWsbO/jmBxeGZLnopJkRdZoXdc9Fd4aX1E7kxYkF0AvfOf94eBqmleYNKZP9n9U72yLudbuTZp/jJ49uYsOeLroHhmaF3/P6bs4/fjr3fmFZTFmif4++P+y6XDK7Ek/fQbAcHKXSz6VLZ0XcV5dbiZyxlKZ9ztYSGLSW9VDAjl4PrjxFCQP0BYpp77Xj1uHQwSk1E8hvDuJXHg4cGqRa7HUBIu+t6LLF6ngmyteJVReX3boav1UPJa5wp+qkKdpV/p6aPNgKO/qKWQbk48ct2jCw81ZsWX70l+ex+wUlDOCXfE71bOWXVWtYd/VHYdJRTD9+WVwZQ7JOvxh1+60oFcTlyWfGiR8cct3TTdqUOoBS6kngyajfrnN8fgh4KJ0ypIv649+jb7LGjrjZtTA02zeoYMfBcBKTyyVUFudz6S2rQ4reidsFx04rZ+OerogGecAX5I8rt4fczdpF2hohy57OfuobO0JuIwURMfNoi/CJt/aFOgb2Q+O1FKOthO2HYcAf5KePb+aqu+qHKHSnBW43PsfNrOCtvd0oRagH7Hywoh/4h+qbuK+uidZeL24Rrjx9Dq/tbOP2V3bhFuGUOVW896hJAJwyp4q7Xmtk0B/kBysWcd5x00KN+YNrm0LWUjCg+MiJM7hoie79i8BdrzWybndnyPJ3NpQnzZrIv7YMjT3a13HbAe3udEnk/85dPJW/rWtmg9UpOnZGeeh/S2ZXxm3EbWXhbPCAuAoR4P1HT+a2VTvxBWJvt1k2t4qCvEhLwylzPE9RR583dK8M+IL8fe0u/gPIKygmv1+xcGop13/0uISepkRlXmRZQZv2dlGY5w7VZ35UwwuwcGopaxraQ3Vhb//9C15EdG6FPxAZEopVp7HuOScLJxVDL1SUTQCGKvVY9RqrkwZw9uIpbLDi5dFhFn+cTpiz3pLdH/b2zTt2cQLgVy5K6Gd6RVFEOe+9Kr5CsqkuUAyUl3HKhIm8vqudHooBbfn7PCVccPx06hrayXOMephSDAGfl4C48ePGQ2DIczScssUj1v5/uSp8T5X+NUhPfxGl0s/cUt0merw9BBGea/RzuQfeM6eUcxcsjPncXfKuSbBafy919XPVIvjijp8h6wPM8BTBBx6FmsQyAlCzFJlyHPS3IxffPrJJgA6TtCr1XKS+sYO7X2vgzX/pqQT/b8qsIRnFgaC2pC88YXpIobuA2upidrb20XZIx8MK89zMm1RCS89ATIUO2rW8IU4Sze6O/tBnBazc2hKK2QNc+/BGggq+fc5Cnt9yMDR5gtPK+cf6Pby+S+c8OmPkzocmVkNw1JQSALr6dQ/ZbvhjWeC2onl4XfOQBjkW2rJsCzXUoHhzTxenzasKJddcfffaUL2ffcxkXt7eSnG+m6qS/NAx7Abwjyt3hJKi/uuRN6mtnsCS2ZWooArJHctyidVgL55ezqvbW3j8zf2h63iJwyoCOLm2krtXN/JQfTP5HhfzJ5cMKd9wGrB4CtHe996r4m+P2O8LyRv2aOw6sDOtGw7oJLKeYD4E+7jk3all+MYrc3lxHjMri9i8t5uJE/Ip8Lj46vvnc/r86thljVEXy+ZWke9xxe34JDp/LGoq9D300s5uPg5MLomv1BN1WABOm1fN7/O2h2SzwyyJZE1GrLKcpPu37KOKMukbctyUyu8foLBoAv9x7tFcfttqeoO6U/PJ48s4/fRwZ/8vD+7CCt/zaP0u3lPoJygegkrH1y87ZdaoDVFMhLNMrfkBWvrKKZV+du8/yJxFwGA3PvcEDg3mgQe2NB3k6+fEvufFF85hmcAAJwS2I5ZHYuuBfnjpYRZenqKC9h2CGUsyotAh9ez3IYxS9ntW4cyevu+fvwPgcsfYxXtfbwxnffqDbLXcpraiO3VeNTtbw1nGJ9RU8NrONqZV6AkRomOI0da0M3FkgxU/FuD4GeVs3NvFmoYOPnHza3z1jHk8+eY+trccQoD/fX4b161YzKa9XUOU6sKppXEtwUQNwcbmrrAiJ9JVGs8aStT4RROroT7QFZ7q0dkBmVqu66/fG+Azt9dFhCGWzK7kxFkVPP/2AYIq8n+rd7WHOg4By7Ud3YOPJXNHn5cnHK7s6P+dXKsfnVd3tHHCzHLy3Ie3qOFwOwGHu1/0f+79wjJufO4dXt7WSh7aSmsfdOEmMCoN96JpZWze2w0Cp82r4htnLUgoT6rKfqTMKNdLrj7zdntSpR5PpkSyLZxaOupJsgvLrM515Wyqe7cwZSTH9fVDXmFI5ub6dtgI3zh9Cjiep8bacnhL/8Ud9CLBAB84dgatHR1Ud7r5+UePG5UyDYcCNUALFcxlP3etfJMV8zpYMtDNoKcEL3khWaMTe23eNS08KU25e5DKRWfCrpsAxRcf74e1z7Hy8hSF6dkPC468290m1ez3WeixBAJUALuBw02kyzpeihrTCmE307ObDvD4hvBQh6CCLfu7OXpqKReeMD2mtXr5KbN4dUcbT286wDFTS1lxwvSIeGZ0Qkm8xJFjZ5bz5l7tng8EFf/7r+0hOews9Y4+b8yGb6QNotOKTWZ52wxHqcST6/61TaE4ml2nO1oOhUIMsTLy41lyI7Xwosse/b8ZFUVMLy9kb9dAhOs9W1kyu5Jrzj6KNQ3t5Fuu10EpoFAUx1ju88Nh8fRyntmsPSmXLR3ZPBQj6bDEY2KR7oRtb/dBAUxIrNOTMlxX84jo1164mXOOhjfW6jnMXe7hHcM/oFdos2X0HAMbGTJD3XHTJoSUerHbjwc/UypKmFIs0JWZKXWVr59WpecqKA4e0m3AQBee4gpUn+6kFbkCcT0jx1SF6+rH585mwbvPhucrYKADSqdCQWlqggz2gLdX/ydDJM1+F5Fbgb9b8XFE5Dz0rHLjAmeMfEqZnj7R5RiWfOeV2sXyxXvW6qE5bmFmRRG72vqsoUmRszk5FRUQshTjzfoUK34W6zh2ZwGJHBc9kvhWKoy2dRTvHIniaKm6X+PJOtIypPK/OZNK2Ns1QGlhbkS47DLv/Oca2Af7+4Rj8tRheyEAFk0Pdwzes6D6sI93uIiyklit5tH+Pqaxp4itqNXvg91QNMxn0tcPJZPD30PLr0aG/xZUh63aq0+dgavOWk/dPfrTxKZKEV56pBSvclPuGmDJ3Cpo7Ka4tJKfn7EE/g7fPHM2c+M9475wKHNBOdbkF1buUyCFFd5seqyRLaXTRlaQUSCVFmeZUiq0gItS6ikR+VUaZRozRE+P+NnTagH4wvK5zHyymOaOPkoL83jizb2hZDE7Q3mXPaY0TuIOwO9f2B5yYUcn+Nikqoid8VI7ZhcrcWc0SYvFMYJzpqJkR7NDk+x/9Y0dvG6NaLj9lQY+sGjqEa+ndLBkdiXvOmEy7IM+lU+eHM4o5DCLLaVenO/mUIws8SOOtfqcV+nmsbm9lzG/0lR/h57W1rYQB3uGr9T9g3qFMhtbqUevfOaYgGhWmUsveOOyll4NZOb65QUHeP9xtQS2lvCR+WVMnl2pOyOl0zh2lk44mFuRwOXiiKnj7dVeC1uZRy/nmoieffp9LFrqDvaKyPeBe6zvlwOJp9TJEZ7eFDk9Yt2udorz3Xz33KMZ/Hk+zR19bN7XTZEjazfP4+KC46dTv7sjaTJMKu7fVHEqmXTE7MY6mehgxGP1zjaC1rRi0Z26bGdPWzc1wAB5+HxePXb9MMu2r1NbSX3eAJf/6fVhzduQFixr02s1j/fXNXDGcYdfzrTS366VeKHl9RjBoi74+8OLuYBeehXg7Sdg2gnhxC/n0qtey5q1V2kbqaW++3XY/qyORQ83wUwp8PUxpaoSSiooyreVcTdMOjoUUiAwGP8YDkudwV7ot4bzVh8F/jdSt9azxFK/FPghYC/o8pL1W85T5ZiKMc/jwhcIsmBKKS6XkP/D67j5zjXM3dcdWsjja2fO57R51Sknw6TLhT2WFNx4ZDQ7a2ON5tZOrdRVPm4Co9JhWb2rPWFOxBHHynq23e8ER6ecaaWvHYomhmO/sdZBT4ZvILzsKsA+a+D7zpWwe3V4jXGnNe610uDdtlIfwdKrTXVwxwX6v6/+H1zxWGqKvalOL5FacwqooF56tsCxXOyhNmjfCfutBAB/AsUcbanbIYf5H+D7790M7zs3tbJkg6VuZbn/2xGQZcxhOxcn5Lu563NL+eI99Zx5tI45uT/4Adq3FTOwt5uW3kFOnVfF188MZ+2mMyPZMLY5EvkGmWJ2uXZheiUfN2pUOixjrhNkud9debpTn+canXKmlf5OvcpYge0yj+MythVh7fKhijPaUg+tKa7Ca4zXLI2y1C2l7rJi6iqoF/pxJcm1cMoRWssc7dq3z5OILY/D/ZfrVdXsde/zirWnYrBHW/7eHthTr/cD7VKPh9eh1Ad7YMCy1Ocs5+z5N4O8qmVOJlf3PsgvST2xLg0kVeoichR64ZVa5/5KqTPTJ9bYwJ5c5JA3gMsltPZ6OWqKdbHWr+esgT38YX8Z/b4AH18y5qNuhiNIrnbWppe6UeLh+NmTKNkffwKX4TDmOkGWUr/j8++BO+Dik6YxPdMyJaO/HSbOTex+b6qDO1ZoF7k7P2x520Rb6rXLtdJUwYg1xp0xdQZtSz0vnG0f9INr6IIzQ+QIeLVr/Jyfh7e5PeHzJOLtJ/S7CoblySvSyrR7r3bl6x3C2xO50G33e1FlpKXe28L6vV7Y+zIn7v3Q0DqLpmdfRl3vkJr7/UHgj8BtxFhBLZfZ3tLLpNICWnoG+WudHl++cKql1K+5hk90D/CbD/4A0JNMGAw5T8CLePI5cVYV7B+9rPAx1QlSARAXS2ongriZnmBGuTFDf4dWSCH3e4wJqzb/IxxXdlreYE3WMBiOP4PeVrsc9r8Jl93viKlb7ndxO2Lqbm2th7YnUOoNqywFa53z4Obwtg/9LjXXe4k12w6iOwL+gLbUC0q1pV0yxdpsWfL+Qf2Kh69P71dYHhlTb3mba/6pFf7KK/OTexF69mfU9Q563pBk+JVSf1BK1Sml6u1X2iXLMEopdhzs5ZzFUygt8PDYBh0rWTgl7FaZkK/7RAUeFwP+cdXfMYwnmupg1Q36PeCzrLLDSIoa6wT9WmGBVlbBMf5sK2XF1CvDyW2x3O8Vs60PrkjLG8KuaadSB5h6nLZiZ747/Jtt+RaURLrfXXYOQpK4eu1yPZYXAImcYav6qMT/tbFd7rNPgxW/1Z9tS32wR1vwAKdfo63rvMLE7ndfv/5/fmmkpT73jLCsqXgRxoClnopSf0xEviIi00Rkov1Ku2QZZn/3AL2DfhZOKeXEWRX0+wJUFOcxqTQ85MPOcB70B/n0n14PTcNqMOQMTXVw5wp4/idw54XQ1awb1NFW6o2vwku/1ufLNM6JW8QdSpwbs/j6tcVbPFErJpcntvvdHoO+4IMxXO+W+zmvKPI/ZTN0rL3f0bbZSttWgBAepw7JO0E1S6GyVn/2FEDLlvC2RNa0k25rAFbVfKiaF5a9oEwnCR54C4qr4Kzr9Pnc+UPd787Oqq8P8ibojoozpj7v/VBl5Uot/1ZiK12pMWGpp+J+v8J6/47jN0Xy9dSzGjuePn9yKW2HvKza1kpJgYd1uztDbsLeQX9onPmYyNo1GEabhlXhrOGA16HU3YBKLSkqGU118Ofz9WdPYfK4ZbpRwbDV6XLrMo5l+q2JZ4oqtVVpW6vx9qt5d4wkuTiWetl0/d69V3caIGyp509wuN+jYurJ6GvXw81a3obGV6ByLnTsTGxNO+lqDpfJzly33e8BL+x9AyYvClvZnsLIDkPjqzrjXim9bdYplqVeAn2t2lLPm6A7KhMmQdu2yGS6WPR36M7VWLfUlVJzYrxyWqEDbD9oK/USyqxZwZo7+rn8ttUhi7ysMI+CPFdoOb8xnyFrMAyX2uUOBZenrR9nUtRoWLENq9BdY0eWdSZxut+zwVK3regiS+na1mo0fXpCpJB17SSRpQ5hyxjCSrugJJwo53KH75NAEve7bQnPPg095yXQZa2JMVxLva8jUnY7/HBgE0w5Nry/Jz/y2KtusFz01j3XvdfqFJTojkp/Z3jyHRG9bf/GxDKFxqiPfUsdETkWWASEunFKqbvSJdRYYNvBXiqK86guyaerP9zzDFnk119PKXDvjGPGTtauwTDa1CyFk66AtbfBmf+lLSB3fljpBQNht+tIccYpo2O9mSAYCHsfXK6xH1NvfFW/9+r58yPGajvps5S/99DQbbbCc84oBw5LfU/4t4BPJ6DlFUe63yMS5RLQ2aTf7WQ0CMfAU7HUlQor9ViWun28KYvD/3EXhJMEtzwOO15wbMvXXgdXnrbUB3t1p6OoAoDrr79eh4b2bdDntq3/6OGBPZZMYz37XUR+CJyBVupPAucBLwM5rdR3HOxl/qQSRIT3HjWJm1/aETmOdvZ8AJYwOsN6DIYxix2LnTDZSpTLdyRFjUJcvWap7iRU1sJH/5hZ1ztYQ7Ks8o11S72pDp75vv78zH/pmd/ssdrR2O73mErdsnY9UZZ6yRStwCMsdZ81Lj0/TqJcknvCdp3PeR9sfUpbym5P8gx1m4HO8Lzsfe2RlnqhY4GhKYvCnz2FOozUVAcPfDrciSishMsf0HXoKdSdAjtRzrLUTzvtNHCfA089rxPhyqaHJ8wJ+MIhI7tzdehg8jKkkVQs9YuBE4A3lFJXisgUwlPG5ixb9nUxZ1JJaBrMIeNoX7Uu4GmnZVZQgyHd2NbTQJfVAA+jAU+FYFArzpIpmVfoYA1py5Ls94ZVjnHYfv29oAy6m4fuay/6Ekvh+6xrnBcVU3d7oGRqpFIPWAu4eArDytHt0S9IQalbrvajPqgVb8MqnYz2wKdTs9RtWSpmaZe3N4aljsCkY8L/8eTrYzesCsuM6Gtds1Rb+8VV2lL3WkPayvXcI6+++irsF04D2LdRK/XQsDz0+4a/wLq79fe/Xa2t9bG2nrqDfqVUUET8IlIGHARq0ixXRnnh7QP0DAZ4s7mLy29bHZqLOsIi/9739PvKlRmR0WA4YoSUeqel1PMdMfVRSCKz3aK+JIlIR4pgMHssdTvnIWgNNaxdDgffju1+H4mlDlqJOd3vQZ8+p9NVb8/9DrFj6k5XdWeTtuxLpupj1yyFXsu6TTQ/u02XJcuU46BzNxxq0d/tIW2gM+Lzi8P/cRfoe3fWqdYPou9hOwnUHtJWUKLv6Z59Iff99773PQgGWHmm6DH7C8+NChnl6ePZnb9UZ8VLE6mkra4VkQrgVvQa6+uA19IqVYZ5drO+wZxZ7QbDuCXCUvdFKvXRsNQDjoZ1LBD0O2LqYzz7vWYpnHCJ/vzpR/T3eO5321KPmSgXx1IHS6k7LXWrAxGh1BPE1Jvq4I7zrWGRH9JzypfPiBw1YY87T8X9bncwph4X+d3jSJRz50UOj7QT5exx8EedCyd+CgID+ndvn5X9PkFv72sNJ8qBvg9Kp8NbD+njljvs2vP+B0641DGePbN5Ialkv39FKdWplPoj8AHgCqXUlekXLXNUFuub02Wy2g2GcIPf3xl2v8soKnX/GFPq0e73sWypg1Y+eRNgtmWF2tnvKmpp3ISWepwhbaAz4GPF1J1KPVFIJiJE4IXW7ZFK0XnelNzve3Scf7LlXu9q1grd5YK2nfq3g2/rDoSt2D3W5DP2SIFjPwZTrez4/k5rnHqxHntvYyXKAbqT1LtfD8G780Ow8f7wtuJKa+z9HD1uPsNDMlPKfrdRSjWkSY6MU9/YEYqZBxS4XXDN2UeFVl0zGMYtMd3v4RXMDpuQ+z2GsskEwUCk+/1wOy6JFlEZDQa7IxcQKSjVMvv6wy7oYCCcbR7LUk+o1KfrxVEGurUXIODX8XPnvq4EMfXa5WDP6CEu7eqvmBW5j91BSMlS36td9xOsqWK794SH4h3YGD6Xcypce/IZuw6KKrUsYCXeOdzvNk5LfaAzHGoKDML25x3yWCuzDXTBMSsynhcyLKWeq7y8vZUr/lSHQpHvcXHCzHJqqyZErLpmMIxb7IY25H4f5UQ5+/hjxVIP+sPhhcNNlAstouLTcd10WHGDvVHKyDFVrK3UB7oIzcc6OIxx6hA5AU1hWWxLPVFMfcbJ4bj/1OP0sMjyqAWwRHT9pGKpdzVr9709GU733vAY/drlurNhdz5tN7inQN9noTH9lWF3+aFWrajzJuhEOZvCisjPnl4tn7i0ZT95EbRu00PZ/IPaZW+P688gRqkDf1/XTMByVfn8QXa0HOLEmiTW+Y03HgHJDIYxgJ1E1Z+uRDnb/d4XOQ44nSSynlVw9CafaVgVfxGV0WKwJ9JS77USxxpehuMu0p/tiWdKpobnNXeSzP0OOqN+8tHhjp072v0eJ/BP2/4AACAASURBVKbevUcr9MIKrdBRQ93v9rlTtdSnLAorcl9fWMaapbrjFH1tPVainK3UCyvC95m9BnocS/1Gu62v8urM9oAXOnbBwvN03Xfvc6yjntkx6pDaOPUbgNuVUpuOgDwZoaJI34yCjqF39vuYO2lC4j+deGL6BTMYxgJOS93lGv1EOWdD7h+IbS2OJk11Oi4aGIxtPQ+x1A+j43IkJtbx9oYtzKY6ePk3+vMjX4aKGl02O0muYhY014Vd6DahRLkkljpY9RMrUS6O96Z9h35fcgW8Yi2+UhFLqRckV+pK6U7Cgg9oa9vGKXfN0qEdJ9sL4LTU7UQ9O9HOXtDFxoqpn+hs60/7GjzxLf15+rug5R2t0O26sesqg6SS/b4FuEVEXheRL4lIedJ/ZBtWj626JJ8bP3ki/oBiTnUSpf7cc/plMOQ6ETH1NLjfnQttJJtfezRoWKWVhwrGnpY2YkEX1+FZ6jVLdUb1hMnpS6Aa7AlnfTesCl+ToC9cNjtJzlamdv7CjpXw0g3QvlOX1RXDzrOtzzetzG97shinVZ9onHqbpdRPuiKc5W53MpykotQHrKS21u06i95WwnnFif/nKdAJmfZCLYXlYfe6rZDtaWJtLEv9ueee4zm7rT96RXi7Ox/KpkUp9SxwvyulbgNuE5GFwJXARhF5BbhVKfVC4n9nB7vbdUPSdsiLWAo+qVL/2c/0+9lnp1M0gyHz2Fact1cru+hpYg8XZ0Pu6wPSPNqkdnnYAnfFWE5TORLlRmPymYAPCtzpS6Aa7Akro9rl1vrhA/oa2WVzWuqgM+D31MPdHyU0ZtuVHzv0sW+9ft/1ItxZB5MW6nOkGlNv36mz03tbwgr/kS/ruLqzTjwpxNS3Pq3ftz+rOyyFZTqJL5l3x52vPTP9HVBQrjsgheW67BGW+tCY+s+stv7ss8/W4+LFpTuET35HD43rdir1zLvfU1peSUTcwNHWqxXYAHxTRO5Lo2xHjKb2Porz3QQVPLZBX5y5yZS6wTBecDa0A12jP02s01I/EslyNUvh3Z/Xn8+4dqiyHc0FXQL+yFhuOnDG1GuWwmce1ddn0YfCZeuPUuqDvfDOM9YBVOR899E4PRl2WWKOU09gqU+cC7tfCa+dHvAN9ZCkElPf/EhY5oA3nMGe1FK3kuf62qDIcja73Fqx29nr+dGJcjGc0g2rIssw2KM7Fa1b9X8Lyob+5wiTVKmLyP8D3gbOB65XSi1RSv23UupC4F3pFjDdKKXY3d7HWcdMAeDZzQeYkO+OWDfdYBjX+AfDSVAQtUrbKCbKQeqzyjnXwh4JxdX6fUIMr0AwOHrZ73Z5/APp67A4Y+qglxGtrI2Uu69dK13ble7tDa9DDtYCLXEMmdCQNHSHLq84PE2sTaJEufYdUDXXykwv0B2lWPkFTks93vU9dFDLYh/DjmEns9Q9ltu/92BkLL6owuF+t8a6503Q9eFMPnTWhbMMM9+tf9+zTstyJJI8k5BK9vtG4PtKqViDSBP6k0TkXOC3gBu4TSn1y6jts4A7gQprn+8qpZ5MRfDRov2Qlz5vgJNmVbCusYM9nf0smFEWcsMbDOMef7+el92eTzxRotxIxmQPcb8noakO7lxhxfdHOEzMuSBINMqx8py4D6/j4ixPX7seijWa+Ad1pyhaAZXNiJzatb9dKzNb+Xt7IxfqmXxM5P5OapZC9QLd2fnoH+Cp/4iRKOeOfU8EA9DRAAvPj5+ZbmNb6s5ERpcH3vUpPWPbpIV67vXjLtby1i6Hult0GCGp+92StfdA5NKoRZV69TUIW/sFJboTEEsHRJfBPwgvoielyfTqghapKPVO537WlLFnKKUeUUrFGBsR2s8N/B49C10zsEZEHlVKbXbs9n3gAaXUH0TEXgWudvjFGDl2PL2mspgTayrY09nPnOqSJP8yGMYR/kFt+UUo9Riu1sbVcOcFOkPZnZ+6sh2upW4nutn/HckwMdtq7osxBXTQH7ZCR8tSB+22Hm2lbo85j1bq5TMjlxfta9dDwOzYu/dQuOyDPVqhxRrOZlNcra3XmqXhBV3cUe53dwxLvatJXyPbKxArM93GU6BlCV1fK5Fx7e2w/q+w/N918t+7vwCzlun/vPmQfk8lUQ50Utuko8O/F1WGO212x0A8oKzORSxZnWWwkwBVcEwkyUFqMfUfOpW3UqoT+GEK/1sKbFdK7VRKeYH7gA9H7aMAOwhRDuzlCGMr9VlVxZxQo2Morb2D1DcmiYHdfLN+GQy5jn9Aj2+2iZgm1qHwNv9dN+gqEDurPO7xnZZ6Ci7q2uXhWOpIh4nZU6X2x7DUndnvrsOcUc4bpdSHQyohhkFr4ZZYlnrPvnDSWl+7nqwlP4ZS9/drazqRUs8rDM9XEGtBF+eICGeinK30Jjpc/fGwh53ZiYxO/AOw+VHdubBd3hCegCap+92SdaAr0v3unGAmr0jXdc9enSVvTTN78803c3O8tt5p9Y+B4WyQmlKPtU8qFv4MoMnxvdn6zcmPgE+JSDPaSv96CscdVZoclnpxni7W6h1tXH7b6sSKfeFC/TIYcpmAXyu10inh3+JZ6lOsubSR4SnbwDCVes1SKJl2eDO02RZ0X4xnfDTXU3eWJ1YHIh5NdfBnxyIo8RS7PeVrfpR3sXwGoMKTovRblrq9YMlgDxxyeCnatiVWjJ6i8CiI0IIuUdPEhmLqjvra8S/rfDFWjRtyDmtImzOR0Z1PaNrXA5tgxpJIhW9PQJPMUnd6FSJi6s6x7hOsjqiVCWd1TBcuXMjCeG19/gSdTQ9ZpdTXishvRGSe9foNerW20eBS4A6l1Ex0It7dIjJEJhG5WkTWisjalpaWUTq1pqm9n0mlBRTlu+ka8Nq3T/LV2R57TL8MhlzGTlyKsNTjzChnr4BVe/rwlK3fOU49xfnfvb1a2TqttuFgW9Cx3O/OGeUO2/3uKM9wLPWGVdoihsReD3s1tiGWujUNq71MaV+7Xngk2lK3x407Qw6xGGKpO2Lq4tbx51BM3ZK7qQ5W/0F/fvDK5EmN9qIroNc2B/jMP/T4dnEBCna+EHmc4VrqkECpF1mJcEURyXyPPfYYjyVq6+1hbFmk1L8OeIH7rdcg8NUU/reHyHXXZ1q/Ofk88ACAUuo1oBCojj6QUuoWpdTJSqmTJ02alMKpU2d3ex81lfqGWDa3moI8F+5UVme74Qb9MhhyGds1XlQRVgDO7HenpW7HxifOG571PFxL3e+FwS59bmc8fjj4UnS/j6qlPgylHhFiyIvv9UgUUwed/KbUUEvd26uV+qSjwxZ2rGVXbSIsdXtBl4KwfM53+55Yd1e47lIJxzgnn/H2aut69mlQOYtQ9n0wEHkcWyk3vpq40xCh1Ctif84rCifCnflfoY7pDTfcwA2J2nrbSxAr6TIDpDL5zCHguyM49hpggYjMQSvzS4DLovbZDZwF3CEix6CV+uia4knY3d7Hu2v1jbFkdiX3fmFZaLU2szqbYdxjW2eeQh1/PHQwvvvdVrCxrN9EOGOwqSTKOY/vPRTZYKdKskS50Zom1jtCS71mKVTUQsdO+MTd8TtJ8WLqdkJeV7OWIeDV1q/LrZWQrdRLpug6b9s+AkvdTia0lLkzpr7lcdj4AHr4mSu1cIzTUvceCndA7Al1ohdpgXB44Z1/ws6V8T1EdocUYlvqzkS/RMl80TTVhbPnn/imHiUw1ldpE5FJwH8Ai9FKFwCl1JmJ/qeU8ovI14Cn0cPVbldKbRKRnwBrlVKPAt8CbhWRf0d7vT+rVPQiwOmjblcbezv7yXNPDP22ZHalUeYGg41tOXkK9WQchw7qBjBWopyt4A+1Dv8c4gIkNUu9z3F876GwC3Y42O73/g5rXLrDaelcT/1wp4kNlUeGb8nZ8fLqBKtFeuNY6gWlOtbbvSfsjdizViuh/Anawu9r15a6SApKPVZM3bbU7dn3LKXY0QgvXB8eGviuT+shacmUnT2VK1hK3QoVJBoK12mnbanEIyGSud+TxeTj0bDKsSSrLz0L9gyTVBLe7kW73VcAXwKuIEVr2hpz/mTUb9c5Pm8GTk9V2NGkvrGDT/+pDgU8sn4vlyydbZS5wRBNaPWugrCrMt7c7yFLfZhK3V5YxeVJTakfilLqI8F2v6ugduU7G3rneuqjNaStZPLwLPVgMFyPsdY/t7Fj6tGJcqCt9a7m8NrfW56Abc/pGdXsmHpxVfi6JkuU8/drV35oQRfbUrfryuqYdewKd4SCwaHTwcY9h5X9rpQ1oY5jMpx41vP8s/QiMbGs+IhjOzos0UuqQniJ2uESb6nXDJKKUq9SSv1JRP5NKfUi8KKIrEm3YOlm9c42fAHdwwoEFat3thmlbjBE41y9y542M2LyGYfCs5X6sC11r57sw10QmVgWD6fLPJX9YeikON4+bZ35+qwx3NFKfbRi6pZSL5uhl65NVcaJc8MWYKz1z20SKfUyS6mvu8v6wRr3rZTuMPgORQ5zS+Z+B610Az5rARfLpe2cbdDlcSSMDXMUhKcAbXH7It3viUg2oY1NMvf7SFcGTPX8R5BUlLod8NonIhegx5KPwN81tlg2t4p8twtvIEi+O0lSXCzuvjs9ghlGxttPwIHNMPd9Y+LByhmclrpt1URkvzuVumW1O1dzSwXbUs8vTtFSdzgKU7HUm+rgjgu0QvMUwhWPhdfgbtumlbpzylQVPU79MJS6tw8QPT1rR0NiGe+80LL4CuDC34a32Yo7FoPWFLGx5m0vnwm7V+v6tcMJ7nw91rtzt/4+oRpKLSW8b338CVc8ltLz9Q+NqTuXcHXnWcPMBOYshzN/kPrz6HF0HFJV6v+fve8Oj6u4135nteqyii13y5YN7r2JYgw2JXQIvYNJArkJCZB2AyQhBAIJuUAccglfIBcwLdQQSgwkJjYWVcbEYIxxl71ylW0Vq69W8/3xm9mZPXt29+xqqzXv8+xzzp49e86clT3vvL8KOPOB98L8/lSkuT4aH3wS4ITUfy3arf4IwB9BxWJ+kNBRJQGzR5Xhmet6ERRXYdMP2CA12LoSeO5yAIyKdSSqxWVfhJ/U85yb3wEiSj23Pew9umjSlco5EqI1v9dWq7H5vMC2arpPyQgidWsEfFBDl16Wic0uoHSyXZ+GH6P8ra2R4l0WUtcVfWezfY1ygMzv8rvH/zep7cr5wLv30m8AkPldWgK2VVNOvN3/H6nUvW30e2TJwDIWrNSbPAA4MOXC6P4f+km9kxZDBUGJULHD7//PDVTlDlwPFRk214cldVHqdSzn/A0ATQAWJmVUSUKvguKef562l1wSvwEZxIZtK8ROhGAZg+ihk7pufrcLlAsg9f3OSd3XSQSRnR9boFwk+BuScFKVFVVETLK3eNuBQKIMqCjn6r1PPaeA1Gs4n3rAGLNVShoQaH63KvqKufamdyAw//+DPyqyzilUaYQFA4Da98VJYf7/SKUux+JyU4CdOzewB7vLDRzcRvv6MziBJN7ujmCfem8hi8/klwbWdM/Op3/PrfUhrRTPi7n+kgyZ68PmqXPOfaACMQZWPPwwvQxSj2GzxE6UPjyDyNBJvUOkT+3fFEKpa6lp0fjVu4X5PbsgsKxqKLTuVy0unZB6+Vj4q4Sd+htg8GTaLxGkvmsNEeU7dwnC7NSCv9y9LxObnU9m3nCd2gZPUWM89+HAtp96oJysi86Ff7xpZ2ilrlsgdPWvLwIKBpDLylJwJQhSqUtXgHStuHMD3Swut3IzlESpcKVS93VFZ353dG1J6hYR56mh+zXUhqzc9/DDD+PhDJrrnRSfeZ8x9r+MsfmMsVnylfCRGRg4xeBJtB19fN80vfe2DWk4yJS2/RuA1U/Q/tIfq9zcgJQ2jdStEfBb/g2svM9+jD4vBco5Nb+3HQBKR9G+o65uWlxvyQi1ECgaTES2d514TqFUfd749VP3tlH5UUkmodLa9m9Q+3nF1CJUjkFX6npRGpebiDA3hFKfdgl9biVrK6nbFFwJgvQ5d4o2INLk7s4LVOpZ2Sp4MdrmNTKYLVqfejTXtpK6tVe8034FaQwnPvUZYnundowDCJunbmCQNEgz44g5fZPQnziT1GRvaqGHglSWu9ZoaUrdQN3HtM9Dmd818tq6EnjqPABMBKpZxigD5Zya31vrgfLxwN614dO9JDwfqf2OZrUQyCmk6O+8YpWPrpvdgfiktEmlDoTu1LZXa17ZsI3qARQNooh53adeUQX0H0155Ud/F9j0T2W1sKKiioICrZHZfrJkalyRgr3cTpW6+P3yy6InZXkPbzstDEK5FWKBvLaV1GVZ2DRKSestIip1zvlCm5chdIP0gR4E1dcgg8CkOTbeSkMq9cp5RLxS9Y06jo47Mb9v/pfY4fZjDAiUc5inXjyM1KITc/2Oj5UpuKNRkXq28HW73Er5z76WtgENXXoTKNeuFg9AaL/6vi+JeNx5ZApu3U+R6blFgUq9pwdoFs0seTcRfjjyq6gC5v8okLClss8vC+6GFgoykEySuvx9sqw+dUHw0frTAWUil79RXJW6GwAjd4VuLXJipcgwOKkod7vdcc75nXbHDQySDkkmvfF9ZipGarWbEqE0pE991HGB+bhDptFxa6AcyyLlq5vfB8oOVyFiHnydQHapUOoRfOQ+LxFzYTkFoEXyqfu8wM7VwIzLqC93Z7NaCOQUkPm5cQfQWEvH3LmB0e9OlLo1B15HVyspbl2p22Hfl/Q7eTuAxu1kfi8cRISuWyOa69SiZP9mItlQPvVQkIuAgijSeEMp9R4f0LxbBZlJgo/Wn67fQ9YhiLUgjB08NQA4sOfz4Aj/NEtJ6y2cmN/1/zV5oMpy6xMznAzCSy+legQGEjKSty8q9QFjaFtWCZz/aPwnJz1PXZ/8ZE56AKl7VR60rtSLhbl5+GzgtN8Ej1EqdSd56tKsXzCAyCkSqX/2V6qEVjyMxtbRpCl1oaC/+hD+ILVDe0mZ+5V6hDKxskUq99m7P7ztwiIgST2ET33femDMQiK0hloyuw8cT2Z4XanXC9970RBg/0b6LJRPPRSkAo6G1IOUejY9e2Mt/V6SKCXZF0fpTweUUveTehzN77XV4m/ZEzrCPwReyrC53klDl4D2NIyx+0D13Ps2yuOYQ2nQO0jze08fJHVpii0anBi10d0hzO4s8LhtlzZB6oXlgVXfJJGFanbh66TvyUA5zoG6VfbqV1oACsvF+WFI3VMDvPFD2l95H53f0awWAjmSbAWhDxirGoQ4LT6zeVlwi9QAUm9TZn7AXqm3HaT7DppIFeC2f0DXLCwHcvoFKnVJ6uNPBz5dQiSVEqXutg8yk79bTOZ3qdTFv5d4mt8r59O/4xh85+UZNtc7UepWFIDaqPZtPPEEbRctSuUoDAAVKOfrg+Z3SUJOfNGxoLvTviUnY8Eq1tdFSq1gAHBgizouiSxUZbRuSepCDda+Bzx5LhGWNbBOWgAKymnSD6fUa6vVosPnJXLt1ALlsvMVsZWPI1KXUegywlyPfrczs/cfo+5nRxYyTz07n0jFjtT3CcPn4ElkIZCBcYWDSIW37FPn1n8FFA4ERh4NrH6cjuXESupRFAb1K3WR1iif1UqUX4lWH73xqfuVehxJvRflXJ8Qc/2iDJnrnfjU18K/lEUWgIEIjITvmzCknj4wSl0FtMUb3vbQNcGtOdw9ojRsYTng+Vgdl0QWioB9XSqlDaAWmtY+3H5SFyViC8uF+T1MoJxM/+I+ZUGwmt+lCi4bTb7vrSvUswGkPHkPBds9ebboJZ6jFhoynzyU+0PmqTNGJLX13eAiJxsEEXZ30nUkigaJZ9yqju3fSJH/A7TObdEq9dwYlLokdVmrwJVtT5S98qkn0PwOxOw7zzRSd5KnfhaAs8XrawCGcc7/N6GjMjCIBn3Zpy6VencClXqofuUsy8annk0quu2g6kMuG5mEI3W9fGd/rQ67Vf3KCb9woAiUC5PSVlFFtQvyy4h8iocJ87sg9X3rgdVLaH/Lv4mwpTlfb+gCUL/u7k5aIOgR/LKGelZuMGH09NDfJbuQiLy9geqr60VOPDXAR6KwyUvfDLRmWKPfOSfz+8BxQPmR6rxYfep7v3Be28Bt8anLeu/W6Ho/qcfiUxeLx0REv/chOCH1oQAOcs63c853AshnjB2V4HEZGDiHP/q9D5J6syT1BCn17nY1oVvhcgdHv0tFzH0UpQ5EVup6Shug/Pc5RcGBZ6374c+vzimMXHzGlUUqvKKK8rl1pb7zE2UR4D1AuxYH4I9+F1OkX0FbIvglqbfstXkusdDKzg/0P3e3Ayt+o8z5ulXioKbKCweRaV0Sacs++k0HTiALQeEgOh6tUm+qo+3mf4esohYEl4ueu1NT6nbwtgJgWp/zKJBI83sfghNSfxiAvhxuFccMDNIDvr7sUxfmd9kiNd4Ip9RdWcENXVzZqhGH9H/7ST2EqtYD5QBg3zp1vRFzA89t20++YFeWMJ9HiH7vaFIm8rwSkdLWSqpw9PGBuff6vfQ8dYBM4QBwxImBC43G7eI+jcF/AxnnkFOo+m5LbFlOhJo/AFTzHTSGI08iKwRA29wiIsqeHuDLV+m4zJsvFyb4aH3q+74UMQNR1jZw5wentOnw1IhKg5yKDUVb4TAopS3O5vc+Aiekzjjn0qcOznkPYguwMzBIDKRK7dNKPVHm947QHaxclhKqvm7hUxe+2o8eUmZnwJ6AuShI49bM73s1UrcuBOo3AmB03ZzCyBXl2htVJ668EqXUs/ODC49UHqc9m1aKFVC+fGvVQqnUAUo/0yGfV7/X6BPkg9PztR8g3/bQ6WqxIBdFDdsUsW17F3j7Ntpfdgc9v1ysNGwL/xtYIQPcwtV6t0N2XmBKmxW11fT3BGIrhORy02IjEdHvfQhOSH0rY+xGxli2eN0EYGvEbx3uWLqUXgaphzS/90mfulDqvi7lw44nvB1hlLo7WKln5QDNe+j96idJjcpgPjtSl1YWXalLUgcCU+M8NcCOD0itLzmH1HGkinJWpe5tI796tiAM3Scs1bh8NkD51iWpW7MMGneooLBDFhO8PFc+V0UVcOLPVWS9rMzXeYjIvqKKnnH/Rvr8qfNVCt+2dwMj+T97FtgkKvW9ekN0qjjWKmruvGCfug5pjYh2sSDBRBnhHi/9RqECNJOMpUuXYmkGzfVOSP2/ABwLYCeAOgBHAbg+kYPKCBQU0Msg9ZCBcn2tolxXG5FWriCt7gSY4Ls7IkS/2/jUD2wSB4R5VxJzd3twzre0ssjiM0Cgf1on9dpqZXr2dZGPuccb2GLUCp3UZY30lj321coKNVJnlkC5VjEOndQ7mskKIc32Vr+6DLrTFWdFFTDhbHrea16jNDZfJ8UhyGeEpnalb3rwFBVrkJUDgGm/hTd6VWxXPjYSsvPDK/V4lFyVjVdyioJrI6QIBQUFKMigud5J7fd9nPNLOeeDOOeDOeeXc873RfreYY8//YleBqlHX1XqMvK9fyVtE0LqnaFJ3Tb63Q2MPVWeQJO0t11N1la1bqfUAUrbAgIbw/iVn7juwAn0NlQBGm87EWaeZn4HgEN7Au8lkVOg/NN68RnAXqk3CcL1k/qe4PsDwe6LIVPpdx0yLTDvXj6jbhofNpOO9x8NDBgHlI0hwpx+meprn6xGJNn58C847HzqQGyLBR3y31oamd7/9Kc/4U8ZNNdHJHXG2BLGWKn2vowx9lhih5UBeOEFehmkHn3Vpy7N2rIASkJIPVyeepZNnnoOMOpooN9QUqGXPUd+d1k21OoDl387vfgMQL5rIFCpD59N29HzidgGTRTXDEHqHaJNqN/8LpR68+7QpCFN8HqZWEAjdc3cL/3pw2cDYKpIzPYPgZX3Azv/Q++zLfeS92it11L0BKlb1e5w0eW6s4XcDZXHqnzrZDci0bMgXAkKq5KunjQi9RdeeAEvZNBc7+QvM41z3ijfcM4bGGMzEzgmA4PokIro93BNPJIFqdTLRtM2YUo9TPR7UEU5ocjLx9J3B4ic85IRFNAVSqnrgXIAEeWaZwJJXar2CWfTby5JNZRfXebHy0A5aX7vOhQ6+K9oMHBwi9azXCp1oah1pS7v338MkfKhPVSk5vHT6bhUs9Z7+Ul9X7BSBwKLpOxaI57lIFkC9KIuyW5EolcWDKXUewu5gLSzpBg4ghNSdzHGyjjnDQDAGOvv8HsGBslBsivKyR7mvi5SL6lq2WhV6olIawsb/W4NlPMGVhTbslxFvpeOpK1VqQeY3zV1NmwGmZYDSF3WfRfR9VLNhYqAD1LqJeqzUKRRJNLJrMVnQil1dz4RetEQUuoblkL5xMVvY/XfS999S33wM1khc9DrRfBcLOVX44UApZ4oUpdK3aSzxQongXL3A/iQMXYXY+zXAD4A8LvEDsvAIAoku596bbXmx09AD3OnOLSbfMDSdJsIpR4x+j2EUi8ZQeOTaV6SjKxKXQ+Uy8pWJNp/DOWj66QuiVWqWj+phzK/C6WeJzqkSfO7/l0rigarZwMUubfZKfXttFhhjNR3y57AQjDyu9YFhFw4tOy1V+o6JLnVf0XbVJJ6MpV6GpnfMw1OAuWeBHABgL0A9gA4n3P+VKIHZmDgGMlW6pXz1YSdlZ2cICU7NO8CioeqidApqW//EHj3d5HToDgPH/3OXBZS7w4kdXBg75fae4QJlBOd4LILKLAtv4zytwNIXevQBqiJP1RVuZiUulDR1uh3aZHQ6wHsW0/P76kB+gmlLiuuARTMZnevQs383rafft9QJJZrIfXidFHqfcennmlw9JfhnK9jjNWD+qmDMTaSc74jwtcOb6xYkeoRGEh0J1mpV1QB488E1r8KnPu/qfOp799EzyxLizrp1OapAZacRSRV/UB414HPC4A7b+giu7QBisT3rBXvhS84VKCcO0ddMzuPxlkwIDD6Xa/7DihzMehohgAAIABJREFUfVcLLVS2rQSOWKiex0rquZpSD+VSkIS7/nVaPMjFm4T8jT01wIHNABjlzE86h5R33Wp1rmw5a71Xdh6lIbbUU4pYQXno9K3sAlo87RdpgrHUVI8XkqLU08/8viLD5non0e/nMMY2AdgG4F0AtQDeTPC4DAycI9nmdwAoECbd0srk3VOHp4bUW8M24K1b6ZiT+u8B7UgjuA6kKg0X/W7XehUASoQPPYjUrUpdi3731JDJ/NBuIkrAXqnL3uRSze35ghYqK+4JrGUuA+UkqbuyFFmEUoJyIfDZc3Stg5Y6W5LUtywXB2RluCb6XT0fAyOPoY92f06/nXVhAJAJXir1UP50QHR3KyIrVEF56MVIMpCdDJ+6Mb/3Fk586ncBOBrARs75aAAnAfgooaPKBNx3H70MUo9UtF6VCwhJAsmGXqTEzjQcCrIdKRDZdSAXCXb91AGb1qu6+V0oyv0baKKWxBXkU9fM77XVSrH6uohArYFy+WWqmpm/29iX2kKlUy1UOhpJ6UorAKAIPpT53d/vXBTOkdXdAFLX0tQ/dLo4KHLmR4h0ux4vMPUiOt60I7xFoKWeFiqh/OkSciGSSpUOBJrfE67U04fU77vvPtyXQXO9E1L3cs4PgKLgXZzz5QDmOLk4Y+w0xtgGxthmxtgtNp//njG2Rrw2MsYa7a6TlnjjDXoZpB6pSGmT9+xI0T/ZUbJOOVMk50SpV1QBwwQBff3h8K4D6aOPqqKclsZVUE5Vz/L7B5rKdfhT2nKCC68MHE/md1lP3EqAcuLvN0QdYy61UOloVIVnJKQJPhRpjD+dyEuOYfBk9VnJcKXUZTOVSecG142vPA4oFZYJa466RNFAMte37VcxAqEg/eqx9CiPJ+TijmUlrtpbGir1N954A29k0FzvxKfeyBgrArASwDOMsX2gTm1hwRjLAvAQgFNA5WVXMcZe45x/Kc/hnP9AO//7AEz+u0H0SEXxGT+pJ1Cph8uFl0rxiIVA1fXAXy915lMH1ORcPCz8ed4IpM5cgS4P2aVNomSEUtfuHNG6M1RKWy5VWrvmNfXMdauAz/5Kv3F+KZG6ToCyopq+sCodFehT14PjgMhKXRZ1kWPQffrFw6nDWU+PKpc69SL6zoEtakxtDUD5OEp5C6fUW1fQQjSSUpcR9amMfAeUUk+USgfS0qeeaXCi1M8F0AbgBwDeArAFwNkOvlcFYDPnfCvnvAvAc+JaoXAZgL86uK6BQSBSUSZW3kuPdo4nat8H/u9rwDu/tu95LRXvuNOAkUfTvtOe6lKByxSxSOc5CZTr8ZEqz9JM3ZKE8kX8QY5Nq1RroJxeZrRAmOylCb5tvzoGKH/zDuENnHw+FY6R+ft6hzYJmdYWzjetj0H3h0vzd3e7+v2lipY12n1dwFNfV+Vm7WrMA5Q619FEJW7D+dQBzfyeYlKXi8FE+dMBWtwBaaXUMw1OUtpaOec9nPNuzvkSzvmDwhwfCcMBeLT3deJYEBhjowCMBvBvJ4M2MAiAVHvgwQ1DEn3PRCl1fxGTED2vJankFCkF5bT9qlTgsqyppwaovj944eAn3DCkLgPl5CJHV3Gy4Iwk1pyiMIFyNrnwflIXarl1v4p8l8gppPxwlxuYdxMdW/oTEXRno9Qjmd+tYNoUKUvdetuVxUGS9y4t6t3XpZ4rUpEbwLlSL04Tn7pdh7a43cOQem+RLpXhLgXwEufcdkZmjF0P0Rlu5MiRyRxXaOSnMArVIBB+UoeoamYTbZyoeyaK1EtHiR1m37CjU1OKciJ0rNQF+bfuFyluZ1PAmuwcJs3X/uj3MGVi9Uh6wIFSt6a0aWVirSgQUe5tB8jk3X4w2P8slfDACeL5GfDVG8Dmd0iVy/rwEpHM71b4K8u5VGEar41Sl21HfaL+/ZiFtDALdR+9I1wkn3pOmvnU9b9xvOH3qaeP+T0/w+b6RJL6TgD6v8IR4pgdLgVwQ6gLcc4fAfAIAMyZM4fHa4C9wpsmqy9toJN6jxeinEKC75ng6HepzgZOAM55MNinrit12YfaqU/dq5nfa6sFGXJlEfCTulSbocrEal3a7JS6JPUDm2nxYGd+11ParNDN7+0NZN63qlqp6IZMA7a/p123yz5QTprfQ5nFrZDFZ/LLtGI37cqnLsmnogq45nXliy+pAN78CdC8k57d+vfTe7dHUuqyC10kd0miIRcoiTS/p6FSfzPD5noneeo3OTlmg1UAxjLGRjPGckDE/ZrNtSYAKAPwoYNrGhgEQ1eoyfKr+5V6gnzqTXW0LSy3j1Dv1EgdoMnQaUU53adeOV9FMrvcgRYBv089hFLXW6/6lbo24csFz46PKC6gxxcmpS0CqUtCs6paGV0+ZKqIns9Wz9LdGWx+l3+vA5b881CQSj2/v1rceNs0pa6VhdV98bLZS/1X9jERRQ6VuqcG2CBI5aVvRK4CmEhIFZ1I87vsSd+wLXH3OMzhJFDuGptjiyJ9iXPeDeB7AN4GsB7AC6Iy3Z2MsXO0Uy8F8BznPD0UuFPcdRe9DFIPnch7kpTWlmjze7Mg9bYQ4StW8687PwZS308EJE39824OXEDsWUfb+o2wRUCgnFTqGjnL4DFpBfC2h1HqNuovp0hEkx9QtdcLLEFluoWgogq48Al6P+0S2uqBcp4a4NMnaf+17zkjSF2p+0m9PXhRZcX29wBoOffWmAjd/G59Jh211SqlL5V9BgD1/IlS6p4aYNX/0f4/fpjaBYyGu+66C3dl0FwfktQZY5cxxl4HMJox9pr2Wg7gYKjv6eCcL+Wcj+OcH8E5v1scu51z/pp2zh2c86Ac9rTHO+/QyyD18HWqWtRJU+oJNr9Lpd4W4r9al4VUsvOcd2mTZvrWeiIMqYJ9msXDUwNUi4Ibr37XfoK1C5TTJ/yxp5C6kznfxcPt89Rl3XcrGCMlvHWFinDXVa2nRgWo/fPn9H7imVQffZ/InNWVem01mfDleJ0QpFTqBf2V+Vkq9exCwBViCpU+dvns1piI7DwK2nNlB1sTrNeRqXt210km/Eo9QaReW639e+pO7QJGwzvvvIN3MmiuD2dH+QDAbgDloE5tEocAfJ7IQRkYRAWflybYzqbk5aonWqlLUm8XxVespNdpMf+685wpdZ9XTZyt9bRokES7b706L6CcrDfQ1y7himB+t/qZ1zwL7P0i8BoyQM8OnhoaX9sBYK+wGujR7wEqVhtjRRWw7hU6rvvUJUHKbnJOCFJGvweY34VPPTdMMJc1393OhZLTjxYZdatCFwFycp1kwa/UE2R+l8WHovn7GAQh5F+Hc74dwHYAx4iUs7Gc82WMsXwA+SByNzBIPbo7yYTZ2ZS8qnKJVOqcE6kzF01wXa3BBNIlA7WET9kpqUuVntOPFgwHRdGU3JJAUped6GTpV7sJNiD63cb8DiiSBYAvX7U3v4eKptaVmlys6aZqf8S5hQQqjgLW/Y32dRUcC0FKAgtQ6iL6PVKEtv7sVnhqgJbdROpLzgnfWCfcdZKJRCv1dFrAZDAiLrkYY9eB0sn6AzgCFMX+/0A14A0MUgsu/LWS3JKt1LvbhdqMY5pPRxORxsAJFGjVftCG1FvJdCtVrlNSl0GFpRVkot4pzNdHnkRE2HmI1H9FFVB5PLDrU+CKF+0n2IBAuRCkriOniCK5e3qATW9Ts5emnaGVeuX8wADAnEIbS4ANCehjtZq2oyVIaX7fuw6o30D73jaylIRT6pFQW+0v3R+UdZCuSLRPHUifBUwGw0mg3A0A5gFoBgDO+SYAg8J+oy9gwAB6GaQWPT4AXJF6MqPfpWk23lXlpOl9yFTa2vnVraTi1Kcuc89lznPdJ7QddxptJXEBpKIHTQo9yeqBcn7zexidIP9GW/5NZW2X3wNsXqb83FZI8/2Rp4hr5wb79vWIc4khU9XioqE29HicQPaD37oCePmbtN/dQYufnH4hvxYRcsGSDr5yp8hOQpnYNMSAAQMwIIPmeiek3inKvAIAGGNuqDVm38XLL9PLILWQwV1JV+peZQqOtwm+WZRzGDKNtu02pN7VEkgqTqPfJfHLhiM7V1NktyRFGWAGULnV4qGhrxUQKBcmNU1C/o0+f14c4PT9cBkLFVXAcTcDYPQ72KWHWbHrP+qaf7uud1HU/i5tXC0YvW3k/uiNUpdWhhN/Ft70nk5wJ9innqZ4+eWX8XIGzfVOSP1dxthtAPIZY6cAeBHA64kdloGBQ0gykf7OpPnUu1TQVrw7tTWJVLCwSv1QYIEOp3nqfqUuCsM0bKOUttJR9BtKvzrn1Nc8XNMXPVDOLqXNCumDlu1LAbJ25EZQvJ6PA1uyRoqKtgugixVjTwns2gaolLbeVj2zszKkM1wu+g36mFLPNDgh9VsA1ANYC+DbAJYC+HkiB5URuPVWehmkFrJ4STKVuvTjy/QquwI0oeqpO0FTHfktB02i93akbg2ey853Zn73K3Wt3HLZKJqwS0ZQoRNPDVVw6+4A+kUidUugXDgVJ/9GujWgrJIiy8PB2pI1kqk6nqZtq6J256uUtt4o9UyFOz+xPvU0xK233opbM2iuj2hH4Zz3AHgUwKOMsf4ARmRcoZhE4ENTAC8t4LOQejJ86pLIZHlPq/ndUwM8cRa5Btx55BeORo017SSztzTvhzS/a6QSrVIvGqzSu0pH0ZgPbCFz+JJzgLMW03lhlbrbJqUtjFKXJHhwK9BvKFkCGrbTfjhEGxVtTaXrrRLWg7ey8+On1DMRLhfQsNW+9O1hig8zbK53UiZ2BWOsWBD6ahC5/z7xQzMwcAArqSejopy8p9/8biH12mp1TixVwJrqKJAty02pZk4C5Zz61P2d1/LV+MtGWQqzdAHb3qX9cKTOHKS06dBJcNbVtOU+Zw1CojVVJ8q0nV1Aro/u9shug8MNnhpqZ7tvvbPYBoOUwIn5vYRz3gzgfABPcs6PgklnM0gXBPnUk6DUI5G6zPEGguupO8GBLWTS99QABWXxVeoyTz07T7kPSkdZ6qZnqdrk4VS0S8TM9vTYN3SxQo8BGHeqMu2HSmlLR2TnU3ldoO8p9drq6GIbDFICJ6TuZowNBXAxgDcSPB4Dg+jQ7TD6vTc+biskgeWXUqCXldQrqoApF9L+8T+OTi1u/xBo3UuV15acI2qfOyD17HyaaPV+8nbP7G/Skqd8ox1NNMZLnqb3c74hCo0woN+Q0GOVJVK5z76inBV6oZzBU4EhU8R3EtjKM97IzgdaRR/6vuZTjza2wSAlcJKbcCeoKct7nPNVjLExADYldlgZgBEjUj0CA0ARbDifuqcGeOw0Mi+783qfQiQJzJ1LxU3s8tTlhB+uWYcdNv1T7HBF0nZKPcj8Lqp9dXdSmtoHD1JPceszS6W+7ytK/QKAV2+gwLlxp5KvvaOZAvGKBoUnaRkU19PtMKVNjLdwELB7DTB4Cj1vRin1ApX73tfM73204tuIDJvrnQTKvQhKY5PvtwK4IJGDygg8/XSqR2AABJvf7XzqAY0i4lC9Syew3GL7PHUZEd/eEN21B00UOyJ9qHSUKuUq0d1JFokcG1Lf/gHw7EWBBV30Z5ZKffd/gpubVFQBgyeTlaBoUHh/OqCRupZrHm4RINPlmjxkhZj/A/GdTCL1PNUApzfFZzIVfbDi29MZNtc7Mb8bGKQv/MVnBMHZKfWRx6r9eJgNdf9xXok9qUv13h5lDnvxcNrOuJxU0cDxweZ3u7af2YLU9YA3Cf2ZJalXHm/fRWzwFCpN27gjfDoboNqS6ko9XLqT5yNRhU9YIeRvs2995gRdZReoBWJfM78bZAQMqceKm2+ml0Fq4Te/S6VuQ+oDx9O2bHR8qnfpSj0UqXfESOpS2VddR+Ms6E/Vy2Q+PhDcSx1QSn3odHGAAXAFuxtknnrlcfYVzQZPoefbvzF8NTkgUKk7Mb9bfbIDjqTjuz7NnGhqWSoV6HuBcn0UN998M27OoLm+b9X7iyfWrEn1CAyA4EA5u4pysuJbYXnshO6pUb5EGdkuSf3gtuDzO2M0v0v/eYEoyJJfpq7TbzDtW3upA4rUpQ9/3KnUjnbjW4HP3N1OxOpy2ZtSZfAa4MD8rgfKOYh+t/pka6tJufOezGtqAhil3kewJsPmeidd2nJBPvRK/XzO+Z2JG5aBgUP4fephot+lWra2/XQKTw3w+BlkZnbnAafdQ8ezsqlfdzx96tLULslcknv7QUXqnWGUuvS/z7wK2PM5sE50RZME7O1Q59phwFgyofd4I5vfAwLlvPQ9a993K6wLiUzrny1jN4C+6VM3SHs4UeqvAmgCFZ7pTOxwDAyihL/4TJg8dUm6kgyjxWd/VYsFX5eKGndlU8nQ1n3BFbY6xT2jrQvf3kDXlSpcllDV/er+Xuo2PvUDgtSLhymC97aqSO3udnWuHdw5VPimYat6hlCwmt+jrQmeidHURqkbpDmckPoIzvlpCR+JQeZBN0mnakIOqigXhtS7YiD1zcuAz55X77NyqM85ABzYDKx/jZTqknOUb5pzqjoGxGZ+L+ivFK+u1CWkxSHHUlEOoBKsAAXcyc87WzRS7wyv1D01QON22v/X7cCwWaH/tgGBct7YGn1kWjS1VOosK/zvaGCQIjgh9Q8YY1M552sTPppMwrhxqR5BauGpAR4/jVSaOz917SOlMs924FOPltQ9NcCzl4h0LQaAA1f9XV1v7xeBtc+lT7irhfzELncMpN6gTO+AUuqfPUc55BVVIczvIi3swBa6b+FAReT6c3vbA9WmFQHlYrvD+7mDlHoGFZGJFZLIc4siuxoMDguMy7C53gmpHwdgEWNsG8j8zgBwzvm0hI4s3fHII6keQWpRW21PaMmGv5Z5jqhFHkap+7ooitztkHxqq4Pz3odOI/UOAMPnAp8+Sdd1ZSmfsPSnFw8n1RuJSHW0NQR2LZNBeF/9g4rJXPOafaCcvH7DNvKFu1yaUj+kzuuO4FOvnE+fO/Fzy4BB7qPfvS9075JK3fjT+wweybC53gmpn57wURhkHirnq8jlVAY5+VOpcsn8G86nDhAhuiO0+pTQn9HlJuLytqt7Dp8FnPdn4KVrgWNvVIsaeb+yUUTq7Y32pL79Q2DHB4Hui/aDlHonsXOV2OHkD1/+G7ouEFz7Xf4eJSLXXSp5q1IPR+rR+LldcTC/Zxrk39H40w3SFE4qym1njE0HIGftas75Z4kdVgbg+utpm2GruLihogroPwZo3gVc/WrqfepZOSJq28b8rueKd7UqP3UkVFQBgyaT0p1yPvDeA0SsevrWhLMAMEVwgEpnKxXk294QnPP95evAC1fSoiErV7kv2htosSAhlbMsGrN1Od2LZQWWV3VriwaZiqb71CW6OwIbq4R6bid/z75ofpekbnLU+wyuF3N9pih2J61XbwLwDIBB4vU0Y+z7iR5Y2mPjRnr1ZWTlkIpNZaCTr4vIxeWiVqVOlHo0cLmoeM2gSfTe2xG4kHDnkJm9Ybt2P0HqZRqpW7HpbdrqOdqcU5S7bn6XvcHHLBQHOJFoliV9TI9ol6Ru61PvCFwA9AbxCJTLNEjzu1HqfQYbN27Exgya652Y378J4CjOeSsAMMbuBfAhgD8mcmAGGQBfFyk/XzcRairQ3akUosyvtiKA1KPMVe9qJWUrSdPbFlw9rXSkihgHgpW6XVpbWaXYYcp94W2jsrd6oBxAxL7wNuXjZyzYp6ub1GWp2VA+9XApbdFAps/tXtuHSN0odYP0hpMysQyA1s8RPnHMoK9Dli7tOhT+vERCJ5Os7NDR75L0OqMca1cb5cDLyby7I7h6Wtkoi1IXi4jSMEpd9mKX5Vql6R2wdw9UVAGniHpP2QVAoaX7W1YO/P8ti8P41LvjpNQ9NcA7d9D+mz+hJid9wvwulXpxasdhYBACTkj9cQAfM8buYIzdAeAjAP+X0FEZZAakYo21qEtcxtCpunzJYDYrOpoU0cWk1IsUEeqBcn6lPgo4tFtF4nc6ML/LY+XjlPvCX00uhM9/9iKyRlh7qQOk3uXCRT6rTPPTn9nbHp9Wp7XVagHV4wXaDvQRUjeBcgbpjYikzjl/AMC1AA6K17Wc88WJHljaY8YMevVlyA5psRR1idsYvIpMwkW/Sz9zNGPlnKqxZRdo5nc9UE7ct2wUAA40esT9msnfXDiItnakLk3y+mdy32p+l8gpVAsAO1KRY5TP6nIRsVsD5Zym14VD5XzALSwVriwam6sPtJKQv93eLzOjAY1BrzFjxgzMyKC5PiSpM8aKxbY/gFoAT4vXdnEsIhhjpzHGNjDGNjPGbglxzsWMsS8ZY+sYY89G/QSpwuLF9OrLkOSWUqWu5Z2H86mXjKD9aEjd10U+7JxCZXbtlkpdi3iXZvbGWtp2NgN5xUSq+aX2ndokgeuV4qzNXOwwZgFt7Xy6spVq0SB1LLco0D0SKaXNKSqqgEv/Svuzv0Hqvy8o9foNtN3+fuZ0ljPoFRYvXozFGTTXh1PqkmBXA/hEe8n3YcEYywLwECjPfRKAyxhjkyznjAVwK4B5nPPJADKnv52BMkOn0qeuB8pluYN96t4OUqexmN/95VgLFRHK6PesHBV9Ls3s0q/e0ax8rnmlIczvNkrd2szFDqNPoG3jDntCySkEdq7W3hepRZevmwrFxEOpA8ARJ9Lv4s4JtJgcztj7hdjhKmvBwCCNEJLUOednie1ozvkY7TWacz7GwbWrAGzmnG/lnHcBeA7AuZZzrgPwEOe8QdxrX2yPkQJceSW9+io410g9xu5n8YBOJnZKXQat9RsCgEVnVdBJXRKhty2YwPoNpXvLCHip1AEi6HDm9zY783sYpc5FzOqetYFK0VMDHNpD99aP5xYp60R3O23jVbOcMSpde2ivWOj0AfO7XMjInvCZ0FnOoFe48sorcWUGzfVO8tTfcXLMBsMBeLT3deKYjnEAxjHG3meMfcQYy5zGMXV19Oqr0H3XKQ+UC+NTl6SeX0aqNZoFiLeNttnW6HdLRzJXFlBaYVHqJeq+diltfvO7hdR1/70ddnxIBWusSlFXjPrxnH7q7+MVBWzi2Yik3xCgZU/fUeqybsCJP0tdvwODpKKurg51GTTXh1xaM8byABQAKGeMlUGlsRUjmJx7c/+xABYAGAFgpWgeEzALMsauB3A9AIwcOTJOtzboFXxaF950CZSzqygnCTWvlBR3NK4Cvca6NfrdSmClowKVeqn4d5pfChzYFHxtf4/3Qyotr+1geNM7QMrQrgd5qJrtuUVA807al0o9XnnqACn1+g19h9SBzOssZ9CnEM5e9m2Qj3sYyI8uSb0ZwP86uPZOABXa+xHimI46AB9zzr0AtjHGNoJIfpV+Euf8EQCPAMCcOXO4g3sbJBoBSj3FPnXZSz3LTXnlOqRSzysRpmiLUg/XPlZeK6dAVHBzqeh3K4Fl5wM7PqLr6T71cOZ36S5ob6DgtvaG8KZ3IHRt9lDHdZ+6X6nHyacOkFLf9q6qvW9gYJBShCR1zvkfAPyBMfZ9znks1eNWARjLGBsNIvNLAVxuOefvAC4D8DhjrBxkjt8aw70Mkg3pTwdSrNS7gKxS2g/nU88rIaWuuwoitY/VfeqM0Tl25ndPDbDpn6Kv+tlkjtd96h1NdA9/AxQfHRswllS8n9QPkrKPhFBK0e54gE9dkHq8lXpHE7kN+kKXNgODNIeThi5/ZIxNAUWw52nHn4zwvW7G2PcAvA0gC8BjnPN1jLE7AXzCOX9NfPY1xtiXoEp1P+GcH4j9cZKIY45J9QhSi27N/J5Sn7o1T91ifvcHn5WSf1lX6ttWqvaxsgPawlsVMXrFubKIS3a+vfm9throkT3Iu4BurpS6XFRsWQ6MPTnwWP8xROoy6r29ARg0MbbfIRR0pd6dIKUOUPxBXzG/G/QpHJNhc31EUmeM/RLk854EYCkoRe09AGFJHQA450vFd/Rjt2v7HMAPxSuz8JvfpHoEqYVufneq1Ld/SF3Gjjw5fj5JPVDO5Q60IACKQHOLSXG37FGflVmSOLYup0A0qdh1pQ5opG6pc145n9K6ujtAXqoeUuqeGmCVKL74/OXANW8EloPtL1qsyvfWZi7xQG4/WrD0+GjsQJyV+hC1b8zvBochfpNhc72TMrEXAjgJwB7O+bUApgMoSeioDNIfeqCcE5+6p4ZM0+/eG9+iHb4uVfY0K4T53Z1HRGb1qctzR8gFhiWi3O9TF6TuzlPFZ3RVKiOi+x+houTzSkTnNWkJ0K4rg/f6i0VF+0HVoW3/pvgWNJFj72rRlHo8SV0rdGNI3cAg5XBC6u2c8x4A3aLK3D4EBsD1TVxwAb36KgJ86iHSxDw1QPX9KhhNRqbHs2hHt+bfzsoJNr93NFLkOxDsU9/1KfmCT7lTlTjNylaR4/7od12pd9hHv1dUAXOuVd/JLVaR6mAAOJn7PTUq8t1P6g1kJUBP/CuV6T3VvXHOUweU+R0w5neDwxIXXHABLsigud4JqX/CGCsF8CgoCv5TUOvVvo0DB+jVVxHJ/O6pAZ44C3jnLiKp/AEivxoUpR6voh06wdo1dOloItUMBPvUd34KDJ0OjDoGWHArHTvzfuUa6GpVRUYAIvVuG/O7xJgFaj+vWEWkz7oGAAO2riBrRZ1I7igZQWNubwA2/Ut8Mc6VyvSe6jIOIl4V5QCgoFz1VTdK3eAwxIEDB3Agg+Z6Jw1dvss5b+Sc/z8ApwC4RpjhMx9bVgBLf0Jbg+ggCSK3xD5QrrZamOgFSbUfAI48iT772j1x9Kl3qS5toYrP+Em9kMiNczpvz+fAsFn02aSviy9oXYW9baR0ZTlYd17oPHUAGDRZWQUaRfZmRRVQNlJdo7sL2P0Z7ef3p+j4toOq3jtzxbdSma7U411RDqD69tIEb5S6gUHKEa74zKxwn3HOP03MkJIETw3w7EU0Qa9eAix6wxSUiAbS/F7Q376w61qlAAAgAElEQVSgS+V8Iijeo0hqz1r6TPfDxmMcUiHapbS1N6re5TmFADiR9YEt5GMeLv6Z9x9NUeF716nvdrWoHHiATPXtDbQosCOwnZ+o+IK3fgIMnkj/pirn0/ndHYIEB9M5+aUqj71wIAAGnHALcMTC+P1b9PdUP6Ty1OOp1AFRKna3SWkzMEgDhFPq94vXQwA+BhV/eVTsP5T4oSUYuo+3x2saM0QLndTtlHpFFbUeBYArXhTR5CLwrG1/fMYg68/rgXJWn3rLXiIcT40iuM4W1fREkrorCxg0QWvYARqv9KcDFGxnl6cuUVtNYwJoHPLflAykyy0BKo8XDWLyadz5/SlQbt+XQPlYYMFP47u4tFXqceinrkP61Y353cAg5QhXfGYhADDG/gZgFud8rXg/BcAdSRldIqGrJ5YVvbnzpJMSM65MgST1/P5A19rgz3t8irxl7rWspd4WJ/+Uv6+5VOoWn7qnhgj90B7y6x/7fTre1QJsfJvM0C31KmBt8GRgw1vq+12tquUqQETsbaf72Cn1yvlEmNZSrQAR9Yg5QGs9Be/JcrD5ZUBzHXVdG5qAns26Tz0RFeUAZXkw5neDwxAnZdhc76St0nhJ6ADAOf+CMRbnChkpQEUVcNnzwFPnArOviV4d/eIXiRlXpkASasEAUXBF62sOEJFKS0hXK1BYroLUZLGVXo9BLCxC+dS3vit2hKJvqKW3Oz4GNr5Fx588V+WlD54C/OdpoGUfuQikT10iO0/1I7cjsFClWiUGjge2fwCUVKjKcQX9Ac/HpNZnXNHLH8QGfqV+iJR6Vg65AOIJo9QNDmP8IsPmeif/uz9njP2FMbZAvB4F8HmiB5YUjDmB/IBSzRg4hwyUkwFe1gj4Jq1BnyRzqdRb42R+l6Re+z6pclc2AK6qxA2ZIk5kRGbS1F5bTefJa0gz+aBJtJUm+K4Wi/m9ILz5HSAin/8j+0Vi+Tgi1r1rVUBdfhkRun7/eMLvUxfR7/FW6YBS6hvfjm+OvYGBQdRwQurXAlgH4Cbx+lIcy3wwpqKPo8Xpp9Orr0I3vwPBpN6okbok83ib33d8RNtNb5N5vWW3GJtQ68XDaDv1QlLQI+aKz8WCxBppPngybT/8E5FTV1tgoJw7T/RT74zN1DxwPG0bdwSa3yXk/eOJ7AIAjBZWDdupGE68ibezmbZf/C2+OfYGBmmA008/Hadn0FzvpPZ7B4Dfi9fhh4L+SilFg/b2+I+lNwjXbSwR8AfKCVKyBss17VD7Uql3xZnU/cGNwrwuFxI9XgDCXw4Ac6+j32Tfenq/90vaHv9j4MhT1O91UPQS2vwvoPY9Ml1bze+8h54jFlNz+Xi1n68pdYDqy5eOiv6akcAYPcP+zdR0hvuIeOPZC1z+zuhRlg+TSWJwmKA93eb6CAiX0vYC5/xixtha+G2VCpzzaQkdWbKQ319V+MpUyBKs3R2kJq95PfGTqp1S1xcWjWHM7/EidUmSUnEPGAtsXqaUeste2hbJlDZB0PXrKad84c8Cr6dnQPi6KA0s25LSBtCiIRalXjiAYhDaDijzu3RfDJoYf1+3RG4RsH+DKlkbb+Kd/HXgk/9TzXXilWNvYGAQNcIp9ZvE9qxkDCRlyC9TAVSZitpqClQDkqeU/Ep9AG3rPgHeuUNM7LlkSs4RbT+9bdTFLN6kXjKctrMXAdMvU0VdZIBe6z7aytQ63T9u9/tUzqdMCO4jcurxBn5HL9oSa6R3+XhgxwfB5ndpFk/E3y2nCKjfQPvxLm4DqJS9ZFqKDAwMbBFSGnDOd4vtdrtX8oaYYBSUxWZ+TydUzqfSqwClWyVDKclFhCSlXZ9SIBbvUZHm5ePos65W1Uwkr4TIXZrigcAa8dFAdmA76jtEJNIk7lfq9WTWlsFiuim94qjg61VUUSYEAFz6DC0OAgLltCCzWCO9B4rfRJrfm3bRdteaxPmjc4to0TBwInDiz+NrepcIFyBoYGCQNIQzvx+CjdkdojsF57w4YaNKJvL7q9aX0eCsNDJgVFQB824GVv4ueROrryswc0D3B7uyKIVq0EQi+65WpdJLRgIda2khlVOguQ46hesgCsKR3c5kGVhZ0axHM7/r1evcOaLpS1foe4yaB3zymFoAhCT1Xih1gFLbhk4HmnfC3/AlUVYW2et9ynn078PAwMAxzkqnud4BwhWf6Rt5XvllpCKtkc6R8OMfJ25MsaB4KG31rlmJhCywIkld79o2+gQKNpPR3t5W5VcvGUEpXa37ab+2WqTHcYoqj4bUpFKXpO5X6pr53VqSNiuXrBmt+4EBRwRfs3QkbetFUJ21+Iz/OjGSuiwtv+7vwIY3gdN+S4sZu4I18YCnRqXoVT8AjIljCVoDgz6AH6fbXB8BjiNzGGODGGMj5SuRg0oqZKBSLGo9nSCrhdmVbE0EfKLYjFS021bStt8wYJso+tJ/DKlnXamXiq690q8ua8QDwZX9IpnlO5qIpLOFr1u2T/UrdQupe2qUj//Jc+2vWyLGt+8r2lqj3yViNb93tYGYvUc1urnmNeDEnyXGLB6Qk2/KIRsYHO6ISOqMsXMYY5sAbAPwLoBaAG8meFzJg4zejtavvmABvdIFsq53qN7m8YZUlm6hfPd8Ttt5NyrVXlJB1o+uNo3UxXpQ1gaoqKKodQAYd6oiNWmWf+dO2toRsN6BDbDxqe9TQXIAEZrslhaqvWnRYHouqdRz4qzURx9Pyly2dJWBZYlym8ie7vr9DAwMHGPBggVYkE5zfQQ4Uep3ATgawEbO+WgAJwH4KKGjSiZkoFe8SpemClKp23VMSwS6RctTmQfNeyji3d/CFGTizikS5nfpU5dKXVSV6+lR1ecO7Vbf9ZvlEZqAraSu+9R9Xlqo6UrdCcG5XOQW8Cv1OPvUZSnZRCnzVN/PwMAgpXBS+93LOT/AGHMxxlyc8+WMscUJH1mycLiY31Oi1AWJ5hRR0NqwmYKgReDX81dSyptufi8eRuZ2aX5v2kGkn98f2POFSInLJsJ1ZVEEuitEw532RhVFDqgMAF83NU4BAkk9Um12idKRwNYVtJ8d5+h3OY5kkmuy72dgYJAyOFHqjYyxIgArATzDGPsDgCQxRxIQq/k93ZB0n7pWKlWmjA2bJRS1ZuLm3aTS5WIjp0iU5hWkLqu7Tb2IrlkvFHJFFTB0Ju3LlDUrwin1FkuOuoQTU3epFjISMk/dNC8xMDBIPzgh9XMBtAP4AYC3AGwBcHYiB5VUWM3vseZMpxpJV+pe1ZVNJj5Kk7ZbM3EXDiSVLpV6TgFQUK5IfZ8g9emX0lYWkAGAlj201euj6wjnU5ekLpuNRIMSndRtKsoBps2ogYFBWiJcnvpDAJ7lnL+vHV6S+CElGdl5NFm3NwBbVgBPnw+Ak+81nA/y4ouTOcrISLZPXQbKeWqAAxvp2Bs/oN9MN3G/+zvyn3vFoiO7kEzyrRqpl46kXuI5RVSEZeaVlOcufe0ydc2KkEq9W1WTkyVio0GAUo9z9LuBgUFG4eJ0m+sjIJxPfSOA+xhjQwG8AOCvnPP/JGdYSYYsQPPZs87rY3/3u8kbnxPIim3JUuoyUK62GuCWNqa6eTunAGjUze8FFMdwYAu937eeWo66XMCQaUqp129U95JdwHRwbqPUpU/dq+q+W83vTiDT7oD456kbGBhkFL6bbnN9BIQrE/sHzvkxAE4AcADAY4yxrxhjv2SMjUvaCJMBf/tVWRmERU7/aWujV7pAKuFk5qnLgDZripaOnKLAQDl3PkXKN+6gPuj7N1LlOYBM5bs+BbZ/qFLKsnLtlbq3nXznIX3q9UBOv+gKCkn4lToLDI5zuWg8gCF1A4M+gra2NrSl01wfAU5ar24HcC+AexljMwE8BuB2AFkJHlvyUFBGSt0r1OSYBcDC28IHU51xBm1XrEjw4BxCpn9Z+5onCr5OIKssckR5doGqKOfOB3Z+Qi1Ae7qBJ8+hbVYemfE3vCGOnwtMOpsIdNAEe1K3VpMDAn3qdtXknKLfUMq5d+epvHb/8+SJZzfmdwODvoAzxFy/Il3m+giISOqMMTeA0wFcCspRXwHgjoSOKtnI70+lNA8Jk+3gyZmXAuQPlEsWqWuBcuFSpvzFZ9ppv7Ya6BEuDtlN7b0HgNa9qka5rxPYuQYoH0t/G6ek7q8o1x1cTS4auLIomE+2k9WfzZ0PoMkodQMDg7RESPM7Y+wUxthjAOoAXAfgHwCO4Jxfyjl/NVkDTAryy8jHK4PMMrG/up7Sxu368MQZMlAuEnKKiKQ7mylITprroSngnm5QcGKOOt6yGxg4gUi7w8an7id1PU9dU+oN2+nvGEsWg6eGlH5XS3DnNBksZ0jdwMAgDREupe1WAB8AmMg5P4dz/iznPKooLMbYaYyxDYyxzYyxW2w+X8QYq2eMrRGvb0U5/vigoD/8eVnZBar7VyZBKnXuU6b4hN7PIanLQLPW/aTUpbl+zqLA6m7TL6fj824C4CJzfW6RIPVwSl0jdelTP7CJitrUfxVbO1O74D/r8xjzu4GBQRoiXJe2E3tzYcZYFoCHAJwCUvurGGOvcc6/tJz6POf8e725V68hC9DkllDQViYrdYAUpp5+lQg4VuqS1OsVIUpz/fTL7X3xH/yR1lhrngUmnROC1C1tVwFFtF+8Ig7E2M5UWhPsOqe5jVI3MDBIXzgpExsrqgBs5pxvBQDG2HOgQjZWUk89ZHGT4TOJeBp3RP7OokUJHVLU6G4n87a3lUi9sDyx99MryoWDzPNurVeNWyTsfPF6V7EeH+Wzd7eTZcCt3S+cT71pBwBG5WhjaWISLvhPRsMbUjcw6BNYlG5zfQQkktSHA/Bo7+sAHGVz3gWMseNBefE/4Jx7bM5JLGT99x6faATiQKmn2x/a20GBYY2tyUlr83mpclwk6Ob3odMjny+brkiVPHgysHU5+eTd2kLFr9SL1TG9Gp3LDcy6Cph+WWxBj6GC//ykbszvBgZ9AYbUo8ProKI2nYyxb4Mq1gWZ/Rlj1wO4HgBGjkxAK3dJ4rXvUy6yy8GEvV90GStPsCJ2As5JzRaWA43bk1OARm/oEg6ydjr3BRZyCQWrSm6opeMdTYHWh44mikTXFxZ1q9Q+76Fua/HOYjDmdwODPoX9Yq4vT4e53gESSeo7AWiluTBCHPODc35Ae/sXAL+zuxDn/BEAjwDAnDlz4h/afWgXmWp5D9DDKRpbdgsLhQsvpG065C7KwLhCURI1UaViPTVEtqOOi8KnXmi/Hw66SpY1+a3Bi9ZqcoDqVe7zJq53uDG/Gxj0KVwo5vrDJk+9F1gFYCxjbDSIzC8FcLl+AmNsKOdcNtE+B8D6BI4nNHSTL3NRRTKrMkxnyMj3AjHeRCh1Tw3w2Gm08HFHUVVNV+d6dTankMRtDZazI/WKKuCa1yO3Vu0NOlsAMGDn6syrZWBgYHDYI2GkzjnvZox9D8DboOpzj3HO1zHG7gTwCef8NQA3MsbOAdAN4CCARYkaT1joJl9vJ7DyXjLJZwypS6UuxpsIn/qW5VpdfC9to1XqTszvVvhJ3ZKr3tEU2EtdIpG9wz01wOZ/AuCUKheu4Y+BgYFBCpBQnzrnfCmApZZjt2v7t4Ly4VMPSQYb36b3mZSrLuu+F8ao1KVZPZy6LRig9rOygW6fs0C5WMzvOsIp9cIYOrD1BrXV5J4BYkuVMzAwMEgwnPRT71uQxUwyKVdddmiLxafuqQGWnA38++7whVrkIie3GLjoCdp3EigXYH6PRamL6HYn5vdEw9orPhE+ewMDA4NeINXR7+kHadKNpNS/853Ej8UppFLPLaZULqfmd08N8OoNalFgVZ+6gt/xER3r8VGrVCB6n3osHdNyiijOwdp+tb0x+aQeqXmNgYHBYYfvpNNc7wCG1K3wK/WG8Oddcknix+IUkpSz88jE7cT87qkBHj9dNVUBAtWn/3MRGMdcAJjquAaoNqTh4HKJTm1tsSl1xoJLxdr1Uk8WEumzNzAwSDtckk5zvQMY87sVTpW6x0OvdIBU6u586iHupFObbH8qkV0YGPi15d/i8x6qHudtBUbMoc9aRDc7pwVYJJnHQupAMKl3tVLQ3u7PYmvYYmBgYOAQHo8HnnSZ6x3AkLoV7lwix0g+9auuolc6IEipOyD1sjG0ZS4y2fs6gWGz1OcFWuQ/Fy1Rh0yhbcs+2jrN1ZYBcrEEygHkVtBJffO/xPad2Bq2GBgYGDjEVVddhavSZa53AGN+t0N+aWZGv7vzqbOZE596gah3P/sb9LzV91E1ugFH0PFOQaLl44D9G2n/P8/QVip1d5Sk3iulLnzq2z8AXr9ZfBBjw5Yo4fV6UVdXh46OjsgnGxz2yMvLw4gRI5CdbUoFG6QfDKnbIa80M6PfI/nU9cC3pjo6dsJ/UwOb6vuA+g2K1Hd8DJSPB6acD6z4DR2T5nq/+d0hqUsyjyVQDiBSP7iNxv/EWSpfPtaGLVGirq4O/fr1Q2VlJRhjkb9gcNiCc44DBw6grq4Oo0ePTvVwDAyCYEjdDvml9u0+0xVWn3rbdnq/eRn5nSXpPXEmRa9n5QATz6Ya94UDVZvW/RsBnEHBcXU1wISzgCNOBN77vSi96qZCN37zu4NAOSBOSr0J+Ox5RehwAWMWAAtuTXjgWkdHhyF0AwAAYwwDBgxAfX19qodiYGALQ+p2yCsFmutSPQrn0JV6bhH51D97HnjleqFmc4EJZ5CpGqDtvi+BkuEUnZ5XAhQNUWb2A5so+n/k0YGlV4dOB56+IPpAuXiRukxrk3niSSB0CUPoBhLm34JBOsMEytkhvxRoj6DUf/QjeqUDJKm784lAO1uAz5+nY7yHSLxTFqRhymxePEJdo3wsmd8BwPMxbStEp9yKKmD+j4AxJ9L3ow2U85vfYwyUyyuhgjo7P6FgvhN/Zkq0RkBREfWx37Vrl78hhRULFizAJ598EvY6ixcvRltbm//9GWecgcbGDHJNGRj0Ej/60Y/wo3SZ6x3AkLod8hwEyp19Nr3SAd4OocizqVhLV6vmPhAkLgvGlI4iQuxoIqUuMXA8sH8T5YCvf4MWCLJDmoRU9f5AOYfmd+nj37sutueT+egHtwIzLqcFhiF0Rxg2bBheeumlmL9vJfWlS5eitNSm5n6agnOOnp6eVA/DIINx9tln4+x0mesdwJC6HfJLydTb4wt9zoYN9EoHdHcQCTNGpN7dDuwTDe8GTSQSdwlPS3c7MHw20LyL+o1LlI+niPf1r1MOe3c78OS5weli+aVAuyB7J+Z3T41KQXvmotjSz3KL1f6EM6P/fgqwensDHlq+Gau3Ryhi5AC33HILHnroIf/7O+64A/fddx9aWlpw0kknYdasWZg6dSpeffXVoO/W1tZiyhRKRWxvb8ell16KiRMn4rzzzkN7e7v/vO985zuYM2cOJk+ejF/+8pcAgAcffBC7du3CwoULsXDhQgBAZWWlv7/0Aw88gClTpmDKlClYvHix/34TJ07Eddddh8mTJ+NrX/tawH0kXn/9dRx11FGYOXMmTj75ZOzdSwvFlpYWXHvttZg6dSqmTZuGl19+GQDw1ltvYdasWZg+fTpOOumkgN9BYsqUKaitrUVtbS3Gjx+Pq6++GlOmTIHH47F9PgBYtWoVjj32WEyfPh1VVVU4dOgQjj/+eKxZs8Z/znHHHYfPPvvM8d/L4PDChg0bsCFd5noHMD51O8iqch1NQEF/+3O+/W3apkOPXW+7CnbLLRLHWikQzp1HqnbVX+h4y17ynXMfUKwp9fKxtH3lvwCEaVqSXwY01NK+k0C52mqV5x5r+plU6sXDKGq/eFh0348jfvX6Ony5qznsOYc6vPhqzyH0cMDFgAlD+qFfXugF0KRhxfjl2ZNDfn7JJZfg5ptvxg033AAAeOGFF/D2228jLy8Pr7zyCoqLi7F//34cffTROOecc0L6fB9++GEUFBRg/fr1+PzzzzFrlqpLcPfdd6N///7w+Xw46aST8Pnnn+PGG2/EAw88gOXLl6O8PLBj4erVq/H444/j448/BuccRx11FE444QSUlZVh06ZN+Otf/4pHH30UF198MV5++WVceeWVAd8/7rjj8NFHH4Exhr/85S/43e9+h/vvvx933XUXSkpKsHbtWgBAQ0MD6uvrcd1112HlypUYPXo0Dh60WJBssGnTJixZsgRHH310yOebMGECLrnkEjz//POYO3cumpubkZ+fj29+85t44oknsHjxYmzcuBEdHR2YPn16xHsaHJ74tpjrM6WfulHqdsh3WCo2XdDdQeQNBPqtx50KNIlKSI0eUeoVVC0OAEoq1LleYWL1ClN5qHSx/DK178SnLnvV96YJSvMusd2dEcVmmju6/c3ceji97w1mzpyJffv2YdeuXfjss89QVlaGiooKcM5x2223Ydq0aTj55JOxc+dOv+K1w8qVK/3kOm3aNEybNs3/2QsvvIBZs2Zh5syZWLduHb788suwY3rvvfdw3nnnobCwEEVFRTj//PNRXV0NABg9ejRmzJgBAJg9ezZqa2uDvl9XV4dTTz0VU6dOxf/8z/9g3TpyzSxbtsy/eAGAsrIyfPTRRzj++OP9KWT9+4dYaGsYNWqUn9BDPd+GDRswdOhQzJ07FwBQXFwMt9uNiy66CG+88Qa8Xi8ee+wxLFq0KOL9DAzSBUap2yHPYanYdIG3XSN1odQHTwGGzQC+egPoaiNyHz6HUtX8pK4p9X1faRcMky6Wp/lTnZjf49EEpe2A2ElOsZlwCKeoJVZvb8AVf/kI3u4eZLtd+MOlMzF7VFnE74XDRRddhJdeegl79uzx16J+5plnUF9fj9WrVyM7OxuVlZUxFcjZtm0b7rvvPqxatQplZWVYtGhRrwrt5OYqC05WVpat+f373/8+fvjDH+Kcc87BihUrcMcdd0R9H7fbHeAv18dcWKgWt9E+X0FBAU455RS8+uqreOGFF7B69eqox2ZgkCoYpW4HqdRX/Z9ShZ4aoPr+9FSJ3R1Adj7tS1LPLgR8QiE21JLarZxHqrn2fTqum99Hzxd++SwKgAuVLqYrdaeBcjJ6PlYiPvIkNbYMaHk6e1QZnvnW0fjh18bjmW8d3WtCB8gE/9xzz+Gll17CRRddBABoamrCoEGDkJ2djeXLl2P79u1hr3H88cfj2WefBQB88cUX+PzzzwEAzc3NKCwsRElJCfbu3Ys333zT/51+/frh0KHgVr7z58/H3//+d7S1taG1tRWvvPIK5s93/ndpamrC8OH072/JkiX+46ecckpA/EBDQwOOPvporFy5Etu2bQMAv/m9srISn376KQDg008/9X9uRajnGz9+PHbv3o1Vq1YBAA4dOoTubvo/861vfQs33ngj5s6di7Ky3v/9DAySBaPU7dAoTNZrngW++Btw2m+BN/+bKqpl5ZDyTCfoSr1VpJvVrQJ2i2Afz8fkQy+rBAYcCexbR0Vq9C5nThW1TuquJJXJzMCWp7NHlcWFzCUmT56MQ4cOYfjw4Rg6dCgA4IorrsDZZ5+NqVOnYs6cOZgwYULYa3znO9/Btddei4kTJ2LixImYPXs2AGD69OmYOXMmJkyYgIqKCsybN8//neuvvx6nnXYahg0bhuXLl/uPz5o1C4sWLUJVFf0tvvWtb2HmzJm2pnY73HHHHbjoootQVlaGE0880U/IP//5z3HDDTdgypQpyMrKwi9/+Uucf/75eOSRR3D++eejp6cHgwYNwr/+9S9ccMEFePLJJzF58mQcddRRGDdunO29Qj1fTk4Onn/+eXz/+99He3s78vPzsWzZMhQVFWH27NkoLi7Gtdde6+h5DAzSBYxznuoxRIU5c+bwSLm1vcayO6iKGkDqsHIesG2len/iz4BOEThz8smJHYsTPHYaRbcvegNYeT+w/NcUnMayiMynXgSsfRG48m/Af54C1r0CDJwA3PBx9Pf64I/AP39O97v9QOTzDwOsX78eEydOTPUwDJKIXbt2YcGCBfjqq6/gcgUbNM2/ib6DZcuWAQBOTvFczxhbzTmfE+k8Y363w+gFYkfkeI8+IfB95Xwi83QgdCBQqY+2BKaxLGqCAgClIyl1DQhMZ4sGUqk7LRFrYJBhePLJJ3HUUUfh7rvvtiV0g76Fk08+OeWEHg3Mv1g7jBEkXnkcmX3Hfo3eSzNwRRWwZg290gHdnSqlTY5RVl0rrQCad9JnJSOAgcJE2XYwtvgAGSjntESsgUGG4eqrr4bH4/HHLhj0baxZsyagbkG6w/jU7cAYkFsCDJ5MJCkDy8rHKn/uzaL9ZzrkLna3UyCZREWVGmdJBQXKFQ6kYLpuLx3f9R9KD4u23KpU6k6D5AwMDAwyGDeLud7kqWc68opVvXTZSKTDpuhIOkTFezuUUreidBRtZU66zFvX08Oigd/87rDuu4GBgYFB0mCUeijk9lP10yWZd1pSezoPAY+fQcFoWbmpazJiVeo6SisCt2NOoEWIryu29LB8Y343MDAwSFcYUg+F3H7BSr3TotQ7GoEeYc5OZVEUb0doc3jpSNq27CVrQm/Tw0ygnIGBgUHawpjfQyG3OJjMrUpdbzSSqqIoPT2Ar1MVn7Gis4W2Oz5WJVZ7UwwmO58i7Y1ST2uke+tVazMWAwOD+MAo9VDI7Qc0iApVksx1n/o99wBtDcB7l1NltoueSJHpXfZSD+FTb60XO3EssZpdQKVb5QLBIG0Rj9arV155JQoKCgBQ61UDg76Ee+65J9VDiApGqYeCbn6386kfeywwQ+R8s6zkk5sM0JM56KGU+thT4lti1VNDjW6ad2ZEc5WUIY4BlIdj61Uda9aswdFHH41p06bhvPPOQ0NDg//+kyZNwrRp03DppZcCAN59913MmDEDM2bMwMyZM21L2BoYxBPHHnssjj322FQPwzGMUg+FvOJgMve2Uj31LDfwwQdAvWiC0iV5HfgAABm4SURBVLIX4JxS4ZIBTw0Rqq9TRaGHUurxLrFaW42wrVkPd7x5C7BnbfhzOpuBvV+Iqn4uaq6ju2qsGDIVOP23IT8+HFuv6rj66qvxxz/+ESeccAJuv/12/OpXv8LixYvx29/+Ftu2bUNubq7f5H/ffffhoYcewrx589DS0oK8vBD/7g0M4oQPPiDhlCnEbpR6KOQWU1S5zxsYICf3b7sNuOdB2vd1qkj5ZKC2mszuvAfo7qJjoZQ60PuGKjoq52dUc5WUoKNJ9ZDnPb3+t3E4tl6VaGpqQmNjI044gQo+XXPNNVi5cqV/jFdccQWefvppuN2kP+bNm4cf/vCHePDBB9HY2Og/bmCQKNx222247bbbUj0Mx0jo/wjG2GkA/gAgC8BfOOe2coQxdgGAlwDM5ZwnuLC7Q+T2o23noUBfeuchoED0c+Zan+yWfSrdK9GonE8KkPvgV82hlHq8kYHNVeKKMIraD78lRaQNXvCXXv9Oh1vrVSf4xz/+gZUrV+L111/H3XffjbVr1+KWW27BmWeeiaVLl2LevHl4++23IzayMTDoS0iYUmeMZQF4CMDpACYBuIwxNsnmvH4AbgIQQ3eRBEKaSzubhfmdqfcSPT6137InMeOQvtmPHwGW/UoFp8lUNUnq4ZR6vBFP5X84wlqqNw6/0+HWelWipKQEZWVlfpX/1FNP4YQTTkBPTw88Hg8WLlyIe++9F01NTWhpacGWLVswdepU/PSnP8XcuXPx1VdfRX1PA4PDGYlU6lUANnPOtwIAY+w5AOcCsNr17gJwL4CfJHAs0UNX6p1NQNFgIm49WK7HotTjDU8NsOQsqu0u8dGfgMueBxq3A0eeDGymDkJJU+oGzqCX6o0DDrfWqzqWLFmC//qv/0JbWxvGjBmDxx9/HD6fD1deeSWamprAOceNN96I0tJS/OIXv8Dy5cvhcrkwefJknH766VHfz8DgcEbCWq8yxi4EcBrn/Fvi/VUAjuKcf087ZxaAn3HOL2CMrQDwYzvzO2PsegDXA8DIkSNnR1IkccGW5cBTXwcWLQWevwLoPwbYuZoIdfxpwIIFQOMO4Oui/eip9wDH3BDfMVTfD7xzp+UgA2ZdBXz6JHDFS8DSH1Nt97P+AMxZFN/7GwAwbTYNgmH+TfQdLFiwAEDqa787bb2asigTxpgLwAMAFkU6l3P+CIBHAOqnntiRCeRp5veOZspF37laKfXFi4H3HwSa3qZguhZLgNKWFYDnY+CIhbErtpHzgo8xRr3M6Q3QJDqwvfXfwOBJxiRuYGBgEEfIdM1MQSJJfSeACu39CHFMoh+AKQBWiBScIQBeY4ydkxbBctKn3rKPAtJk//FOEck8YwZQmw90FBPJ6uZ3Tw3w9Ncpze2938fuV3WLdLVJ5wFjFgBrn6fKcPUbgP5HAHs+U1HWvu6+l15mYGBgkGDITI5MQSJT2lYBGMsYG80YywFwKYDX5Iec8ybOeTnnvJJzXgngIwDpQeiA8qnLXuTFw2krlfqyZcAnX5GiLxoUqNS3riBCB2LrhCaxeRkABpx5H5nWv/ZrWmBsfx8YMYeiz7NyTHqZgYGBQYKwbNkyLFu2LNXDcIyEKXXOeTdj7HsA3galtD3GOV/HGLsTwCec89fCXyHFkEq9qY62/YYQecr0tl//GtjzBfDjmdSrvKFWfbd4hNqPRLaemtDpYZv+BQybCRSKwh/DZgEFA4G2eqCg3KSXGRgYGCQYv/71rwEAJ598copH4gwJ9alzzpcCWGo5dnuIcxckcixRI1sUWJGknlscWDoWoDx1qdQ9Wkaev6IXA656JTTZemqAJ84kn7w7L9BMv2kZULcKmHG5Or9uFdBBJTSx6i/A5K/HPcrawMDAwCBzYSrKhQJjROLS/J7bjwjcmqeeW0zpbm0HiJwBYN86cQIHykaFvkdtNZnn9WYrnhrgb9cDz15Mx9e+pOqH11YrH3pPd+xmfQMDAwODwxKG1MMhr1hFl+cVi3asljz1vGKg32AAHGilRhfYu06d07wr9PUr58Nf1Ia5gPwBwONnAJ8/L6rFIZC8K+dTH3PjQzcwMDAwsIEh9XCQ9d8BUuq5xYElY3WlDqhgub3rgMFTab9ZD/i3oKJKBeRVVAGt+4Aer3YCCyTvBFQqMzBINnw+X+STDAwMYoIh9XCQhAsQeevm94f+CJyZI3zqktT3kVpv2UstT4HwSt3bTtfLygF2/YfeA6Tas3KAOdcGk7cp0drnUFtbiwkTJmDRokUYN24crrjiCixbtgzz5s3D2LFjUVND7pmamhocc8wxmDlzJo499lhs2LABAPD73/8e3/jGNwAAa9euxZQpU9DW1hZ0j/nz52PWrFmYNWuWvzMVANx7772YOnUqpk+fjltuuQUAsHnzZpx88smYPn06Zs2ahS1btmDFihU466yz/N/73ve+hyeeeAIAtWz96U9/ilmzZuHFF1/Eo48+irlz52L69Om44IIL/OPZu3cvzjvvPEyfPh3Tp0/HBx98gNtvvz0gV/hnP/sZ/vCHP8T5VzYwsMef//xn/PnPf071MBzDtDgKB71dZm4/ESgnSH3UEKA8C8gtoUA5gMrIStP76PnAhw+FV+qS8Cd9HVj7AgW/9RsOzP0GMPp4Q9xpCllhSsfFF1+M7373u2hra8MZZ5wR9PmiRYuwaNEi7N+/HxdeeGHAZ04qVW3evBkvvvgiHnvsMcydOxfPPvss3nvvPbz22mu455578Pe//x0TJkxAdXU13G43li1bhttuuw0vv/wybrrpJixYsACvvPIK7r77bvz5z39GQUFBwPUHDRr0/9u7/9goq3SB49+nU7CUQhVKKtoq4KIJUtpqwQ0uJcgq/kCkkK1yTaQoqIvAqvEHBrzZXE10UZeVq2g0YIELF7iuIFwVdZFs4V5lgdIiIlpEyKUWpGUpEKSU9tw/zjvTaelMp6XDOz+eTzKZd05nJs/pmXmfeX+dh88//5ykpCQqKiqYNGkS27dv55NPPuHDDz9k69atJCcnc+zYMcBOUTt79mwKCgo4c+aMb672YHr37k1paSkANTU1TJs2DYC5c+eyaNEiZs6cyaxZsxg5ciRr1qyhoaGBU6dOccUVVzBhwgQef/xxGhsbWblype+HjFLhdt1117kdQrtoUg/Gu6XeNQUSPM2PqX+4Br6rh4Ke0N1J6rs/gD7OByB9MPS8Ak5UBX5/b8Ifci98+9/2B0PO/ZD/VHj6o6JW//79ycqyh3Suv/56Ro8ejYiQlZXlm2+9traWyZMnU1FRgYhQX28P5SQkJFBcXMyQIUN45JFHms3t7lVfX8+MGTMoKyvD4/Hw/fffA/Ya3SlTpvh+BPTq1YuTJ09SWVlJQUEBQMg1zb3V5cAWlJk7dy7Hjx/n1KlTjBkzBoAvvviCpUuXArbCW2pqKqmpqfTu3ZudO3dy5MgRcnNz6d27d3v/hUp1yPr16wG4++67XY4kNJrUg/Emdf/7MyfsxDJvvANVZ22iP2yrXbF/k514JjHJXrfe88rgu9+9J+HVnbA12QF2vAeDJ+hWegQLtmWdnJwc9O9paWkdmkPav5xpQkKC73FCQgLnztnCQs8//zyjRo1izZo1HDhwoNkehYqKClJSUvjpp9Y/j/Pnzyc9PZ3y8nIaGxtDTtT+EhMTaWxs9D1uWb61e/fuvuWioiLWrl1LdnY2xcXFbf5Ppk6dSnFxMYcPH/YdSlDqYnjttdeA6Enqekw9GO/8797d8Ek97Yls5+qaaqkn9XTOTvdem27g3BlbT9vTtY3d787fqivwlVBtqNdL1VSH1NbWcuWVduZD77Fsb/usWbMoKSmhpqaG999/v9XX9u3bl4SEBJYtW+Y7me3WW2/lvffe8x3zPnbsGD169CAjI4O1a9cCUFdXx+nTp7n66qvZs2cPdXV1HD9+nI0bNwaM9eTJk/Tt25f6+nqWL1/uax89ejRvvfUWYE+oq6210zIXFBSwYcMGtm3b5tuqV0qdT5N6MN4t9JbJve5EUy31S3ras9MTk2hK7NjrzhvOwMkq8Nt6aeZEJXTrZYu+6KVq6gI988wzPPfcc+Tm5vq23gGeeOIJHnvsMa699loWLVrE7Nmz+fnn5qWCp0+fzpIlS8jOzmbv3r2+rerbb7+dcePGkZeXR05ODq+++ipg654vWLCAIUOGMHz4cA4fPkxmZiaFhYUMHjyYwsJCcnNzA8b6wgsvcNNNN3HzzTc3Kxn7+uuvs2nTJrKysrjxxhvZs8dWau7atSujRo2isLAQj8fTaf8zpWJN2EqvhkteXp7Zvv0iTQ+/9R345Gm45hY7M1z5KljzMMwshTFj7Rb2zn1wWT87QUz5Cti5wl5b7ukKeQ/CV2/CU/sgpc/577/iXpvYH90SfLpY5Sots+m+xsZG35nzAwcOdDsc/UzEES29Gkt8x9J7Nn98prb5ljo0Tdea/S9NyfnUEZvUT1S2ntRrKyH1yuavV0o1s2fPHsaOHUtBQUFEJHSlIpkm9WBanijnX2N99kT48o3ml71B8+RcucPen/gJrmilfN+JSk3kSrVh0KBB7N+/3+0wVJxatmyZ2yG0iyb1YLxJPCnV3nuTe91JSE2AtB7gCfIv9JZr9T9Z7sD/wI8lcPXN8Msxe9mbUkqpiJSZmel2CO2iST0YbxI//LU95t3d2YW+azVs2Qf/bOP13fvYk9++WQt9s+3Jc8VjAQOJziVKqRlB30IppZR7Vq1aBTSfZyGSaVIP5tiP9v7HEnuJ2qi59vG362H9qabEHEjlDltV7eAWW2K126X4Ll07d9bee7fmlVJKRRzvJZbRktT1krZgqiucBac06g9/a3ocigObm57bcNbODe/jtOvud6WUUp1Ek3ow14yCxG5N148PGm+XvTxdg7/ed/26vwR7CZxXsBnnlGqHdevW8fLLL7frNSkpKWGKRinlBk3qwbQsdZpXBBPebfp7W7vfM4fB5PW22pqnq/1BkHgJ5D3U9Jzlv7PH65W6QOPGjfNVUVNKxSdN6m1pWeo0ayIMvM0unzvTdkLOHAZj/wJFHzX9OGisxzf7XMNZnRZWBRVq6dXi4mJmzJgB2LnVZ82axfDhwxkwYECrU8P6M8bw9NNPM3jwYLKysnwnB1VVVZGfn09OTg6DBw9m8+bNNDQ0UFRU5Hvu/Pnzw/sPUEqFTE+U64hrboHCDUCjPYGuZc3z1rScXCYxySZ0nRY2+rRSepXCQpg+HU6fhlZKr1JUZG/V1dCi9CqdVHq1paqqKrZs2cLevXsZN27ceSVf/X3wwQeUlZVRXl5OdXU1Q4cOJT8/nxUrVjBmzBjmzJlDQ0MDp0+fpqysjMrKSnbv3g3A8ePH24xfqWjV1g/iSKNJvSPOnoZkD74T6A5sbt8kMt7d+jotrApRKKVXWxo/fjwJCQkMGjSII0eOBH3/LVu2MGnSJDweD+np6YwcOZJt27YxdOhQHnzwQerr6xk/fjw5OTkMGDCA/fv3M3PmTO666y5uu+22zu6uUhEjLS3N7RDaRZN6R/QfAbuMneM9r1vHtrR1WtjoFWzLOjk5+N/T0kLaMm8plNKrwV7T0RoP+fn5lJSU8NFHH1FUVMSTTz7JAw88QHl5OZ9++ilvv/02q1evZvHixR16f6UinbfiYVFRkatxhEqPqXdE5jCo+hUcvDy0Xe9KRbgRI0awatUqGhoaOHr0KCUlJQwbNoyDBw+Snp7OtGnTmDp1KqWlpVRXV9PY2MjEiRN58cUXKS0tdTt8pcKmuLi4WSnjSKdb6h11SQ9704SuYkBBQQFffvkl2dnZiAjz5s3j8ssvZ8mSJbzyyit06dKFlJQUli5dSmVlJVOmTKHRKSn80ksvuRy9UspLS692lPdkKZfL8anw0zKbqiX9TMSPaCu9qrvflVJKqRihSV0ppZSKEXpMvaM+/tjtCJRSSoXZx1G2rg/rlrqI3C4i34nIPhE5b/5KEXlURL4WkTIR2SIig8IZT6dKTrY3FRei7dwTFT76WYgvycnJJEfRuj5sSV1EPMCbwB3AIGBSK0l7hTEmyxiTA8wD/hyueDrdwoX2pmJeUlISNTU1ujJXGGOoqakhKalloSYVqxYuXMjCKFrXh3P3+zBgnzFmP4CIrATuAfZ4n2CMOeH3/O6EXNM0Aqxebe+nT3c3DhV2GRkZHDp0iKNHj7odiooASUlJZGRkuB2GukhWO+v66VGyrg9nUr8S+D+/x4eAm1o+SUQeA54EugK3tPZGIvIw8DDAVVdd1emBKhVMly5d6N+/v9thKKVUm1w/+90Y86Yx5hrgWWBugOe8Y4zJM8bk9enT5+IGqJRSSkWJcCb1SiDT73GG0xbISmB8GONRSimlYlo4k/o2YKCI9BeRrsB9wDr/J4jIQL+HdwEVYYxHKaWUimlhO6ZujDknIjOATwEPsNgY842I/Buw3RizDpghIr8F6oF/ApPbet8dO3ZUi8jBTggxDai+4HcRufBILlzn9CUyaF8ik/YlMmlfLhJp37o+HH25OpQnRd3c751FRLaHMo9uNNC+RCbtS2TSvkQm7UvncP1EOaWUUkp1Dk3qSimlVIyI56T+jtsBdCLtS2TSvkQm7Utk0r50grg9pq6UUkrFmnjeUldKKaViSlwm9baqx0UyEckUkU0iskdEvhGRPzjtfxSRSqfiXZmI3Ol2rKEQkQN+lfq2O229RORzEalw7i9zO862iMh1fv/7MhE5ISKPR8u4iMhiEflZRHb7tbU6DmItcL4/u0TkBvciP1+AvrwiInudeNeIyKVOez8R+cVvfN52L/LzBehLwM+UiDznjMt3IjLGnahbF6Avq/z6cUBEypz2SB+XQOth978zxpi4umGvmf8BGICdb74cGOR2XO2Ivy9wg7PcA/geWwXvj8BTbsfXgf4cANJatM0DZjvLs4E/uR1nO/vkAQ5jryuNinEB8oEbgN1tjQNwJ/AJIMCvga1uxx9CX24DEp3lP/n1pZ//8yLtFqAvrX6mnPVAOXAJ0N9Zz3nc7kOwvrT4+2vAv0bJuARaD7v+nYnHLXVf9ThjzFns9LT3uBxTyIwxVcaYUmf5JPAttnhOLLkHWOIsLyH6pg8eDfxgjOmMSZIuCmNMCXCsRXOgcbgHWGqsr4BLRaTvxYm0ba31xRjzmTHmnPPwK+y01REvwLgEcg+w0hhTZ4z5EdiHXd9FhGB9ETuzSyHwnxc1qA4Ksh52/TsTj0m9tepxUZkURaQfkAtsdZpmOLt2FkfDLmuHAT4TkR1iq/EBpBtjqpzlw0C6O6F12H00XzlF47hA4HGI9u/Qg9itJq/+IrJTRP4uIiPcCqqdWvtMRfO4jACOGGP8pwqPinFpsR52/TsTj0k9JohICvBX4HFj69K/BVwD5ABV2F1Z0eA3xpgbgDuAx0Qk3/+Pxu67ippLNMTWORgH/JfTFK3j0ky0jUMgIjIHOAcsd5qqgKuMMbnYEtArRKSnW/GFKCY+Uy1MovkP4agYl1bWwz5ufWfiMam3t3pcxBGRLtgP0nJjzAcAxpgjxpgGY0wj8C4RtNstGGNMpXP/M7AGG/cR764p5/5n9yJstzuAUmPMEYjecXEEGoeo/A6JSBEwFrjfWeHi7KqucZZ3YI9DX+takCEI8pmK1nFJBCYAq7xt0TAura2HiYDvTDwm9Tarx0Uy59jTIuBbY8yf/dr9j88UALtbvjbSiEh3EenhXcaezLQbOx7e4j6TgQ/dibBDmm1xROO4+Ak0DuuAB5wzen8N1PrtcoxIInI78Awwzhhz2q+9j4h4nOUBwEBgvztRhibIZ2odcJ+IXCIi/bF9+cfFjq8DfgvsNcYc8jZE+rgEWg8TCd8Zt88idOOGPRPxe+yvvzlux9PO2H+D3aWzCyhzbncCy4CvnfZ1QF+3Yw2hLwOwZ+uWA994xwLoDWzEluL9G9DL7VhD7E93oAZI9WuLinHB/hCpwlZMPAQ8FGgcsGfwvul8f74G8tyOP4S+7MMe0/R+Z952njvR+eyVAaXA3W7HH0JfAn6mgDnOuHwH3OF2/G31xWkvBh5t8dxIH5dA62HXvzM6o5xSSikVI+Jx97tSSikVkzSpK6WUUjFCk7pSSikVIzSpK6WUUjFCk7pSSikVIzSpKxUnRKRBmleS67QKhU5VrWi6Bl+pmJTodgBKqYvmF2NMjttBKKXCR7fUlYpzTh3reWLr2v9DRH7ltPcTkS+cwiEbReQqpz1dbE3ycuc23Hkrj4i869SX/kxEujnPn+XUnd4lIitd6qZScUGTulLxo1uL3e/3+v2t1hiTBbwB/MVp+3dgiTFmCLYAygKnfQHwd2NMNrY+9jdO+0DgTWPM9cBx7KxgYOtK5zrv82i4OqeUQmeUUypeiMgpY0xKK+0HgFuMMfudIhWHjTG9RaQaOwVpvdNeZYxJE5GjQIYxps7vPfoBnxtjBjqPnwW6GGNeFJENwClgLbDWGHMqzF1VKm7plrpSCpqXiOzoL/06v+UGms7ZuQs77/UNwDanKpdSKgw0qSulAO71u//SWf5fbBVDgPuBzc7yRuD3ACLiEZHUQG8qIglApjFmE/AskAqct7dAKdU59BezUvGjm4iU+T3eYIzxXtZ2mYjswm5tT3LaZgLvicjTwFFgitP+B+AdEXkIu0X+e2z1rdZ4gP9wEr8AC4wxxzutR0qpZvSYulJxzjmmnmeMqXY7FqXUhdHd70oppVSM0C11pZRSKkbolrpSSikVIzSpK6WUUjFCk7pSSikVIzSpK6WUUjFCk7pSSikVIzSpK6WUUjHi/wHFvSGZMMvcrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, init_val_acc, label='validation accuracy', marker='.')\n",
    "plt.plot(epochs, init_val_loss, label='validation loss', marker='.')\n",
    "plt.axvline(x=max_accu_epoch + 1, linestyle='--', color='k', label='max accuracy')\n",
    "plt.axvline(x=min_loss_epoch + 1 , linestyle='--', color='r', label='min loss')\n",
    "plt.ylabel('Validation set accuracy and loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Initial model validation accuracy and loss rates')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ From eyeball inspection, it seems that the model performance starts to degrade around the 7th epoch based on the validation loss. In terms of validation set accuracy, the model does not seem to perform much better as it reaches around the 7th epoch. However, the maximum accuracy rate was achieved closer to the 200th epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ii. implement dropout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "drop_model = models.Sequential()\n",
    "drop_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(512, activation='relu'))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(512, activation='relu'))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(512, activation='relu'))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "drop_model.compile(optimizer='rmsprop',\n",
    "                   loss=losses.categorical_crossentropy,\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 0.9769 - acc: 0.6362 - val_loss: 0.5683 - val_acc: 0.7899\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.5964 - acc: 0.7852 - val_loss: 0.4729 - val_acc: 0.8299\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5169 - acc: 0.8152 - val_loss: 0.4732 - val_acc: 0.8253\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4793 - acc: 0.8266 - val_loss: 0.4385 - val_acc: 0.8392\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4514 - acc: 0.8401 - val_loss: 0.3998 - val_acc: 0.8543\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4296 - acc: 0.8471 - val_loss: 0.4080 - val_acc: 0.8481\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4143 - acc: 0.8526 - val_loss: 0.4151 - val_acc: 0.8534\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4051 - acc: 0.8555 - val_loss: 0.3680 - val_acc: 0.8655\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3915 - acc: 0.8611 - val_loss: 0.3848 - val_acc: 0.8548\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3912 - acc: 0.8627 - val_loss: 0.3515 - val_acc: 0.8744\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3797 - acc: 0.8661 - val_loss: 0.3625 - val_acc: 0.8715\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3648 - acc: 0.8703 - val_loss: 0.3406 - val_acc: 0.8783\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3598 - acc: 0.8710 - val_loss: 0.3776 - val_acc: 0.8640\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3578 - acc: 0.8731 - val_loss: 0.3498 - val_acc: 0.8735\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3514 - acc: 0.8756 - val_loss: 0.3388 - val_acc: 0.8729\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3487 - acc: 0.8773 - val_loss: 0.3619 - val_acc: 0.8614\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3464 - acc: 0.8774 - val_loss: 0.3287 - val_acc: 0.8805\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3379 - acc: 0.8805 - val_loss: 0.3756 - val_acc: 0.8640\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3408 - acc: 0.8805 - val_loss: 0.3599 - val_acc: 0.8698\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3317 - acc: 0.8838 - val_loss: 0.3579 - val_acc: 0.8790\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3339 - acc: 0.8836 - val_loss: 0.3480 - val_acc: 0.8770\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3297 - acc: 0.8837 - val_loss: 0.3721 - val_acc: 0.8642\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3266 - acc: 0.8853 - val_loss: 0.3462 - val_acc: 0.8829\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3233 - acc: 0.8848 - val_loss: 0.3432 - val_acc: 0.8767\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3220 - acc: 0.8853 - val_loss: 0.3448 - val_acc: 0.8790\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3238 - acc: 0.8864 - val_loss: 0.3500 - val_acc: 0.8737\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3196 - acc: 0.8882 - val_loss: 0.3421 - val_acc: 0.8781\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3197 - acc: 0.8876 - val_loss: 0.3384 - val_acc: 0.8699\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3178 - acc: 0.8887 - val_loss: 0.3209 - val_acc: 0.8847\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3145 - acc: 0.8898 - val_loss: 0.3337 - val_acc: 0.8789\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3128 - acc: 0.8903 - val_loss: 0.3304 - val_acc: 0.8852\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3116 - acc: 0.8934 - val_loss: 0.3481 - val_acc: 0.8835\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3090 - acc: 0.8929 - val_loss: 0.3361 - val_acc: 0.8854\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3071 - acc: 0.8940 - val_loss: 0.3572 - val_acc: 0.8816\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3042 - acc: 0.8939 - val_loss: 0.3398 - val_acc: 0.8798\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3052 - acc: 0.8937 - val_loss: 0.3359 - val_acc: 0.8875\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3066 - acc: 0.8939 - val_loss: 0.3281 - val_acc: 0.8825\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3055 - acc: 0.8931 - val_loss: 0.3560 - val_acc: 0.8663\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2970 - acc: 0.8974 - val_loss: 0.3400 - val_acc: 0.8841\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2999 - acc: 0.8959 - val_loss: 0.3400 - val_acc: 0.8864\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3032 - acc: 0.8963 - val_loss: 0.3244 - val_acc: 0.8911\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3010 - acc: 0.8973 - val_loss: 0.3215 - val_acc: 0.8887\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2981 - acc: 0.8960 - val_loss: 0.3317 - val_acc: 0.8826\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2932 - acc: 0.8980 - val_loss: 0.3446 - val_acc: 0.8747\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3039 - acc: 0.8968 - val_loss: 0.3346 - val_acc: 0.8815\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2967 - acc: 0.8990 - val_loss: 0.3206 - val_acc: 0.8883\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2935 - acc: 0.8999 - val_loss: 0.3380 - val_acc: 0.8898\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2964 - acc: 0.8988 - val_loss: 0.3341 - val_acc: 0.8841\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2953 - acc: 0.8982 - val_loss: 0.3255 - val_acc: 0.8882\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2904 - acc: 0.9007 - val_loss: 0.3358 - val_acc: 0.8883\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2971 - acc: 0.8992 - val_loss: 0.3366 - val_acc: 0.8849\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2954 - acc: 0.8992 - val_loss: 0.3368 - val_acc: 0.8863\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2912 - acc: 0.8997 - val_loss: 0.3424 - val_acc: 0.8838\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2960 - acc: 0.9004 - val_loss: 0.3319 - val_acc: 0.8885\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2956 - acc: 0.9005 - val_loss: 0.3358 - val_acc: 0.8880\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2927 - acc: 0.9009 - val_loss: 0.3294 - val_acc: 0.8864\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2918 - acc: 0.9022 - val_loss: 0.3301 - val_acc: 0.8874\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2937 - acc: 0.9008 - val_loss: 0.3285 - val_acc: 0.8890\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2850 - acc: 0.9038 - val_loss: 0.3349 - val_acc: 0.8875\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2909 - acc: 0.9026 - val_loss: 0.3316 - val_acc: 0.8871\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2963 - acc: 0.9025 - val_loss: 0.3330 - val_acc: 0.8928\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2938 - acc: 0.9024 - val_loss: 0.3400 - val_acc: 0.8884\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2896 - acc: 0.9028 - val_loss: 0.3305 - val_acc: 0.8919\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2959 - acc: 0.9054 - val_loss: 0.3487 - val_acc: 0.8907\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2916 - acc: 0.9037 - val_loss: 0.3446 - val_acc: 0.8903\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2945 - acc: 0.9029 - val_loss: 0.3414 - val_acc: 0.8889\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2912 - acc: 0.9015 - val_loss: 0.3315 - val_acc: 0.8946\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2944 - acc: 0.9024 - val_loss: 0.3383 - val_acc: 0.8893\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2895 - acc: 0.9037 - val_loss: 0.3392 - val_acc: 0.8866\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2913 - acc: 0.9044 - val_loss: 0.3509 - val_acc: 0.8902\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2939 - acc: 0.9041 - val_loss: 0.3351 - val_acc: 0.8927\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2947 - acc: 0.9044 - val_loss: 0.3510 - val_acc: 0.8895\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2863 - acc: 0.9048 - val_loss: 0.3618 - val_acc: 0.8760\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2913 - acc: 0.9037 - val_loss: 0.3514 - val_acc: 0.8883\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2894 - acc: 0.9063 - val_loss: 0.3452 - val_acc: 0.8876\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2876 - acc: 0.9049 - val_loss: 0.3485 - val_acc: 0.8845\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2874 - acc: 0.9066 - val_loss: 0.3564 - val_acc: 0.8846\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2904 - acc: 0.9061 - val_loss: 0.3590 - val_acc: 0.8748\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2909 - acc: 0.9049 - val_loss: 0.3447 - val_acc: 0.8908\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2987 - acc: 0.9039 - val_loss: 0.3539 - val_acc: 0.8817\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2908 - acc: 0.9045 - val_loss: 0.3485 - val_acc: 0.8845\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2883 - acc: 0.9057 - val_loss: 0.3396 - val_acc: 0.8920\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2894 - acc: 0.9065 - val_loss: 0.3584 - val_acc: 0.8925\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2892 - acc: 0.9057 - val_loss: 0.3477 - val_acc: 0.8894\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2955 - acc: 0.9062 - val_loss: 0.3502 - val_acc: 0.8902\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2923 - acc: 0.9072 - val_loss: 0.3591 - val_acc: 0.8904\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2902 - acc: 0.9079 - val_loss: 0.3473 - val_acc: 0.8911\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2918 - acc: 0.9062 - val_loss: 0.3503 - val_acc: 0.8897\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2922 - acc: 0.9075 - val_loss: 0.3514 - val_acc: 0.8942\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2940 - acc: 0.9064 - val_loss: 0.3633 - val_acc: 0.8881\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2986 - acc: 0.9061 - val_loss: 0.3552 - val_acc: 0.8943\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2962 - acc: 0.9078 - val_loss: 0.3510 - val_acc: 0.8874\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2914 - acc: 0.9078 - val_loss: 0.3537 - val_acc: 0.8891\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2915 - acc: 0.9078 - val_loss: 0.3432 - val_acc: 0.8914\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2970 - acc: 0.9066 - val_loss: 0.3554 - val_acc: 0.8867\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2919 - acc: 0.9075 - val_loss: 0.3717 - val_acc: 0.8890\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2953 - acc: 0.9089 - val_loss: 0.3769 - val_acc: 0.8830\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2984 - acc: 0.9080 - val_loss: 0.3524 - val_acc: 0.8933\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2977 - acc: 0.9073 - val_loss: 0.3649 - val_acc: 0.8895\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2958 - acc: 0.9082 - val_loss: 0.3443 - val_acc: 0.8899\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3004 - acc: 0.9081 - val_loss: 0.3609 - val_acc: 0.8901\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2977 - acc: 0.9072 - val_loss: 0.3676 - val_acc: 0.8912\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3021 - acc: 0.9060 - val_loss: 0.3636 - val_acc: 0.8845\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.2984 - acc: 0.9086 - val_loss: 0.3543 - val_acc: 0.8958\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3063 - acc: 0.9070 - val_loss: 0.3767 - val_acc: 0.8856\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2916 - acc: 0.9097 - val_loss: 0.3658 - val_acc: 0.8835\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2943 - acc: 0.9083 - val_loss: 0.3448 - val_acc: 0.8943\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2936 - acc: 0.9098 - val_loss: 0.3869 - val_acc: 0.8847\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2959 - acc: 0.9106 - val_loss: 0.3751 - val_acc: 0.8917\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2957 - acc: 0.9098 - val_loss: 0.3588 - val_acc: 0.8922\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2986 - acc: 0.9087 - val_loss: 0.3776 - val_acc: 0.8864\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2978 - acc: 0.9074 - val_loss: 0.3905 - val_acc: 0.8807\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2948 - acc: 0.9099 - val_loss: 0.3615 - val_acc: 0.8946\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3031 - acc: 0.9110 - val_loss: 0.3620 - val_acc: 0.8913\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3066 - acc: 0.9103 - val_loss: 0.3767 - val_acc: 0.8910\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3056 - acc: 0.9090 - val_loss: 0.3660 - val_acc: 0.8932\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3019 - acc: 0.9082 - val_loss: 0.3812 - val_acc: 0.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3064 - acc: 0.9083 - val_loss: 0.3874 - val_acc: 0.8896\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3000 - acc: 0.9094 - val_loss: 0.4007 - val_acc: 0.8798\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2994 - acc: 0.9112 - val_loss: 0.3730 - val_acc: 0.8874\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3030 - acc: 0.9093 - val_loss: 0.3772 - val_acc: 0.8888\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3006 - acc: 0.9115 - val_loss: 0.3617 - val_acc: 0.8913\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3011 - acc: 0.9105 - val_loss: 0.3723 - val_acc: 0.8910\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2920 - acc: 0.9127 - val_loss: 0.3766 - val_acc: 0.8869\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3031 - acc: 0.9088 - val_loss: 0.3800 - val_acc: 0.8927\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2982 - acc: 0.9122 - val_loss: 0.3795 - val_acc: 0.8898\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2956 - acc: 0.9113 - val_loss: 0.3602 - val_acc: 0.8911\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2991 - acc: 0.9115 - val_loss: 0.3836 - val_acc: 0.8911\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3000 - acc: 0.9135 - val_loss: 0.3764 - val_acc: 0.8917\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3100 - acc: 0.9113 - val_loss: 0.3763 - val_acc: 0.8911\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3083 - acc: 0.9102 - val_loss: 0.3718 - val_acc: 0.8907\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3038 - acc: 0.9106 - val_loss: 0.3817 - val_acc: 0.8897\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3068 - acc: 0.9111 - val_loss: 0.3783 - val_acc: 0.8861\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3055 - acc: 0.9118 - val_loss: 0.3934 - val_acc: 0.8881\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2989 - acc: 0.9114 - val_loss: 0.3716 - val_acc: 0.8908\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3050 - acc: 0.9109 - val_loss: 0.3730 - val_acc: 0.8935\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3080 - acc: 0.9112 - val_loss: 0.3779 - val_acc: 0.8911\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3092 - acc: 0.9112 - val_loss: 0.3912 - val_acc: 0.8815\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2989 - acc: 0.9124 - val_loss: 0.3876 - val_acc: 0.8943\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3065 - acc: 0.9117 - val_loss: 0.4061 - val_acc: 0.8836\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3057 - acc: 0.9113 - val_loss: 0.3830 - val_acc: 0.8917\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3158 - acc: 0.9111 - val_loss: 0.4065 - val_acc: 0.8929\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3100 - acc: 0.9119 - val_loss: 0.4103 - val_acc: 0.8859\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3062 - acc: 0.9124 - val_loss: 0.3890 - val_acc: 0.8917\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3162 - acc: 0.9099 - val_loss: 0.3699 - val_acc: 0.8942\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3202 - acc: 0.9129 - val_loss: 0.3992 - val_acc: 0.8911\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3106 - acc: 0.9124 - val_loss: 0.3779 - val_acc: 0.8934\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3070 - acc: 0.9101 - val_loss: 0.3755 - val_acc: 0.8948\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3050 - acc: 0.9134 - val_loss: 0.3676 - val_acc: 0.8969\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3037 - acc: 0.9137 - val_loss: 0.3760 - val_acc: 0.8917\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3132 - acc: 0.9121 - val_loss: 0.3752 - val_acc: 0.8935\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3090 - acc: 0.9125 - val_loss: 0.3940 - val_acc: 0.8957\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3204 - acc: 0.9113 - val_loss: 0.3841 - val_acc: 0.8884\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3111 - acc: 0.9140 - val_loss: 0.3915 - val_acc: 0.8960\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3262 - acc: 0.9111 - val_loss: 0.3982 - val_acc: 0.8901\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3034 - acc: 0.9128 - val_loss: 0.4003 - val_acc: 0.8910\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3036 - acc: 0.9131 - val_loss: 0.4170 - val_acc: 0.8868\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3127 - acc: 0.9136 - val_loss: 0.3911 - val_acc: 0.8958\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3062 - acc: 0.9146 - val_loss: 0.4074 - val_acc: 0.8925\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3067 - acc: 0.9148 - val_loss: 0.3871 - val_acc: 0.8906\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3174 - acc: 0.9120 - val_loss: 0.4037 - val_acc: 0.8945\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3214 - acc: 0.9145 - val_loss: 0.4011 - val_acc: 0.8906\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3362 - acc: 0.9103 - val_loss: 0.3870 - val_acc: 0.8912\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3205 - acc: 0.9113 - val_loss: 0.4003 - val_acc: 0.8893\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3165 - acc: 0.9131 - val_loss: 0.4050 - val_acc: 0.8885\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3283 - acc: 0.9127 - val_loss: 0.4017 - val_acc: 0.8915\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3282 - acc: 0.9130 - val_loss: 0.4015 - val_acc: 0.8909\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3320 - acc: 0.9124 - val_loss: 0.3846 - val_acc: 0.8937\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3191 - acc: 0.9130 - val_loss: 0.4001 - val_acc: 0.8927\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3291 - acc: 0.9128 - val_loss: 0.4167 - val_acc: 0.8855\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3293 - acc: 0.9115 - val_loss: 0.3796 - val_acc: 0.8943\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3406 - acc: 0.9101 - val_loss: 0.3898 - val_acc: 0.8923\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3261 - acc: 0.9125 - val_loss: 0.4007 - val_acc: 0.8924\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3298 - acc: 0.9109 - val_loss: 0.3928 - val_acc: 0.8905\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3248 - acc: 0.9121 - val_loss: 0.4218 - val_acc: 0.8895\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3332 - acc: 0.9134 - val_loss: 0.4062 - val_acc: 0.8906\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3327 - acc: 0.9125 - val_loss: 0.4153 - val_acc: 0.8928\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3303 - acc: 0.9143 - val_loss: 0.4193 - val_acc: 0.8930\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3225 - acc: 0.9150 - val_loss: 0.4062 - val_acc: 0.8878\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3318 - acc: 0.9132 - val_loss: 0.4226 - val_acc: 0.8874\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3282 - acc: 0.9134 - val_loss: 0.4309 - val_acc: 0.8891\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3275 - acc: 0.9133 - val_loss: 0.4051 - val_acc: 0.8938\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3271 - acc: 0.9140 - val_loss: 0.4246 - val_acc: 0.8924\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3180 - acc: 0.9140 - val_loss: 0.4283 - val_acc: 0.8850\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3404 - acc: 0.9117 - val_loss: 0.4249 - val_acc: 0.8892\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3221 - acc: 0.9149 - val_loss: 0.4191 - val_acc: 0.8893\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3335 - acc: 0.9116 - val_loss: 0.4169 - val_acc: 0.8910\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3392 - acc: 0.9134 - val_loss: 0.4266 - val_acc: 0.8924\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3270 - acc: 0.9152 - val_loss: 0.4306 - val_acc: 0.8905\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3467 - acc: 0.9143 - val_loss: 0.4085 - val_acc: 0.8918\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3370 - acc: 0.9125 - val_loss: 0.4250 - val_acc: 0.8871\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3342 - acc: 0.9145 - val_loss: 0.4141 - val_acc: 0.8934\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3270 - acc: 0.9151 - val_loss: 0.4253 - val_acc: 0.8921\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3497 - acc: 0.9144 - val_loss: 0.4226 - val_acc: 0.8902\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3385 - acc: 0.9156 - val_loss: 0.4323 - val_acc: 0.8878\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3447 - acc: 0.9144 - val_loss: 0.4312 - val_acc: 0.8899\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3341 - acc: 0.9139 - val_loss: 0.4139 - val_acc: 0.8901\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3487 - acc: 0.9139 - val_loss: 0.4419 - val_acc: 0.8925\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3421 - acc: 0.9138 - val_loss: 0.4383 - val_acc: 0.8889\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3362 - acc: 0.9118 - val_loss: 0.4329 - val_acc: 0.8905\n"
     ]
    }
   ],
   "source": [
    "drop_history = drop_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_history_dict = drop_history.history\n",
    "drop_val_loss = drop_history_dict['val_loss']\n",
    "min_loss_epoch = drop_val_loss.index(min(drop_val_loss))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, init_val_loss, label='initial validation loss', marker='.')\n",
    "plt.plot(epochs, drop_val_loss, label='dropout validation loss', marker='v')\n",
    "plt.axvline(x=min_loss_epoch + 1, linestyle='--', color='r', label='dropout min loss')\n",
    "plt.ylabel('Validation set loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Initial model vs model with dropout layers')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ Based on eyeball inspection, it is obvious that the dropout model is more resistant to overfitting as the loss rates are mostly lower than the initial test model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__iii. Weight regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__L1 regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model = models.Sequential()\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu', input_shape=(28 * 28,)))\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "l1_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 14.6055 - acc: 0.5410 - val_loss: 4.2310 - val_acc: 0.5521\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 3.0245 - acc: 0.6547 - val_loss: 2.4671 - val_acc: 0.6561\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 2.2099 - acc: 0.6978 - val_loss: 2.0057 - val_acc: 0.7125\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.9220 - acc: 0.7267 - val_loss: 1.8770 - val_acc: 0.7309\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.7633 - acc: 0.7440 - val_loss: 1.6946 - val_acc: 0.7482\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.6541 - acc: 0.7611 - val_loss: 1.6213 - val_acc: 0.7736\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.5934 - acc: 0.7682 - val_loss: 1.5844 - val_acc: 0.7649\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.5417 - acc: 0.7792 - val_loss: 1.5527 - val_acc: 0.7571\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.5031 - acc: 0.7816 - val_loss: 1.4944 - val_acc: 0.7788\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.4690 - acc: 0.7874 - val_loss: 1.4604 - val_acc: 0.7863\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.4482 - acc: 0.7926 - val_loss: 1.4336 - val_acc: 0.7950\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.4183 - acc: 0.7981 - val_loss: 1.4213 - val_acc: 0.7945\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3957 - acc: 0.8024 - val_loss: 1.4581 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3807 - acc: 0.8033 - val_loss: 1.3706 - val_acc: 0.8072\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3652 - acc: 0.8096 - val_loss: 1.3581 - val_acc: 0.8098\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3556 - acc: 0.8096 - val_loss: 1.3728 - val_acc: 0.8052\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3492 - acc: 0.8092 - val_loss: 1.3908 - val_acc: 0.7905\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3393 - acc: 0.8126 - val_loss: 1.3493 - val_acc: 0.8083\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3296 - acc: 0.8157 - val_loss: 1.3708 - val_acc: 0.7968\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3275 - acc: 0.8148 - val_loss: 1.3170 - val_acc: 0.8180\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3180 - acc: 0.8160 - val_loss: 1.3148 - val_acc: 0.8169\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3121 - acc: 0.8174 - val_loss: 1.3856 - val_acc: 0.7899\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3068 - acc: 0.8194 - val_loss: 1.3232 - val_acc: 0.8109\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3005 - acc: 0.8195 - val_loss: 1.3423 - val_acc: 0.8036\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2942 - acc: 0.8214 - val_loss: 1.3021 - val_acc: 0.8163\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2894 - acc: 0.8214 - val_loss: 1.3080 - val_acc: 0.8158\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2820 - acc: 0.8231 - val_loss: 1.3074 - val_acc: 0.8153\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2803 - acc: 0.8244 - val_loss: 1.2799 - val_acc: 0.8242\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2768 - acc: 0.8240 - val_loss: 1.3001 - val_acc: 0.8151\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2716 - acc: 0.8249 - val_loss: 1.3325 - val_acc: 0.8055\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2682 - acc: 0.8256 - val_loss: 1.3328 - val_acc: 0.8010\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2656 - acc: 0.8256 - val_loss: 1.2738 - val_acc: 0.8215\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2620 - acc: 0.8252 - val_loss: 1.2763 - val_acc: 0.8221\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2583 - acc: 0.8274 - val_loss: 1.2900 - val_acc: 0.8091\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2519 - acc: 0.8288 - val_loss: 1.2873 - val_acc: 0.8109\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2519 - acc: 0.8282 - val_loss: 1.2579 - val_acc: 0.8258\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2485 - acc: 0.8285 - val_loss: 1.2925 - val_acc: 0.8144\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2462 - acc: 0.8290 - val_loss: 1.2982 - val_acc: 0.8061\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2438 - acc: 0.8285 - val_loss: 1.2543 - val_acc: 0.8235\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2402 - acc: 0.8303 - val_loss: 1.2647 - val_acc: 0.8204\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2356 - acc: 0.8322 - val_loss: 1.2472 - val_acc: 0.8237\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2350 - acc: 0.8308 - val_loss: 1.2392 - val_acc: 0.8268\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2334 - acc: 0.8291 - val_loss: 1.2323 - val_acc: 0.8312\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2290 - acc: 0.8325 - val_loss: 1.2686 - val_acc: 0.8149\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2275 - acc: 0.8323 - val_loss: 1.2539 - val_acc: 0.8175\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2240 - acc: 0.8337 - val_loss: 1.2705 - val_acc: 0.8121\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2231 - acc: 0.8319 - val_loss: 1.2793 - val_acc: 0.8137\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2222 - acc: 0.8328 - val_loss: 1.2582 - val_acc: 0.8213\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2236 - acc: 0.8323 - val_loss: 1.2255 - val_acc: 0.8293\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2199 - acc: 0.8332 - val_loss: 1.2846 - val_acc: 0.8141\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2197 - acc: 0.8325 - val_loss: 1.2174 - val_acc: 0.8334\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2168 - acc: 0.8331 - val_loss: 1.2213 - val_acc: 0.8306\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2159 - acc: 0.8348 - val_loss: 1.2396 - val_acc: 0.8257\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2138 - acc: 0.8335 - val_loss: 1.2494 - val_acc: 0.8195\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2120 - acc: 0.8340 - val_loss: 1.3004 - val_acc: 0.7935\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2135 - acc: 0.8343 - val_loss: 1.2544 - val_acc: 0.8174\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2086 - acc: 0.8352 - val_loss: 1.2325 - val_acc: 0.8233\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2055 - acc: 0.8350 - val_loss: 1.2635 - val_acc: 0.8093\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2079 - acc: 0.8346 - val_loss: 1.3055 - val_acc: 0.7997\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2092 - acc: 0.8343 - val_loss: 1.2647 - val_acc: 0.8132\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2021 - acc: 0.8361 - val_loss: 1.2716 - val_acc: 0.8038\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2034 - acc: 0.8337 - val_loss: 1.2129 - val_acc: 0.8310\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2009 - acc: 0.8368 - val_loss: 1.2542 - val_acc: 0.8166\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1996 - acc: 0.8362 - val_loss: 1.2642 - val_acc: 0.8108\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2003 - acc: 0.8352 - val_loss: 1.2356 - val_acc: 0.8203\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1998 - acc: 0.8364 - val_loss: 1.2233 - val_acc: 0.8277\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1981 - acc: 0.8341 - val_loss: 1.2557 - val_acc: 0.8109\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1965 - acc: 0.8365 - val_loss: 1.2511 - val_acc: 0.8066\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1975 - acc: 0.8360 - val_loss: 1.2440 - val_acc: 0.8185\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1959 - acc: 0.8356 - val_loss: 1.2347 - val_acc: 0.8251\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1964 - acc: 0.8367 - val_loss: 1.2141 - val_acc: 0.8285\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1938 - acc: 0.8364 - val_loss: 1.2173 - val_acc: 0.8297\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1905 - acc: 0.8386 - val_loss: 1.2187 - val_acc: 0.8258\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1904 - acc: 0.8372 - val_loss: 1.2672 - val_acc: 0.8121\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1893 - acc: 0.8383 - val_loss: 1.2415 - val_acc: 0.8177\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1904 - acc: 0.8372 - val_loss: 1.2440 - val_acc: 0.8109\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1913 - acc: 0.8372 - val_loss: 1.2419 - val_acc: 0.8122\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1862 - acc: 0.8397 - val_loss: 1.2141 - val_acc: 0.8264\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1849 - acc: 0.8384 - val_loss: 1.2293 - val_acc: 0.8253\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1850 - acc: 0.8384 - val_loss: 1.2474 - val_acc: 0.8177\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1838 - acc: 0.8400 - val_loss: 1.1915 - val_acc: 0.8355\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1870 - acc: 0.8360 - val_loss: 1.2190 - val_acc: 0.8259\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1816 - acc: 0.8393 - val_loss: 1.1993 - val_acc: 0.8333\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1823 - acc: 0.8378 - val_loss: 1.2006 - val_acc: 0.8315\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1825 - acc: 0.8376 - val_loss: 1.2103 - val_acc: 0.8230\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1801 - acc: 0.8381 - val_loss: 1.2506 - val_acc: 0.8060\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1817 - acc: 0.8378 - val_loss: 1.2039 - val_acc: 0.8295\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1806 - acc: 0.8390 - val_loss: 1.2289 - val_acc: 0.8192\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1791 - acc: 0.8388 - val_loss: 1.1892 - val_acc: 0.8328\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1790 - acc: 0.8394 - val_loss: 1.1949 - val_acc: 0.8328\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1792 - acc: 0.8381 - val_loss: 1.2174 - val_acc: 0.8245\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1757 - acc: 0.8399 - val_loss: 1.1772 - val_acc: 0.8390\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1782 - acc: 0.8387 - val_loss: 1.2090 - val_acc: 0.8274\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1769 - acc: 0.8380 - val_loss: 1.3014 - val_acc: 0.7999\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1765 - acc: 0.8382 - val_loss: 1.2207 - val_acc: 0.8234\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1766 - acc: 0.8383 - val_loss: 1.1785 - val_acc: 0.8372\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1739 - acc: 0.8402 - val_loss: 1.1882 - val_acc: 0.8367\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1756 - acc: 0.8376 - val_loss: 1.1783 - val_acc: 0.8393\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1738 - acc: 0.8395 - val_loss: 1.2031 - val_acc: 0.8277\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1745 - acc: 0.8397 - val_loss: 1.1961 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1728 - acc: 0.8409 - val_loss: 1.2628 - val_acc: 0.8035\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1715 - acc: 0.8403 - val_loss: 1.2673 - val_acc: 0.8072\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1733 - acc: 0.8388 - val_loss: 1.2161 - val_acc: 0.8206\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1717 - acc: 0.8404 - val_loss: 1.2192 - val_acc: 0.8257\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1684 - acc: 0.8401 - val_loss: 1.2671 - val_acc: 0.7963\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1702 - acc: 0.8401 - val_loss: 1.1779 - val_acc: 0.8372\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1737 - acc: 0.8374 - val_loss: 1.2321 - val_acc: 0.8168\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1713 - acc: 0.8404 - val_loss: 1.1876 - val_acc: 0.8347\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1661 - acc: 0.8415 - val_loss: 1.1807 - val_acc: 0.8337\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1640 - acc: 0.8419 - val_loss: 1.2682 - val_acc: 0.8088\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1701 - acc: 0.8387 - val_loss: 1.2041 - val_acc: 0.8274\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1652 - acc: 0.8420 - val_loss: 1.2265 - val_acc: 0.8226\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1661 - acc: 0.8403 - val_loss: 1.2139 - val_acc: 0.8223\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1641 - acc: 0.8425 - val_loss: 1.2188 - val_acc: 0.8189\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1642 - acc: 0.8432 - val_loss: 1.1898 - val_acc: 0.8308\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1631 - acc: 0.8423 - val_loss: 1.2006 - val_acc: 0.8278\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1657 - acc: 0.8409 - val_loss: 1.2198 - val_acc: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1656 - acc: 0.8406 - val_loss: 1.1736 - val_acc: 0.8373\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1639 - acc: 0.8399 - val_loss: 1.1971 - val_acc: 0.8273\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1619 - acc: 0.8417 - val_loss: 1.2253 - val_acc: 0.8207\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1634 - acc: 0.8421 - val_loss: 1.1883 - val_acc: 0.8328\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1631 - acc: 0.8410 - val_loss: 1.1921 - val_acc: 0.8269\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1628 - acc: 0.8416 - val_loss: 1.2574 - val_acc: 0.8149\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1627 - acc: 0.8404 - val_loss: 1.1944 - val_acc: 0.8286\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1617 - acc: 0.8414 - val_loss: 1.2658 - val_acc: 0.8070\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1622 - acc: 0.8403 - val_loss: 1.1755 - val_acc: 0.8385\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1608 - acc: 0.8411 - val_loss: 1.1878 - val_acc: 0.8287\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1624 - acc: 0.8422 - val_loss: 1.1705 - val_acc: 0.8362\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1599 - acc: 0.8415 - val_loss: 1.1772 - val_acc: 0.8344\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1591 - acc: 0.8411 - val_loss: 1.2234 - val_acc: 0.8212\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1585 - acc: 0.8432 - val_loss: 1.1861 - val_acc: 0.8350\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1605 - acc: 0.8423 - val_loss: 1.2627 - val_acc: 0.7940\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1605 - acc: 0.8403 - val_loss: 1.1852 - val_acc: 0.8327\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1604 - acc: 0.8417 - val_loss: 1.1690 - val_acc: 0.8398\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1587 - acc: 0.8414 - val_loss: 1.1895 - val_acc: 0.8290\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1565 - acc: 0.8436 - val_loss: 1.1755 - val_acc: 0.8349\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1561 - acc: 0.8429 - val_loss: 1.1872 - val_acc: 0.8327\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1593 - acc: 0.8421 - val_loss: 1.1822 - val_acc: 0.8338\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1537 - acc: 0.8427 - val_loss: 1.1972 - val_acc: 0.8273\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1570 - acc: 0.8422 - val_loss: 1.1813 - val_acc: 0.8334\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1550 - acc: 0.8433 - val_loss: 1.1737 - val_acc: 0.8336\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1570 - acc: 0.8416 - val_loss: 1.1952 - val_acc: 0.8296\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1581 - acc: 0.8414 - val_loss: 1.2035 - val_acc: 0.8229\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1568 - acc: 0.8435 - val_loss: 1.1834 - val_acc: 0.8303\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1553 - acc: 0.8432 - val_loss: 1.1784 - val_acc: 0.8303\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1529 - acc: 0.8426 - val_loss: 1.2104 - val_acc: 0.8179\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1536 - acc: 0.8443 - val_loss: 1.1853 - val_acc: 0.8298\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1532 - acc: 0.8438 - val_loss: 1.1875 - val_acc: 0.8303\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1521 - acc: 0.8422 - val_loss: 1.2262 - val_acc: 0.8099\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1540 - acc: 0.8425 - val_loss: 1.2669 - val_acc: 0.8079\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1529 - acc: 0.8422 - val_loss: 1.2080 - val_acc: 0.8158\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1516 - acc: 0.8438 - val_loss: 1.2777 - val_acc: 0.8003\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1559 - acc: 0.8413 - val_loss: 1.1978 - val_acc: 0.8209\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1503 - acc: 0.8437 - val_loss: 1.2418 - val_acc: 0.8026\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1532 - acc: 0.8434 - val_loss: 1.1566 - val_acc: 0.8417\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1535 - acc: 0.8433 - val_loss: 1.1630 - val_acc: 0.8390\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1544 - acc: 0.8418 - val_loss: 1.2479 - val_acc: 0.8034\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1508 - acc: 0.8434 - val_loss: 1.1944 - val_acc: 0.8264\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1514 - acc: 0.8433 - val_loss: 1.2005 - val_acc: 0.8206\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1506 - acc: 0.8437 - val_loss: 1.1729 - val_acc: 0.8338\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1533 - acc: 0.8414 - val_loss: 1.1640 - val_acc: 0.8377\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1510 - acc: 0.8418 - val_loss: 1.1880 - val_acc: 0.8319\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1505 - acc: 0.8431 - val_loss: 1.1702 - val_acc: 0.8384\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1494 - acc: 0.8433 - val_loss: 1.1900 - val_acc: 0.8267\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1516 - acc: 0.8426 - val_loss: 1.2123 - val_acc: 0.8165\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1503 - acc: 0.8428 - val_loss: 1.2443 - val_acc: 0.8137\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1508 - acc: 0.8415 - val_loss: 1.2041 - val_acc: 0.8264\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1486 - acc: 0.8429 - val_loss: 1.2087 - val_acc: 0.8193\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1505 - acc: 0.8409 - val_loss: 1.1908 - val_acc: 0.8258\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1498 - acc: 0.8436 - val_loss: 1.1662 - val_acc: 0.8384\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1480 - acc: 0.8453 - val_loss: 1.2158 - val_acc: 0.8150\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1475 - acc: 0.8441 - val_loss: 1.1798 - val_acc: 0.8314\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1476 - acc: 0.8449 - val_loss: 1.1839 - val_acc: 0.8265\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1500 - acc: 0.8433 - val_loss: 1.2079 - val_acc: 0.8256\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1457 - acc: 0.8447 - val_loss: 1.1675 - val_acc: 0.8374\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1476 - acc: 0.8428 - val_loss: 1.1765 - val_acc: 0.8350\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1477 - acc: 0.8439 - val_loss: 1.1550 - val_acc: 0.8400\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1480 - acc: 0.8440 - val_loss: 1.2170 - val_acc: 0.8185\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1459 - acc: 0.8449 - val_loss: 1.1962 - val_acc: 0.8241\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1472 - acc: 0.8455 - val_loss: 1.1933 - val_acc: 0.8272\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1443 - acc: 0.8445 - val_loss: 1.1794 - val_acc: 0.8324\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1470 - acc: 0.8435 - val_loss: 1.1711 - val_acc: 0.8335\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1437 - acc: 0.8454 - val_loss: 1.1621 - val_acc: 0.8380\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1445 - acc: 0.8442 - val_loss: 1.1599 - val_acc: 0.8379\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1421 - acc: 0.8457 - val_loss: 1.2122 - val_acc: 0.8223\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1474 - acc: 0.8430 - val_loss: 1.2028 - val_acc: 0.8261\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1423 - acc: 0.8450 - val_loss: 1.1839 - val_acc: 0.8257\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1452 - acc: 0.8433 - val_loss: 1.1552 - val_acc: 0.8412\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1407 - acc: 0.8468 - val_loss: 1.4026 - val_acc: 0.7478\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1454 - acc: 0.8445 - val_loss: 1.1841 - val_acc: 0.8305\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1406 - acc: 0.8456 - val_loss: 1.1779 - val_acc: 0.8335\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1435 - acc: 0.8456 - val_loss: 1.1714 - val_acc: 0.8348\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1437 - acc: 0.8434 - val_loss: 1.2121 - val_acc: 0.8220\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1424 - acc: 0.8456 - val_loss: 1.1609 - val_acc: 0.8368\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1413 - acc: 0.8459 - val_loss: 1.2991 - val_acc: 0.7972\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1448 - acc: 0.8429 - val_loss: 1.2566 - val_acc: 0.8104\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1410 - acc: 0.8447 - val_loss: 1.2084 - val_acc: 0.8241\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1400 - acc: 0.8456 - val_loss: 1.1667 - val_acc: 0.8347\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1417 - acc: 0.8444 - val_loss: 1.1763 - val_acc: 0.8313\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1428 - acc: 0.8446 - val_loss: 1.1660 - val_acc: 0.8353\n"
     ]
    }
   ],
   "source": [
    "l1_history = l1_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__L2 Regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(28 * 28,)))\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "l2_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 2.1480 - acc: 0.6742 - val_loss: 1.5078 - val_acc: 0.7431\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1808 - acc: 0.7924 - val_loss: 1.0462 - val_acc: 0.7896\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.8801 - acc: 0.8142 - val_loss: 0.8234 - val_acc: 0.8151\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.7490 - acc: 0.8278 - val_loss: 0.7166 - val_acc: 0.8252\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.6699 - acc: 0.8350 - val_loss: 0.6593 - val_acc: 0.8331\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.6230 - acc: 0.8414 - val_loss: 0.7079 - val_acc: 0.8206\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5859 - acc: 0.8469 - val_loss: 0.5701 - val_acc: 0.8506\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5536 - acc: 0.8528 - val_loss: 0.5758 - val_acc: 0.8463\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5332 - acc: 0.8551 - val_loss: 0.5426 - val_acc: 0.8537\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5169 - acc: 0.8590 - val_loss: 0.4854 - val_acc: 0.8678\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4998 - acc: 0.8636 - val_loss: 0.6316 - val_acc: 0.8197\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4944 - acc: 0.8643 - val_loss: 0.5493 - val_acc: 0.8433\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4828 - acc: 0.8660 - val_loss: 0.5550 - val_acc: 0.8425\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4673 - acc: 0.8710 - val_loss: 0.5017 - val_acc: 0.8569\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4628 - acc: 0.8723 - val_loss: 0.4737 - val_acc: 0.8647\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4579 - acc: 0.8737 - val_loss: 0.5146 - val_acc: 0.8444\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4498 - acc: 0.8742 - val_loss: 0.4879 - val_acc: 0.8600\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4430 - acc: 0.8770 - val_loss: 0.4613 - val_acc: 0.8685\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4363 - acc: 0.8786 - val_loss: 0.4972 - val_acc: 0.8553\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4357 - acc: 0.8800 - val_loss: 0.4495 - val_acc: 0.8676\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4266 - acc: 0.8805 - val_loss: 0.5393 - val_acc: 0.8424\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4238 - acc: 0.8813 - val_loss: 0.4968 - val_acc: 0.8593\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4193 - acc: 0.8824 - val_loss: 0.4651 - val_acc: 0.8637\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4186 - acc: 0.8830 - val_loss: 0.4422 - val_acc: 0.8705\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4143 - acc: 0.8842 - val_loss: 0.4584 - val_acc: 0.8651\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4107 - acc: 0.8855 - val_loss: 0.4248 - val_acc: 0.8832\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4094 - acc: 0.8867 - val_loss: 0.4653 - val_acc: 0.8670\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4068 - acc: 0.8857 - val_loss: 0.4543 - val_acc: 0.8679\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4013 - acc: 0.8873 - val_loss: 0.5118 - val_acc: 0.8428\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3981 - acc: 0.8899 - val_loss: 0.4451 - val_acc: 0.8695\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3943 - acc: 0.8911 - val_loss: 0.4657 - val_acc: 0.8672\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3969 - acc: 0.8888 - val_loss: 0.4347 - val_acc: 0.8764\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3950 - acc: 0.8892 - val_loss: 0.4772 - val_acc: 0.8598\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3905 - acc: 0.8919 - val_loss: 0.4368 - val_acc: 0.8706\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3857 - acc: 0.8929 - val_loss: 0.4565 - val_acc: 0.8685\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3864 - acc: 0.8921 - val_loss: 0.4686 - val_acc: 0.8629\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3852 - acc: 0.8930 - val_loss: 0.4997 - val_acc: 0.8440\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3840 - acc: 0.8931 - val_loss: 0.4528 - val_acc: 0.8662\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3818 - acc: 0.8931 - val_loss: 0.5099 - val_acc: 0.8496\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3792 - acc: 0.8947 - val_loss: 0.4417 - val_acc: 0.8749\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3789 - acc: 0.8969 - val_loss: 0.5532 - val_acc: 0.8425\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3776 - acc: 0.8951 - val_loss: 0.4462 - val_acc: 0.8719\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3782 - acc: 0.8953 - val_loss: 0.4543 - val_acc: 0.8683\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3725 - acc: 0.8960 - val_loss: 0.4204 - val_acc: 0.8812\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3749 - acc: 0.8967 - val_loss: 0.4185 - val_acc: 0.8802\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3718 - acc: 0.8978 - val_loss: 0.4632 - val_acc: 0.8580\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3717 - acc: 0.8980 - val_loss: 0.4688 - val_acc: 0.8616\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3707 - acc: 0.8981 - val_loss: 0.4159 - val_acc: 0.8809\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3709 - acc: 0.8972 - val_loss: 0.4321 - val_acc: 0.8790\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3679 - acc: 0.8979 - val_loss: 0.4695 - val_acc: 0.8658\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3670 - acc: 0.8992 - val_loss: 0.4451 - val_acc: 0.8713\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3620 - acc: 0.9005 - val_loss: 0.4327 - val_acc: 0.8765\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3662 - acc: 0.8996 - val_loss: 0.4679 - val_acc: 0.8574\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3591 - acc: 0.9019 - val_loss: 0.4171 - val_acc: 0.8801\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3635 - acc: 0.9005 - val_loss: 0.4599 - val_acc: 0.8627\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3609 - acc: 0.9010 - val_loss: 0.4044 - val_acc: 0.8879\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3607 - acc: 0.9005 - val_loss: 0.4119 - val_acc: 0.8838\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3608 - acc: 0.9024 - val_loss: 0.4365 - val_acc: 0.8762\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3592 - acc: 0.9019 - val_loss: 0.4369 - val_acc: 0.8750\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3567 - acc: 0.9034 - val_loss: 0.4411 - val_acc: 0.8712\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3565 - acc: 0.9023 - val_loss: 0.4555 - val_acc: 0.8665\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3556 - acc: 0.9039 - val_loss: 0.4376 - val_acc: 0.8727\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3549 - acc: 0.9037 - val_loss: 0.5352 - val_acc: 0.8446\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3553 - acc: 0.9032 - val_loss: 0.4437 - val_acc: 0.8747\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3555 - acc: 0.9022 - val_loss: 0.4200 - val_acc: 0.8782\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3529 - acc: 0.9026 - val_loss: 0.4231 - val_acc: 0.8802\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3538 - acc: 0.9043 - val_loss: 0.4365 - val_acc: 0.8771\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3490 - acc: 0.9070 - val_loss: 0.4653 - val_acc: 0.8632\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3506 - acc: 0.9036 - val_loss: 0.4168 - val_acc: 0.8814\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3502 - acc: 0.9059 - val_loss: 0.4077 - val_acc: 0.8867\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3507 - acc: 0.9049 - val_loss: 0.4015 - val_acc: 0.8878\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3514 - acc: 0.9035 - val_loss: 0.4652 - val_acc: 0.8672\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3475 - acc: 0.9062 - val_loss: 0.4303 - val_acc: 0.8730\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3470 - acc: 0.9064 - val_loss: 0.4043 - val_acc: 0.8845\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3486 - acc: 0.9056 - val_loss: 0.4687 - val_acc: 0.8656\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3466 - acc: 0.9066 - val_loss: 0.4241 - val_acc: 0.8806\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3447 - acc: 0.9069 - val_loss: 0.4173 - val_acc: 0.8803\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3461 - acc: 0.9072 - val_loss: 0.4269 - val_acc: 0.8764\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3437 - acc: 0.9069 - val_loss: 0.5975 - val_acc: 0.8334\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3441 - acc: 0.9067 - val_loss: 0.4060 - val_acc: 0.8866\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3398 - acc: 0.9089 - val_loss: 0.4334 - val_acc: 0.8783\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3431 - acc: 0.9071 - val_loss: 0.3982 - val_acc: 0.8899\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3447 - acc: 0.9074 - val_loss: 0.4662 - val_acc: 0.8666\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3430 - acc: 0.9081 - val_loss: 0.4318 - val_acc: 0.8753\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3386 - acc: 0.9099 - val_loss: 0.4253 - val_acc: 0.8833\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3393 - acc: 0.9091 - val_loss: 0.4605 - val_acc: 0.8708\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3422 - acc: 0.9083 - val_loss: 0.5057 - val_acc: 0.8596\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3379 - acc: 0.9102 - val_loss: 0.4128 - val_acc: 0.8822\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3412 - acc: 0.9082 - val_loss: 0.4428 - val_acc: 0.8740\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3364 - acc: 0.9097 - val_loss: 0.4347 - val_acc: 0.8746\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3383 - acc: 0.9091 - val_loss: 0.4388 - val_acc: 0.8710\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3414 - acc: 0.9082 - val_loss: 0.4206 - val_acc: 0.8793\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3395 - acc: 0.9091 - val_loss: 0.4165 - val_acc: 0.8816\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3360 - acc: 0.9098 - val_loss: 0.6708 - val_acc: 0.8215\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3373 - acc: 0.9092 - val_loss: 0.4307 - val_acc: 0.8775\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3359 - acc: 0.9108 - val_loss: 0.3909 - val_acc: 0.8913\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3325 - acc: 0.9106 - val_loss: 0.4520 - val_acc: 0.8690\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3369 - acc: 0.9100 - val_loss: 0.3941 - val_acc: 0.8899\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3334 - acc: 0.9103 - val_loss: 0.4476 - val_acc: 0.8730\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3326 - acc: 0.9117 - val_loss: 0.5043 - val_acc: 0.8577\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3342 - acc: 0.9113 - val_loss: 0.4076 - val_acc: 0.8866\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3341 - acc: 0.9118 - val_loss: 0.4215 - val_acc: 0.8792\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3322 - acc: 0.9108 - val_loss: 0.4411 - val_acc: 0.8718\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3349 - acc: 0.9110 - val_loss: 0.4079 - val_acc: 0.8813\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3322 - acc: 0.9119 - val_loss: 0.4259 - val_acc: 0.8813\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3319 - acc: 0.9124 - val_loss: 0.3998 - val_acc: 0.8897\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3318 - acc: 0.9110 - val_loss: 0.4616 - val_acc: 0.8692\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3305 - acc: 0.9119 - val_loss: 0.4074 - val_acc: 0.8874\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3306 - acc: 0.9129 - val_loss: 0.5062 - val_acc: 0.8386\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3286 - acc: 0.9128 - val_loss: 0.4566 - val_acc: 0.8740\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3296 - acc: 0.9131 - val_loss: 0.4071 - val_acc: 0.8887\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3289 - acc: 0.9122 - val_loss: 0.4702 - val_acc: 0.8648\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3302 - acc: 0.9132 - val_loss: 0.4445 - val_acc: 0.8762\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3278 - acc: 0.9134 - val_loss: 0.4213 - val_acc: 0.8802\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3275 - acc: 0.9137 - val_loss: 0.4679 - val_acc: 0.8649\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3252 - acc: 0.9137 - val_loss: 0.4502 - val_acc: 0.8742\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3271 - acc: 0.9136 - val_loss: 0.4323 - val_acc: 0.8793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3293 - acc: 0.9132 - val_loss: 0.4446 - val_acc: 0.8749\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3282 - acc: 0.9127 - val_loss: 0.4384 - val_acc: 0.8812\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3289 - acc: 0.9127 - val_loss: 0.4440 - val_acc: 0.8772\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3269 - acc: 0.9136 - val_loss: 0.4840 - val_acc: 0.8556\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3267 - acc: 0.9139 - val_loss: 0.4448 - val_acc: 0.8732\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3288 - acc: 0.9131 - val_loss: 0.4343 - val_acc: 0.8744\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3292 - acc: 0.9136 - val_loss: 0.4148 - val_acc: 0.8869\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3269 - acc: 0.9142 - val_loss: 0.4559 - val_acc: 0.8697\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3248 - acc: 0.9139 - val_loss: 0.4686 - val_acc: 0.8705\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3247 - acc: 0.9152 - val_loss: 0.4476 - val_acc: 0.8803\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3296 - acc: 0.9127 - val_loss: 0.5337 - val_acc: 0.8527\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3246 - acc: 0.9139 - val_loss: 0.4470 - val_acc: 0.8754\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3301 - acc: 0.9129 - val_loss: 0.4748 - val_acc: 0.8682\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3224 - acc: 0.9149 - val_loss: 0.4749 - val_acc: 0.8663\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3230 - acc: 0.9153 - val_loss: 0.4497 - val_acc: 0.8777\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3237 - acc: 0.9152 - val_loss: 0.4231 - val_acc: 0.8787\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3270 - acc: 0.9132 - val_loss: 0.4404 - val_acc: 0.8749\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3268 - acc: 0.9148 - val_loss: 0.4339 - val_acc: 0.8776\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3244 - acc: 0.9152 - val_loss: 0.4481 - val_acc: 0.8669\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3244 - acc: 0.9152 - val_loss: 0.4254 - val_acc: 0.8802\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3217 - acc: 0.9151 - val_loss: 0.4825 - val_acc: 0.8638\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3262 - acc: 0.9142 - val_loss: 0.4167 - val_acc: 0.8841\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3229 - acc: 0.9149 - val_loss: 0.4637 - val_acc: 0.8634\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3243 - acc: 0.9141 - val_loss: 0.4119 - val_acc: 0.8879\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3226 - acc: 0.9150 - val_loss: 0.4237 - val_acc: 0.8837\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3173 - acc: 0.9173 - val_loss: 0.4262 - val_acc: 0.8824\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3218 - acc: 0.9169 - val_loss: 0.4599 - val_acc: 0.8718\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3213 - acc: 0.9156 - val_loss: 0.4572 - val_acc: 0.8689\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3245 - acc: 0.9143 - val_loss: 0.4492 - val_acc: 0.8794\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3184 - acc: 0.9181 - val_loss: 0.4494 - val_acc: 0.8771\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3218 - acc: 0.9143 - val_loss: 0.4670 - val_acc: 0.8720\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3213 - acc: 0.9171 - val_loss: 0.4223 - val_acc: 0.8883\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3201 - acc: 0.9167 - val_loss: 0.4425 - val_acc: 0.8764\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3184 - acc: 0.9163 - val_loss: 0.4769 - val_acc: 0.8754\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3216 - acc: 0.9151 - val_loss: 0.4328 - val_acc: 0.8784\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3213 - acc: 0.9151 - val_loss: 0.4788 - val_acc: 0.8669\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3179 - acc: 0.9170 - val_loss: 0.4224 - val_acc: 0.8810\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3210 - acc: 0.9154 - val_loss: 0.4076 - val_acc: 0.8892\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3197 - acc: 0.9160 - val_loss: 0.4219 - val_acc: 0.8835\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3159 - acc: 0.9196 - val_loss: 0.4432 - val_acc: 0.8798\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3238 - acc: 0.9146 - val_loss: 0.4684 - val_acc: 0.8660\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3205 - acc: 0.9169 - val_loss: 0.4329 - val_acc: 0.8793\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3227 - acc: 0.9164 - val_loss: 0.4443 - val_acc: 0.8747\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3184 - acc: 0.9177 - val_loss: 0.4821 - val_acc: 0.8639\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3168 - acc: 0.9183 - val_loss: 0.4426 - val_acc: 0.8734\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3180 - acc: 0.9170 - val_loss: 0.4804 - val_acc: 0.8670\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3210 - acc: 0.9158 - val_loss: 0.4025 - val_acc: 0.8923\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3173 - acc: 0.9179 - val_loss: 0.5277 - val_acc: 0.8521\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3194 - acc: 0.9179 - val_loss: 0.4334 - val_acc: 0.8770\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3162 - acc: 0.9192 - val_loss: 0.4159 - val_acc: 0.8861\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3149 - acc: 0.9189 - val_loss: 0.4160 - val_acc: 0.8899\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3201 - acc: 0.9174 - val_loss: 0.4246 - val_acc: 0.8858\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3202 - acc: 0.9181 - val_loss: 0.5162 - val_acc: 0.8526\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3159 - acc: 0.9185 - val_loss: 0.4255 - val_acc: 0.8846\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3171 - acc: 0.9174 - val_loss: 0.4352 - val_acc: 0.8769\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3177 - acc: 0.9186 - val_loss: 0.4351 - val_acc: 0.8836\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3196 - acc: 0.9180 - val_loss: 0.4297 - val_acc: 0.8826\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3170 - acc: 0.9179 - val_loss: 0.5150 - val_acc: 0.8623\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3157 - acc: 0.9187 - val_loss: 0.5033 - val_acc: 0.8591\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3198 - acc: 0.9184 - val_loss: 0.4149 - val_acc: 0.8867\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3173 - acc: 0.9195 - val_loss: 0.4340 - val_acc: 0.8797\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3150 - acc: 0.9186 - val_loss: 0.4815 - val_acc: 0.8642\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3180 - acc: 0.9188 - val_loss: 0.4297 - val_acc: 0.8858\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3183 - acc: 0.9169 - val_loss: 0.4522 - val_acc: 0.8730\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3186 - acc: 0.9184 - val_loss: 0.4813 - val_acc: 0.8717\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3129 - acc: 0.9199 - val_loss: 0.4771 - val_acc: 0.8649\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3182 - acc: 0.9169 - val_loss: 0.4099 - val_acc: 0.8883\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3155 - acc: 0.9195 - val_loss: 0.4439 - val_acc: 0.8784\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3160 - acc: 0.9188 - val_loss: 0.4833 - val_acc: 0.8653\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3166 - acc: 0.9172 - val_loss: 0.4624 - val_acc: 0.8732\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3147 - acc: 0.9182 - val_loss: 0.4821 - val_acc: 0.8669\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3147 - acc: 0.9184 - val_loss: 0.4854 - val_acc: 0.8639\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3172 - acc: 0.9194 - val_loss: 0.4441 - val_acc: 0.8769\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3230 - acc: 0.9148 - val_loss: 0.4235 - val_acc: 0.8873\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3090 - acc: 0.9205 - val_loss: 0.4701 - val_acc: 0.8734\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3121 - acc: 0.9202 - val_loss: 0.4653 - val_acc: 0.8720\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3151 - acc: 0.9187 - val_loss: 0.4454 - val_acc: 0.8745\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3122 - acc: 0.9187 - val_loss: 0.4338 - val_acc: 0.8832\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3130 - acc: 0.9184 - val_loss: 0.5209 - val_acc: 0.8523\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3159 - acc: 0.9190 - val_loss: 0.4274 - val_acc: 0.8819\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3110 - acc: 0.9207 - val_loss: 0.4367 - val_acc: 0.8762\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3140 - acc: 0.9194 - val_loss: 0.5313 - val_acc: 0.8591\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3147 - acc: 0.9184 - val_loss: 0.5191 - val_acc: 0.8618\n"
     ]
    }
   ],
   "source": [
    "l2_history = l2_model.fit(X_train,\n",
    "                          y_train,\n",
    "                          epochs=200,\n",
    "                          batch_size=512,\n",
    "                          validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_history_dict = l1_history.history\n",
    "l1_val_loss = l1_history_dict['val_loss']\n",
    "l2_history_dict = l2_history.history\n",
    "l2_val_loss = l2_history_dict['val_loss']\n",
    "min_loss_epoch_l1 = l1_val_loss.index(min(l1_val_loss))\n",
    "min_loss_epoch_l2 = l2_val_loss.index(min(l2_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGDCAYAAAAyM4nNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl8U2XWwPHfSVvWVraCiICAA2VpoewgIiJuyKJgAUdU0Bk3RhnHd1BUVJRBRdFx1NG6Au5sgqCo40JZVMSCBUR2BEG2gmylQEvzvH/cJKQhadOmSdrkfP3cT9rk3puTcO25z3Of+xwxxqCUUkqpis8W7gCUUkopVTY0qSullFIRQpO6UkopFSE0qSullFIRQpO6UkopFSE0qSullFIRQpO6imoi8pmIjCji9XQRedjPfWWIyF/LLjqllCoZTeoq4ojINhG51J91jTF9jTHTHNuNFJGlHq/fYYyZEIw4S0pEmoiIEZEcx7JXRD4RkcvCHZs3bvHGhut9RCRZRL4Qkf0iEpJJOURkqoj8y8vz9UTkAxHZJSKHReRbEekaiphU9NCkrlTFU9MYEw+0A74E5ojISG8rBjuhVgD5wAzgL+EOBIgHfgQ6ArWBacCnIhIf1qhURNGkriKas/UtIpNF5KCI/Coifd1ezxCRv4pIKyAd6O5oBR9yvO5qdYlILUfLONuxr09EpKEfMTQQkeMiUtvtufaO1mOciPxJRBY5Wm/7RWS6P5/NGLPHGPMfYDwwSURsjn1vE5H7RWQ1cExEYkWkleOzHhKRtSIy0C2WqY7LDF+KyFFHLOe5vX6BiPzoiO9HEbnA7bVCvSIiMl5E3nX8utjxeMjxnXYPxffi8R1tMMa8Cawtbl0ReUVEJns897GI3Ov4+X4R+d3xHW0QkT4ljGWrMeY5Y8xuY0yBMeY1oBKQVJL9KFUUTeoqGnQFNgCJwNPAmyIi7isYY9YBdwDfG2PijTE1vezHBkwBzgMaA8eBl4p7c2PMLuB74Fq3p68HZhlj8oEJwP+AWkBD4MUSfTr4CKhH4eTwZ6AfUBMQYL7jPeoBdwPviYj7+sMdcSQCWcB7AI6E+ynwAlAHeA6rdVnHj7gucjzWdHyn37u/GILvpaQ+AIY5jw0RqQVcDnzo+K7uAjobYxKAK4BtgbyZiKRiJfXNgexHKXea1FU02G6Med0YU4DV5XkOcHZJd2KMOWCMmW2MyTXGHAUmAr383Px9rESLI2lc53gOrC7i84AGxpgTxpil3nfh0y7HY223514wxuwwxhwHumF1/T5ljMkzxnwDfOKMx+FTY8xiY8xJ4CGsHotGWCcGm4wx7xhjThljPgDWAwNKGKMvwfxeSmoJYICejt/TsE7ydgEFQGWgtYjEGWO2GWO2lPaNROQs4B3gMWPM4QDjVspFk7qKBnucPxhjch0/lvg6pohUE5FXRWS7iBzB6l6uKSIxfmw+GytRnoPVgrVjJRGA+7Ba08sdXeO3lDC0cx2Pf7g9t8Pt5wbADmOM3e257W7bFVrfGJPj2FcDx7Ld4/08tw1EML+XEjFWdasPOX2ycz2OHgtjzGbgHqxLHftE5EMRaVCa9xGRqlg9J8uMMU8GGrdS7jSpK3VacaOj/w+ri7urMeYsTncvi+9NHDs25iBWV/IwrGTxoSOJOK+N32qMaQDcDrwsIn8qQdyDgH1Ylxi8fZZdQCPnNXeHxsDvbr83cv7gGLhV27HdLqzWsjv3bY8B1dxeq+8jBq+C/L2UxgdAmmNMQVeskw5nrO8bYy7E+j4MMKmkOxeRysBcYCfWZ1KqTGlSV+q0vUBDEank4/UErOvohxzXmh8t4f7fB27C6tZ1djEjIkPcBtwdxEoY9jM3L0xEzhaRuxxxPODREnf3A5AL3OcYgHYxVvf5h27rXCUiFzo++wSsVuQOYAHQQkSudwy4Gwa0xuq+B+v6+3WO/XZyfDanbMfnaFbMRymr76WyiFRxW2xiqYJ17RrH85V97cAY8xOwH3gD+MIY4xwwmSQilzi2PYF1HBQVS4xHLJVEJA6Y5dh2RBH/XkqVmiZ1pU77BmuU9B4R2e/l9eeBqlh/9JcBn5dw//OA5sAeY8wqt+c7Az+ISI5jnb8bY7YWsZ9DInIMWANcBQwxxrzla2VjTB5WEu/riP1l4CZjzHq31d7HOjn4A+uWqxsc2x4A+mP1UhzA6hLvb4xxfj8PA+djJd3HcEvKjksdE4FvHaPuuwX5e8nBSpjO5RKsVvVxTo9+P07hHg1v3gcudf8sWNfTn8L6/vZgDTh8oIh9jPWI5RvgAqzv8nJO3xGQIyI9fe9GqZIRR0+XUipKichUYKcxZly4Y1FKBUZb6koppVSE0KSulFJKRQjtfldKKaUihLbUlVJKqQihSV0ppZSKEBWuglNiYqJp0qRJuMNQqsKzO+6StumpvSov9KD0acWKFfuNMXWLW6/CJfUmTZqQmZkZ7jCUUkqpkBERz+mavdLTIaWi1MsvW4tS5YYelAHTpK5UlJoxw1qUKjf0oAyYJnWllFIqQlS4a+pKKVVe5Ofns3PnTk6cOBHuUCLDo44aSevWhTeOMKpSpQoNGzYkLi6uVNtrUldKqVLauXMnCQkJNGnSBJFiK/Cq4jhHvSclhTeOMDHGcODAAXbu3EnTpk1LtQ/tfldKqVI6ceIEderU0YSuyoSIUKdOnYB6frSlrlSUysgIdwSRQRN6GYrSFrq7QI8nbakrpVQFdsEFFxS7zl//+ld++eUXAJ544okSbx8fH1+64HzsZ9euXaSlpXld5+KLLy52LpLnn3+e3Nxc1+9XXXUVhw4dCji+8ePHM3ny5ID3E06a1JWKUpMnW4uq2L777rti13njjTdo3bo1cGZS92f7stagQQNmzZp15gt79kBeXrHbeyb1BQsWULNmzbIMscLSpA5k52YzYdkE0uZ5P3NUKhJ98om1qNBasf0g/124mRXbD5bJ/pyt34yMDC6++GLS0tJo2bIlw4cPx1mF09n6HTt2LMePHyc1NZXhw4cX2j4nJ4c+ffrQoUMHUlJS+Pjjj4t837Fjx/Lf//7X9buzlevPfrZt20ZycjIAx48f57rrrqNVq1YMuvFGjh875lrvzjvvpFOnTrRp04ZHHSPjX3jhBXbt2kXv3r3p3bs3YM00un//fgCee+45kpOTSU5O5vnnn3e9X6tWrbj11ltp06YNl19+OcePHy/y82VlZdGtWzfatm3LoEGDOHjwoOv9W7duTdu2bbnuuusAWLRoEampqaSmptK+fXuOHj1a5L6DKaqvqWfnZpO+Op2PN3+M3djJt+eHOySlVAX12Py1/LLrSJHrHD2Rz/o9R7EbsAm0rJ9AQhXfty61bnAWjw5o43cMP/30E2vXrqVBgwb06NGDb7/9lgsvvND1+lNPPcVLL71EVlbWGdtWqVKFOXPmcNZZZ7F//366devGwIEDfV7jHTZsGPfccw9/+9vfAJgxYwZffPFFiffzyiuvUK1aNdatW8fqefPoMHiw67WJEydSu3ZtCgoK6NOnD6tXr2b06NE899xzLFy4kMTExEL7WrFiBVOmTOGHH37AGEPXrl3p1asXtWrVYtOmTXzwwQe8/vrrDB06lNmzZ3PDDTf4/C5vuukmXnzxRXr16sUjjzzCY489xvPPP89TTz3Fr7/+SuXKlV1d/pMnT+a///0vPXr0ICcnhypVqvjcb7BFZUvd2TK/8qMrmb1xNicLTmpCV0oF3ZETp7BbjWfsxvq9LHXp0oWGDRtis9lITU1l27Ztfm9rjOHBBx+kbdu2XHrppfz+++/s3bvX5/rt27dn37597Nq1i1WrVlGrVi0aNWpU4v0sXrzYlVzbJiXR1m2w3IwZM+jQoQPt27dn7dq1rnEBvixdupRBgwZRvXp14uPjGTx4MEuWLAGgadOmpKamAtCxY8civ5vDhw9z6NAhevXqBcCIESNYvHixFWPbtgwfPpx3332X2FirXdyjRw/uvfdeXnjhBQ4dOuR6PhyisqU+ZvEYVu5dicGEOxSlVITwp0W9YvtBhr+xjPxTduJibfznuvZ0PK9WmcVQuXJl188xMTGcOuX/ScN7771HdnY2K1asIC4ujiZNmhR7a9WQIUOYNWsWe/bsYdiwYaXejze//vorkydP5scff6RWrVqMHDkyoFu9PL+b4rrfffn0009ZvHgx8+fPZ+LEiaxZs4axY8fSr18/FixYQI8ePfjiiy9o2bJlqWMNRFS21Cf3mszQpKHE2Uo3Y49SkaBqVWtRodPxvFq899du3Ht5Eu/9tVuZJnR/xcXFkZ9/Zs/k4cOHqVevHnFxcSxcuJDt24svCjZs2DA+/PBDZs2axZAhQ0q1n4suuoj3338fgJ83bWL1hg0AHDlyhOrVq1OjRg327t3LZ5995tomISHB63Xrnj17MnfuXHJzczl27Bhz5syhZ8+exX4OTzVq1KBWrVquVv4777xDr169sNvt7Nixg969ezNp0iQOHz5MTk4OW7ZsISUlhfvvv5/OnTuzfv36Er9nWYnKlnpi1UTGdRtHj3N7MPqb0a7krl3wKpq4/Y1UIdTxvFphSeZOt912G23btqVDhw689957rueHDx/OgAEDSElJoVOnTn61NNu0acPRo0c599xzOeecc0q1nzvvvJObb76ZVq1a0apVKzp27AhAu3btaN++PS1btqRRo0b06NGj0Ge48soradCgAQsXLnQ936FDB0aOHEmXLl0A61a+9u3bl+gyhNO0adO44447yM3NpVmzZkyZMoWCggJuuOEGDh8+jDGG0aNHU7NmTR5++GEWLlyIzWajTZs29O3bt8TvV1bEOTqyoujUqZMpq3rqq7NXM3zBcJ688EmysrPI2pfFrIFebrNQSikv1q1bR6tWrcIdhoow3o4rEVlhjOlU3LZR2VJ3irHFABBfKZ5x3caFORqlQmvCBOvx4YfDG4dSLrt2WY8NGoQ3jgosKq+pO8WKdU5TYC8IcyRKhd7XX1uLUuXG0aPWokotqpN6jFgt9VOmbG8rUUoppcIhupO6o/tdW+pKKaUiQVQndVf3u9GkrpRSquLTgXLAKbt2v6voU6dOuCNQykNMTLgjqPCiuqXuvKauLXUVjWbPthYVOcJdOtSzAlyJ/elP1kLhIi2+ysOOHDnSe7U3N1OnTmWXc1Q9hcvQBmLq1KncddddAe+nrGlLHb2mrpQKgfQLYc+aM5+vnwJ3LA3qW586dSok85E/8cQTPPjgg2W+30DKw06dOpXk5GQaOG6Te+ONN8oqrHJJW+ro6HcVnR54wFpUiDTsAjGVCj8XU8l6PgATJ06kRYsWXHjhhWxwTLEKVrnVe+65h06dOvGf//yHbdu2cckll9C2bVv69OnDb7/9Blit3TvuuINOnTrRokULPnHU4z1x4gQ333wzKSkptG/f3jVzm2cLtX///mRkZHgt6+qUnp7OmDFjXL+77+Oaa66hY8eOtGnThtcmTYKdO8/4jM7ysMYY7rrrLpKSkrj00kvZt2+fa53HH3+czp07k5yczG233YYxhlmzZpGZmcnw4cNJTU3l+PHjrjK0AB988AEpKSkkJydz//33F3q/hx56iHbt2tGtW7ciC9IAPr/bmTNnkpycTLt27bjooosAWLt2LV26dCE1NZW2bduyadOmIvddUtpSB+zGHuZIlAq9778PdwQR5rOx3lviTqfywHP8jv2Utc2Uft63qZ8CfZ/yucsVK1bw4YcfkpWVxalTp+jQoYNrmlWAvLw8VwIbMGAAI0aMYMSIEbz11luMHj2auXPnAlZSWr58OVu2bKF3795s3ryZ//73v4gIa9asYf369Vx++eVs3LjRZyxFlXW99tpr6d69O8888wwA06dP56GHHgLgrbfeonbt2hw/fpzO7dpxba9e1GnY0Ot7zJkzhw0bNvDLL7+wd+9eWrduzS233ALAXXfdxSOPPALAjTfeyCeffEJaWhovvfQSkydPplOnwpOx7dq1i/vvv58VK1ZQq1YtLr/8cubOncs111zDsWPH6NatGxMnTuS+++7j9ddfZ9w43xOU3X333V6/28cff5wvvviCc88911WmNT09nb///e8MHz6cvLw8CgrKtqc4qlvqOvmMUipkYitB9XqAs664WL97tt5LYMmSJQwaNIhq1apx1llnMXDgwEKvOyunAXz//fdcf/31gJX0li493eU/dOhQbDYbzZs3p1mzZqxfv56lS5e6SqK2bNmS8847r8ikXpS6devSrFkzli1bxoEDB1i/fr1rLvcXXnjB1SLesXs3m4ooALN48WL+/Oc/ExMTQ4MGDbjkkktcry1cuJCuXbuSkpLCN998w9q1a4uM6ccff+Tiiy+mbt26xMbGMnz4cFd51UqVKtG/f3+g+DKt4Pu77dGjByNHjuT11193Je/u3bvzxBNPMGnSJLZv307VMq6qFPSWuojEAJnA78aY/h6vVQbeBjoCB4BhxphtwY7JyTX6XbvflVKBKqJF7XJ0D/ynHZw6AbGV4fbFkHB20EKqXr26X+uJSJG/u4uNjcVuP9276W851Ouuu44ZM2bQsmVLBg0ahIiQkZHBV199xffff0+1atW4uEsXTpw86df+3J04cYJRo0aRmZlJo0aNGD9+fEBlWuPi4lzfQUlL2LpLT0/nhx9+4NNPP6Vjx46sWLGC66+/nq5du/Lpp59y1VVX8eqrrxY6OQlUKFrqfwfW+XjtL8BBY8yfgH8Dk0IQj4tr9Lu21JVSoZBQH1KHg9isxwAT+kUXXcTcuXM5fvw4R48eZf78+T7XveCCC/jwww8Bq+a5e0nSmTNnYrfb2bJlC1u3biUpKYmePXu6qrht3LiR3377jaSkJJo0aUJWVparDOny5ctd+/FV1hVg0KBBfPzxx3zwwQdcd911gFWmtVatWlSrVo3169ezbNWqYj/v9OnTKSgoYPfu3a7r/M4EnpiYSE5OTqER8b7KtHbp0oVFixaxf/9+CgoK+OCDD+jVq1eR7++Lr+92y5YtdO3alccff5y6deuyY8cOtm7dSrNmzRg9ejRXX301q1evLtV7+hLUlrqINAT6AROBe72scjUw3vHzLOAlERETotJxekubimY+LluqYOt1H2Svg173F79uMTp06MCwYcNo164d9erVo3Pnzj7XffHFF7n55pt55plnqFu3LlOmTHG91rhxY7p06cKRI0dIT0+nSpUqjBo1ijvvvJOUlBRiY2OZOnUqlStXpkePHjRt2pTWrVvTqlUrOnTo4NqPr7KuALVq1aJVq1b88ssvrtKoV155Jenp6bRq1YqkpCS6tW8PRYzSHzRoEN988w2tW7emcePGdO/eHYCaNWty6623kpycTP369Qt9D86BgFWrVuV7t4Ek55xzDk899RS9e/fGGEO/fv24+uqr/fzm/ftux4wZw6ZNmzDG0KdPH9q1a8ekSZN45513iIuLo379+mV+t0BQS6+KyCzgSSAB+KeX7vefgSuNMTsdv28Buhpj9nusdxtwG0Djxo07bi/imktJpb6dyi3JtzC6w+gy26dSKjpEQunVkSNH0r9/f9LS0sIdinIIpPRq0LrfRaQ/sM8YsyLQfRljXjPGdDLGdKpbt24ZRHdajMRoS10ppVRECGb3ew9goIhcBVQBzhKRd40xN7it8zvQCNgpIrFADawBcyETY4vRa+oqKt1zj/X4/PPhjUOF19SpU8MdwmmO+7tp3Di8cVRgQWupG2MeMMY0NMY0Aa4DvvFI6ADzgBGOn9Mc64TkerqTttRVtMrKshalyo3jx61FlVrIJ58RkceBTGPMPOBN4B0R2Qz8gZX8QyrGFqMFXZRSSkWEkCR1Y0wGkOH4+RG3508AQ0IRgy8xEqMzyimllIoIUT2jHFizymn3u1JKqUgQ9Uldu99VtGrRwlpUZLvqqqs4dOgQhw4d4uWXX3Y9n5GR4ZoKtSi+ypteeeWV1KxZ0699+GvkQw8x6+uvAd8lUv0peZqRkVGoslt6ejpvv/12wPFt27aN5OTkgPcTTFFd0AV0oJyKXq+9Fu4Iolt2bjbpq9NZtW8VswYWXRM8EAsWLACshPTyyy8zatSoMtnvmDFjyM3N5dVXXy2T/QEQHw/16gGBlUjNyMggPj7eVYf9jjvuKJPwKoKob6nH2mL1ljalVMhk52YzYdkE+n7Ulzmb5rDh4IbiN/LhmWee4YUXXgDgH//4h2sO8W+++cZV/rRJkybs37+fsWPHsmXLFlJTU11lUHNyckhLS6Nly5YMHz6cktx81KdPHxISEny+vn79etfMcWCdVKSkpADey6R6ci+ROmXKFFq0aEGXLl349ttvXevMnz+frl270r59ey699FL27t3Ltm3bSE9P59///jepqaksWbKE8ePHM3nyZACysrLo1q0bbdu2ZdCgQRw8eND1fvfffz9dunShRYsWLFmypMjP76s0rbfSqseOHaNfv360a9eO5ORkpk+f7s9XXCraUpcYLeiiotJtt1mP2mIvG5OWT2L9H+t9vp5XkMfuY7vZf9yaMNNwOpHd/PnNXrdpWbsl93fxPZ1sz549efbZZxk9ejSZmZmcPHmS/Px8lixZ4qrf7fTUU0/x888/u0qjZmRk8NNPP7F27VoaNGhAjx49+Pbbb7nwwgv9/sxFadmyJXl5efz66680bdqU6dOnu6rGeSuTOmDAAMjJAbca6QC7d+/m0UcfZcWKFdSoUYPevXvTvn17AC688EKWLVuGiPDGG2/w9NNP8+yzz3LHHXcQHx/PP//5TwC+dnTpA9x00028+OKL9OrVi0ceeYTHHnuM5x2TNZw6dYrly5ezYMECHnvsMb766iufn89XaVpvpVUXLFhAgwYN+PTTTwFrzvtgifqWuk4+o6LVxo3WokJj6+GtZB/Pxjj+KwvOyl9HjhyhcuXKdO/enczMTJYsWVKoYIsvXbp0oWHDhthsNlJTU4stMVpSQ4cOdbVK3ZO6zzKpBQXgURDmhx9+cJVIrVSpUqFysjt37uSKK64gJSWFZ555pthyq4cPH+bQoUOuwi0jRoxwlVsFGDx4MOBfuVVfpWm9lVZNSUnhyy+/5P7772fJkiXUqFGjmG+u9LSlrtfUlVJloKgWNcD+4/tJX5XO3M1zsRs7+fbTyWvKlVOK2NK3uLg4mjZtytSpU7ngggto27YtCxcuZPPmzX7NSV+5cmXXz4GUGPVl2LBhDBkyhMGDByMiNG/evEzLpN59993ce++9DBw4kIyMDMaPHx9QvM7vI5Dvwldp1ZUrV7JgwQLGjRtHnz59XD0VZU1b6tr9rpQKgcSqiYzrNo7Pr/2cwc0HUzmmMnG2uID327NnTyZPnsxFF11Ez549SU9Pp3379mfURPdVgjSYzj//fGJiYpgwYYKrhV1UmVRvunbtyqJFizhw4AD5+fnMnDnT9drhw4c599xzAZg2bZrreV+ftUaNGtSqVct1vfydd94pdblVX6VpvZVW3bVrF9WqVeOGG25gzJgxrFy5slTv6Q9N6tr9rpQKIc/knlQrKaD99ezZk927d9O9e3fOPvtsqlSp4rXrvU6dOvTo0YPk5GTXQDl/3X777TRs2JCGDRu6yp327NmTIUOG8PXXX9OwYUO++OILr9sOGzaMd999l6FDhwKFy6ReccUVRZaLBatE6vjx4+nevTs9evQo1AMxfvx4hgwZQseOHUlMTHQ9P2DAAObMmeMaKOdu2rRpjBkzhrZt25KVlVXqFvOoUaOw2+2kpKQwbNgwV2naGTNmkJycTGpqKj///DM33XQTa9ascQ2ee+yxxxg3blyp3tMfQS29GgydOnUyzhGRZWHEZyOItcXy5hVvltk+laoItKBL4CKh9Gq5ogVdgMBKr0b9NfVYW6xOPqOikiZzVe5EeTIvC9r9rgPllFJKRQhN6npNXUWpG26wFqXKja1brUWVmna/a0EXFaV27gx3BEp58LhHXZWcttRtekubUkqpyKBJXbT7XSmlVGTQpG7TgXJKqcgVjNKrWVlZdO/enTZt2tC2bdsyK1AycuxYZn3+OaClV0sr6q+px4jWU1fRyTGHiAqRrdcMompqKomj7iTOUV40FIJRerVatWq8/fbbNG/enF27dtGxY0euuOIKatasGdiOY2OhShVAS6+WlrbU9ZY2FaWefNJaVGicXL+eQ7Nns+Wyy9k9/jHyPaqRlUa4Sq+2aNGC5s2bA9CgQQPq1atHdnZ2oXVKVXq1enWoUwfQ0qulFfUtda2nrpQqC3ueeIKT63yXXgUgPx8DHJo+nUPTpxOTmEilBg2QSpW8rl65VUvqP/igz92Vh9Kry5cvJy8vj/PPP7/Q86UqveqFll4tGW2pa0tdRalrr7UWFQbGgDEUZGdzcsuWUu8m3KVXd+/ezY033siUKVOw2c5MJyUuvXrkCOzeXWgfWnq1ZKK+pa4D5VS0OnAg3BFElqJa1ADrWrrN5R0Xh9hs1Bg8mLqj7iS2bt1SvWc4S68eOXKEfv36MXHiRLp16+Z1nRKXXjUG7Ha/Y9DSq2fSlrre0qaUCpW4OKRyZWqmpfGnr77knEcfKXVCdwpH6dW8vDwGDRrETTfdRFpams/1tPRq6EuvRn1LPdamM8oppYKvcsuWVG3fPqCWuTc9e/Zk4sSJdO/enerVq/tVerVv377069fP7/e4/fbbucdR1q9Ro0b87W9/Y/HixRw4cICpU6cC1q1mqampZ2w7bNgwxowZw6+//goULr1av379EpVerVmzZqH3cJZerVWrFpdcconrPQYMGEBaWhoff/wxL774YqH9TZs2jTvuuIPc3FyaNWvGlClT/P4e3I0aNYo777yTlJQUYmNjC5Vefeedd4iLi6N+/fo8+OCD/Pjjj4wZMwabzUZcXByvvPJKqd7TH1FfevX5Fc/z9i9vs/LG4J05KVUeXXyx9ZiREc4oKjYtvVrGNmywHpMCqzFf0Wnp1QDoNXUVrfr0CXcESnlISAh3BBVe1Cf1WInFbuzYjR2bRP0QAxVFHn443BEo5aFBg3BHUOFFfRaLscUAaGtdKaVUhRe0pC4iVURkuYisEpG1IvKYl3VGiki2iGQ5lr8GKx5fnK1zHQGvok1l6CXFAAAgAElEQVTfvtaiVLmxcaO1qFILZvf7SeASY0yOiMQBS0XkM2PMMo/1phtjip6dP4hixfoKtKWuos3x4+GOQCkPFWzgdnkUtKRurGH1OY5f4xxLufsX0+53pZRSkSKo19RFJEZEsoB9wJfGmB+8rHatiKwWkVki0iiY8XgTI46krt3vSqkKKD4+/oznFi9eTIcOHYiNjS12cpfizJs3j6eeeirgmFRoBDWpG2MKjDGpQEOgi4h4FqKdDzQxxrQFvgSmee4DQERuE5FMEcn0rAQUqFibdr8rpSJL48aNmTp1Ktdff33A+xo4cCBjx44tg6hUKIRk9Lsx5hCwELjS4/kDxpiTjl/fADr62P41Y0wnY0ynumU4ExOcbqlrTXUVbfr3txYVeZo0aULbtm29Fllx2rZtGy1btmTkyJG0aNGC4cOH89VXX9GjRw+aN2/O8uXLAWumuLvusoY9jRw5ktGjR3PBBRfQrFmzYnsBjDGMGTOG5ORkUlJSXMVddu/ezUUXXURqairJycksWbKEgoICRj7yCMlXX01KSgr//ve/y+jbiC5Bu6YuInWBfGPMIRGpClwGTPJY5xxjjLMkz0BgXbDi8UWvqato5ahKqcqSc5o+d0OHwqhRkJsLV1115usjR1rL/v3gOY96kKf727x5MzNnzuStt96ic+fOvP/++yxdupR58+bxxBNPMHfu3DO22b17N0uXLmX9+vUMHDiwyLnfP/roI7Kysli1ahX79++nc+fOXHTRRbz//vtcccUVPPTQQxQUFJCbm0tWVha///EHP6+3ytceOnQoaJ87kgVz9Ps5wDQRicHqEZhhjPlERB4HMo0x84DRIjIQOAX8AYwMYjxe6TV1pVS0atq0KSkpKQC0adOGPn36ICKkpKT4LD16zTXXYLPZaN26NXv37i1y/0uXLuXPf/4zMTExnH322fTq1Ysff/yRzp07c8stt5Cfn88111xDamoqzZo1Y+vWrdx9993069ePyy+/vKw/blQI5uj31UB7L88/4vbzA8ADwYrBH85r6qeMdr+r6KJzvwdBUV9mtWpFv56YGPJ/DPfSqzabzfW7zWbzWXrUfZvS1g656KKLWLx4MZ9++ikjR47k3nvv5aabbmLVzJl8sXQp6enpzJgxg7feeqtU+49mOqOcttSVUiooevbsyfTp0ykoKCA7O5vFixfTpUsXtm/fztlnn82tt97KX//6V1auXMn+/fuxG8O1V1zBv/71r6CWJ41kUT/3uyup6zV1pVQFlJubS8OGDV2/33vvvfTs2ZNBgwZx8OBB5s+fz6OPPsratWtDHtugQYP4/vvvadeuHSLC008/Tf369Zk2bRrPPPMMcXFxxMfH8/bbb/P7779z8003YbfboXJlnnzyyZDHGwmivvRqxo4M7v7mbj7s9yFtEtuU2X6VKu+0+z1wWnq1jGnpVSCw0qva/e68pU2vqSullKrgtPvdcUub3djDHIlSoTV0aLgjUMpDrVrhjqDCi/qk7izoopPPqGgzalS4I1DKQ7164Y6gwtPud518RkWp3FxrUarcKCiwFlVqUd9S11vaVLRyTm6mA+VUubF5s/UY5QPlAhH1LXUt6KKUUipSRH1S14IuSqmKzFuZ0+eee47WrVvTtm1b+vTpw/bt20u9fy29WrFoUtdr6kqpCNO+fXsyMzNZvXo1aWlp3HfffaXel5ZerVg0qes1daVUhOnduzfVqlUDoFu3buzcufOMdcpl6dWxY0keMEBLrwZAB8rp5DMqSo0cGe4IIk95rLz65ptv0rdvX6+vlbvSqwcP8vN330FiopZeLSVN6jZtqavopEk98r377rtkZmayaNEir6+Xu9KrO3Zw92OPaenVAER9UndOPqMzyqlos3+/9ZiYGN44Ikl5qrz61VdfMXHiRBYtWlSoXKq7cld6NTOTL/73Py29GgC9pm7T7ncVndLSzuzuVZHhp59+4vbbb2fevHnUC+MsbSUuvbp1K9empmrp1QBEfUtdB8oppSoyb6VXFyxYQE5ODkOGDAGgcePGzJs3L+SxaenV0Iv60quHTx7mwg8vZGyXsQxvNbzM9qtUeaelVwOnpVfLmJZeBbT0akB08hmllFKRQpO6Tj6jlFIqQkT9NXXn6He9pq6izZ13hjsCpTzUrRvuCCq8qE/qOvpdRathw8IdQWQwxiAi4Q4jMtSuHe4Iwi7QcW5R3/1uE+sr0Ja6ijY7dliLKr0qVapw4MCBgP8QK4e8PGuJUsYYDhw4QJUqVUq9j6hvqYPVBa/X1FW0ufFG61FHv5dew4YN2blzJ9nZ2eEOJTLs2WM91q8f3jjCqEqVKoVuUSwpTepYXfCa1JVSJRUXF0fTpk3DHUbkcA700DPNUov67newbmvT7nellFIVnSZ1tKWulFIqMmhSx7qmrpPPKKWUquj0mjraUlfR6f/+L9wRKOVBD8qABS2pi0gVYDFQ2fE+s4wxj3qsUxl4G+gIHACGGWO2BSsmX/SauopGAwaEOwKlPOhBGbBgdr+fBC4xxrQDUoErRaSbxzp/AQ4aY/4E/BuYFMR4fIq16S1tKvps2HC6foZS5YIelAELWkvdWLMx5Dh+jXMsnjM0XA2Md/w8C3hJRMSEeCaHGInRa+oq6tx+u/Wodw+pckMPyoAFdaCciMSISBawD/jSGPODxyrnAjsAjDGngMNAnWDG5I1NbNpSV0opVeEFNakbYwqMMalAQ6CLiCSXZj8icpuIZIpIZjBmboq1xeo1daWUUhVeSG5pM8YcAhYCV3q89DvQCEBEYoEaWAPmPLd/zRjTyRjTqW4QqvjESIwWdFFKKVXhBS2pi0hdEanp+LkqcBmw3mO1ecAIx89pwDehvp4O1i1tdmMP9dsqpZRSZSqY96mfA0wTkRisk4cZxphPRORxINMYMw94E3hHRDYDfwDXBTEen2JFu99V9Bk3LtwRKOVBD8qABXP0+2qgvZfnH3H7+QQwJFgx+CvGpt3vKvpcemm4I1DKgx6UAdNpYtHJZ1R0ysqyFqXKDT0oA6bTxGK11PMK8sIdhlIhdc891qPeEqzKDT0oA6YtdfSaulJKqcigSR29pq6UUioyaFLHMaOcttSVUkpVcJrUcXS/6zSxSimlKrhiB8qJyBDgc2PMUREZB3QA/mWMWRn06EIkxqYFXVT0eeKJcEeglAc9KAPmz+j3h40xM0XkQuBS4BngFaBrUCMLoRjRGeVU9LnggnBHoJQHPSgD5k/3u7Nfuh/wmjHmU6BS8EIKPa2nrqLRd99Zi1Llhh6UAfOnpf67iLyKNXf7JBGpTIRdi9d66ioaPfig9ai3BKtyQw/KgPmTnIcCXwBXOKqt1QbGBDWqEIuxxWhLXSmlVIXnT0v9HOBTY8xJEbkYaAu8HdSoQkyniVVKKRUJ/GmpzwYKRORPwGtY9c/fD2pUIRZri9XJZ5RSSlV4/iR1uzHmFDAYeNEYMwar9R4xtKWulFIqEvjT/Z4vIn8GbgIGOJ6LC15IoafX1FU0ev75cEeglAc9KAPmT1K/GbgDmGiM+VVEmgLvBDes0NKWuopGqanhjkApD3pQBqzY7ndjzC/AP4E1IpIM7DTGTAp6ZCEUI1ZBF2NMuENRKmS++spalCo39KAMmD/TxF4MTAO2AQI0EpERxpjFwQ0tdGJsMQDYjZ0YiQlzNEqFxr/+ZT1eeml441DKRQ/KgPnT/f4scLkxZgOAiLQAPgA6BjOwUIoV62uwGzsxaFJXSilVMfkz+j3OmdABjDEbicCBcoDe1qaUUqpC86elnikibwDvOn4fDmQGL6TQc3a562A5pZRSFZk/Sf1O4G/AaMfvS4CXgxZRGMTarK9Bb2tTSilVkRWb1I0xJ4HnHEtEcrbUtaiLiiavvhruCJTyoAdlwHwmdRFZA/i8x8sY0zYoEYWB85q6ttRVNElKCncESnnQgzJgRbXU+4csijBzjn7Xa+oqmsyfbz0OGFD0ekqFjB6UAfOZ1I0x20MZSDjZxLoJQEe/q2jy7LPWo/79VOWGHpQB8+eWtojn6n7XlrpSSqkKTJM6bt3vek1dKaVUBVZsUheRv/vzXEWmA+WUUkpFAn9a6iO8PDeyuI1EpJGILBSRX0RkrY+Tg4tF5LCIZDmWR/yIp8zp5DNKKaUiQVG3tP0ZuB5oKiLz3F5KAP7wY9+ngP8zxqwUkQRghYh86aj65m6JMSasI+118hkVjd6JqALKKiLoQRmwom5p+w7YDSRiFXVxOgqsLm7Hxpjdju0xxhwVkXXAuYBnUg87nXxGRaNGjcIdgVIe9KAMmM/ud2PMdmNMhjGmO1bZ1ThjzCJgHVC1JG8iIk2A9sAPXl7uLiKrROQzEWlTkv2WFfdr6tm52UxYNoG0eWnhCEWpkJk+3VqUKjf0oAyYP/XUbwVuA2oD5wMNgXSgjz9vICLxwGzgHmPMEY+XVwLnGWNyROQqYC7Q3Ms+bnPEQOPGjf152xJxttSn/jyV73d/j93Yybfnl/n7KFWevPKK9ThsWHjjUMpFD8qA+TNQ7m9AD+AIgDFmE1DPn52LSBxWQn/PGPOR5+vGmCPGmBzHzwuAOBFJ9LLea8aYTsaYTnXr1vXnrf2WnZvNu79YBeiW/L6EkwUnNaErpZSqkPyp0nbSGJMnIgCISCxFzAnvJNYGbwLrjDFei8GISH1grzHGiEgXrJOMA/4GXxbGLB7Dyr0rAR0op5RSqmLzp6W+SEQeBKqKyGXATGC+H9v1AG4ELnG7Ze0qEblDRO5wrJMG/Cwiq4AXgOuMMcWeMJSlyb0m07dJX+B0N7xSSilVEfnTUh8L/AVYA9wOLADeKG4jY8xSQIpZ5yXgJT9iCJrEqomM6TKGBdsW0K5uO9YeWKvX1JVSSlVI/tRTtwOvA6+LSG2gYahb08GWUCkBgJ4Ne/Lsxc+SviqdrH1ZYY5KqeCaNSvcESjlQQ/KgPkz+j0DGOhYdwWwT0S+M8b8I8ixhUzlmMrE2eI4mneUxKqJjOs2LtwhKRV0iWcMSVUqzPSgDJg/19RrOG5FGwy8bYzpip+3s1UkCZUSyMnLCXcYSoXM1KnWolS5oQdlwPxJ6rEicg4wFPgkyPGETfW46hzNPxruMJQKGf37qcodPSgD5k9Sfxz4AthsjPlRRJoBm4IbVujFx8VrS10ppVSF5s9AuZlYt7E5f98KXBvMoMIhoVICOfma1JVSSlVc/rTUo0J8XDxH87T7XSmlVMWlSd0hvlK8ttSVUkpVaP5MPhMVdPS7ijYLFoQ7AqU86EEZMH/uU6+MdQ29ifv6xpjHgxdW6MXHxXMs/xh2Y8cm2oGhIl+1auGOQCkPelAGzJ+W+sfAYayJZ04GN5zwSaiUgMFwLP+Ya4Y5pSLZyy9bj6NGhTcOpVz0oAyYP0m9oTHmyqBHEmbxcfEA5OTlaFJXUWHGDOtR/36qckMPyoD508/8nYikBD2SMIuv5EjqOlhOKaVUBeVPS/1CYKSI/IrV/S6AMca0DWpkIZYQZ7XONakrpZSqqPxJ6n2DHkU5UL1SdQC9V10ppVSFVWz3uzFmO1ATGOBYajqeiyiulrre1qaUUqqC8ueWtr8DtwIfOZ56V0ReM8a8GNTIQkyvqatok5ER7giU8qAHZcD86X7/C9DVGHMMQEQmAd8DkZXUHaPftftdKaVUReXP6HcBCtx+L3A8F1GqxlYlRmK0pa6ixuTJ1qJUuaEHZcD8SepTgB9EZLyIjAeWAW8GNaowEBHiK2lRFxU9PvnEWpQqN/SgDJg/pVefE5EMrFvbAG42xvwU1KjCJD5Oi7oopZSquHwmdRE5yxhzRERqA9sci/O12saYP4IfXmhpURellFIVWVEt9feB/lhzvhu358Xxe7MgxhUWWlNdKaVUReYzqRtj+jsem4YunPCKrxTPrpxd4Q5DqZCoWjXcESjlQQ/KgPlzn/rXxpg+xT0XCRLitPtdRY/PPgt3BEp50IMyYEVdU68CVAMSRaQWp29jOws4NwSxhVz1uOo6UE4ppVSFVVRL/XbgHqAB1nV1Z1I/ArwU5LjCIqFSAsfyj2GMQSTibsVXqpAJE6zHhx8ObxxKuehBGTCf96kbY/7juJ7+T2NMM2NMU8fSzhgTkUk9vlI8BaaA46eOhzsUpYLu66+tRalyQw/KgPlzn/qLIpIMtAaquD3/djADCwf3qWKrxVULczRKKaVUyRQ7o5yIPIo1z/uLQG/gaWCgH9s1EpGFIvKLiKx1FIbxXEdE5AUR2Swiq0WkQyk+Q5lJqHS6pnp2bjYTlk0gbV5aOENSSiml/OZPQZc0oB3wkzHmZhE5G3jXj+1OAf9njFkpIgnAChH50hjzi9s6fYHmjqUr8IrjMSycLfUXVr7At7u+xW7s5NvzwxWOUkopVSL+JPXjxhi7iJwSkbOAfUCj4jYyxuwGdjt+Pioi67BGzbsn9auBt40xBlgmIjVF5BzHtiGVnZvNrI2zAFi0cxEFpqCYLZSq2OrUCXcESnnQgzJg/iT1TBGpCbyONQo+B6v0qt9EpAnQHvjB46VzgR1uv+90PBfypD5m8RhW7l0JoAldRYXZs8MdgVIe9KAMWLHX1I0xo4wxh4wx6cBlwAhjzM3+voGIxAOzgXuMMUdKE6SI3CYimSKSmZ2dXZpdFGtyr8kMTRoKgM2v4nVKKaVU+VLU5DM+B62JSAdjzMridi4icVgJ/T1jzEdeVvmdwl35DR3PFWKMeQ14DaBTp07G8/WykFg1kXHdxrH10FY2HtzIiYITek1dRbQHHrAen3wyvHEo5aIHZcCK6n5/1vFYBegErMKagKYtkAl0L2rHYs3e8iawzhjznI/V5gF3iciHWAPkDofjerq7Dmd3YMW+FXxyzSdM+2UaWfuywhmOUkHzfYkuoikVAnpQBqyogi69AUTkI6CDMWaN4/dkYLwf++4B3AisERFnZnwQaOzYfzqwALgK2AzkAn536wdLcmIydmMn+3g247qNC3c4SimllN/8GSiX5EzoAMaYn0WkVXEbGWOWcnpqWV/rGOBvfsQQMsmJyQD8vP9nOpwd1tvmlVJKqRLxJ6mvFpE3OH1v+nBgdfBCCq/EqonUr16fn/f/HO5QlFJKqRLxJ6nfDNwJOGeEW4w1SUzESklM4ecDVlLPzs0mfXU6q/atYtbAWWGOTKmy07BhuCNQyoMelAHzZ+73E8C/HUtUaFOnDV9u/5KHlz7MZ9s+01HwKiK968+8kEqFkh6UASvqlrYZxpihIrIGOOM2MmNM26BGFibZudmuEe/zt87XiWiUUkpVGEW11J3d7f1DEUh5oTPLqWhxzz3W4/PPhzcOpVz0oAxYUbe0Oedt3x66cMJvcq/JpK9KZ/qG6diwYcce7pCUCoosnYJBlTd6UAasqO73o3jpdse6Tc0YY84KWlRh5JxZbvX+1RzIPcDhvMN6TV0ppVSF4HOSc2NMgjHmLC9LQqQmdHfNazZHRPj82s8Z3HwwSbWSwh2SUkopVSR/bmkDQETqYU0ZC4Ax5regRFROnHfWeczbMo9qsdV0ZjmllFIVQrFJXUQGYs0D3wCrlvp5wDqgTXBDC6/zzjoPgB1Hd5BUW1vpKvK0aBHuCJTyoAdlwPxpqU8AugFfGWPai0hv4IbghhV+zqS+7cg2TeoqIr32WrgjUMqDHpQB86dweL4x5gBgExGbMWYhVtW2iNY4oTEAvx2J6KsMSimlIog/LfVDIhKPNT3seyKyDzgW3LDCr1pcNepVq8e2I9vCHYpSQXHbbdajNo5UuaEHZcD8SepXAyeAf2AVc6kBPB7MoMqL8846j+1Houo2fRVFNm4MdwRKedCDMmA+u99F5L8i0sMYc8wYU2CMOWWMmWaMecHRHR/xzjvrPO1+V0opVWEUdU19IzBZRLaJyNMi0j5UQZUXTc5qwsGTBzl88jDZudlMWDaBtHlp4Q5LKaWU8qqoaWL/A/xHRM4DrgPeEpGqwAfAB8aYiO8ncY6Af/S7R1n6+1KdWU4ppVS55k/p1e3AJGCSo7X+FvAIEBPk2MIqOzebBVsXAJCxI0OLu6iIk5oa7giU8qAHZcD8mXwmFuiL1VrvA2QA44MaVTmg1dpUpNNCWKrc0YMyYEUNlLtMRN4CdgK3Ap8C5xtjrjPGfByqAMNlcq/JDE0aSoxEdIeEUkqpCFLUQLkHgO+AVsaYgcaY940xEX9/upOzWtubl78JQKzEEmeLA9ABcyoi3HCDtShVbuhBGbCiBspdEspAyquO9TuSXCeZY/nHsImNrYe3MmfTHB0wpyq8nTvDHYFSHvSgDJjfVdqiVXZuNnExcfx64FdiJRaD0YSulFKqXPJn7veoNmbxGLL2ZQFwypwq9Jp2wyullCpPNKkXwzlgLlbO7NSYs2kOGw5uCENUSiml1Jm0+70YzgFzac3TGPn5SI6dOj1WULvhVUXWvXu4I1DKgx6UARNjTLhjKJFOnTqZzMzMkL/vyM9HsnLvSgxnfl9Dk4ayat8qZg2cFfK4lFJKRT4RWWGMKbbsuXa/+8nZDV/JVumM17QbXimlVHmgSd1Pzm749/u9zznVzyn0mnbDq4ro2mutRalyQw/KgAUtqYvIWyKyT0R+9vH6xSJyWESyHMsjwYrF09ZrBrF7/GPk79tX4m2fXP4ke47tCUJUSoXWgQPWolS5oQdlwILZUp8KXFnMOkuMMamO5fEgxlLIyfXrOTR7Nlsuu7zEyb2obni9xU0ppVQ4BS2pG2MWA38Ea/8By8/HnDzJoQ8/ZMull/md3J3d8F+kfUGD6g0AEATQa+tKKaXCK9zX1LuLyCoR+UxE2oQrCJOXx6Hp0/n93v/zfxtjSKqdZP3sGBGv19aVUkqFUzjvU18JnGeMyRGRq4C5QHNvK4rIbcBtAI0bNy77SOLiqJmWRt1Rd/q9iXtpVk8Tlk044xa37Nxs0len661vqtzo0yfcESjlQQ/KgAX1PnURaQJ8YoxJ9mPdbUAnY8z+otYri/vU17VsBXFxiAgmL4+6940h8ZZbSrSP/cf3k74qnbmb53Ky4GSh1+JsceTb81kzYg37ju3j1TWv8vHmj7Ebu+t5pZRSyl/l/j51EakvIuL4uYsjlpAMe6zcsiU109Jo+vFcKxbHNfGScF5bf++q92gY37DQa85u+KvnXE2fWX2YtWEWJwtOave8UkqpoApa97uIfABcDCSKyE7gUSAOwBiTDqQBd4rIKeA4cJ0J0fR2zebOAcDY7SCCPedoqff15PIn+T3nd6+vbT2yFQA79lLvX6lg6dvXevzss/DGoZSLHpQBC1pSN8b8uZjXXwJeCtb7+0NsNmzVq1OQk1PqfUzuNZn0VenM2TSHPHteGUanVHAdPx7uCJTyEIaDMtLGO0V9QRdbQgL2o6VP6s5u+HV/rGN19uoi13Vea/fG3wMr0g5ApZQKB+ffUvfxTpEg6pN6THx8QN3vTv/p/R/SV6UzY8MMr0VfAAY1H8SKPSsKjY5ff2A9Y5eMZevhrcTaYl0HlmfyjtQDUCmlQsn5t3T2xtkAFJiCMEdUtqI+qdsSEigIoKXu5GyxD20xlPsW38eWw1vOWOfA8QPszNnJb5t+I9+eT/f3u5OTf/q9nYl6wrIJhZL3hGUTmLtpLgWmIOIOQKWUCiXn7ci+Gl8VXbgnnwk7W0I89qOBt9SdWtRuwdxr5jJ7wGzOr3E+cHp0/cLfFhYaBe+e0N3N3DCz0HozN8wkz57nNaFn52br9LSqVPr3txalyo0QHJSTe01mcPPBQX2PcIr6lnpMfAJ527aV+X6dyX34guGua+3+joL3PIMc3HwwszfNPmM9zxa9v5zdTyv2rKBj/Y56fT5K/fOf4Y5AKQ8hOCgTqyZyU5ubmL1pNjESQ6wtNqIuaUZ9Urda6oF3v/viz7X24uzM2QlA3ap1yT6ejSAYDDM3zCzRPp3JfO6mueTb8zEYfjv6W8QczEop5Y+9x/YC1vX0j/p/xPvr3ydrX1aYoyobUZ/UY+LLtvvdkz/X2n1xJu/lu5cD0O2cbszfOt+VyL0ldPcBdq9c+oqrRd7h7A58tPEjCijchR/pCV3vFvDt4outx4yMcEahlJsQHZR7c/e6fj5RcIJx3cYF9f1CKeqTui0+AZOfj/3kSWyVKwftfZzd8Rv/2Mh9i+8rNNr9/BrnnzH6HTgjeX+y9ZMi3+Oaudew9fBWYiSGU+YUfT/q6+pWKsnJhK9EWB677YuLVe8W8C3fnseunF2kzftn2P8dlQolZ0sdYHfOblrXae33tuW9oaBJPSEeAPvRo0FN6k7O5O6cOz5rXxazBs5y/V5UN31xXe3OxH3KnAI4Y0764nhLhBOWTXAl8bLuti8uIRf1P82enD28/vPrZyRt57ZzNs3BYDhlPxVQjJFoV84uXl31KquzBwJGywVHmPKedMqDvbl7qRxTmZMFJ33OCOqpojQUoj6pxyQkAFBw9CixiYkhe19nt7zn7/500xc1iU1JOfd1zdxr2HJ4i6vL38l53d4zHvf3L+6PiOfrxd2bX9T/NNm52Tz949N8vu1zYiTmjDsCirpdxf0EJdhV9MrjH1b3+3MLTAF2E9go46I+Y3mfTKk8/vuUlmcPWnlPOuXB3ty9NK3RlN+O/MbuY7uLXNf9/xu7sZf7W+GiPqnb4q2kbg9gqtiy5NlN7y25D24+OKCBdwAN4xuyM2cn9avVZ0fODtf7eO6zuPdwdvl7XjoA70n6gg8u4Gje6TEMzm2c+ynu/cYsHsOKvSuAMyeNmLBsAtm52a7LD56cJyjuvQy+TjA8P4O/lxxCeTZf0sRUVvfnFvWd+fv5Q93qKcvEV15OCLwNfN12ZJvOZeGHfbn7qF+tPqfsp4ptqRfXUAj3ceAp6pN6jFv3e3lS1DV49xa9r2RUnJa1W7IzZyc7cnYEFKfzZMB94pwfdv1ArC2WLYe3YMNW6FY+94Tubc2OMc0AACAASURBVD/FSWue5krqnoq7G8D5mvuJhPv7ektO3i45ePsf2X19z0mC3HsIijo5KGnrtqSJaXKvyTz5w5P8b/v/AKjR5Qu/tnNaf2A992TcU+iPoHsvyytZrzBn8xxEpNhkPnvjbATxevJVlsoy8a3dv5aPNn3Ex1vC2xIu6ljz9bkCudRVkpgCTnBDh5Z+2xLYe2wv7eq2w4692Jb65F6TeTnrZWZunHnGa3M2zSl3PSJRn9Rtzu73ctJS9+TtGry35+dunuv6QzPw/IEs2rGIEwUnyC/IL5RUnd3tX//2dVDi9UysZVWhLjs32xpzsHGGz3VK2gL1dSLhmeydnP/zOv9Hdk/uRZ3NO78TZ0+E53iEdfvX8cDSB4o9QXP/Y24wPnsVfP1hTayaSFLtJP63/X/UqVIH+kx3HA++vyP3/c7Y4Pu7d+9B8fbP4NzH/M3zOVFwwue/VaDJwbNFPmfTHE7ZTxV6v5Im9OzcbJ7JfIbPfv3M6yWfUCtJj4uvE8BdR3fx5to3A+4pKfMel1GjAtveDycLTnLw5EHqVasHwE/7fipy/cSqiQxLGsbMjTOpU7kOB06erhBe3hI6aFI/3f0exHvVy4LnNXjP5+9od4cr6U+8cCKA14Q/uPlgMvdk0ql+J1dyKstrRGW1L+cfzweXPkjGjgyfLXx/eI4TKE5xvQbekvv+3P00qN6A34+d2ZXneReDc/slO5bwj4x/cNJ+ekBjUWMViusG9PWH1X0/VWKrkFwnmRta38B9X42nW8Ne7MrbXGQ3ovN9i5JYxfd4FM/YUuumkpV95j3B3qZH9ncMhLfk4s/lHH/cs/AeVu+3JpAKR0L3/KwPdHmA27+8nQMnDpyxbqzEcsqccj1eNusybGIrdEw8uORB5m+dH9AJivMke/am2SXaR7Enbbm51mO1aiXbrgTvue/YPgDOrnY2cbY4juYd5WjeURIqJfjcftLySQD8cfKPEr13OEiISpiXmU6dOpnMzMwy21/B4cNs7NqNsx8YS+0RI8psv+WJ50h7z+fdk7uzJT8saRhzN889o6XvfD7Qs/LiEm312OocO3Ws1PsHCn2WYJbGLelJgz+GJg0tlKCGJg3lh10/sCd3j9e7GjxjWDNijddEJwg3tr6RnLwcJv+lP9Viq3Le2JGu19eMWHPGvjf8sYF7Ft7DzpydPhOB8/3d43D+7LlN5/qd2XFkB/tyrT+uxvGf52dw/u78d1wzYo3X6/lDk4Yyd5N1TLp351/R5Aq+2HbmJYYYYrBjd23v7TMD/LL/F2Zvms3czXN9Hju+tvWmpANKvf37OT+rZzzO76rT2Z3I3JtJjUo1OJx32O/YnJ/F3+Q5/NPhrhMdT0OThp5xMubts7h/d87XB9/6Am3qtHHdp17cdkXx9f19v+t7dhzdweuXv86hk4cYs2gMswbMIql2ks/tnX8Hnf9fev4/ODRpaNCvrYvICmNMp2LXi/akbgoKWN8mmcS77qLuXX8rs/1WJM7k7mzBe95m557E14xY4/VkoDie9+IPSxrGx5s/5kTBiaB9rmFJw1yfZcMfG7jr67vYk7snaO8XTCU9cWhWoxlbD2/1+lqsxFJgCtjy5JvWug/c4nrN/Q+7+6Ay5x+1Jmc1YduRbQGfyNSpUoce5/Zg/pb5fu8nPi7ea70EX7GcX+N8thzeQs3KNTl08pDr+TZ12rD2wFoGNhvIhoMbCiUd56RNj3z7CEt3LcUmNuzmzOsTzhMN9z/mvpKyt8F57onJ14nKx5s/psAUlOi2TGdcnp/ZXWLVRPYf3+/1+3KPwVvSdX6W2RtmnzGRlZPnyZjz38Hz5M55rL2y6hXmbZmH3dh5deIGOtfvTPaCmWeMhXByfufOybV89eLM2TQHY0yhEz33O4fmXTOPnLwcrl9wPS/0foHkxORCn3HuprnYsRf6/p1//8YtHce3u749Y78lOckrKU3qJbC+Q0dqDRnC2Q+MLdP9RoriWvrOk4GPNn5EvvHeenc/GfB20uDZI+BLJVslv3sV3P8HG/n5SJ9d184/Or4MSxrGtzu/5Uj+EY7kHSk2RvftgnGJo6xsffItoHBSd34XvhJlSW6ndJ48+PrszjswAlXcCYZnzM6u6Ue7P0pyneQzEmqHeh1Yua/oyw2eCdCzZ8Xze/QcMDo0aSjf7vyWgycPknsqN+DvoDiVYyq7YrOJjRta3cD8LfM5ePKgz23cW9zBuEvB24nnW09upXP9zgwfc67PngDnv5/7Z3KPtbhxG04tarXg1ctepfeM3v/P3nvHx1Gd+//vs1W9y5YlW7IluWEwxjZgCDWUALEDppebkOQSCCGVBBJCLsk3v3uTG3KBFEihhZAYTDEGQiDBhW7LxgL3KsuSLcmS1bu07fz+mLKzq53dlSxZkj3v10svSbMzZ86UPZ/zPOc5z+G0Caexs3lnzGvUO71b/sRLewcG5g7G2zFYLFEfBPvOO5/kc88h/3/+Z1jLPdHQRLqsrgyHzWHa6zc7ziiAZg31O9e/MyivQvg5Ig0dbLt1W9QphMZyNtRt4O737o5L3I0dmU31m5iTM4d3D71Lt7d71IOtQBF1AUwziHq8aB0pf8AfNYLdjt3UohttkhxJEQW1NKOUiraKqMdqwqIxEkMww8mPz/wx+9v2896h96jvqefB8x7kkfJHokZ+RxpSGWme/mUliY5Ebrpn0qDOG+4dMHu24Vw/43pe3PvigE6X6f4zr4/aaYjU2RsucbdEfRDs//xi3CUlTP7db4e13BMdMws/1v6RAvnidW/FOmcs8Y80hTDSOY2dgPDGL1Zdo3UwBsvRJCKq/OXTJDoSmHTPzYM+1thhMYq7y+bSx3vjbZTDryGW58QiiFmKaYfNEeI2vqToEh6+4GG+9OaX2Na0bVinEg6n+D/9S8Vy/+p9xcNRtWEnlnfQbP/hcMtboj4Iqm64EVtyEoVPPz2s5VocHWZj/cNZdizxj3XO8DoOpq7hx0YS+XA3bnjHIdzFPxghPfLeFQgg49zXYu4fTiQvyOYjm3E73PpSw/ESHnxp9JxUtlciEIOaGjkcQwfhxGvJHWvCO1faPQy/p26bmxRXSsSI+aPNUHnDzBviGoKLhys/UIYDXjs3U982kh6DoZa57dZt7GnZo7+j8ex/tFiiPggO3vY1/O3tTHvJfB6uhcVIEysw0azjEM3DEd4J0DA2xPF4DKIFUcW6BmMZZsMbseI2jOWZWadmHZ1Y2+NhuGZ9mBFLXMzqbta50t6LR8ofYc3BNXR7zWeSDDX2I1odXq141XTtiaEKqfYMfH7foId0Ys2AGax3aNut26LG6UTa/2ixRH0Q1Hzve/Tv2k3Jv94a1nItLIbCYIctzI4P7wQM6CxoAdDJsYUzmvBGq0M0CzyeeAuze2JmnZp1dOLpAIVb48ZArEidq0ju1/D7FmnWh1mHI9aw01A8V/EIj7FsLR4mksCF3x/j/TZ7XmbTYs06nsntvQC0pQ5MoRL+Dv7inF/EvZz1tlu3ccubt5h6kcLjasw8Y5HqEk9nzxL1KIyEqB/+rwfofOcdZnz4wbCWa2ExlggXxvClq82E82iGPWJZ4Ec7pDLcHSBjA60FZQ42PiPWfYwlzsM57BRNeKKN90bqfEUaJhnK+aN5ny77yq+QUvLV+6YN6ETE8g4ZOySR4luidTQieRtidYqjXWO8nq3BYIn6IGh48Ne0LlvGrC0Ds1xZWByvhIu6xdA6CcPVQRlJYnk2Yh032I5eeXUrZZXNLCrOZkFRZtzHec/7DHVddXzngVOjCmk81xqr0zTUDkq8cTjD/V5Yoj4Imv74Rxp/+ztmbd2CcLmGtWwLi7GKJeonHseiA1Je3crNT5Th9QdwOWwsu20RC4oyYx8IA17KkazveOiMGYlX1E/43O8QzP/u7+7GYYm6hYXFcYrZGhLDSVllM/0+xbXt9QUoq2yOX9TDGMn6Hot7MRqc8KJeedVS7OnpgLr8aubQXj4LCwsLC1hUnI1AWazP6bCxqDh7tKt0QnHCi3r/7t1gtwPQ8NBD5N1/P84JE0a5VhYWI8+dd452DSyORxYUZZLkstPt8fOXL58+OCvdeimPmhNe1AHwK3Meu1avYf+775G+dCk537jTEneL45obbhjtGlgcj3T1++j2KG1qYXby4A62XsqjxjZSBQshnhZCHBFCbDf5XAghfieEqBBCbBVCzB+pusSN34/s76fthReovfv7o10bC4sR5dAh5cfCYjg53Nar/93cFTkBjSnWS3nUjKSl/gzwKPCsyeeXA9PVnzOBP6q/Rw+7HeFwkH711eR+w3IDWRzffPGLym8r+t1iOKk1inp35Axuplgv5VEzYqIupXxfCDE1yi5XAs9KZU5dmRAiQwgxSUppvmzQSOF0gteLa+pUip75C47c3GNeBQsLC4vjgRBR7woV9U1VLXxU0cQ503OHHBFvEZ3RHFMvAIx+lhp12wBRF0LcDtwOUFhYOKyVcM+aReJpp9FbXo5j4kRL0C0sLCyOgjqDqLd0B93v5dWt3Ph4Gb6A5I/v7R/c/HWLuBmxMfXhREr5uJRyoZRyYe4wi27xqyuZ9NMHcBUV4q2rG9ayLSwsLE406tr6KMhIxOWwhVjqZZXN+AJKsjOPOn/dYvgZTVGvBaYY/p+sbhsVHJMm4T18mPGWYc/CwsJiLFHb1ktBRiLZya6QMXVt/jqAw2bNXx8pRtP9/jrwTSHEcpQAufZRGU9XcebnI3t68Le14bAS0FicAHz/GE7wCM8FbnH8UtfWy8KiTHq8vpDo95l5qfpacV9cVBj5PTiGL+Vwv5Nj5R0fMVEXQjwPXADkCCFqgJ8CTgAp5Z+AN4ErgAqgB/jKSNUlHpz5+QB46+osUbc4IViyZGjHDbbx2lDZzE1PlAEMPhe4xbjCH5DUt/eRn5FIS4+XFoOlvq+hU/+73x8IOU5/p+aec0zeDWV8fz3+gByWd1Irz+uXuB02nvva6L3jIxn9flOMzyVw10idf7A48wsARdQT58wZ5dpYWIw8e/Yov2fOjP+Y8upWbnmijH5fALczvsZw1c4G1KHUo84FbjG2aezsxxeQ5GckUt/eR2Vjl/7Zvgbl75wUFxVHgtuNgji7vY5fX3cqJ3/2jBGt57r9TXj9yks5HO9kWWWwvH5fgJ//YwcPLJkzKu/5uAiUOxY4CxRL3WcFy1mcINxxh/IzGLTFOiTxBztNykgAQDD2coGXV7fy2DsVlFe3jnZVjgu06WwFGYlkJbtCAuX2NHSS4LRx3oxc9jd269vLKpt1QfzpP39H5t3fGvF65qcn6n8PxzuZkRi6ENiWmnZufqJsVN4rS9RV7BkZiMREKwLewiIKi4qzsduUcCe7TcTVGCY6FYfg9IkpY8r1rnkd/u/fe7jlydFpgIfCWO6IaNPZ8jMSyUpx0ev10+PxAbC3oZPSCSnMmJhKY2c/7b1eQHmn1FcKIQRpCc4Rr6fX4P5/+tbI+ekHc583VrWQ5LRzdkkwGNDnH50If0vUVYQQOPPzLVG3sIjCgqJMrjpN8WrdeLpJsFMYNa09AGQmucaMoMPQvA6jjbZW+Uh3RIbacQiKegI5yW4gmIBmX0MXMyakUpqbAqC74OcXZpDsUhbVSnbbSU0Y+fjtLTXt+t+pEToR5dWt3PR4GQ+9Hfs+r9nVwD+21HHBrFy+f+lM3E4bdjF6XilL1A048/Px1lqibmERDaddaTY0iz0WNa1KQ98y2JShI8xQvA6ROJaWczwdkfKqFn7x5q646hOp7uXVrVz/5/VD6jhsPtSGy2Fjb0MXWcmKS7ql20N7r5f6jj5m5KVSOkER9f2qqDd29dPZ78flsNHrCRBpUnF5dSuPrt03bPd4y6E2CjIUF/y+I50DPi+rbMbjDxCQwTH3SJRXt3LH38oJSFiz6wgAy25bxN2Xzhw1r5S1SpsBZ34+fdu2jXY1LCzGNI2dyjSl+va+uPbXLPVB5wEfYRYUZXL+jFzW7D7CrWdPHVIDvPFAMzc8XgaSuAMHj4ZF07L0vyN1RMqrW7npiQ14/AH+8tEBlt9+lml91lU08R9PbQBCZyW8u+cI/sDggshW72rg4bf3sPOwIpC3PFnGT5coAcfN3f26u3vGxBQmZybistuoUIPo9tYrv684OQ9/IECf10+ioWzlmsrw+AI4bPv4+Rfm0NrrHfLUsT6vnz0Nndx27jSe/vAA+wxBexqnTw2W67CbW9zr9jfpCXU0d/tdF5Yen1PaxhuVVy1FuFz429oI9PRgS0oa7SpZWIwoP/nJ0I7TRP1wR7yirljqrT0e/AEZt4V/LOj3KWKT6LQP+CyeqXuvba5DxhnZr5TXxKLinJB9BjNF0G2o59klA/dXgs6Ua/L6Jev3N5mW+cQHlRFnJUwyBJEJEdmDYazz4fZevvncpyGfe30BDqjBcM1dHjZUtgCKd8Fht5GXlsCaXQ18bk4eu+s7ALjh9EJ+f/aN3HFeMeeFX5P6nHwByf2vbUcQ7Iho+8Qr8jvqOvAHJPMLM3kn54g+1c54TWmJQZf8PZ+baVqu9i7bRtHdHo4l6ir9u3eDXfnC1N3/Eybe9yNrPXWL45qLLx7acUFLvTfGnopVdKSzX88u1tbjITvFPbQTjwCaF0G7Jg1tTNUXCESdx2wMuIrWqJdXt3Ldn9YRkJDgrNDL06Zz+fwyLkt/7e4jCAELCjM50NQz4PNFxdnKNANVrA80dfPYOxUDBK/P6+fTQ20R6+60K0I1Mc1NS7eHNbsaAPTjjXW22UAQ2knTZjmcPzOXxz+oZGtNO89tOAjAd1/YzAPdXmraeghIxaI/uySbnBQXZ07L4vaZC/n3pPwQUTdekxAgpXJ5Hm+An7++g531HSHzzSFU5MurW1m3vwmX3YbXH9CHgeZNyWD6xFS217ZTXt3KDX9W5q27nTa+dm6xfv4edW1447PUyl9X0UxOsotbPzOVs0tyxkTMiCXqRvzKw+t8+2261q4lfelScr5xpyXuFsclmzcrv+fNi/8YKSVNXR6EUOck+xXLywwtcOrUKRms3X2Elu7hEfXhyN4VCEjq2hRvw5EwUX9p0yE8msUbZoEbz61NzUp02vn7bWea1uWjiqaIVrFxOlefN8BvVu/luxfPMC1n7e4jzJ2cwefm5PE/b+7iSGcfh1p69frMyktFAGdMy6KmrZcVn9RiEwOT/jz09h7aerycOz2HD/Y1cfclwXNWNnXjsAnuv2I2316+mT+8u5+nPzqgH//hvka9zsotUv62CXDYBNctnMLV8yczvzADt8PGlpo2/DLozn9r+2Hdu+HxBdh5uJMZE1Ox2QQX9ddRteYA5fMn6/WZmZeKDVg4LYsr5xXwwGvb8QUkAWBLbTDgzesL8PzGalZ+UkdAKuJ85wUl/GbVvpBxegEkOG3UtPYyfUIKb247zD+31uludK8vwLr9TSQ4bUxKT2SL2vn5uKqFx9+rZO3uIwSk0qHxB+DmM6bwrc9Oj/i8RgNL1CPh9yP9ftpeeIH+igqm/v1vo10jC4th57vfVX4PZunqjl4fHn+Aktxk9jd209jVH+KuDUdzvc+dnM7a3Udo6vIwfeJRVBoGbd2a0djVrwt3uKXe2efV/zZasRsPNHPT4xuQSFx2Gx5/gPREJ+29Xkpyk03PlZcW7MgYXdon5aeF7PfhviY+rmpRLE4p+Wh/M58pVSzAtbsb2HyojRtPn8ICdcz3pY8P8du1FXh8ARIcNn542SwCEr5xYSlvbK3jpU01IcFeC4oy+WBfI09+cABQhCrJZWdPfXBcubKxi6LsJA61Bj0xxuNtQrHMDQ4BbMBnSnMGdEhyUtzsPqy41zUX9eUnT2LjgRb6fQEEgtZuDzNPzlO8I88/gpSSmzOK9KxsHx9owS/h2xdN5zOlOczMS+Xel7eEzHXXeGPrYb0D0ecN8NvV+wYE3kn1s1ueLOOuC0qREtbvDwbC2e02ejx+Zk9KY1p2Mu/va6K8qoUb/1ymlw1ahwZWfFLLNQumjAkrHazo98gIgXC7ybjxRiY/8vBo18bCYlj4uKqF367ee1QRxI1dimV7SkE6AIdjBMtpon7q5AxgeCLgNetWEj0yORZa3XJT3RzpDF6HlJKtte2kq+Oqd5xXojfY/9iiiEZAokdH33C6si7VgSZFZCJFlPepY8IZSU4mpLmZX6jcj36v4h2cq95P7ZpWfFLD9Y+X8fCqvdz8RBnPbTjI7c+WA/DKp7V4fQHcDhv/3tmARy273xfg7Z312IQyTey6BZOB0KQ/r2+p5WvPbtKFzusLMC0nmbe2H+Z3a5To8v2N3RTnprCoOBuXQ5EImyEob0ddBxlJTm46YwouhzJ9y+W0RfQwZCW78PglpbnJfF+NCL/5zEJdsP1S0q92SMoqm/UFtfp9Ae5fuY3y6lY+qlBc51rZC4oyefDaU3Fr57YLMpOc+KUi1kY074g2QGAcKPD6ArT0KO/jrvpOZkxUovKvmpdPTUsvc/LTOHVKBk1d/bxUXhMi6EZGaz66GZaoG3E69XH14jf+waSfPmCtr36CMpYTfAwFbS3rR1bvO6r5zZqb+hRVpGNFwNe09uCwCWZPUixS4/raQ2VBUYb+t+0opqJp4+mnTcmgqctDQFWAPQ2dHGrp5YeXzWLGxBRe/bSWx95RBM/tCDaZAam4m2flpQKKqJvNb958sI3cVDc/vmI2dW193L9yu+rGbyHBaeP+z8/WBVQIQb/Xr0eg9/sC/Gb1Ht097PcH2FTdSnFOMlsN860l0NDRz5z8dFITnJwxLZszp2WSmuBg2X+eSXNXP99+frMufJrlPL8wkx6Pn0dW7+WWJ8s40NRFcW4yC4oyef62M5mQ6iY/PZH5hRl09nlZu+cIV80r4BdXz+X5r0WfvuVQx+c/d3JeSFT4gqJM7rygRN/vqY+qyExy6V4AgN31ndzw5/Ws3tXA/KIMEgxBgguKMnlOPffzt5/FzWcW6p/ZgKnZSbqA24Bzpufwi6WncNOZhXpHxOmwUZwT9K5UN/cwY2IK7+1tpLPfx5z8dOZOVjpb7+xWpqtpnYhLT5oYUs5YCJDTsNzvKu5Zs0g87TSS5p9G3T334q2pwTVlSuwDLY47tKAZX0CScAymKR0LyiqbgyLhVSyLzr4UOvp8lFf3RYzGTnDYqO/o47KTJ+mfa25qrbGLx1LPz0gkJ0WZsxw+rS18bDyesXItQx3AGVOzhvxstJSm8wozeHtnAy09HnJS3KzaoQSGXXzSBA639/L7tRU89PZeXI4KzpiaRWaSk/REJ1XNPfgCkh+v3IZNKKJ+sKVHd+n3G8bIN9e0cerkDH1u9HMbD/LKpzVMTE1gQVEmZxZn8/zXFvHt5z/BH5CI0NgzjnQq900T4swklz4Vyybgc3PyeGt7PZVN3Sw+ZZJ+3JJTC9hwYDuZyS7+7+09+naju/yjikZACUDz+BTvQ0mOYrUumJrF9y6ZwX2vbOO+V7bhDwTw+ALMmKh0ZBYUZUaN9tc6HU99cIDPzpoYsu+e+k7dhe/3B2jt8TB7Uho1rT3YhNJp8gUkVc09nBVBNMPP/dSHB/D6AjgdNm4/r4Sfv7FD/9/oRbhm/mT9HTNa2D5/gImpCexVc9TPyU9jxsRU7AIaOvtZWJTJhbMmDOpdHQ0sUVcpfnUlAP6ubrDb6d6wgeSzzhrlWlmMBmWVzSFBM8fDAiQz1UYYlEa0vLqFXYczkRJueXJjSDS2NidY49n11bq7tEnNDjZ9Qgpuh40Gk2ltWoO3u76DyZmJOOw2MpKcIbnAy6tbuf5P6/WgpgcWz+Fnr++IGXG+tUYJXDp3eg6fHmyj3+fH7Rg4JS0WNa29ZCY5mZqtWGuNnf3kpLh5dXMtk9ITONTSq0eCa+PSW2vbWTQtm5IJyTz2zn5A2Z6W6KSyqZtT1c6Odp8/3Nekjx9fM38ymw+16ULm8QWobunhGtVNvqAok/uumM03n/uUVz6pZXZeKjmpbj7c14QkVIjLKpsJqO5gAWQmu3Qh/PfOesqrW1lQlMm503MAJcBuV30nNhF0xxuF7rerK/BLZbphwC8pNsQHFGUp03uXf3xI3/bzN3YwMy816vfC6E73+gd+jxYVZ+N22vCowruoOJvUBAeTM5NwOWx4vAG0t3DFp7Vcu9B83HpBUSbLblsUIrIz81Ijim54ZyDBoUTFOx02rjqtgA8qmhACuvt97Kjr0Ouwrbad+66YHeJtGIvtgiXqYVT/x39gz0in+6N1wUgii3HPYHrVRleaM0riifGENvVqYVEmm6pbWbu7kbRzlZzc4dHYRkHXjtU+b+zsx2kXpCc6mZSeoFvqH+xrZGtNO4uKs+nq8/LlZz4GdeqRPyApr24lK9kVMqb+zu4jIVHR/9hSaxpxbmRLTTs5KS6+fPZUPti3ibLKFs6foQyTDeY517b2MjkziQmpShBbY2c/NS0N7G/sRqBMt3pg8RxdLB12G209Xk4rzGDh1KwQy7A4J5kDjd1kJ7tw2W3MKUjj04Ntyhi5ek3zpiguZLfDRp9qEQNkJQUXA9HqEpCwv6mbL541lY+rWiJanC6HTd9uNOwDAanfu6LsZAqzkvj92grae738+IpZeP0y5P4sKMrknstm8r9v7eakSWlsqWmnRE3lCvDpoTb9HujvRBydXW1M3msQbSORhJhf/IJUYFnBbH6zeq8+a8AfoVMQTrjIxiO6C4oyWfa1YB20sHwp4SvPfMw18yfr0YC+OOowFrBEPYz+3bvBZsPf3ELdf/0XvZ9uJmnhQmtq2zgm3jnHGsYo5gevnTvmv8TxsEkdDz5vRi6b1HHehMnKb7st2OBOzR6YdMlmiNZu7OwnN8WNEIKJaQnUt/fy3IZqfrxyuz51an5hJsaYov2N3dzyZBnTspNpNoypZyYHE3zYbYKUBOP/5p2prTVtzJ2cwWdKc3A7/z5F6gAAIABJREFUbDyyag8pbqUp04ZNtDWtQZlOpkWQG6lp7WHGxFRyVSE90tnPu3uUsVMtYK21x8N3Lp7BI6v2snjuJFZ8Usu8KRkDBOmfWw/z/MaDdPX7OHd6Dt+4sJSbHl+Pxy91MQxIqYvII6v28mFFEwD//eZOZuenKZHeVa0DXNIDhI+Bggiw4pOaiAJ67vQclm04SFqCg9MKMzl9ajArncaXz57Ko2sr2FLTTmaSk8zkYEdDE2fNco430UpE0Y6wT8j2s89WtgPfvXhGSIdmpDrXxjo89k6F3oHxqul43U7zjslYxBL1SASUnnX7KyvB78dTWUn7K6+QfvXVlriPQ8oqm+KyADWqmoNJPdKTXKb7jSc2VbdyqiqEf3i3Aq8vgKcuE58fli5J0u/H5kNt2AXcfn4JUzKTeOjtPUzLSQ6OqXf1k6OK4KT0BDZVt/Lkh8r0KK0hPKyOVRunPHl9AXwBGWKp96pJPRKddmZMTGHzoTZOzk/jQFM3pRNSIj6j7n4fFUe6uOKUSeyo68DrD7D5UDvX/3kdeWkJ+rBJvy/Af726jV31nUgJf3ingmVfC3bmpJTUtvVy4cwJuqg3dvbr7mJjANT0iSk8unYfb26rx24TnKK62I1isPNwB71ePwdberjt3GlKkNntZ3H/ym3srlcyln3t2U16h/Kskixd1I3vpOaSNoqImcUZvt1MQAvUpW87+3x88akNETu1CU47F8+ewKub60h02XX3vXYerezMJBetPZ64x5EH7aJet075ffbZcXUKhptw78I18yeHjMGPhw6+JerRUJPREAggPR7aXnqJ9pUrraQ044yZE4NzgePpbVc1Bee/aslTxjN9Xj87atv524ZHya8/k2VLb6asXfD0fUUcaulh7xlbAVi/v4ln11dzxrQsfnjZLECZBveRKj6gCF9+uiISeemJ1LXVhbhlnQ4bLT0ezp2ew5SsJF4ur8GvjldOzUnmE0PU/bbadqblJLN47iR+v7YCgDvPL6bfJ/nVv3bzwGvbuXJeQUhDur22nYBUpsgZg5z8AahtCx3f1/KQgzL9zNiZa+720OcNMDkzkSSXgxS3gyOdfdS19zE7L5XFp+aHNOKLirP5YF8TE1Ld7DrcOaBxN0ZRa6uTLSjK5IpT8nRRDxXvHBKcFQMswKMRMjMB9ctgBytap3aGGsVf19bHLU+WhYj/MRs//vGPld9q8oRjPW5tdv/Hg5hrWFPaBoPfj+zvp+2FF6i9+/ujXRuLOElyK0FUQsBfvhx57WQjVc3dCKG4hI+FqP97R70+ZWok2HKoDV9AklF7gLYVK0j+ynVc/d4yUuyS9CQXO+o6WLOrgS89tZF+X4Dy6ja9LicXpHOks58jakBcU1e/btn61HnaLruN286dBsAtZxTS3utj6WkF/GLpKSFTnmbnpdLaE5w6tq2mnVMK0vU57wAP/nsPLocyQvzs+mpueHy9Pl8Z4J/bDqt7St2qMo4nh09n0rerQwgfV7XwwGvbeWSVEgmu5X7PTXVT29rLjtoOzp2RO2BRDm3a2pHO/ohTArv7ffrfd7+0Wf/8M6W5JERYilMTj0jTwRYUZQ7roiBnl+TEtRyo1xBLcTTz/8c7w33/jzWWpR4Bv92B3e+L+Jlwu0m/+mpyv3HnMa6VxVCpVDNPSQnJ7tivfFVTN/lqlrTa1pEV9Zc2HeKel7ciALchJ/hgiBUc9toWw3LCXi8SaHv5ZXqrPk9GZha+vg4l6EubBx0IWnOa4G6rbeeCFDfNqqiXV7fy1/VVyv5Scv6MXP66rooXy2sAOHe6ErhmtLS21bQRkNDW68UfkNS19zF3cjr7jnSFWJLv7mnU//f5Jcs2HGTFJzXcf8Vs/lZWDcCdyz5h2W2LWHbbIlZ8UhPiETBOZ7LbBAlOO9PV6H8ltiLoWnh41V4WTs0iN9XN+v3KcpvzpgTnwWsYU+FGsnb3NnRG/Dya5X2srNB4rf9zpufyx/f2j6vxY4uBWKJuoLyqhfr0fHZmTWXxgXUR9yn827MkzZ07YHvlVUtJnDfPcsuPQfY3dukLQew63MHcyQMbbSNVzT1MzUnC4wvoc5lHir+tV0QqlmvUjPBpYeGdgvLqVp7feHDggT4fBAKI5iZ+Ur6M7ycondTwIKg5+WkIoYj63MkZBKSS+tM47x0p2VrTztklOby3t5EJqW4OtvToFr1GlprzvaW7n0Mtyn09pSAdh90WMo58+cmT+LiqhX5vcG3tPm+AX765e8CKaJpFFT7uaZzO9NKmQ7y1vZ71hmUy9duguuVzU91sVK3tSKJ+8eyJ/OWjA6aCd1ZJDm5HBT7/wM/HwtSnuCPBj/EYtsXwY4m6gVc+rWXZhXcDmIp6/U9/RvHKVwZs79+9m/79+0+IMfexmnTBjMrGbmblpXGwuZuddR0x969q7ubzp0yiq9/HJweju8SP5l509HnZXd+pdzhAGcN/bsPBiMFIkc717p7QaWHhnYJXPqnBJLsl2GzIzCx+sfA/ALDb4MbTC7nasJhGsttBcU4y22vbeX+vkqSks8/LWSU5A6YrdfR6eW9vI42qizq8g5GtRlQ3dXnYWtOOEDCnIJ0UtyPiHOMVn9Tw8qYaPcixR02pGin6Otp0pv2NXSz/+BDJrtDmzlhOU5cSlT8h1c0kNWbASCzBW1CkZDgbT9+LSIyFDojF0WGJuoEklzr2Gv6B04kQAunxkHbFFeYFaK7NFSuOW3EPX6JwPGRb29/YxfzCTJJcdnYZgqci0dbjoa3Hy9TsZFp7PLy57bDpGuDl1a3c8kQZHn98U+XCefVTZV72r6+Zy6PvVFDd0sMydYlKxR1vC0kKc+Pj60OWmFxQlInL4BbWUqYaxX+PGqSl5lBBOpwIvw+k5LdPpfJ6h4MXKlMVV4GE/IzEAddQkJHIh/uaeGe3Iuq/W1PBWSU5A0ROS6Vp5nXIVrPKPbfhIHsbOslMcrGnvlMXkkiifM38yfxm9d6ICVjivdfaftrQwFfPmUZpbkpIx2nDAWX8eN6UDER4OrewOkU7z1j/Lox5fvOb0a7BuMcSdQPd6hSbfHUKCE4nwmZTprLd+XUql3wB76FDUUpQ0cT9OFzlbTDZ1saCRd/n9VPb1su1CyaTlujgtU/rkFKaNtzadLapOckkdtjx+iWNnf3kRbDeyiqb9YU6tNSr8Vznp59bzMG8Ev42+Vzy0jIonpDCpXMm8oS6chYMFManPqjUl7s0bq9t6yXJaQcBpxQoUf5ap0tbGvKzs3JZUJSFf+t0ss9YSPtrryF7epg7rR3XxAmsfNJ8Hq6yFnVziNtaG3MPDya6cNYEnvyw0rQsbQGV1w1j/JEseiMLijIHzFcejKCDEpmemeRk1+EOZuWl8sDikwbsowW6hQ8ZWBxjBrMOsEVELFE3sEtdIrC1x6vngs/9xp36oi4JJ82mb+fOuMo6XgPqTp8abEyjBdMMxYodSicg1jEHmrqREkpyU8hNdfP3soPUtPYyJWtgkhUITmeblpOEQ7XOa9t6I4q68V5IlOUbk1x2uvt9nFUyMNkJwLPrqzi9ej9TD1bx64/XsqrwdL7Z0sy3rjuLBGdoakxQ3PG/W7OXf++s17dpS3dKKflgXxPnzsihICOJv64/wA9e2hJc+EMt6KOKZu66cDon//N1At3dtD3/PACr/+0n+azobmVjOlIIXfErnFguau37ZSSeOIKjHesVQlCSm8Km6lZ9dTQj5dWtPPG+0qF6qbwmZPjB4hizerXy++KLR7ce45gTU9T/dA7Ubxuw+RdyKjcn/ZrWHi/yib8xyZAqsfKqpYAydn74gZ+S8827BrrV7XZ9bvuEe+8h65ZbRu4aRoB4RDU3NShuv7lhnul+ZZXN9KsZmeJpuMurW7lZzTnudthCEoWY8f6eRm59ZiMCTDsOWuR7cW6ynv70obf38MWzpkYsf91+ZU52Y2c/BZlKBHxdW2/EfTXPzmdKslm3v5kPK5r0hCJuR4WeL93IK5/UcDrgkn6Q8LnqjVxy8GMaOy5h2dfvpKxdkJnk4g/vVlDT2qu74wGcdkF2sovWHi9rdzdQ29ZDbVsvd15Qgtthwx8ILv9pTPxiTG/pbTiil/fg34twroF33zV3GxuTcdhtgusWTokqetFc0GeX5PCYQ1n7ezCZyWKVG4vy6lY2H1LyxUda+1rxPinvRjzpSC1GkP/+b+W3JepD5sQU9clnQOMe8AezW0mbi489pVy5oIBn1lWxvTY0/3H/7t36sqxtL71E+6uvkn71UnK+8Q2cEybgnjULkZBA3+bN2DMyaHzkN/Tvqxg3Y+rxplI1JmYpuOd2Dp8ZOYXuouJsPQBMiNjLY2qdABiYKMSMv6w7gJTRI8f3NyorLk3LSWbzQaVhf21zHf/aUT8wUryqhZfVcdevPPMxT3xpIWCegOb1zXWkJzo5szib9ZXNIQFp/b4A6/Y3hZQfUFecMuJUxb3gg3+R1NPIXepQzYGmrhB3vHb8wqlZvLH1MI+9s18fJ89KcnGguUvfzwacMjmdXfWd+jQv7f77jjTo+0lP7LXNhzMiekFRMM/2YDOTHQ1Gb0Ok/N2xcpRbWIwnTszkM+ffCyL00gNC8Hvf1Sw5dRIuh40dkaKktQxzUioZ5pa/QMVFF3P4Z/+PKY//GVfhFHA4sE+YQKCri7YVK9h/yaUc/tn/w3vkyMDyolB51dIhHTdUVu9qwKMmE4mWeKKqOSjqjgMVptc4vzBDDzx0OWzMmJgyoCwjp+QHE5DE0wmQUupBYBC0+MLXQa9s7KIgQ8ka9qlqrRk7ARqbqlr41vOf6tnRvL4AW2vaSUtwhExrW1fRxM/f2MEzHx3gja11nDE1k8+UKpHg2huljdav3tkQkqSk/GArbT3e0OsQNqTLTeaNNzL5kYf17ZedPAm3oUzNqk1PdOrlq0Ps3P3SZjKT3CSo6zu7nDYeWDIn4lrXvgZF1EViYlyiDsObjEMr6+YzC49Zgg9NtM2Sr0RLBGNhMd44MS311DyYdwt88lcI+MBmZ1vuEpp6MjhpUjqz81LZXtseX1leL23Ll9O3cyeyrw98PjyVlfpnEoaUXvZYT5EzZsSKtjJZVVM3KW5HcJxVvcaWl16i9ZVXyFTz47cmpNHV7+ea+ZNZ8UkNdy37hO9ECXDaoybvSEtwkJXsitmwrtvfTF17H9NykjjQ1MNjN89HSskNj5chZTBCfFttO067oLy6lUXF2Tz6zsPsyizilTmf06+xvLqVGx4v0+ddG93CL358iI8qmnRx/uJTG/UpZADv7W3i6xeUhuTG3l7XxvKNh9hS087NT5Tpbvh/ba8PRqvbbBAI4JpcwNTnlulxGxrGKVJGqxaUhTuMc7i1hUeWRZhSFX4fNfd74pw5yJr4RH28E83boOWXmPuNO1lwYeko1nJ8YOXjGMhYuycnpqiDYq1vXqaIuoRl7huYlu0i0WVnTkE6b2yJHiUdghD0796N9KpWmC8sG53fj/T7aXvhBdpfe430K6+M7wUwZP8airjH+7JJKdlQ2UKyy063x883P2tuQR1QE7MEQlfnxOb3g99PqxrxX/PTRwAlInvlp/D+viY2HGiJOM78cVULv1+7j9l5qVx+yiQeWb2Xth4PGREWU9HG/d/cVkeC08ZXPzON/3ptB33eAG9tP6QLs9cX4M/v7Q9ZRnPZbYsoaa9jSkcDl9eWk526G+837mTlJw1BQSc4ZQrgUGsPAakcf9GsiSGCDpEjwR97JyiW/b4AZZVNICUvbTrE3MnpuGfNwtfUhL+pCVtqygBB1zAbR46URS3awh9GfA0N2FJScJWUIPtPDFEH83t5IuWXGA7ivV/xtj1jTRCjYVZX7Z60vfACrpIS8h98kMSTZo9aPUfU/S6EuEwIsUcIUSGE+FGEz78shGgUQmxWf24byfqEoFnrADYHG4/YmT1JmRJ0cn46HX0+fvnW7tAcz051aUhb2G1T3fHmWT4UMm68EdnbO3i3vM83pJzz/bt3x3WuHXUd7Gno5N7LZpGT4manGqWsDQGUf7KPx96pYPvnv8DZrz/JSS4P0wzLk2p4bA5qz72cyY88rKfNPNIZXGqz3xfgl2/tCnVJq2P5HX0+Khq7yEp2ISWUVbaEuNLLq1r46jMbufZP6/j1v/ewo66TPm+A/3lzFwkOG2WVzRw0DA34JazZpbiaw93tLunH7vXQ9uKL7Lv4EiY89Vsy+zp017U2ZarMME7e5w3wwT5lnna4SzzcqxGek/yfWw9zvXqNW2raaP3t0/pQjrf6oL4yWLxkfuerfGvLKzx/demgXca+Iw048ibizJvIT3Pu54+/6zfddziHgI71cNKg8HqV79fy5ey/+JKxW8+xgna/Xn7ZtG2Jt+3R9qs4/wL2L15C3z33wp//fCyuYtBEvSavF6TEU1FB1dVXs3/xEnp37hqVeo6YpS6EsAOPAZcANcDHQojXpZThc8JekFJ+c6TqEY0tJXcwZcdqsnqrSWvbSXv2GZRXt+JQW+0n3q/k2fVVLLttEZnqFLfejz8m8fTT9WlBOsa0YCbolrxmgS9fTtsrr5Bx9dX0bNoUc9329OuvY8I3B3mr4kiI86d392MXgqnZSXz+lDye23iQR1bt5bLdu+mr2I/9xZfpKTwde9U+zrJVck5FGTVnXKhck92OUAXq2ZOv4Ob7f4QjN5N9HxwmM8nJRbMm8PRHB3R38aaqVt0lDfCjFVv1KVgBdWnORKed17fUsnb3Efq9Af3WRrq7Xl+AKdnJrN7VwJHOfq6cl099Rx8bKlv0MWfTKOtAAOHxcFHFOvJaD7PlB/8bEtmtLYPZ51XcEh19PuwCbjyjkDn56aaBXpq7d0X5IZ7feChktbBAQFK+tZJzW1txFhTgra3F39KCIzv+4CzNMkheuZKrly4lZ0780ya9DUdwTpiII28S01xVlKTXA0VRzzMcVux4sYilx3Nc5pcYEXw+pM9nfr/iHX5U20VPRQUHvv99XKWlI2rtHpV3wJCDRLumSHgqKqi65hoybrjhmL/rI+l+PwOokFJWAgghlgNXAvFN9B5hyqtbuXlZJa/Z/GTZ4B/unyhdj7/AAuB6debWjkAR71a+wl2vrgw5vu355xXLXRNqKYNT2pxO8PlwlZTgqajQj2l/+eWBFfF4aFu+XPmzupr2lStJW7JE+czhCHHl9+3YOWirTidCQpztn/8C29Km8NHEc/AnpHHH38v50llT8folv1uzj8sA4fPiRpl6BeAK+CHgp3DdKgKAJzGZhK4OupwJLPQGo7331HcyY2IqC6Zmsey2RSFZwfp9AX748hYqm7r1wDRNeD9TmsOaXQ2s3X1EF1OzS9aPKcnWp35detJEqpq72VjZEjEDWXjf2WOz8+/CM3lh9sV8NSybmibOj6zaq09VAyXr2s1nFka93Zqlb+zraXO8T7cpIp9ywQW0LluGp/rgoEQdGHK8hq+hAXdJCc5JebzTdQHbX+zjunviOM+LLx69IB9FjEkshs2NKwS29HSckwvYv3hJzI72iNZlkOcZjvMOtsy48nEYhh9jdZZSujph86e6IEYzdrS6me1jdi3D0sGUUveeRttnNDqIIynqBYAx/VoNcGaE/a4RQpwH7AW+J6UckLJNCHE7cDtAYWH0xjReyiqb8foDfMwsZogaImQBpV862MyMiEFjWnKaEIvd7wchcBUVkf/rB0mcPZtdswbR21QbPU387enp+JuDEdr927ez78KLOHDmReR98y4WzJ8ecnjML7UQuEpKaPryXfzPXzdx9/59nCQq+Yt4n1WFp/PC7EvYVdfBo2sfZldWqPXmlP7QopBKKtOuDvrtTtpPOo38vbuob+9lYloC+xq6uOq0AkBxF99TOptb3l/PtqxpPDfrEioag2U9uvZh2opnMvve7wHKcIBmvT+69mH2ZE/lxZMupcmVwu/WPox31sl4bv4yja7UkFSoAN9/aQsPLJ4TskBIeAYyqSqtBP5VdCZ/nnc1rjBL3hhA9b1LZrCpuiVkypPZvTZuN5vjPXXDKuqBlAsvVET9YDVJ80+L+Ry17SEMosGUfj++piYcEyfgmDiRZ1q+guuv2dFFXSMQ0BuxeBqpqO9iHDEmgxUoY0OdtmQJud/+VvxjvWrnWSQnI7u7CbS10fHPN8HrxVNZSfsrryhZJYcY5BrLCxfrWmON5WrnGYxYDbVMICwfx71k3XJzzHuC00nGtdfGTMaV1dICQFdKqiKYUurGTvg1aXUze07hY92eigplf4jowdSeUzxeUwAcDjKuu07RgDADzJiN9FgnIBNDtvxiFSzEtcBlUsrb1P+/CJxpdLULIbKBLillvxDiDuAGKeVno5W7cOFCuWnTpqOuX3l1K7c8WUaGr5kPXd/CIQID9umVLtYvWcNnFw5clU0jomgLQeKCBUz9+98GJ+pxIoF+uxP75YuZfe939Rdv16zZEb0EUgiE+pwDDgfeAKwqPJ3FVev1Mr3Cjl366c8vIrGuGo+wKwlSouATNiQQSEgkYfp05NbNbJu1iKwf/IDb3qji/7tyDl88a2qwXl4vAQQ+m523C0/nuVmX0JaQxpuv/gDpcGKz26g5/UJ+mHoGze40BOifYRPULrqIye+/FfzCqF/yP21v56G39wJKjvO7L53JouJsyiqbOf//7ib79AUhvfXuygNszColyddHhqeb5+743wHCr9VZO0/dF26mrF3o7vbwz7XyYx0H0PC/v6L1+eeZsXEDe06bT87X7yD32982PXd42bp3SMVoLZkF3YHieq84/3zyfvoA6VddxaLsbTgnT+ZvJ90V0aLRPEg6djsZ118f8zyRrsGsLM3jZXqt6rscyx0b/j0TLldIAx9yTYZypc+HPT2dvi1bcE6ZEj0NtNNJxjXXxOyAhNRFneWAzYZwOCJ2DsKvVfp8JC9apIuLVueI9yj8PPoNEAin07QzEvUdMyvTbodAAFt6OoHOTuwpKSSffx4FDz4Y+XkYxD918eeZ/H//F3k/gyAWHlRWLTw4rTj4fhgQLhciKYmU88+n47XXBpRnvO4B71w0NJea9v2K8Lx2zZodvCcJbhLnzWPqM88oicnsdvp37Bgg5rG+J4NBCFEupVwYc78RFPWzgJ9JKT+n/n8fgJTylyb724EWKWV6pM81hkvUIRhJfVPVT8iqfiv6znmnwNc/HLA55EsQ4YGaNcRHg0TNGCYENqeT1M9dyoR77qHivPND9tF+NyZlMqG/Qx/7BpSMXoM5F8H51xKwJSfj6e7BqZ5J2h0Iv48A4LM5eLvwdM7/7x9yxsKZETs2EvDa7Bw4/SJmbnh7QL2rUyfy2zP/g0dWPxQ8yKQ37LnkCureX8/27Gmc3HyA/PPOInn3tpAGUWswc+66i7rvfY/GxAyaEtOZ3VJN77MrmH+Gkg88oqDZbEpDEaXx0z4Pb0jCxQXg4B134Gs4QvGrK6m4+BL8HR2kXXFF5LLtdqVxiSSM2i452aRefElMS6N32zaqrrueyX94jNTPfpYz0z7BnpXFUwmXDxTgsHfWnp2NLSmJ0lVvx2VFh38vIr3/6Vcvpf2V0GEtXC4yTBpkV2npAMELEb4IJMydy7QXX4j+PXS7cRUUBKeixkAkJJB+1VWmohtVTAzPM+LzDieCWAMDhvbMKxs0MMDk/VZxlZbGV6ZarrOwEH97OzPWfYQICx6uvGopgd5e/G1tJC9aROfq1WRcdy09m8pD3s3Kq5aC00H/tu3gdFJ0oBKcTqoLJpNx7bXm9zKOGKbBkHHTTQPjpAy40jxIKQh4bDgS/SRN8NC6N5n04h5yT+mk5oMs+tsdpE/rIXdOF45EwzMz0Y7BMhZE3YHiUr8IqAU+Bm6WUu4w7DNJSnlY/Xsp8EMp5aJo5Q6nqOt01sNv5oLfJBLY7oLTvgiLHx7wUUiPN0LvrPKqpQPd9Ibe4IC5YZGIZz9Dr9hIJFE+GoLlCUTE0LXgfjgcZEb7YsY4DwYPQ1TUL7jf7sDu94VYR9HuW8Bux+b3Y8/JwZaSQvKiRREFzXieqB4Ys4ZGPS7Q1UXivHl0vfceSafNo+Dhhzn41f+ke926+EXBjPB3SpsHbwg66li1itpvfRvn1KkkL1rEVb+/GpvbzdNpVwbLiXTPbDYSTp1L36ebSVuyhI5//GOAlXfo9jvMrVUz4n3/zY7T7neUcrRO1ZDuaTx1iCS6cbapWudg2OtmIPWKy8m77z4Ofu32UE/FEI0M4XIh1emrWpuTcuml5P3k/tAx+K/fwYGrliIDARJOmk1P2YZgp9z4bp7ZyOF/NuHptJM+rYe8rYfx9duoyCwBIUEaW614WrF4WzzjfuBM8eHtcsbYH0Bgd/tJyPLSfTgBhFQeeUCQNauTifPCVoGMoh2DZdRFXa3EFcBvADvwtJTyf4QQPwc2SSlfF0L8EvgC4ANagDullLujlTkiog7wxt1Q/hfILIaWOHurQOWaKSReHNslGS7+EaPoTRqE4RLkoRDvV2Oonw+5YddQ4wTitjCOAldpKQW/fpAEk1gJ+4QJ+CNM3RGJiUx+9Pcc+s/b9AbVffLJSrIiCK17vA2u6n2wpaYS6Ii9RrwtLY20xYtpe+45/fhbK58Eu4O/5g9ijYJInUeD6zKauz1Sp/O4x+2G/kjGwnB3t83RLfC4xdy8TglzT6Fv68B1M8LPI/xepPa1tkkIRL/GzBmd5M3vpPdhDzaHpHLCtLD6QPT7Zdwn2rWo+SicAQJee5T9YjFwf2GTpBd3kzOnC6dmqTsS4DtbIXXiIMqOzJgQ9ZFgxES9sx5e/gpc9iD8fSl0N8Y+ZhC9MM1iDxf/cLEPt+iFzcahMy9i8vtvxjXOHf6qxXNMtLK6JxWScji4qIjHZlci4AdRRsirH25lDQfDPLxhilpnvfE6mg7JUYqcXoejKOewNw+ASc56853i9HqEYPZsx6qe0ZCPAAAT8ElEQVSwq98zaRTf8Gc9VAbci6GK+NGI/3D76eL9fDDnlWSUdtO1yw02ic8+MPGU+TnBlebF0+GKcs7gfgVntZGQ6WPX8vwY5Q7tOSXmeph6UTPYnXDal4bFSgdL1I+Oznp4aBaRZ0bHYJDjJ5rY1y25ifVtcNE3vjDAnb++DdpvuZFdWVNZXLVOPzbaaxcAvDYnH01fxGf3fGDYLrAZr8tEEG1paRT89jeknHWW3vGQwqYGq72p7xfu8pbChpDmjf+QGsmjtebDOVadgJFkmMcUzUi76ko6Xo0QkDQkzKzTYyU6yj66lWZTXKfp07rJndPFvtfygtvmJJD72KpgXExMa/OofVZh+4W6h13pfjztcUxWEhJhA+kfzLlibNevXd0eh+U9NMzrI2yKizvSZwnZHqZd0mwi0gPFXGNooh6905BR2h0cUx9GKx3iF/UTc0GXWKTmwdwbBy/pdpeyAhwoy7v+LH3gz5/OCTmk+LJGJsmHWPD6Qr75/kLcGR4yilopuMnNpJ8+gGPFUs5dVsriKzZxzyJ1nrtNmY7VOmFySFkeYVeml7mSWFO4kK9//n52XH9H8DObk7rzLld2djoRbjcZ116r/48QuEpLmfbqSmZu3EDKWWcByvS9jGuvZcaaVVzy+EMhx2dffx3u0lIybrgBd2kpmTfeEPUWebQpJWZoATc2m1K/m25i+nvvRj8mWlnqNZlecxT040aCWOmHzT7X7suNN0Y/PjzrYQTe6rictzoui15MQqLJJ5LYnd7wz82u2RiCaTy5cg5XWng6Wzngt7Apll7wuEjnV84V8NoQ9gAZxd2ULm5g0sIOHIkB5bunbTvpAI7HSuFn6fp28zpIXGlhnURbvNduLE8px5XqJaO0G3ea8nv6lQ2UXB4+rBN2b2wSYZdklCj1j/dcoXUdeB+FXRquXb2GgLGcWOeJ9P/A5yzsynlTOzpIjTCc5M6M8A6odZ1yTuuA/Y0kZHsouaIpRNCN5zarS+jnYfcm5JqUezntxmQmnd6Fo3AGCJuSsXSYBH0wnLi532Nxyc8Q+9cguxsRyPhGwPwe2PSU8hMBn3AiW2tw/sw8wL/4MjXJSV+H0gkIw53hITHXz6a58/mh/XZWvPg9PMKOFDa2zT2Xk374PZxZ2dgrm3lMnXddmZHPzsyprDj5Uh775qW4j1SGDAX0rn6RxPRWtYdZC8vVdAKq16H4skaofwgee0itQw6JOV3kXjgFx/cfGFDHAYl5wHyIQcVVWgp+P0mLFunxBqZxCjEsbWNZWhnhwx+9n34aDGA0BplJiaukhIL/+zUJs2bFOSVxcG5GBKQXddNelRy63ViGlGHbJcIO6dM6lOckH6INg6WhuYvTPCAFSRP7aatIGWhVGayu5W1Kx+DytH+ZXkPb8ufDtgfHJAs+08qhd3Oi3Iew8gyWcVtFSsh2AgYXapgF7UgMKFaVYT/tGnuPuEmc0K/v19vkIjHHo28PP094uUb0714Y2vbg/QytQ3gdza8xkndCsULTiyPXaQCG82uWZ+W/ckjM8Qw8PuI5g88uJc+jH2t2H7X/Q64lrg5K6PMMv2favQw+j24ciX661yrf6860NKUcG2QUd5N7ci/7Xs1VjrHZSZ/aSe55E3H0HDapjwSbIKO4h9yTQ5c7RthBBnDn2EjM6KStIjm0Lif34kjw0tvkVu5NSyqJWZ3kXncxjsBh2n5VFfoczukm4aST4fOPwL/uVYZw/3UvnP/DGPdpZLBE3YzUPPj6B4jfngq+PvzShg3JAfIoFoeH5Cx0SC/0D+xVDkYStAZmCWtYwhoqM3LIUL988xL/Dq/9HVCy4vGeckzPzSdRdcp9PKbNlQ4T6eKLIpzI6HUIW39eb/w6d4R2PNROgDvXTmJ6a+gXt6hV7wToQqpOM9MENCJ/OgfqtwH5IWWFNjIKrtJS07LCOybF8wC5ll61gxLaqBk6NuQbOhGR3JLG8TyT7Wq9hT1Aan4fE07txJEYUEQ9DqELF48Q9OO7BnyuNczhDah2rRw0FhRDgCOISXz3IbJwDWzUle1mAuXO8EQWrgHPOVSYzc4zFGLVIfzz8HObdgrOy1PFaWjnj9QZ0fY1fXbCDhKKL2tGea9tGExw0w4OYHJNhqGCkA5HLok5A9/d8E4DdjdMmg+sA4Hage3RhZSMItzvribxpBJy/+sRHO9+XxHPN76rtA/azCU7CIeL9JNc5P7kYRwbfwEZRbD1BciZAU174ZTrob2a4pcU8e19tpHE5CMh52LrCxTfezG0VwdF+upfQupE3CuXkJhcT+7lp+A4sBIWfCU4bv6Vt0J/jwLWmHos3ribwKanWeE7h0JbIz/13Mqz7l+SKzqOUezqOMHuAlcK9Lbom8waaFPLIgrhx4RbbgOEZpgIt2TMRCLcSoslUtGuKV4Bivc+mu13xoOrAPhr4a1RBfhoriHcAhxs3WMi7CD9GMefh3KPDAWiDkrHsW+oEMY6d+W/J5A4JYXc0jocrj5VyOYqFl64OGl1iSC4UeuODN4Tu5vKN9NJzO5TrU8f5M5Uhe0GaN4XPKfdDRNmwZHdyv+qNUvuTGjcw67lkwzPtUexknsrqFyVT2JGZ9CaPbkHR4I3ePzcG0PPo1fVUH7TXl0Ye3Oysdk82N95UxHka59RXNhaILP2vxF15lLle9NJPH/xQA+fMQj6X/cOLCO87GjnMhLvfsOEFSg3XHTW0/n3L3JpzVc47Fes0lxa+cD9XRKEFx8CO3LYhF13ysnYw64nMsMmCsN03uGoz7G+pjMeXAUCnp36pagCPBhiXoMuwmbbI4tzEFXgcmdFFqdYaOcZUA/1vHNvgp0rwdcX+9hwIYy4/0Dh0qfPGi08ULZvejrYqYhVfjhaJyG7VLFMF3xF2V7+F+U+Ga1OTYjC66L9H7Z/Zbg1q5UT/luzirXjw8+jW8sm9bngAqXO774b+3o1jrG4jhaWqA8z5dWt3L9yG7vVPOP/7Xiamx1rWOE7hwsd20mXHTiFXxdj7bdPKqIfQElhGg0JCLXBCC/HLwU2oaR8Id4xfouxh92t/I6nkR5hFj38b2xOyftfWxK04hp3q6ISRdQjiRsYLLwIomlzQlI2lFwIW5YHhSsuiy7sXJp1G0mccmYoQ0Xh5Rst1PZqRXyM9dDKvWEZvPerUAEKFyJNuMKF0Gz/cOEyEyFte7zlh//W9jeWj4wuePFaqUdrvcayljWGIuonCJaojwDl1cqyoT5/gHxHOy9mP8EX6m8DZNBylzZsBAhgwyEC9Eon+2QBM0UtbuHVRThgyMgmgIBwYEvOgZILkVuWs08WUEqNXk7A5sY2MY5eu90NSH38e3Bobj4zd1+sz0cIYQdkdKEZbUwtQOPnAVj4VeV/o0Vmeqx6n8O3x3su1XVqdp6mnlwgQM6iS4PiY3QDh5/HKMDh4gahFl64aGrTezSRGaxFFy504YSLRnj5ZsIaqdzwsmKJcqz9B0u85Q/X+cYSTepYfk5O9P1OQCxRHyG0fPHagiEPvb2HgIT/z/E0t9jXsDJwLvPT2pHpRUyr+wf7Cq9n1bR7ua7+ESbsWWbuWgtr9Hac+hMy3vsJ7pxp5FSujL/XrjWwRtEwY7DuxIjjblFcprHEJ14cCTBnaahIDBUzodIsuXBLL97jw4XOzGozWk/hwmNmPWruVDOhi2UhRjpPJEHVCHfBmu0fzSKMJpoweItusC7WMTouamExVCxRPwZoK715fQHybG38PePPdCx+glNnzzTvbZu51mJZIPH22sNFI5KrM5IrMh53X6Rxt2hBMEahM6tHNFep8bzn3xt6/2K5Is1+mwmV2dhgvMcPxWqL9x2JJXSxzmVynmf6l0NCOl/+cpzv3FCEzxJNi8HwzDPK7wEvpUW8oo6Uclz9LFiwQI4lNlW1yEfX7pObqlriO6DjsJRPXyZlR33k/4cTrexX7pDyZxlSrrhD+b9ua/Q6aP9r+8Xa/x/fU8p/9IzQ84Tvb1YPs+3h541Wt3h/x3vfB3sPhpORLNvA+ecrPxYWYwbrpTQFZc2UmBppWeonAiNtLcUbBHO0QTgWw4oVk2Qx5rBeSlMs97uFhUVUrPbTYsxhvZSmWLnfLSwsLCwsTjAsUbewsLCwsDhOsHK/W1icoLz5Zux9LCyOKdZLedRYom5hcYKSlDTaNbCwCMN6KY8ay/1uYXGC8oc/KD8WFmMG66U8aixRt7A4QXnxReXHwmLMYL2UR40l6hYWFhYWFscJlqhbWFhYWFgcJ1iibmFhYWFhcZxgibqFhYWFhcVxwrhLEyuEaASqh6GoHKBpGMoZC1jXMjaxrmVsYl3L2MS6lugUSSlzY+007kR9uBBCbIonj+54wLqWsYl1LWMT61rGJta1DA+W+93CwsLCwuI4wRJ1CwsLCwuL44QTWdQfH+0KDCPWtYxNrGsZm1jXMjaxrmUYOGHH1C0sLCwsLI43TmRL3cLCwsLC4rjihBR1IcRlQog9QogKIcSPRrs+g0EIMUUI8Y4QYqcQYocQ4jvq9p8JIWqFEJvVnytGu67xIISoEkJsU+u8Sd2WJYRYJYTYp/7OHO16xkIIMdNw7zcLITqEEN8dL89FCPG0EOKIEGK7YVvE5yAUfqd+f7YKIeaPXs0HYnItvxZC7Fbru1IIkaFunyqE6DU8nz+NXs0HYnItpu+UEOI+9bnsEUJ8bnRqHRmTa3nBcB1VQojN6vax/lzM2uHR/85IKU+oH8AO7AeKARewBThptOs1iPpPAuarf6cCe4GTgJ8BPxjt+g3heqqAnLBtDwI/Uv/+EfCr0a7nIK/JDtQDRePluQDnAfOB7bGeA3AF8BYggEXAhtGufxzXcingUP/+leFaphr3G2s/JtcS8Z1S24EtgBuYprZz9tG+hmjXEvb5Q8AD4+S5mLXDo/6dOREt9TOACillpZTSAywHrhzlOsWNlPKwlPIT9e9OYBdQMLq1GnauBP6q/v1X4KpRrMtQuAjYL6UcjiRJxwQp5ftAS9hms+dwJfCsVCgDMoQQk45NTWMT6VqklG9LKX3qv2XA5GNesSFg8lzMuBJYLqXsl1IeACpQ2rsxQbRrEUII4Hrg+WNaqSESpR0e9e/MiSjqBcAhw/81jFNRFEJMBU4DNqibvqm6dp4eDy5rFQm8LYQoF0Lcrm6bKKU8rP5dD0wcnaoNmRsJbZzG43MB8+cw3r9DX0WxmjSmCSE+FUK8J4Q4d7QqNUgivVPj+bmcCzRIKfcZto2L5xLWDo/6d+ZEFPXjAiFECrAC+K6UsgP4I1ACzAMOo7iyxgPnSCnnA5cDdwkhzjN+KBXf1biZoiGEcAFfAF5SN43X5xLCeHsOZggh7gd8wDJ102GgUEp5GnA38JwQIm206hcnx8U7FcZNhHaEx8VzidAO64zWd+ZEFPVaYIrh/8nqtnGDEMKJ8iItk1K+AiClbJBS+qWUAeAJxpDbLRpSylr19xFgJUq9GzTXlPr7yOjVcNBcDnwipWyA8ftcVMyew7j8DgkhvgwsBm5RG1xUV3Wz+nc5yjj0jFGrZBxEeafG63NxAFcDL2jbxsNzidQOMwa+MyeiqH8MTBdCTFOtqhuB10e5TnGjjj09BeySUj5s2G4cn1kKbA8/dqwhhEgWQqRqf6MEM21HeR63qrvdCrw2OjUcEiEWx3h8LgbMnsPrwJfUiN5FQLvB5TgmEUJcBtwLfEFK2WPYniuEsKt/FwPTgcrRqWV8RHmnXgduFEK4hRDTUK5l47Gu3xC4GNgtpazRNoz152LWDjMWvjOjHUU4Gj8okYh7UXp/9492fQZZ93NQXDpbgc3qzxXA34Bt6vbXgUmjXdc4rqUYJVp3C7BDexZANrAG2AesBrJGu65xXk8y0AykG7aNi+eC0hE5DHhRxvv+0+w5oETwPqZ+f7YBC0e7/nFcSwXKmKb2nfmTuu816ru3GfgEWDLa9Y/jWkzfKeB+9bnsAS4f7frHuhZ1+zPA18P2HevPxawdHvXvjJVRzsLCwsLC4jjhRHS/W1hYWFhYHJdYom5hYWFhYXGcYIm6hYWFhYXFcYIl6hYWFhYWFscJlqhbWFhYWFgcJ1iibmFxgiCE8IvQleSGbYVCdVWt8TQH38LiuMQx2hWwsLA4ZvRKKeeNdiUsLCxGDstSt7A4wVHXsX5QKOvabxRClKrbpwoh1qoLh6wRQhSq2ycKZU3yLerP2WpRdiHEE+r60m8LIRLV/b+trju9VQixfJQu08LihMASdQuLE4fEMPf7DYbP2qWU/397969aRRDFcfx7DBaCEIKWCjapRIPiE9j6ABKsxMYUYiV5gTxAuImNjQg+QMqAiAQhFjYi2IqdQlKkuE0Q+VnMBG8wNpqLsPf7aXb2FMNOdfbsnznXgE1gvcc2gBdJrtMaoIx6fATsJFmi9cf+1OOLwNMkV4ED2q5g0PpK3+jzPJzW4iThjnLSrKiqcZLzJ8S/ALeTfO5NKr4luVBV+7QtSL/3+NckF6tqD7iU5HBijivAqySL/XwVOJtkraq2gTGwBWwlGU95qdLMslKXBMdbRP7tnf7hxPgHv77ZuUPb9/om8L535ZI0BSZ1SQB3J47v+niX1sUQ4B7wto9fAysAVTVXVfN/mrSqzgCXk7wBVoF54LenBZJOh3fM0uw4V1UfJs63kxz91rZQVR9p1fZyjz0CnlfVE2APuN/jj4FnVfWAVpGv0LpvnWQOeNkTfwGjJAentiJJx/hOXZpx/Z36rST7//taJP0bH79LkjQQVuqSJA2ElbokSQNhUpckaSBM6pIkDYRJXZKkgTCpS5I0ECZ1SZIG4icUUilgnE9unQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, init_val_loss, label='initial validation loss', marker='.')\n",
    "plt.plot(epochs, drop_val_loss, label='dropout validation loss', marker='v')\n",
    "plt.plot(epochs, l1_val_loss, label='with L1 validation loss', marker='<')\n",
    "plt.plot(epochs, l2_val_loss, label='with L2 validation loss', marker='>')\n",
    "plt.axvline(x=min_loss_epoch_l1 + 1, linestyle='--', color='r', label='L1 min loss')\n",
    "plt.axvline(x=min_loss_epoch_l2 + 1, linestyle='--', color='b', label='L2 min loss')\n",
    "plt.ylabel('Validation set loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Initial vs Dropout vs L1 vs L2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ Based on visual inspection, the dropout model seems to perform best because its validation loss rates seem to be lower than that of other models. It is quite surprising to me that the L1 weight regularization model performs worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__iv. estimate alternative models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {\n",
    "   'm1': '3 layers; 50 epochs; all else like initial model',\n",
    "   'm2': '6 layers; 50 epochs; all else like initial model',\n",
    "   'm3': '256 hidden units; 50 epochs; all else like initial model',\n",
    "   'm4': '64 hidden units; 50 epochs; all else like initial model',\n",
    "   'm5': '16 hidden units; 50 epochs; all else like initial model',\n",
    "   'm6': '3 layers; 256 hidden units; 50 epochs; all else like initial model',\n",
    "   'm7': '128 batch size; all else like initial model',\n",
    "   'm8': '3 layers; 50 epochs; 0.001 L1; all else like initial model',\n",
    "   'm9': '3 layers; 50 epochs; 0.2 dropout rate; all else like initial model',\n",
    "   'm10': '3 layers; 50 epochs; 0.3 dropout rate; all else like initial model',\n",
    "   'm11': '3 layers; 50 epochs; 0.5 dropout rate; all else like initial model',\n",
    "   'm12': '3 layers; 50 epochs; 0.5 dropout rate; 0.001 L1; all else like initial model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_epoch(val_loss_list):\n",
    "    '''\n",
    "    Find number of epoch that yields the lowest validation loss.\n",
    "    '''\n",
    "    min_loss = min(val_loss_list)\n",
    "    best_num_epoch = val_loss_list.index(min_loss)\n",
    "    return (min_loss, best_num_epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_loss_epoch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_model = models.Sequential()\n",
    "m1_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m1_model.add(layers.Dense(512, activation='relu'))\n",
    "m1_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m1_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.7219 - acc: 0.7384 - val_loss: 0.5936 - val_acc: 0.7893\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.4618 - acc: 0.8308 - val_loss: 0.4142 - val_acc: 0.8479\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3948 - acc: 0.8538 - val_loss: 0.4657 - val_acc: 0.8335\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3609 - acc: 0.8650 - val_loss: 0.3844 - val_acc: 0.8569\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3306 - acc: 0.8767 - val_loss: 0.4188 - val_acc: 0.8435\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3082 - acc: 0.8841 - val_loss: 0.4542 - val_acc: 0.8477\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2921 - acc: 0.8897 - val_loss: 0.3409 - val_acc: 0.8726\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2766 - acc: 0.8949 - val_loss: 0.3313 - val_acc: 0.8772\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2599 - acc: 0.9016 - val_loss: 0.3291 - val_acc: 0.8818\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2487 - acc: 0.9045 - val_loss: 0.4394 - val_acc: 0.8478\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2391 - acc: 0.9086 - val_loss: 0.3816 - val_acc: 0.8664\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2260 - acc: 0.9134 - val_loss: 0.3202 - val_acc: 0.8854\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2190 - acc: 0.9164 - val_loss: 0.4070 - val_acc: 0.8546\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2120 - acc: 0.9188 - val_loss: 0.3269 - val_acc: 0.8887\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1982 - acc: 0.9249 - val_loss: 0.3668 - val_acc: 0.8782\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1952 - acc: 0.9259 - val_loss: 0.3023 - val_acc: 0.8976\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1865 - acc: 0.9282 - val_loss: 0.3612 - val_acc: 0.8797\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1804 - acc: 0.9313 - val_loss: 0.3651 - val_acc: 0.8824\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1727 - acc: 0.9344 - val_loss: 0.3107 - val_acc: 0.8959\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1638 - acc: 0.9364 - val_loss: 0.3467 - val_acc: 0.8854\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1638 - acc: 0.9383 - val_loss: 0.3471 - val_acc: 0.8909\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1543 - acc: 0.9415 - val_loss: 0.4036 - val_acc: 0.8803\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1494 - acc: 0.9429 - val_loss: 0.3436 - val_acc: 0.8915\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1444 - acc: 0.9445 - val_loss: 0.3989 - val_acc: 0.8866\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1427 - acc: 0.9461 - val_loss: 0.4341 - val_acc: 0.8601\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1358 - acc: 0.9469 - val_loss: 0.3754 - val_acc: 0.8928\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1290 - acc: 0.9509 - val_loss: 0.4166 - val_acc: 0.8913\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1291 - acc: 0.9508 - val_loss: 0.3769 - val_acc: 0.8973\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1224 - acc: 0.9532 - val_loss: 0.4083 - val_acc: 0.8898\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1194 - acc: 0.9527 - val_loss: 0.3803 - val_acc: 0.8940\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1165 - acc: 0.9558 - val_loss: 0.3818 - val_acc: 0.8937\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1135 - acc: 0.9561 - val_loss: 0.3865 - val_acc: 0.8996\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1107 - acc: 0.9593 - val_loss: 0.4146 - val_acc: 0.8923\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1061 - acc: 0.9598 - val_loss: 0.4582 - val_acc: 0.8806\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1013 - acc: 0.9608 - val_loss: 0.5169 - val_acc: 0.8820\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1022 - acc: 0.9622 - val_loss: 0.4158 - val_acc: 0.8999\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0977 - acc: 0.9635 - val_loss: 0.4106 - val_acc: 0.9003\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0907 - acc: 0.9652 - val_loss: 0.5240 - val_acc: 0.8898\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0917 - acc: 0.9647 - val_loss: 0.5197 - val_acc: 0.8868\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0881 - acc: 0.9661 - val_loss: 0.4802 - val_acc: 0.8956\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0896 - acc: 0.9656 - val_loss: 0.4401 - val_acc: 0.8976\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0864 - acc: 0.9667 - val_loss: 0.5585 - val_acc: 0.8900\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0840 - acc: 0.9672 - val_loss: 0.6674 - val_acc: 0.8766\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0796 - acc: 0.9695 - val_loss: 0.5349 - val_acc: 0.8870\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0849 - acc: 0.9688 - val_loss: 0.4469 - val_acc: 0.9023\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0759 - acc: 0.9716 - val_loss: 0.5312 - val_acc: 0.8981\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0756 - acc: 0.9717 - val_loss: 0.5046 - val_acc: 0.8896\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0748 - acc: 0.9718 - val_loss: 0.4903 - val_acc: 0.8987\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0696 - acc: 0.9734 - val_loss: 0.5256 - val_acc: 0.8952\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0767 - acc: 0.9723 - val_loss: 0.5126 - val_acc: 0.8999\n"
     ]
    }
   ],
   "source": [
    "m1_history = m1_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m1_history.history['val_loss'])\n",
    "tup = ('m1', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_model = models.Sequential()\n",
    "m2_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m2_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.9563 - acc: 0.6453 - val_loss: 0.5561 - val_acc: 0.7898\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.5462 - acc: 0.7977 - val_loss: 0.7164 - val_acc: 0.7348\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.4613 - acc: 0.8278 - val_loss: 0.3916 - val_acc: 0.8594\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.4134 - acc: 0.8482 - val_loss: 0.5741 - val_acc: 0.7829\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3762 - acc: 0.8610 - val_loss: 0.4315 - val_acc: 0.8447\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3480 - acc: 0.8704 - val_loss: 0.3947 - val_acc: 0.8506\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3293 - acc: 0.8773 - val_loss: 0.3320 - val_acc: 0.8748\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3141 - acc: 0.8830 - val_loss: 0.3567 - val_acc: 0.8675\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2962 - acc: 0.8887 - val_loss: 0.3653 - val_acc: 0.8643\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2809 - acc: 0.8944 - val_loss: 0.3445 - val_acc: 0.8721\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2700 - acc: 0.8994 - val_loss: 0.3499 - val_acc: 0.8753\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2593 - acc: 0.9023 - val_loss: 0.3525 - val_acc: 0.8735\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2482 - acc: 0.9054 - val_loss: 0.3582 - val_acc: 0.8757\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2435 - acc: 0.9082 - val_loss: 0.4859 - val_acc: 0.8409\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2353 - acc: 0.9100 - val_loss: 0.3819 - val_acc: 0.8811\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2260 - acc: 0.9148 - val_loss: 0.3705 - val_acc: 0.8740\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2216 - acc: 0.9166 - val_loss: 0.3432 - val_acc: 0.8899\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2148 - acc: 0.9176 - val_loss: 0.3488 - val_acc: 0.8917\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.2129 - acc: 0.9196 - val_loss: 0.4108 - val_acc: 0.8696\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.2034 - acc: 0.9223 - val_loss: 0.4180 - val_acc: 0.8822\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.2004 - acc: 0.9233 - val_loss: 0.4371 - val_acc: 0.8589\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.1961 - acc: 0.9256 - val_loss: 0.3429 - val_acc: 0.8988\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.1969 - acc: 0.9260 - val_loss: 0.3275 - val_acc: 0.8931\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1872 - acc: 0.9285 - val_loss: 0.4700 - val_acc: 0.8705\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1926 - acc: 0.9295 - val_loss: 0.3621 - val_acc: 0.8970\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1822 - acc: 0.9305 - val_loss: 0.4568 - val_acc: 0.8884\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1826 - acc: 0.9307 - val_loss: 0.3992 - val_acc: 0.8984\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1780 - acc: 0.9331 - val_loss: 0.4041 - val_acc: 0.8815\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1795 - acc: 0.9342 - val_loss: 0.4129 - val_acc: 0.8940\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1685 - acc: 0.9377 - val_loss: 0.4508 - val_acc: 0.8726\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1688 - acc: 0.9375 - val_loss: 0.4239 - val_acc: 0.8981\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1669 - acc: 0.9379 - val_loss: 0.3968 - val_acc: 0.8944\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1680 - acc: 0.9379 - val_loss: 0.6102 - val_acc: 0.8573\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1643 - acc: 0.9392 - val_loss: 0.4532 - val_acc: 0.8922\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1638 - acc: 0.9392 - val_loss: 0.7216 - val_acc: 0.8664\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1738 - acc: 0.9381 - val_loss: 0.3766 - val_acc: 0.8950\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1556 - acc: 0.9427 - val_loss: 0.5315 - val_acc: 0.8749\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1594 - acc: 0.9412 - val_loss: 0.7130 - val_acc: 0.8777\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1655 - acc: 0.9439 - val_loss: 0.4649 - val_acc: 0.8815\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1572 - acc: 0.9443 - val_loss: 0.5296 - val_acc: 0.8797\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1541 - acc: 0.9445 - val_loss: 0.4349 - val_acc: 0.9001\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1498 - acc: 0.9459 - val_loss: 0.4493 - val_acc: 0.8954\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1522 - acc: 0.9472 - val_loss: 0.5069 - val_acc: 0.8614\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1469 - acc: 0.9479 - val_loss: 0.4900 - val_acc: 0.8870\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1559 - acc: 0.9478 - val_loss: 0.4277 - val_acc: 0.8960\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1455 - acc: 0.9474 - val_loss: 0.4214 - val_acc: 0.8865\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1411 - acc: 0.9494 - val_loss: 0.3926 - val_acc: 0.8882\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1381 - acc: 0.9491 - val_loss: 0.5387 - val_acc: 0.8914\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1441 - acc: 0.9483 - val_loss: 0.4263 - val_acc: 0.9006\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1363 - acc: 0.9518 - val_loss: 0.5020 - val_acc: 0.8975\n"
     ]
    }
   ],
   "source": [
    "m2_history = m2_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m2_history.history['val_loss'])\n",
    "tup = ('m2', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_model = models.Sequential()\n",
    "m3_model.add(layers.Dense(256, activation='relu', input_shape=(28 * 28,)))\n",
    "m3_model.add(layers.Dense(256, activation='relu'))\n",
    "m3_model.add(layers.Dense(256, activation='relu'))\n",
    "m3_model.add(layers.Dense(256, activation='relu'))\n",
    "m3_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m3_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.8060 - acc: 0.6983 - val_loss: 0.6078 - val_acc: 0.7655\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.5033 - acc: 0.8126 - val_loss: 0.6147 - val_acc: 0.7764\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.4271 - acc: 0.8410 - val_loss: 0.4823 - val_acc: 0.8236\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3887 - acc: 0.8543 - val_loss: 0.4331 - val_acc: 0.8370\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3548 - acc: 0.8677 - val_loss: 0.3707 - val_acc: 0.8621\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3297 - acc: 0.8743 - val_loss: 0.4142 - val_acc: 0.8472\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3105 - acc: 0.8835 - val_loss: 0.3614 - val_acc: 0.8673\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2931 - acc: 0.8897 - val_loss: 0.3499 - val_acc: 0.8665\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2851 - acc: 0.8920 - val_loss: 0.3581 - val_acc: 0.8698\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2708 - acc: 0.8970 - val_loss: 0.3340 - val_acc: 0.8773\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2589 - acc: 0.9022 - val_loss: 0.3369 - val_acc: 0.8769\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2458 - acc: 0.9058 - val_loss: 0.3319 - val_acc: 0.8771\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2397 - acc: 0.9072 - val_loss: 0.3445 - val_acc: 0.8818\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2278 - acc: 0.9130 - val_loss: 0.3219 - val_acc: 0.8886\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2216 - acc: 0.9134 - val_loss: 0.3650 - val_acc: 0.8783\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2152 - acc: 0.9161 - val_loss: 0.3336 - val_acc: 0.8880\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2055 - acc: 0.9205 - val_loss: 0.3568 - val_acc: 0.8810\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2017 - acc: 0.9220 - val_loss: 0.3454 - val_acc: 0.8788\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1919 - acc: 0.9252 - val_loss: 0.3462 - val_acc: 0.8819\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1845 - acc: 0.9277 - val_loss: 0.3609 - val_acc: 0.8867\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1774 - acc: 0.9306 - val_loss: 0.4181 - val_acc: 0.8806\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1793 - acc: 0.9308 - val_loss: 0.3213 - val_acc: 0.8892\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1691 - acc: 0.9345 - val_loss: 0.3559 - val_acc: 0.8892\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1625 - acc: 0.9359 - val_loss: 0.3659 - val_acc: 0.8888\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1604 - acc: 0.9379 - val_loss: 0.4075 - val_acc: 0.8831\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1569 - acc: 0.9395 - val_loss: 0.3796 - val_acc: 0.8946\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1515 - acc: 0.9406 - val_loss: 0.4151 - val_acc: 0.8886\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1478 - acc: 0.9418 - val_loss: 0.4354 - val_acc: 0.8761\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1436 - acc: 0.9438 - val_loss: 0.4282 - val_acc: 0.8941\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1398 - acc: 0.9446 - val_loss: 0.4134 - val_acc: 0.8904\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1330 - acc: 0.9480 - val_loss: 0.4394 - val_acc: 0.8902\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1336 - acc: 0.9489 - val_loss: 0.4411 - val_acc: 0.8694\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1297 - acc: 0.9497 - val_loss: 0.3912 - val_acc: 0.8939\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1252 - acc: 0.9519 - val_loss: 0.3959 - val_acc: 0.8905\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1184 - acc: 0.9531 - val_loss: 0.4730 - val_acc: 0.8903\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1190 - acc: 0.9543 - val_loss: 0.4585 - val_acc: 0.8939\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1171 - acc: 0.9549 - val_loss: 0.4626 - val_acc: 0.8887\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1139 - acc: 0.9555 - val_loss: 0.4717 - val_acc: 0.8850\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1101 - acc: 0.9560 - val_loss: 0.4906 - val_acc: 0.8873\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1104 - acc: 0.9578 - val_loss: 0.4811 - val_acc: 0.8932\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1035 - acc: 0.9598 - val_loss: 0.5425 - val_acc: 0.8697\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1022 - acc: 0.9594 - val_loss: 0.4819 - val_acc: 0.8912\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1002 - acc: 0.9617 - val_loss: 0.4957 - val_acc: 0.8959\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0993 - acc: 0.9626 - val_loss: 0.5578 - val_acc: 0.8884\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0956 - acc: 0.9633 - val_loss: 0.5450 - val_acc: 0.8827\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0946 - acc: 0.9640 - val_loss: 0.5375 - val_acc: 0.8885\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0925 - acc: 0.9642 - val_loss: 0.5113 - val_acc: 0.8956\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0898 - acc: 0.9661 - val_loss: 0.6237 - val_acc: 0.8929\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0888 - acc: 0.9657 - val_loss: 0.6247 - val_acc: 0.8933\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0881 - acc: 0.9664 - val_loss: 0.5723 - val_acc: 0.8921\n"
     ]
    }
   ],
   "source": [
    "m3_history = m3_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m3_history.history['val_loss'])\n",
    "tup = ('m3', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. model 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_model = models.Sequential()\n",
    "m4_model.add(layers.Dense(64, activation='relu', input_shape=(28 * 28,)))\n",
    "m4_model.add(layers.Dense(64, activation='relu'))\n",
    "m4_model.add(layers.Dense(64, activation='relu'))\n",
    "m4_model.add(layers.Dense(64, activation='relu'))\n",
    "m4_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m4_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.9261 - acc: 0.6657 - val_loss: 0.6246 - val_acc: 0.7662\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.5588 - acc: 0.7966 - val_loss: 0.5060 - val_acc: 0.8263\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.4857 - acc: 0.8255 - val_loss: 0.4922 - val_acc: 0.8217\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.4419 - acc: 0.8401 - val_loss: 0.4309 - val_acc: 0.8414\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.4135 - acc: 0.8484 - val_loss: 0.5364 - val_acc: 0.8059\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3901 - acc: 0.8575 - val_loss: 0.4538 - val_acc: 0.8289\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3719 - acc: 0.8631 - val_loss: 0.3853 - val_acc: 0.8599\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3561 - acc: 0.8686 - val_loss: 0.3766 - val_acc: 0.8571\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3438 - acc: 0.8725 - val_loss: 0.3837 - val_acc: 0.8553\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3308 - acc: 0.8777 - val_loss: 0.3848 - val_acc: 0.8543\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3231 - acc: 0.8809 - val_loss: 0.3861 - val_acc: 0.8507\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3128 - acc: 0.8821 - val_loss: 0.3638 - val_acc: 0.8688\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3050 - acc: 0.8858 - val_loss: 0.3447 - val_acc: 0.8690\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2988 - acc: 0.8877 - val_loss: 0.3574 - val_acc: 0.8658\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2930 - acc: 0.8914 - val_loss: 0.3947 - val_acc: 0.8515\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2847 - acc: 0.8930 - val_loss: 0.3538 - val_acc: 0.8633\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2808 - acc: 0.8950 - val_loss: 0.3413 - val_acc: 0.8724\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2737 - acc: 0.8973 - val_loss: 0.3566 - val_acc: 0.8687\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2688 - acc: 0.8988 - val_loss: 0.3420 - val_acc: 0.8764\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2615 - acc: 0.9022 - val_loss: 0.3366 - val_acc: 0.8710\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2583 - acc: 0.9035 - val_loss: 0.3260 - val_acc: 0.8777\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2546 - acc: 0.9042 - val_loss: 0.3333 - val_acc: 0.8796\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2470 - acc: 0.9068 - val_loss: 0.3982 - val_acc: 0.8594\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2448 - acc: 0.9070 - val_loss: 0.4007 - val_acc: 0.8528\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2418 - acc: 0.9096 - val_loss: 0.3435 - val_acc: 0.8747\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2384 - acc: 0.9100 - val_loss: 0.3503 - val_acc: 0.8767\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2312 - acc: 0.9134 - val_loss: 0.3470 - val_acc: 0.8791\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2289 - acc: 0.9129 - val_loss: 0.3346 - val_acc: 0.8828\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2257 - acc: 0.9143 - val_loss: 0.3395 - val_acc: 0.8772\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2213 - acc: 0.9175 - val_loss: 0.3382 - val_acc: 0.8827\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2182 - acc: 0.9184 - val_loss: 0.3564 - val_acc: 0.8802\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2145 - acc: 0.9186 - val_loss: 0.3720 - val_acc: 0.8791\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2121 - acc: 0.9181 - val_loss: 0.3542 - val_acc: 0.8832\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2064 - acc: 0.9220 - val_loss: 0.3373 - val_acc: 0.8822\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2084 - acc: 0.9217 - val_loss: 0.3467 - val_acc: 0.8806\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2029 - acc: 0.9233 - val_loss: 0.3411 - val_acc: 0.8795\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1998 - acc: 0.9242 - val_loss: 0.3462 - val_acc: 0.8782\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1972 - acc: 0.9260 - val_loss: 0.3659 - val_acc: 0.8786\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3370 - val_acc: 0.8887\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 0s 10us/step - loss: 0.1906 - acc: 0.9276 - val_loss: 0.3818 - val_acc: 0.8781\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1862 - acc: 0.9289 - val_loss: 0.3594 - val_acc: 0.8846\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1841 - acc: 0.9306 - val_loss: 0.3808 - val_acc: 0.8791\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1850 - acc: 0.9292 - val_loss: 0.3481 - val_acc: 0.8824\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1821 - acc: 0.9303 - val_loss: 0.3627 - val_acc: 0.8777\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1772 - acc: 0.9331 - val_loss: 0.3589 - val_acc: 0.8777\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1771 - acc: 0.9318 - val_loss: 0.3615 - val_acc: 0.8846\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1733 - acc: 0.9344 - val_loss: 0.3680 - val_acc: 0.8798\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1703 - acc: 0.9354 - val_loss: 0.4329 - val_acc: 0.8655\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1704 - acc: 0.9348 - val_loss: 0.3527 - val_acc: 0.8863\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1659 - acc: 0.9366 - val_loss: 0.3829 - val_acc: 0.8841\n"
     ]
    }
   ],
   "source": [
    "m4_history = m4_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m4_history.history['val_loss'])\n",
    "tup = ('m4', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. model 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_model = models.Sequential()\n",
    "m5_model.add(layers.Dense(16, activation='relu', input_shape=(28 * 28,)))\n",
    "m5_model.add(layers.Dense(16, activation='relu'))\n",
    "m5_model.add(layers.Dense(16, activation='relu'))\n",
    "m5_model.add(layers.Dense(16, activation='relu'))\n",
    "m5_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m5_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0729 - acc: 0.9846 - val_loss: 0.9496 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0568 - acc: 0.9868 - val_loss: 0.9095 - val_acc: 0.8973\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0553 - acc: 0.9856 - val_loss: 0.9049 - val_acc: 0.8985\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0638 - acc: 0.9849 - val_loss: 0.8479 - val_acc: 0.8977\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9861 - val_loss: 0.8433 - val_acc: 0.8936\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0556 - acc: 0.9866 - val_loss: 0.7711 - val_acc: 0.8921\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0573 - acc: 0.9876 - val_loss: 0.8463 - val_acc: 0.8946\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0510 - acc: 0.9870 - val_loss: 0.9319 - val_acc: 0.8904\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0699 - acc: 0.9857 - val_loss: 0.7972 - val_acc: 0.9037\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0541 - acc: 0.9873 - val_loss: 0.8245 - val_acc: 0.8998\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0548 - acc: 0.9881 - val_loss: 0.8221 - val_acc: 0.8950\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0562 - acc: 0.9863 - val_loss: 0.9467 - val_acc: 0.8968\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0510 - acc: 0.9875 - val_loss: 0.9477 - val_acc: 0.8932\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0800 - acc: 0.9835 - val_loss: 0.8654 - val_acc: 0.8975\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0532 - acc: 0.9877 - val_loss: 0.9771 - val_acc: 0.8785\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0539 - acc: 0.9866 - val_loss: 0.8814 - val_acc: 0.9019\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0484 - acc: 0.9883 - val_loss: 1.0617 - val_acc: 0.8931\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0743 - acc: 0.9850 - val_loss: 0.8041 - val_acc: 0.8974\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0494 - acc: 0.9884 - val_loss: 0.8662 - val_acc: 0.8993\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0679 - acc: 0.9865 - val_loss: 0.8708 - val_acc: 0.8977\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0574 - acc: 0.9872 - val_loss: 0.9909 - val_acc: 0.8786\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0559 - acc: 0.9876 - val_loss: 1.0061 - val_acc: 0.8946\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0609 - acc: 0.9864 - val_loss: 0.9879 - val_acc: 0.8981\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0564 - acc: 0.9869 - val_loss: 0.9428 - val_acc: 0.8830\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0614 - acc: 0.9864 - val_loss: 0.9171 - val_acc: 0.8954\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0672 - acc: 0.9855 - val_loss: 0.7766 - val_acc: 0.8963\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9878 - val_loss: 0.9837 - val_acc: 0.8925\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0661 - acc: 0.9854 - val_loss: 0.9219 - val_acc: 0.8981\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0690 - acc: 0.9869 - val_loss: 0.8125 - val_acc: 0.8924\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0670 - acc: 0.9860 - val_loss: 0.9309 - val_acc: 0.8877\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0560 - acc: 0.9878 - val_loss: 0.9550 - val_acc: 0.8866\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0643 - acc: 0.9863 - val_loss: 1.0348 - val_acc: 0.8963\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0658 - acc: 0.9868 - val_loss: 0.9072 - val_acc: 0.8965\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0547 - acc: 0.9879 - val_loss: 1.0186 - val_acc: 0.8913\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9874 - val_loss: 0.9535 - val_acc: 0.8941\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0483 - acc: 0.9884 - val_loss: 0.9594 - val_acc: 0.8919\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0867 - acc: 0.9858 - val_loss: 0.9381 - val_acc: 0.8959\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0565 - acc: 0.9885 - val_loss: 0.8649 - val_acc: 0.9010\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0567 - acc: 0.9886 - val_loss: 0.8913 - val_acc: 0.8987\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0645 - acc: 0.9873 - val_loss: 0.8779 - val_acc: 0.8874\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0561 - acc: 0.9877 - val_loss: 0.8765 - val_acc: 0.8831\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0633 - acc: 0.9866 - val_loss: 0.7585 - val_acc: 0.8957\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0540 - acc: 0.9876 - val_loss: 1.0877 - val_acc: 0.8654\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0591 - acc: 0.9869 - val_loss: 0.9296 - val_acc: 0.8949\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0581 - acc: 0.9887 - val_loss: 0.9580 - val_acc: 0.8935\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0663 - acc: 0.9880 - val_loss: 0.9188 - val_acc: 0.8975\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0561 - acc: 0.9884 - val_loss: 1.0852 - val_acc: 0.8747\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9874 - val_loss: 0.8796 - val_acc: 0.8959\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0566 - acc: 0.9883 - val_loss: 0.9867 - val_acc: 0.8933\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9869 - val_loss: 0.9337 - val_acc: 0.8952\n"
     ]
    }
   ],
   "source": [
    "m5_history = init_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m5_history.history['val_loss'])\n",
    "tup = ('m5', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. model 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m6_model = models.Sequential()\n",
    "m6_model.add(layers.Dense(256, activation='relu', input_shape=(28 * 28,)))\n",
    "m6_model.add(layers.Dense(256, activation='relu'))\n",
    "m6_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m6_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0686 - acc: 0.9744 - val_loss: 0.5410 - val_acc: 0.8964\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0660 - acc: 0.9762 - val_loss: 0.5900 - val_acc: 0.8845\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0657 - acc: 0.9758 - val_loss: 0.5789 - val_acc: 0.8956\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0639 - acc: 0.9754 - val_loss: 0.5310 - val_acc: 0.8987\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0623 - acc: 0.9768 - val_loss: 0.4891 - val_acc: 0.8991\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0625 - acc: 0.9775 - val_loss: 0.5374 - val_acc: 0.8956\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0601 - acc: 0.9781 - val_loss: 0.5756 - val_acc: 0.8962\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0597 - acc: 0.9778 - val_loss: 0.6844 - val_acc: 0.8891\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0635 - acc: 0.9773 - val_loss: 0.5559 - val_acc: 0.8984\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0600 - acc: 0.9787 - val_loss: 0.5622 - val_acc: 0.8967\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0554 - acc: 0.9792 - val_loss: 0.6040 - val_acc: 0.8928\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0620 - acc: 0.9783 - val_loss: 0.5267 - val_acc: 0.9000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0549 - acc: 0.9800 - val_loss: 0.5648 - val_acc: 0.8960\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0556 - acc: 0.9803 - val_loss: 0.5967 - val_acc: 0.8988\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0555 - acc: 0.9811 - val_loss: 0.6656 - val_acc: 0.8912\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0526 - acc: 0.9819 - val_loss: 0.6242 - val_acc: 0.8953\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0590 - acc: 0.9804 - val_loss: 0.6203 - val_acc: 0.8925\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0555 - acc: 0.9819 - val_loss: 0.6177 - val_acc: 0.8968\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0535 - acc: 0.9810 - val_loss: 0.5887 - val_acc: 0.8977\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0476 - acc: 0.9831 - val_loss: 0.6211 - val_acc: 0.8999\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0496 - acc: 0.9828 - val_loss: 0.6410 - val_acc: 0.9017\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0491 - acc: 0.9834 - val_loss: 0.6113 - val_acc: 0.9008\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0485 - acc: 0.9835 - val_loss: 0.5949 - val_acc: 0.9023\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0525 - acc: 0.9832 - val_loss: 0.6053 - val_acc: 0.8979\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0456 - acc: 0.9847 - val_loss: 0.6146 - val_acc: 0.8986\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0457 - acc: 0.9841 - val_loss: 0.7430 - val_acc: 0.8789\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0442 - acc: 0.9848 - val_loss: 0.7319 - val_acc: 0.8871\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0449 - acc: 0.9845 - val_loss: 0.6563 - val_acc: 0.8956\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0484 - acc: 0.9842 - val_loss: 0.6613 - val_acc: 0.8974\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0470 - acc: 0.9847 - val_loss: 0.6522 - val_acc: 0.9007\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0473 - acc: 0.9843 - val_loss: 0.6515 - val_acc: 0.9017\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0471 - acc: 0.9847 - val_loss: 0.6368 - val_acc: 0.9024\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0429 - acc: 0.9858 - val_loss: 0.6947 - val_acc: 0.8960\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0441 - acc: 0.9857 - val_loss: 0.6985 - val_acc: 0.8991\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0436 - acc: 0.9854 - val_loss: 0.8285 - val_acc: 0.8697\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0452 - acc: 0.9851 - val_loss: 0.7740 - val_acc: 0.8887\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0428 - acc: 0.9859 - val_loss: 0.6875 - val_acc: 0.8991\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0400 - acc: 0.9869 - val_loss: 0.7328 - val_acc: 0.8927\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0386 - acc: 0.9863 - val_loss: 0.8003 - val_acc: 0.8895\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0441 - acc: 0.9855 - val_loss: 0.7526 - val_acc: 0.8916\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.9767 - val_acc: 0.8755\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0491 - acc: 0.9849 - val_loss: 0.6363 - val_acc: 0.9006\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0386 - acc: 0.9879 - val_loss: 0.7372 - val_acc: 0.8970\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0412 - acc: 0.9862 - val_loss: 0.8248 - val_acc: 0.8873\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0385 - acc: 0.9874 - val_loss: 0.7628 - val_acc: 0.8922\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0456 - acc: 0.9871 - val_loss: 0.7155 - val_acc: 0.8973\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0384 - acc: 0.9879 - val_loss: 0.6687 - val_acc: 0.8996\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0374 - acc: 0.9882 - val_loss: 0.7032 - val_acc: 0.9024\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0373 - acc: 0.9884 - val_loss: 0.7282 - val_acc: 0.9007\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0397 - acc: 0.9881 - val_loss: 0.6883 - val_acc: 0.8966\n"
     ]
    }
   ],
   "source": [
    "m6_history = m1_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m6_history.history['val_loss'])\n",
    "tup = ('m6', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. model 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m7_model = models.Sequential()\n",
    "m7_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m7_model.add(layers.Dense(512, activation='relu'))\n",
    "m7_model.add(layers.Dense(512, activation='relu'))\n",
    "m7_model.add(layers.Dense(512, activation='relu'))\n",
    "m7_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m7_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 3s 63us/step - loss: 0.6310 - acc: 0.7660 - val_loss: 0.5010 - val_acc: 0.8235\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.4202 - acc: 0.8484 - val_loss: 0.4688 - val_acc: 0.8341\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3777 - acc: 0.8653 - val_loss: 0.4673 - val_acc: 0.8421\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3519 - acc: 0.8755 - val_loss: 0.4188 - val_acc: 0.8571\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3364 - acc: 0.8804 - val_loss: 0.4076 - val_acc: 0.8639\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3322 - acc: 0.8828 - val_loss: 0.3656 - val_acc: 0.8726\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3184 - acc: 0.8875 - val_loss: 0.4108 - val_acc: 0.8503\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3107 - acc: 0.8887 - val_loss: 0.3775 - val_acc: 0.8745\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3056 - acc: 0.8917 - val_loss: 0.3613 - val_acc: 0.8824\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2979 - acc: 0.8940 - val_loss: 0.4450 - val_acc: 0.8653\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2936 - acc: 0.8966 - val_loss: 0.4490 - val_acc: 0.8544\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2833 - acc: 0.8992 - val_loss: 0.3329 - val_acc: 0.8893\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2814 - acc: 0.9001 - val_loss: 0.3678 - val_acc: 0.8766\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2791 - acc: 0.9033 - val_loss: 0.4054 - val_acc: 0.8853\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2776 - acc: 0.9035 - val_loss: 0.3719 - val_acc: 0.8851\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2706 - acc: 0.9060 - val_loss: 0.4519 - val_acc: 0.8722\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2698 - acc: 0.9067 - val_loss: 0.3545 - val_acc: 0.8823\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2632 - acc: 0.9080 - val_loss: 0.3776 - val_acc: 0.8854\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2598 - acc: 0.9108 - val_loss: 0.4303 - val_acc: 0.8722\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.3429 - val_acc: 0.8830\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2524 - acc: 0.9118 - val_loss: 0.4265 - val_acc: 0.8850\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2549 - acc: 0.9141 - val_loss: 0.4946 - val_acc: 0.8655\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2563 - acc: 0.9149 - val_loss: 0.4880 - val_acc: 0.8616\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2678 - acc: 0.9139 - val_loss: 0.4597 - val_acc: 0.8762\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2541 - acc: 0.9143 - val_loss: 0.4014 - val_acc: 0.8903\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2519 - acc: 0.9176 - val_loss: 0.5788 - val_acc: 0.8796\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2496 - acc: 0.9189 - val_loss: 0.4676 - val_acc: 0.8667\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2473 - acc: 0.9212 - val_loss: 0.4527 - val_acc: 0.8845\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2445 - acc: 0.9198 - val_loss: 0.4691 - val_acc: 0.8752\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2493 - acc: 0.9193 - val_loss: 0.5302 - val_acc: 0.8688\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2577 - acc: 0.9215 - val_loss: 0.4717 - val_acc: 0.8895\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2465 - acc: 0.9221 - val_loss: 0.4908 - val_acc: 0.8764\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2438 - acc: 0.9236 - val_loss: 0.4981 - val_acc: 0.8868\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2410 - acc: 0.9237 - val_loss: 0.5172 - val_acc: 0.8803\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2470 - acc: 0.9256 - val_loss: 0.4304 - val_acc: 0.8913\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2320 - acc: 0.9274 - val_loss: 0.6607 - val_acc: 0.8460\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2371 - acc: 0.9267 - val_loss: 0.4929 - val_acc: 0.8681\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2354 - acc: 0.9261 - val_loss: 0.4967 - val_acc: 0.8805\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2404 - acc: 0.9265 - val_loss: 0.6020 - val_acc: 0.8775\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2330 - acc: 0.9275 - val_loss: 0.4695 - val_acc: 0.8889\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2187 - acc: 0.9308 - val_loss: 0.5328 - val_acc: 0.8847\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2293 - acc: 0.9302 - val_loss: 0.5443 - val_acc: 0.8862\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2417 - acc: 0.9289 - val_loss: 0.4805 - val_acc: 0.8882\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2466 - acc: 0.9312 - val_loss: 0.5932 - val_acc: 0.8784\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2263 - acc: 0.9325 - val_loss: 0.4857 - val_acc: 0.8731\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2214 - acc: 0.9322 - val_loss: 0.5322 - val_acc: 0.8897\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2320 - acc: 0.9331 - val_loss: 0.5095 - val_acc: 0.8790\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2248 - acc: 0.9328 - val_loss: 0.5368 - val_acc: 0.8740\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2358 - acc: 0.9329 - val_loss: 0.6116 - val_acc: 0.8791\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2337 - acc: 0.9325 - val_loss: 0.4833 - val_acc: 0.8840\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2225 - acc: 0.9338 - val_loss: 0.5512 - val_acc: 0.8920\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2336 - acc: 0.9332 - val_loss: 0.5376 - val_acc: 0.8945\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2341 - acc: 0.9337 - val_loss: 0.5431 - val_acc: 0.8718\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2287 - acc: 0.9359 - val_loss: 0.5692 - val_acc: 0.8882\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2259 - acc: 0.9347 - val_loss: 0.5405 - val_acc: 0.8839\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2092 - acc: 0.9384 - val_loss: 0.5276 - val_acc: 0.8900\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2193 - acc: 0.9360 - val_loss: 0.6293 - val_acc: 0.8907\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2183 - acc: 0.9377 - val_loss: 0.6509 - val_acc: 0.8834\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2251 - acc: 0.9393 - val_loss: 0.6398 - val_acc: 0.8786\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2323 - acc: 0.9373 - val_loss: 0.5390 - val_acc: 0.8890\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2102 - acc: 0.9389 - val_loss: 0.5879 - val_acc: 0.8849\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2118 - acc: 0.9399 - val_loss: 0.5148 - val_acc: 0.8910\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2108 - acc: 0.9411 - val_loss: 0.6145 - val_acc: 0.8856\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2133 - acc: 0.9411 - val_loss: 0.5677 - val_acc: 0.8874\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2236 - acc: 0.9403 - val_loss: 0.5975 - val_acc: 0.8861\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2306 - acc: 0.9378 - val_loss: 0.6104 - val_acc: 0.8840\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2076 - acc: 0.9409 - val_loss: 0.6370 - val_acc: 0.8825\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2089 - acc: 0.9403 - val_loss: 0.5450 - val_acc: 0.8875\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2057 - acc: 0.9426 - val_loss: 0.6341 - val_acc: 0.8848\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2153 - acc: 0.9399 - val_loss: 0.5762 - val_acc: 0.8911\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2057 - acc: 0.9413 - val_loss: 0.7083 - val_acc: 0.8716\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2130 - acc: 0.9422 - val_loss: 0.6614 - val_acc: 0.8865\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2144 - acc: 0.9417 - val_loss: 0.6735 - val_acc: 0.8820\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2174 - acc: 0.9426 - val_loss: 1.3971 - val_acc: 0.8268\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2324 - acc: 0.9410 - val_loss: 0.5886 - val_acc: 0.8838\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2142 - acc: 0.9442 - val_loss: 0.6512 - val_acc: 0.8886\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2308 - acc: 0.9421 - val_loss: 0.6027 - val_acc: 0.8952\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2383 - acc: 0.9419 - val_loss: 0.8559 - val_acc: 0.8162\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2268 - acc: 0.9439 - val_loss: 0.6297 - val_acc: 0.8842\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2341 - acc: 0.9420 - val_loss: 0.5904 - val_acc: 0.8851\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2238 - acc: 0.9426 - val_loss: 0.6021 - val_acc: 0.8855\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2078 - acc: 0.9443 - val_loss: 0.6316 - val_acc: 0.8673\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2136 - acc: 0.9439 - val_loss: 0.7463 - val_acc: 0.8826\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2186 - acc: 0.9453 - val_loss: 0.6093 - val_acc: 0.8937\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2244 - acc: 0.9446 - val_loss: 0.6157 - val_acc: 0.8868\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2441 - acc: 0.9426 - val_loss: 0.7038 - val_acc: 0.8908\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2381 - acc: 0.9455 - val_loss: 0.7364 - val_acc: 0.8838\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2382 - acc: 0.9438 - val_loss: 0.6451 - val_acc: 0.8873\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2198 - acc: 0.9459 - val_loss: 0.7281 - val_acc: 0.8895\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2358 - acc: 0.9425 - val_loss: 0.7418 - val_acc: 0.8878\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2475 - acc: 0.9434 - val_loss: 0.8162 - val_acc: 0.8819\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2398 - acc: 0.9453 - val_loss: 0.6758 - val_acc: 0.8842\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2322 - acc: 0.9470 - val_loss: 0.7366 - val_acc: 0.8890\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2291 - acc: 0.9451 - val_loss: 0.8881 - val_acc: 0.8668\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2451 - acc: 0.9440 - val_loss: 0.6352 - val_acc: 0.8942\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2200 - acc: 0.9471 - val_loss: 0.7358 - val_acc: 0.8869\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2200 - acc: 0.9471 - val_loss: 0.6981 - val_acc: 0.8894\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2164 - acc: 0.9462 - val_loss: 0.6631 - val_acc: 0.8723\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2382 - acc: 0.9465 - val_loss: 0.6720 - val_acc: 0.8897\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2361 - acc: 0.9463 - val_loss: 0.7231 - val_acc: 0.8691\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2122 - acc: 0.9481 - val_loss: 0.7692 - val_acc: 0.8889\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2550 - acc: 0.9455 - val_loss: 0.7299 - val_acc: 0.8893\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2876 - acc: 0.9423 - val_loss: 0.5756 - val_acc: 0.8953\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2249 - acc: 0.9475 - val_loss: 0.6724 - val_acc: 0.8894\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2413 - acc: 0.9457 - val_loss: 0.7120 - val_acc: 0.8904\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2459 - acc: 0.9466 - val_loss: 0.6849 - val_acc: 0.8862\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2659 - acc: 0.9458 - val_loss: 0.8104 - val_acc: 0.8832\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2418 - acc: 0.9471 - val_loss: 0.7678 - val_acc: 0.8899\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2552 - acc: 0.9465 - val_loss: 0.7597 - val_acc: 0.8844\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2490 - acc: 0.9450 - val_loss: 0.6897 - val_acc: 0.8835\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2246 - acc: 0.9483 - val_loss: 0.6891 - val_acc: 0.8929\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2372 - acc: 0.9472 - val_loss: 0.7701 - val_acc: 0.8852\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2644 - acc: 0.9455 - val_loss: 0.7187 - val_acc: 0.8952\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2518 - acc: 0.9457 - val_loss: 0.6815 - val_acc: 0.8875\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2373 - acc: 0.9483 - val_loss: 0.7894 - val_acc: 0.8838\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2435 - acc: 0.9482 - val_loss: 0.6791 - val_acc: 0.8811\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2426 - acc: 0.9469 - val_loss: 0.7122 - val_acc: 0.8865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2267 - acc: 0.9507 - val_loss: 0.6451 - val_acc: 0.8893\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2310 - acc: 0.9503 - val_loss: 0.6974 - val_acc: 0.8915\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2451 - acc: 0.9487 - val_loss: 0.7914 - val_acc: 0.8888\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2394 - acc: 0.9517 - val_loss: 0.6761 - val_acc: 0.8914\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2353 - acc: 0.9500 - val_loss: 0.7945 - val_acc: 0.8832\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2358 - acc: 0.9487 - val_loss: 0.8703 - val_acc: 0.8864\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2554 - acc: 0.9463 - val_loss: 0.7225 - val_acc: 0.8886\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2542 - acc: 0.9498 - val_loss: 0.7287 - val_acc: 0.8894\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2348 - acc: 0.9500 - val_loss: 0.7973 - val_acc: 0.8749\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2360 - acc: 0.9495 - val_loss: 0.8368 - val_acc: 0.8824\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2402 - acc: 0.9487 - val_loss: 0.6800 - val_acc: 0.8906\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2376 - acc: 0.9493 - val_loss: 0.7184 - val_acc: 0.8862\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2512 - acc: 0.9491 - val_loss: 0.8455 - val_acc: 0.8771\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2208 - acc: 0.9531 - val_loss: 0.6618 - val_acc: 0.8935\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2597 - acc: 0.9491 - val_loss: 0.7775 - val_acc: 0.8853\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2182 - acc: 0.9532 - val_loss: 0.8419 - val_acc: 0.8850\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2289 - acc: 0.9519 - val_loss: 0.8042 - val_acc: 0.8888\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2531 - acc: 0.9494 - val_loss: 0.7931 - val_acc: 0.8876\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2513 - acc: 0.9501 - val_loss: 0.9120 - val_acc: 0.8727\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2576 - acc: 0.9503 - val_loss: 0.9425 - val_acc: 0.8804\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2472 - acc: 0.9510 - val_loss: 0.9021 - val_acc: 0.8868\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2721 - acc: 0.9499 - val_loss: 0.7979 - val_acc: 0.8876\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2761 - acc: 0.9490 - val_loss: 0.9943 - val_acc: 0.8703\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2333 - acc: 0.9524 - val_loss: 0.8144 - val_acc: 0.8835\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2981 - acc: 0.9481 - val_loss: 0.7653 - val_acc: 0.8871\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2348 - acc: 0.9540 - val_loss: 0.8669 - val_acc: 0.8876\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2465 - acc: 0.9506 - val_loss: 0.8176 - val_acc: 0.8847\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2485 - acc: 0.9516 - val_loss: 0.8487 - val_acc: 0.8832\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2642 - acc: 0.9516 - val_loss: 0.8776 - val_acc: 0.8727\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2812 - acc: 0.9487 - val_loss: 0.7614 - val_acc: 0.8918\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2660 - acc: 0.9515 - val_loss: 0.9377 - val_acc: 0.8863\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2589 - acc: 0.9527 - val_loss: 1.0104 - val_acc: 0.8774\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2577 - acc: 0.9525 - val_loss: 0.8883 - val_acc: 0.8806\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2667 - acc: 0.9515 - val_loss: 0.7890 - val_acc: 0.8857\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2695 - acc: 0.9514 - val_loss: 0.8800 - val_acc: 0.8877\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2836 - acc: 0.9496 - val_loss: 0.7821 - val_acc: 0.8658\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2368 - acc: 0.9546 - val_loss: 0.7967 - val_acc: 0.8852\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2617 - acc: 0.9522 - val_loss: 0.9822 - val_acc: 0.8863\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2383 - acc: 0.9547 - val_loss: 0.8070 - val_acc: 0.8914\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2730 - acc: 0.9505 - val_loss: 0.8802 - val_acc: 0.8893\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2491 - acc: 0.9540 - val_loss: 0.8923 - val_acc: 0.8847\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2473 - acc: 0.9552 - val_loss: 0.8957 - val_acc: 0.8894\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2669 - acc: 0.9535 - val_loss: 0.8934 - val_acc: 0.8878\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2364 - acc: 0.9576 - val_loss: 0.9082 - val_acc: 0.8877\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2619 - acc: 0.9545 - val_loss: 0.8232 - val_acc: 0.8845\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2522 - acc: 0.9539 - val_loss: 0.9365 - val_acc: 0.8855\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3020 - acc: 0.9507 - val_loss: 0.8423 - val_acc: 0.8788\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2901 - acc: 0.9519 - val_loss: 0.8815 - val_acc: 0.8841\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2758 - acc: 0.9548 - val_loss: 0.9409 - val_acc: 0.8801\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2665 - acc: 0.9560 - val_loss: 0.9959 - val_acc: 0.8699\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2796 - acc: 0.9541 - val_loss: 0.8488 - val_acc: 0.8887\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2985 - acc: 0.9520 - val_loss: 1.0982 - val_acc: 0.8647\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2829 - acc: 0.9536 - val_loss: 1.0562 - val_acc: 0.8864\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3292 - acc: 0.9482 - val_loss: 0.8725 - val_acc: 0.8887\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2982 - acc: 0.9512 - val_loss: 1.0032 - val_acc: 0.8839\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2805 - acc: 0.9526 - val_loss: 0.9851 - val_acc: 0.8773\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2733 - acc: 0.9554 - val_loss: 0.8489 - val_acc: 0.8862\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2888 - acc: 0.9555 - val_loss: 0.8406 - val_acc: 0.8885\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2596 - acc: 0.9544 - val_loss: 0.8726 - val_acc: 0.8849\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2914 - acc: 0.9549 - val_loss: 1.4161 - val_acc: 0.8581\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3067 - acc: 0.9543 - val_loss: 0.9823 - val_acc: 0.8793\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2860 - acc: 0.9565 - val_loss: 0.9265 - val_acc: 0.8817\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2892 - acc: 0.9536 - val_loss: 0.9366 - val_acc: 0.8833\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2803 - acc: 0.9557 - val_loss: 0.8832 - val_acc: 0.8868\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2652 - acc: 0.9543 - val_loss: 0.8378 - val_acc: 0.8864\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2757 - acc: 0.9554 - val_loss: 0.9692 - val_acc: 0.8784\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2876 - acc: 0.9550 - val_loss: 1.0473 - val_acc: 0.8824\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2659 - acc: 0.9562 - val_loss: 1.5801 - val_acc: 0.8529\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3500 - acc: 0.9502 - val_loss: 0.9496 - val_acc: 0.8825\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2592 - acc: 0.9576 - val_loss: 0.9425 - val_acc: 0.8852\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2868 - acc: 0.9566 - val_loss: 0.8569 - val_acc: 0.8866\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3129 - acc: 0.9550 - val_loss: 0.9962 - val_acc: 0.8845\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2880 - acc: 0.9563 - val_loss: 0.9246 - val_acc: 0.8857\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3027 - acc: 0.9564 - val_loss: 1.2169 - val_acc: 0.8644\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3170 - acc: 0.9548 - val_loss: 0.8832 - val_acc: 0.8881\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2979 - acc: 0.9546 - val_loss: 0.9236 - val_acc: 0.8836\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2894 - acc: 0.9544 - val_loss: 0.8921 - val_acc: 0.8811\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2831 - acc: 0.9554 - val_loss: 0.9696 - val_acc: 0.8799\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3040 - acc: 0.9545 - val_loss: 0.9535 - val_acc: 0.8852\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2997 - acc: 0.9548 - val_loss: 0.9259 - val_acc: 0.8899\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2911 - acc: 0.9567 - val_loss: 1.1993 - val_acc: 0.8784\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3179 - acc: 0.9522 - val_loss: 1.1144 - val_acc: 0.8534\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3543 - acc: 0.9501 - val_loss: 0.8850 - val_acc: 0.8877\n"
     ]
    }
   ],
   "source": [
    "m7_history = m7_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=128,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m7_history.history['val_loss'])\n",
    "tup = ('m7', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. model 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m8_model = models.Sequential()\n",
    "m8_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu', input_shape=(28 * 28,)))\n",
    "m8_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu'))\n",
    "m8_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m8_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 9.1376 - acc: 0.6610 - val_loss: 2.9679 - val_acc: 0.7465\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 2.1710 - acc: 0.7373 - val_loss: 1.6803 - val_acc: 0.7548\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.5086 - acc: 0.7667 - val_loss: 1.4339 - val_acc: 0.7657\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.3125 - acc: 0.7792 - val_loss: 1.2575 - val_acc: 0.7843\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.2102 - acc: 0.7924 - val_loss: 1.1901 - val_acc: 0.7817\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1527 - acc: 0.8016 - val_loss: 1.1780 - val_acc: 0.7882\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 1.1045 - acc: 0.8078 - val_loss: 1.0977 - val_acc: 0.8001\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 1.0687 - acc: 0.8144 - val_loss: 1.0817 - val_acc: 0.8040\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.0484 - acc: 0.8175 - val_loss: 1.0773 - val_acc: 0.8060\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.0315 - acc: 0.8204 - val_loss: 1.0469 - val_acc: 0.8082\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.0119 - acc: 0.8235 - val_loss: 1.0271 - val_acc: 0.8153\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9963 - acc: 0.8277 - val_loss: 1.0262 - val_acc: 0.8134\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9856 - acc: 0.8284 - val_loss: 0.9754 - val_acc: 0.8284\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9709 - acc: 0.8316 - val_loss: 1.0612 - val_acc: 0.7872\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9619 - acc: 0.8334 - val_loss: 0.9789 - val_acc: 0.8230\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9565 - acc: 0.8329 - val_loss: 0.9727 - val_acc: 0.8223\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9484 - acc: 0.8356 - val_loss: 0.9564 - val_acc: 0.8287\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9435 - acc: 0.8358 - val_loss: 0.9704 - val_acc: 0.8205\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9401 - acc: 0.8380 - val_loss: 0.9682 - val_acc: 0.8262\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9359 - acc: 0.8382 - val_loss: 0.9471 - val_acc: 0.8332\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9305 - acc: 0.8395 - val_loss: 0.9551 - val_acc: 0.8281\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9301 - acc: 0.8379 - val_loss: 0.9676 - val_acc: 0.8263\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9278 - acc: 0.8395 - val_loss: 0.9752 - val_acc: 0.8214\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9227 - acc: 0.8407 - val_loss: 0.9899 - val_acc: 0.8167\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9203 - acc: 0.8409 - val_loss: 1.0165 - val_acc: 0.7918\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9177 - acc: 0.8411 - val_loss: 0.9608 - val_acc: 0.8193\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9173 - acc: 0.8408 - val_loss: 0.9155 - val_acc: 0.8419\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9151 - acc: 0.8428 - val_loss: 0.9119 - val_acc: 0.8430\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9108 - acc: 0.8419 - val_loss: 0.9850 - val_acc: 0.8157\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9112 - acc: 0.8423 - val_loss: 0.9206 - val_acc: 0.8382\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9087 - acc: 0.8425 - val_loss: 0.9629 - val_acc: 0.8164\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9074 - acc: 0.8422 - val_loss: 0.9622 - val_acc: 0.8222\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9044 - acc: 0.8439 - val_loss: 0.9291 - val_acc: 0.8284\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9022 - acc: 0.8442 - val_loss: 0.9652 - val_acc: 0.8266\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9011 - acc: 0.8455 - val_loss: 0.9279 - val_acc: 0.8361\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9008 - acc: 0.8450 - val_loss: 0.9085 - val_acc: 0.8402\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8974 - acc: 0.8450 - val_loss: 0.9539 - val_acc: 0.8191\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8970 - acc: 0.8455 - val_loss: 0.9246 - val_acc: 0.8318\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8953 - acc: 0.8442 - val_loss: 0.9660 - val_acc: 0.8193\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8940 - acc: 0.8446 - val_loss: 0.9218 - val_acc: 0.8313\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8931 - acc: 0.8454 - val_loss: 0.9625 - val_acc: 0.8146\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8882 - acc: 0.8462 - val_loss: 0.9189 - val_acc: 0.8308\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8901 - acc: 0.8464 - val_loss: 0.9116 - val_acc: 0.8407\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8884 - acc: 0.8471 - val_loss: 0.9286 - val_acc: 0.8303\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8871 - acc: 0.8459 - val_loss: 0.9898 - val_acc: 0.8034\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8858 - acc: 0.8487 - val_loss: 0.9256 - val_acc: 0.8307\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8865 - acc: 0.8478 - val_loss: 0.8931 - val_acc: 0.8450\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8828 - acc: 0.8493 - val_loss: 0.8955 - val_acc: 0.8400\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8815 - acc: 0.8470 - val_loss: 0.8930 - val_acc: 0.8439\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8833 - acc: 0.8464 - val_loss: 0.9106 - val_acc: 0.8336\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8811 - acc: 0.8501 - val_loss: 0.9233 - val_acc: 0.8332\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8793 - acc: 0.8480 - val_loss: 0.9480 - val_acc: 0.8201\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8786 - acc: 0.8484 - val_loss: 0.9123 - val_acc: 0.8351\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8785 - acc: 0.8485 - val_loss: 0.9466 - val_acc: 0.8229\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8788 - acc: 0.8489 - val_loss: 0.8931 - val_acc: 0.8430\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8726 - acc: 0.8492 - val_loss: 0.9179 - val_acc: 0.8321\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8753 - acc: 0.8490 - val_loss: 0.8813 - val_acc: 0.8472\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8749 - acc: 0.8511 - val_loss: 0.8924 - val_acc: 0.8389\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8759 - acc: 0.8488 - val_loss: 0.9141 - val_acc: 0.8295\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8725 - acc: 0.8504 - val_loss: 0.8880 - val_acc: 0.8434\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8740 - acc: 0.8500 - val_loss: 0.8799 - val_acc: 0.8465\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8716 - acc: 0.8495 - val_loss: 0.8815 - val_acc: 0.8443\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8704 - acc: 0.8513 - val_loss: 0.9118 - val_acc: 0.8334\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8676 - acc: 0.8517 - val_loss: 0.9089 - val_acc: 0.8368\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8708 - acc: 0.8506 - val_loss: 0.9079 - val_acc: 0.8302\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8707 - acc: 0.8499 - val_loss: 0.9217 - val_acc: 0.8283\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8690 - acc: 0.8502 - val_loss: 0.9063 - val_acc: 0.8342\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8689 - acc: 0.8503 - val_loss: 0.9070 - val_acc: 0.8325\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8675 - acc: 0.8500 - val_loss: 0.8883 - val_acc: 0.8424\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8662 - acc: 0.8511 - val_loss: 0.9148 - val_acc: 0.8298\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8673 - acc: 0.8503 - val_loss: 0.8783 - val_acc: 0.8448\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8646 - acc: 0.8516 - val_loss: 0.9017 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8632 - acc: 0.8520 - val_loss: 0.8819 - val_acc: 0.8377\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8640 - acc: 0.8524 - val_loss: 0.8964 - val_acc: 0.8388\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8638 - acc: 0.8521 - val_loss: 0.8959 - val_acc: 0.8364\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8612 - acc: 0.8534 - val_loss: 0.9230 - val_acc: 0.8257\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8618 - acc: 0.8526 - val_loss: 0.8871 - val_acc: 0.8432\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8610 - acc: 0.8531 - val_loss: 0.8859 - val_acc: 0.8414\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8624 - acc: 0.8502 - val_loss: 0.8849 - val_acc: 0.8383\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8608 - acc: 0.8525 - val_loss: 0.8901 - val_acc: 0.8410\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8612 - acc: 0.8516 - val_loss: 0.8979 - val_acc: 0.8365\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8615 - acc: 0.8515 - val_loss: 0.8870 - val_acc: 0.8398\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8589 - acc: 0.8527 - val_loss: 0.9004 - val_acc: 0.8379\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8583 - acc: 0.8520 - val_loss: 0.9359 - val_acc: 0.8205\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8577 - acc: 0.8540 - val_loss: 0.9441 - val_acc: 0.8215\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8597 - acc: 0.8519 - val_loss: 0.9203 - val_acc: 0.8290\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8589 - acc: 0.8518 - val_loss: 0.8782 - val_acc: 0.8418\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8594 - acc: 0.8518 - val_loss: 0.8724 - val_acc: 0.8463\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8559 - acc: 0.8534 - val_loss: 0.8843 - val_acc: 0.8421\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8555 - acc: 0.8534 - val_loss: 0.8762 - val_acc: 0.8415\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8565 - acc: 0.8519 - val_loss: 0.9426 - val_acc: 0.8194\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8581 - acc: 0.8525 - val_loss: 0.8775 - val_acc: 0.8432\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8546 - acc: 0.8531 - val_loss: 0.8679 - val_acc: 0.8459\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8537 - acc: 0.8542 - val_loss: 0.8845 - val_acc: 0.8408\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8536 - acc: 0.8545 - val_loss: 0.9061 - val_acc: 0.8345\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8527 - acc: 0.8551 - val_loss: 0.9056 - val_acc: 0.8328\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8524 - acc: 0.8535 - val_loss: 0.9002 - val_acc: 0.8375\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8525 - acc: 0.8539 - val_loss: 0.8696 - val_acc: 0.8469\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8537 - acc: 0.8525 - val_loss: 0.9424 - val_acc: 0.8134\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8519 - acc: 0.8546 - val_loss: 0.9053 - val_acc: 0.8325\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8518 - acc: 0.8549 - val_loss: 0.8985 - val_acc: 0.8377\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8526 - acc: 0.8548 - val_loss: 0.8669 - val_acc: 0.8460\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8496 - acc: 0.8543 - val_loss: 0.9076 - val_acc: 0.8287\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8473 - acc: 0.8556 - val_loss: 0.8899 - val_acc: 0.8378\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8493 - acc: 0.8549 - val_loss: 0.9360 - val_acc: 0.8227\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8504 - acc: 0.8561 - val_loss: 0.9046 - val_acc: 0.8312\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8481 - acc: 0.8535 - val_loss: 0.9156 - val_acc: 0.8353\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8470 - acc: 0.8554 - val_loss: 0.9911 - val_acc: 0.8021\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8496 - acc: 0.8543 - val_loss: 0.8890 - val_acc: 0.8353\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8469 - acc: 0.8549 - val_loss: 0.9244 - val_acc: 0.8259\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8487 - acc: 0.8556 - val_loss: 0.8773 - val_acc: 0.8369\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8473 - acc: 0.8556 - val_loss: 0.8717 - val_acc: 0.8447\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8463 - acc: 0.8552 - val_loss: 0.9170 - val_acc: 0.8262\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8470 - acc: 0.8553 - val_loss: 0.8728 - val_acc: 0.8434\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8462 - acc: 0.8563 - val_loss: 0.8629 - val_acc: 0.8459\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8466 - acc: 0.8549 - val_loss: 0.8891 - val_acc: 0.8380\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8440 - acc: 0.8567 - val_loss: 0.8677 - val_acc: 0.8474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8444 - acc: 0.8563 - val_loss: 0.8654 - val_acc: 0.8454\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8438 - acc: 0.8570 - val_loss: 0.8832 - val_acc: 0.8385\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8457 - acc: 0.8550 - val_loss: 0.8583 - val_acc: 0.8479\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8453 - acc: 0.8559 - val_loss: 0.9061 - val_acc: 0.8293\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8438 - acc: 0.8557 - val_loss: 0.9236 - val_acc: 0.8257\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8446 - acc: 0.8564 - val_loss: 0.8775 - val_acc: 0.8409\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8450 - acc: 0.8559 - val_loss: 0.8650 - val_acc: 0.8438\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8429 - acc: 0.8567 - val_loss: 0.8785 - val_acc: 0.8364\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8420 - acc: 0.8570 - val_loss: 0.8973 - val_acc: 0.8348\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8452 - acc: 0.8552 - val_loss: 0.8628 - val_acc: 0.8445\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8405 - acc: 0.8579 - val_loss: 0.8581 - val_acc: 0.8481\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8451 - acc: 0.8551 - val_loss: 0.9333 - val_acc: 0.8271\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8411 - acc: 0.8566 - val_loss: 0.8928 - val_acc: 0.8366\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8423 - acc: 0.8563 - val_loss: 0.8558 - val_acc: 0.8508\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8425 - acc: 0.8563 - val_loss: 0.8886 - val_acc: 0.8388\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8396 - acc: 0.8565 - val_loss: 0.8611 - val_acc: 0.8469\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8404 - acc: 0.8581 - val_loss: 0.8964 - val_acc: 0.8331\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8408 - acc: 0.8571 - val_loss: 0.8591 - val_acc: 0.8467\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8412 - acc: 0.8559 - val_loss: 0.8703 - val_acc: 0.8453\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8389 - acc: 0.8573 - val_loss: 0.8871 - val_acc: 0.8351\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8404 - acc: 0.8562 - val_loss: 0.8706 - val_acc: 0.8416\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8390 - acc: 0.8572 - val_loss: 0.8599 - val_acc: 0.8463\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8377 - acc: 0.8587 - val_loss: 0.8748 - val_acc: 0.8411\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8396 - acc: 0.8564 - val_loss: 0.9348 - val_acc: 0.8238\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8419 - acc: 0.8549 - val_loss: 0.8503 - val_acc: 0.8504\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8369 - acc: 0.8571 - val_loss: 0.8488 - val_acc: 0.8499\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8379 - acc: 0.8572 - val_loss: 0.8804 - val_acc: 0.8378\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8384 - acc: 0.8575 - val_loss: 0.8810 - val_acc: 0.8403\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8382 - acc: 0.8575 - val_loss: 0.8492 - val_acc: 0.8507\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8354 - acc: 0.8584 - val_loss: 0.8793 - val_acc: 0.8413\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8371 - acc: 0.8579 - val_loss: 0.8572 - val_acc: 0.8516\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8383 - acc: 0.8577 - val_loss: 0.8648 - val_acc: 0.8443\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8354 - acc: 0.8594 - val_loss: 0.8590 - val_acc: 0.8457\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8360 - acc: 0.8577 - val_loss: 0.8825 - val_acc: 0.8401\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8376 - acc: 0.8569 - val_loss: 0.8817 - val_acc: 0.8348\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8370 - acc: 0.8573 - val_loss: 0.8752 - val_acc: 0.8417\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8381 - acc: 0.8566 - val_loss: 0.8597 - val_acc: 0.8447\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8352 - acc: 0.8570 - val_loss: 0.8578 - val_acc: 0.8493\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8363 - acc: 0.8572 - val_loss: 0.9148 - val_acc: 0.8275\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8354 - acc: 0.8575 - val_loss: 0.8940 - val_acc: 0.8356\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8370 - acc: 0.8564 - val_loss: 0.9250 - val_acc: 0.8201\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8364 - acc: 0.8576 - val_loss: 0.9041 - val_acc: 0.8248\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8362 - acc: 0.8566 - val_loss: 0.8853 - val_acc: 0.8344\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8347 - acc: 0.8583 - val_loss: 0.8607 - val_acc: 0.8490\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8349 - acc: 0.8574 - val_loss: 0.8531 - val_acc: 0.8480\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8341 - acc: 0.8576 - val_loss: 0.8551 - val_acc: 0.8484\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8371 - acc: 0.8564 - val_loss: 0.8649 - val_acc: 0.8455\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8338 - acc: 0.8583 - val_loss: 0.8603 - val_acc: 0.8443\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8325 - acc: 0.8583 - val_loss: 0.9003 - val_acc: 0.8305\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8333 - acc: 0.8592 - val_loss: 0.9124 - val_acc: 0.8230\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8337 - acc: 0.8586 - val_loss: 0.8898 - val_acc: 0.8303\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8345 - acc: 0.8572 - val_loss: 0.8687 - val_acc: 0.8456\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8330 - acc: 0.8588 - val_loss: 0.8433 - val_acc: 0.8521\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8313 - acc: 0.8582 - val_loss: 0.8563 - val_acc: 0.8489\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8338 - acc: 0.8590 - val_loss: 0.8780 - val_acc: 0.8391\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8319 - acc: 0.8580 - val_loss: 0.8516 - val_acc: 0.8515\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8326 - acc: 0.8577 - val_loss: 0.9101 - val_acc: 0.8286\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8313 - acc: 0.8577 - val_loss: 0.9009 - val_acc: 0.8293\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8348 - acc: 0.8558 - val_loss: 0.8625 - val_acc: 0.8446\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8312 - acc: 0.8584 - val_loss: 0.8674 - val_acc: 0.8433\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8330 - acc: 0.8577 - val_loss: 0.8784 - val_acc: 0.8410\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8315 - acc: 0.8590 - val_loss: 0.8767 - val_acc: 0.8398\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8321 - acc: 0.8587 - val_loss: 0.9301 - val_acc: 0.8235\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8310 - acc: 0.8588 - val_loss: 0.9036 - val_acc: 0.8320\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8335 - acc: 0.8577 - val_loss: 0.8683 - val_acc: 0.8431\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8314 - acc: 0.8584 - val_loss: 0.8549 - val_acc: 0.8478\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8335 - acc: 0.8578 - val_loss: 0.8813 - val_acc: 0.8366\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8306 - acc: 0.8581 - val_loss: 0.8944 - val_acc: 0.8319\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8324 - acc: 0.8579 - val_loss: 0.8762 - val_acc: 0.8376\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8317 - acc: 0.8590 - val_loss: 0.8767 - val_acc: 0.8397\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8302 - acc: 0.8582 - val_loss: 0.8768 - val_acc: 0.8390\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8312 - acc: 0.8591 - val_loss: 0.8706 - val_acc: 0.8425\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8306 - acc: 0.8597 - val_loss: 0.9156 - val_acc: 0.8315\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8297 - acc: 0.8579 - val_loss: 0.8846 - val_acc: 0.8397\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8317 - acc: 0.8577 - val_loss: 0.8693 - val_acc: 0.8421\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8301 - acc: 0.8598 - val_loss: 0.8446 - val_acc: 0.8521\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8288 - acc: 0.8581 - val_loss: 0.8501 - val_acc: 0.8490\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8331 - acc: 0.8577 - val_loss: 0.9072 - val_acc: 0.8234\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8284 - acc: 0.8600 - val_loss: 0.8535 - val_acc: 0.8496\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8302 - acc: 0.8583 - val_loss: 0.8453 - val_acc: 0.8498\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8288 - acc: 0.8591 - val_loss: 0.8765 - val_acc: 0.8409\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8295 - acc: 0.8582 - val_loss: 0.9110 - val_acc: 0.8261\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8289 - acc: 0.8587 - val_loss: 0.8628 - val_acc: 0.8478\n"
     ]
    }
   ],
   "source": [
    "m8_history = m8_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m8_history.history['val_loss'])\n",
    "tup = ('m8', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. model 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m9_model = models.Sequential()\n",
    "m9_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m9_model.add(layers.Dropout(0.2))\n",
    "m9_model.add(layers.Dense(512, activation='relu'))\n",
    "m9_model.add(layers.Dropout(0.2))\n",
    "m9_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m9_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.7547 - acc: 0.7291 - val_loss: 0.5037 - val_acc: 0.8216\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4779 - acc: 0.8214 - val_loss: 0.4463 - val_acc: 0.8367\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4141 - acc: 0.8474 - val_loss: 0.4062 - val_acc: 0.8517\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3806 - acc: 0.8597 - val_loss: 0.3703 - val_acc: 0.8666\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3510 - acc: 0.8679 - val_loss: 0.3876 - val_acc: 0.8568\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3347 - acc: 0.8759 - val_loss: 0.4000 - val_acc: 0.8557\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3177 - acc: 0.8806 - val_loss: 0.4498 - val_acc: 0.8397\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3057 - acc: 0.8861 - val_loss: 0.3501 - val_acc: 0.8628\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2882 - acc: 0.8917 - val_loss: 0.3240 - val_acc: 0.8805\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2834 - acc: 0.8954 - val_loss: 0.3100 - val_acc: 0.8860\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2719 - acc: 0.8965 - val_loss: 0.3133 - val_acc: 0.8854\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2634 - acc: 0.9012 - val_loss: 0.3197 - val_acc: 0.8827\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2539 - acc: 0.9042 - val_loss: 0.3094 - val_acc: 0.8902\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2489 - acc: 0.9047 - val_loss: 0.3153 - val_acc: 0.8847\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2408 - acc: 0.9081 - val_loss: 0.3335 - val_acc: 0.8825\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2355 - acc: 0.9109 - val_loss: 0.3334 - val_acc: 0.8821\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2268 - acc: 0.9134 - val_loss: 0.3235 - val_acc: 0.8873\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2202 - acc: 0.9150 - val_loss: 0.3113 - val_acc: 0.8940\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2183 - acc: 0.9159 - val_loss: 0.2956 - val_acc: 0.8954\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2121 - acc: 0.9196 - val_loss: 0.3272 - val_acc: 0.8867\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2058 - acc: 0.9203 - val_loss: 0.3106 - val_acc: 0.8968\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2045 - acc: 0.9219 - val_loss: 0.3522 - val_acc: 0.8761\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1968 - acc: 0.9256 - val_loss: 0.3500 - val_acc: 0.8849\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1951 - acc: 0.9261 - val_loss: 0.3699 - val_acc: 0.8780\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1929 - acc: 0.9270 - val_loss: 0.3182 - val_acc: 0.8932\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1873 - acc: 0.9285 - val_loss: 0.3565 - val_acc: 0.8831\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1830 - acc: 0.9314 - val_loss: 0.3312 - val_acc: 0.8978\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1819 - acc: 0.9297 - val_loss: 0.3628 - val_acc: 0.8841\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1740 - acc: 0.9336 - val_loss: 0.3710 - val_acc: 0.8813\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1717 - acc: 0.9343 - val_loss: 0.3611 - val_acc: 0.8930\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1699 - acc: 0.9351 - val_loss: 0.3810 - val_acc: 0.8904\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1653 - acc: 0.9363 - val_loss: 0.3297 - val_acc: 0.8996\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1656 - acc: 0.9368 - val_loss: 0.3523 - val_acc: 0.8934\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1596 - acc: 0.9395 - val_loss: 0.3463 - val_acc: 0.8927\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1606 - acc: 0.9384 - val_loss: 0.3520 - val_acc: 0.8945\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1567 - acc: 0.9403 - val_loss: 0.3700 - val_acc: 0.8900\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1539 - acc: 0.9403 - val_loss: 0.4502 - val_acc: 0.8777\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1513 - acc: 0.9426 - val_loss: 0.3905 - val_acc: 0.8866\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1497 - acc: 0.9428 - val_loss: 0.3653 - val_acc: 0.8934\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1490 - acc: 0.9430 - val_loss: 0.3865 - val_acc: 0.8933\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1458 - acc: 0.9433 - val_loss: 0.4568 - val_acc: 0.8732\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1432 - acc: 0.9448 - val_loss: 0.3542 - val_acc: 0.9003\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1425 - acc: 0.9448 - val_loss: 0.3802 - val_acc: 0.8967\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1367 - acc: 0.9482 - val_loss: 0.3649 - val_acc: 0.8952\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1388 - acc: 0.9473 - val_loss: 0.3908 - val_acc: 0.8949\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1369 - acc: 0.9488 - val_loss: 0.4569 - val_acc: 0.8879\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1392 - acc: 0.9468 - val_loss: 0.4091 - val_acc: 0.8914\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1318 - acc: 0.9503 - val_loss: 0.3970 - val_acc: 0.8993\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1334 - acc: 0.9499 - val_loss: 0.3801 - val_acc: 0.9013\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1304 - acc: 0.9505 - val_loss: 0.3919 - val_acc: 0.9007\n"
     ]
    }
   ],
   "source": [
    "m9_history = m9_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m9_history.history['val_loss'])\n",
    "tup = ('m9', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. model 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10_model = models.Sequential()\n",
    "m10_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m10_model.add(layers.Dropout(0.3))\n",
    "m10_model.add(layers.Dense(512, activation='relu'))\n",
    "m10_model.add(layers.Dropout(0.3))\n",
    "m10_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m10_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.7503 - acc: 0.7292 - val_loss: 0.5447 - val_acc: 0.7976\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4845 - acc: 0.8203 - val_loss: 0.4805 - val_acc: 0.8285\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4232 - acc: 0.8434 - val_loss: 0.4016 - val_acc: 0.8460\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3843 - acc: 0.8580 - val_loss: 0.4085 - val_acc: 0.8464\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3656 - acc: 0.8647 - val_loss: 0.4042 - val_acc: 0.8460\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3455 - acc: 0.8706 - val_loss: 0.3965 - val_acc: 0.8534\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3291 - acc: 0.8779 - val_loss: 0.3510 - val_acc: 0.8712\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3143 - acc: 0.8828 - val_loss: 0.3811 - val_acc: 0.8591\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3074 - acc: 0.8843 - val_loss: 0.3861 - val_acc: 0.8630\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2987 - acc: 0.8881 - val_loss: 0.3360 - val_acc: 0.8742\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2864 - acc: 0.8912 - val_loss: 0.3095 - val_acc: 0.8868\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2786 - acc: 0.8948 - val_loss: 0.3434 - val_acc: 0.8727\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2735 - acc: 0.8960 - val_loss: 0.3181 - val_acc: 0.8873\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2661 - acc: 0.8987 - val_loss: 0.3166 - val_acc: 0.8831\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2618 - acc: 0.9002 - val_loss: 0.3309 - val_acc: 0.8826\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2544 - acc: 0.9037 - val_loss: 0.3483 - val_acc: 0.8736\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2472 - acc: 0.9058 - val_loss: 0.3149 - val_acc: 0.8894\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2446 - acc: 0.9076 - val_loss: 0.3677 - val_acc: 0.8749\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2396 - acc: 0.9090 - val_loss: 0.3091 - val_acc: 0.8907\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2349 - acc: 0.9116 - val_loss: 0.3080 - val_acc: 0.8888\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2310 - acc: 0.9128 - val_loss: 0.3003 - val_acc: 0.8954\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2281 - acc: 0.9145 - val_loss: 0.3173 - val_acc: 0.8877\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2205 - acc: 0.9159 - val_loss: 0.3202 - val_acc: 0.8880\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2185 - acc: 0.9174 - val_loss: 0.3303 - val_acc: 0.8867\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2121 - acc: 0.9189 - val_loss: 0.3662 - val_acc: 0.8757\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2116 - acc: 0.9198 - val_loss: 0.3119 - val_acc: 0.8915\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2101 - acc: 0.9199 - val_loss: 0.3478 - val_acc: 0.8824\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2062 - acc: 0.9217 - val_loss: 0.3183 - val_acc: 0.8930\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2075 - acc: 0.9214 - val_loss: 0.3639 - val_acc: 0.8794\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2011 - acc: 0.9241 - val_loss: 0.3421 - val_acc: 0.8834\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1984 - acc: 0.9247 - val_loss: 0.3084 - val_acc: 0.8957\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1967 - acc: 0.9248 - val_loss: 0.3454 - val_acc: 0.8917\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1909 - acc: 0.9285 - val_loss: 0.3317 - val_acc: 0.8928\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1889 - acc: 0.9283 - val_loss: 0.3209 - val_acc: 0.8951\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1898 - acc: 0.9279 - val_loss: 0.3243 - val_acc: 0.8987\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1868 - acc: 0.9284 - val_loss: 0.3169 - val_acc: 0.9003\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1834 - acc: 0.9304 - val_loss: 0.3560 - val_acc: 0.8908\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1827 - acc: 0.9309 - val_loss: 0.3331 - val_acc: 0.8982\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1781 - acc: 0.9318 - val_loss: 0.3357 - val_acc: 0.8984\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1760 - acc: 0.9332 - val_loss: 0.3452 - val_acc: 0.8909\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1739 - acc: 0.9337 - val_loss: 0.3516 - val_acc: 0.8934\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1751 - acc: 0.9344 - val_loss: 0.3155 - val_acc: 0.9018\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1678 - acc: 0.9360 - val_loss: 0.3759 - val_acc: 0.8957\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1680 - acc: 0.9354 - val_loss: 0.3358 - val_acc: 0.9010\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1698 - acc: 0.9337 - val_loss: 0.3574 - val_acc: 0.8952\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1639 - acc: 0.9376 - val_loss: 0.3770 - val_acc: 0.8972\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1660 - acc: 0.9371 - val_loss: 0.3423 - val_acc: 0.9015\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1648 - acc: 0.9374 - val_loss: 0.3330 - val_acc: 0.9028\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1623 - acc: 0.9389 - val_loss: 0.3570 - val_acc: 0.8957\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1594 - acc: 0.9398 - val_loss: 0.3965 - val_acc: 0.8946\n"
     ]
    }
   ],
   "source": [
    "m10_history = m10_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m10_history.history['val_loss'])\n",
    "tup = ('m10', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19), ('m10', 0.3003294213294983, 21)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. model 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "m11_model = models.Sequential()\n",
    "m11_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m11_model.add(layers.Dropout(0.5))\n",
    "m11_model.add(layers.Dense(512, activation='relu'))\n",
    "m11_model.add(layers.Dropout(0.5))\n",
    "m11_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m11_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.7932 - acc: 0.7140 - val_loss: 0.5045 - val_acc: 0.8132\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.5170 - acc: 0.8113 - val_loss: 0.4461 - val_acc: 0.8308\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4588 - acc: 0.8313 - val_loss: 0.4367 - val_acc: 0.8368\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4259 - acc: 0.8448 - val_loss: 0.4178 - val_acc: 0.8472\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4015 - acc: 0.8535 - val_loss: 0.4009 - val_acc: 0.8531\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3821 - acc: 0.8613 - val_loss: 0.4245 - val_acc: 0.8455\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3695 - acc: 0.8627 - val_loss: 0.3444 - val_acc: 0.8730\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3578 - acc: 0.8694 - val_loss: 0.3538 - val_acc: 0.8639\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3509 - acc: 0.8725 - val_loss: 0.3398 - val_acc: 0.8738\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3399 - acc: 0.8742 - val_loss: 0.3811 - val_acc: 0.8567\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3356 - acc: 0.8784 - val_loss: 0.3741 - val_acc: 0.8631\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3261 - acc: 0.8807 - val_loss: 0.3309 - val_acc: 0.8767\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3178 - acc: 0.8838 - val_loss: 0.3311 - val_acc: 0.8770\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3172 - acc: 0.8825 - val_loss: 0.3301 - val_acc: 0.8781\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3069 - acc: 0.8875 - val_loss: 0.3202 - val_acc: 0.8817\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3040 - acc: 0.8875 - val_loss: 0.3638 - val_acc: 0.8624\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3029 - acc: 0.8889 - val_loss: 0.3206 - val_acc: 0.8852\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2932 - acc: 0.8901 - val_loss: 0.3327 - val_acc: 0.8756\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2945 - acc: 0.8907 - val_loss: 0.3173 - val_acc: 0.8859\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2873 - acc: 0.8945 - val_loss: 0.3471 - val_acc: 0.8781\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2880 - acc: 0.8932 - val_loss: 0.3088 - val_acc: 0.8882\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2818 - acc: 0.8953 - val_loss: 0.3355 - val_acc: 0.8846\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2767 - acc: 0.8976 - val_loss: 0.3285 - val_acc: 0.8810\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2780 - acc: 0.8966 - val_loss: 0.3325 - val_acc: 0.8810\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2722 - acc: 0.8992 - val_loss: 0.3164 - val_acc: 0.8914\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2715 - acc: 0.8984 - val_loss: 0.3302 - val_acc: 0.8832\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2665 - acc: 0.9021 - val_loss: 0.3244 - val_acc: 0.8853\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2685 - acc: 0.9016 - val_loss: 0.3175 - val_acc: 0.8864\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2640 - acc: 0.9014 - val_loss: 0.3314 - val_acc: 0.8856\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2622 - acc: 0.9020 - val_loss: 0.3522 - val_acc: 0.8798\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2602 - acc: 0.9033 - val_loss: 0.3200 - val_acc: 0.8905\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2587 - acc: 0.9037 - val_loss: 0.3208 - val_acc: 0.8899\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2547 - acc: 0.9066 - val_loss: 0.3235 - val_acc: 0.8878\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2569 - acc: 0.9040 - val_loss: 0.3272 - val_acc: 0.8881\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2523 - acc: 0.9065 - val_loss: 0.3362 - val_acc: 0.8851\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2481 - acc: 0.9084 - val_loss: 0.3035 - val_acc: 0.8945\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2457 - acc: 0.9087 - val_loss: 0.3397 - val_acc: 0.8896\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2471 - acc: 0.9098 - val_loss: 0.3282 - val_acc: 0.8942\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2432 - acc: 0.9101 - val_loss: 0.3642 - val_acc: 0.8844\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2414 - acc: 0.9106 - val_loss: 0.3319 - val_acc: 0.8915\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2392 - acc: 0.9109 - val_loss: 0.3183 - val_acc: 0.8922\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2401 - acc: 0.9110 - val_loss: 0.3353 - val_acc: 0.8936\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2391 - acc: 0.9103 - val_loss: 0.3360 - val_acc: 0.8906\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2385 - acc: 0.9131 - val_loss: 0.3300 - val_acc: 0.8901\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2350 - acc: 0.9119 - val_loss: 0.3408 - val_acc: 0.8893\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2321 - acc: 0.9141 - val_loss: 0.3120 - val_acc: 0.8991\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2306 - acc: 0.9142 - val_loss: 0.3349 - val_acc: 0.8911\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2326 - acc: 0.9137 - val_loss: 0.3325 - val_acc: 0.8908\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2282 - acc: 0.9152 - val_loss: 0.3224 - val_acc: 0.8940\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2270 - acc: 0.9170 - val_loss: 0.3257 - val_acc: 0.8929\n"
     ]
    }
   ],
   "source": [
    "m11_history = m11_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m11_history.history['val_loss'])\n",
    "tup = ('m11', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19), ('m10', 0.3003294213294983, 21), ('m11', 0.3035426574230194, 36)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. model 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "m12_model = models.Sequential()\n",
    "m12_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu', input_shape=(28 * 28,)))\n",
    "m12_model.add(layers.Dropout(0.5))\n",
    "m12_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu'))\n",
    "m12_model.add(layers.Dropout(0.5))\n",
    "m12_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m12_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 8.9216 - acc: 0.6389 - val_loss: 2.9850 - val_acc: 0.6993\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2435 - acc: 0.6990 - val_loss: 1.7952 - val_acc: 0.7444\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7196 - acc: 0.7173 - val_loss: 1.5472 - val_acc: 0.7502\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5666 - acc: 0.7281 - val_loss: 1.4505 - val_acc: 0.7546\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4942 - acc: 0.7345 - val_loss: 1.3656 - val_acc: 0.7773\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4383 - acc: 0.7434 - val_loss: 1.3078 - val_acc: 0.7845\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4123 - acc: 0.7443 - val_loss: 1.2762 - val_acc: 0.7846\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3904 - acc: 0.7492 - val_loss: 1.2594 - val_acc: 0.7888\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3665 - acc: 0.7517 - val_loss: 1.2756 - val_acc: 0.7741\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3557 - acc: 0.7522 - val_loss: 1.3039 - val_acc: 0.7853\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3403 - acc: 0.7569 - val_loss: 1.2800 - val_acc: 0.7764\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3382 - acc: 0.7555 - val_loss: 1.2449 - val_acc: 0.7827\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3237 - acc: 0.7570 - val_loss: 1.2182 - val_acc: 0.7904\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3110 - acc: 0.7615 - val_loss: 1.2366 - val_acc: 0.7830\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3099 - acc: 0.7602 - val_loss: 1.2531 - val_acc: 0.7802\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3076 - acc: 0.7610 - val_loss: 1.1937 - val_acc: 0.8003\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2983 - acc: 0.7630 - val_loss: 1.2118 - val_acc: 0.7919\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2919 - acc: 0.7630 - val_loss: 1.1777 - val_acc: 0.8021\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2844 - acc: 0.7663 - val_loss: 1.1636 - val_acc: 0.8066\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2769 - acc: 0.7659 - val_loss: 1.1502 - val_acc: 0.8102\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2771 - acc: 0.7668 - val_loss: 1.1501 - val_acc: 0.8101\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2753 - acc: 0.7662 - val_loss: 1.1505 - val_acc: 0.8061\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2732 - acc: 0.7648 - val_loss: 1.1779 - val_acc: 0.8002\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2659 - acc: 0.7693 - val_loss: 1.1702 - val_acc: 0.7997\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2648 - acc: 0.7670 - val_loss: 1.1749 - val_acc: 0.7993\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2574 - acc: 0.7680 - val_loss: 1.2088 - val_acc: 0.7880\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2560 - acc: 0.7681 - val_loss: 1.1561 - val_acc: 0.7997\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2541 - acc: 0.7678 - val_loss: 1.2036 - val_acc: 0.7752\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2560 - acc: 0.7660 - val_loss: 1.2155 - val_acc: 0.7858\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2511 - acc: 0.7697 - val_loss: 1.1342 - val_acc: 0.8127\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2471 - acc: 0.7696 - val_loss: 1.1459 - val_acc: 0.7922\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2431 - acc: 0.7694 - val_loss: 1.1666 - val_acc: 0.7883\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2420 - acc: 0.7709 - val_loss: 1.1932 - val_acc: 0.7828\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2397 - acc: 0.7703 - val_loss: 1.1227 - val_acc: 0.8129\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2412 - acc: 0.7725 - val_loss: 1.1376 - val_acc: 0.8037\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2322 - acc: 0.7739 - val_loss: 1.1758 - val_acc: 0.7826\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2404 - acc: 0.7714 - val_loss: 1.1524 - val_acc: 0.7901\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2325 - acc: 0.7725 - val_loss: 1.1260 - val_acc: 0.7990\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2279 - acc: 0.7736 - val_loss: 1.1243 - val_acc: 0.8110\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2333 - acc: 0.7718 - val_loss: 1.1792 - val_acc: 0.7864\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2307 - acc: 0.7703 - val_loss: 1.1354 - val_acc: 0.8046\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2313 - acc: 0.7739 - val_loss: 1.1046 - val_acc: 0.8127\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2222 - acc: 0.7732 - val_loss: 1.1544 - val_acc: 0.7880\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2258 - acc: 0.7734 - val_loss: 1.1423 - val_acc: 0.7900\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2277 - acc: 0.7724 - val_loss: 1.1070 - val_acc: 0.8095\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2238 - acc: 0.7710 - val_loss: 1.1338 - val_acc: 0.7981\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2266 - acc: 0.7732 - val_loss: 1.1276 - val_acc: 0.8015\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2197 - acc: 0.7759 - val_loss: 1.1310 - val_acc: 0.8005\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2187 - acc: 0.7738 - val_loss: 1.1729 - val_acc: 0.7872\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2176 - acc: 0.7740 - val_loss: 1.1245 - val_acc: 0.7952\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2196 - acc: 0.7731 - val_loss: 1.0881 - val_acc: 0.8182\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2142 - acc: 0.7761 - val_loss: 1.1372 - val_acc: 0.8056\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2162 - acc: 0.7743 - val_loss: 1.0972 - val_acc: 0.8133\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2170 - acc: 0.7739 - val_loss: 1.1418 - val_acc: 0.7941\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2158 - acc: 0.7741 - val_loss: 1.0765 - val_acc: 0.8195\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2130 - acc: 0.7768 - val_loss: 1.1683 - val_acc: 0.7799\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2136 - acc: 0.7759 - val_loss: 1.1501 - val_acc: 0.7940\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2205 - acc: 0.7733 - val_loss: 1.0879 - val_acc: 0.8153\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2129 - acc: 0.7767 - val_loss: 1.1421 - val_acc: 0.7896\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2093 - acc: 0.7765 - val_loss: 1.1259 - val_acc: 0.7991\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2064 - acc: 0.7764 - val_loss: 1.1714 - val_acc: 0.7923\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2125 - acc: 0.7756 - val_loss: 1.1158 - val_acc: 0.8204\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2098 - acc: 0.7756 - val_loss: 1.1409 - val_acc: 0.7994\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2125 - acc: 0.7748 - val_loss: 1.1361 - val_acc: 0.7971\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2036 - acc: 0.7770 - val_loss: 1.1158 - val_acc: 0.7903\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2064 - acc: 0.7764 - val_loss: 1.1467 - val_acc: 0.8088\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2072 - acc: 0.7770 - val_loss: 1.1109 - val_acc: 0.8149\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2069 - acc: 0.7768 - val_loss: 1.0748 - val_acc: 0.8186\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1988 - acc: 0.7788 - val_loss: 1.1297 - val_acc: 0.7918\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2032 - acc: 0.7786 - val_loss: 1.0950 - val_acc: 0.8145\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2069 - acc: 0.7778 - val_loss: 1.0872 - val_acc: 0.8232\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2051 - acc: 0.7773 - val_loss: 1.0788 - val_acc: 0.8209\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2002 - acc: 0.7777 - val_loss: 1.1234 - val_acc: 0.8066\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2125 - acc: 0.7736 - val_loss: 1.1259 - val_acc: 0.8046\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1996 - acc: 0.7779 - val_loss: 1.1127 - val_acc: 0.7993\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2008 - acc: 0.7767 - val_loss: 1.1546 - val_acc: 0.7889\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2019 - acc: 0.7774 - val_loss: 1.0848 - val_acc: 0.8194\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1972 - acc: 0.7790 - val_loss: 1.0825 - val_acc: 0.8168\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1942 - acc: 0.7777 - val_loss: 1.2143 - val_acc: 0.7743\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2024 - acc: 0.7787 - val_loss: 1.1052 - val_acc: 0.8003\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2035 - acc: 0.7757 - val_loss: 1.0832 - val_acc: 0.8193\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1962 - acc: 0.7776 - val_loss: 1.2346 - val_acc: 0.7618\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2046 - acc: 0.7753 - val_loss: 1.0950 - val_acc: 0.8193\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1978 - acc: 0.7791 - val_loss: 1.0893 - val_acc: 0.8158\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.2009 - acc: 0.7743 - val_loss: 1.0657 - val_acc: 0.8211\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1968 - acc: 0.7783 - val_loss: 1.0594 - val_acc: 0.8234\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1962 - acc: 0.7770 - val_loss: 1.1071 - val_acc: 0.8080\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1985 - acc: 0.7778 - val_loss: 1.0886 - val_acc: 0.8132\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1883 - acc: 0.7798 - val_loss: 1.1826 - val_acc: 0.7740\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1996 - acc: 0.7779 - val_loss: 1.1185 - val_acc: 0.8067\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2034 - acc: 0.7769 - val_loss: 1.0733 - val_acc: 0.8164\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1911 - acc: 0.7791 - val_loss: 1.1302 - val_acc: 0.7900\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1862 - acc: 0.7815 - val_loss: 1.1291 - val_acc: 0.7936\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2047 - acc: 0.7753 - val_loss: 1.0845 - val_acc: 0.8128\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1955 - acc: 0.7775 - val_loss: 1.0805 - val_acc: 0.8211\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1991 - acc: 0.7759 - val_loss: 1.1188 - val_acc: 0.7996\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1916 - acc: 0.7773 - val_loss: 1.1168 - val_acc: 0.7914\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1957 - acc: 0.7771 - val_loss: 1.1247 - val_acc: 0.7948\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1910 - acc: 0.7792 - val_loss: 1.2160 - val_acc: 0.7490\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1985 - acc: 0.7773 - val_loss: 1.1301 - val_acc: 0.7762\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1925 - acc: 0.7776 - val_loss: 1.2857 - val_acc: 0.7533\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1990 - acc: 0.7783 - val_loss: 1.0924 - val_acc: 0.8100\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1987 - acc: 0.7764 - val_loss: 1.1123 - val_acc: 0.8030\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1928 - acc: 0.7794 - val_loss: 1.1127 - val_acc: 0.7950\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1958 - acc: 0.7784 - val_loss: 1.0600 - val_acc: 0.8184\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1975 - acc: 0.7785 - val_loss: 1.0979 - val_acc: 0.8036\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1957 - acc: 0.7771 - val_loss: 1.1862 - val_acc: 0.7525\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1850 - acc: 0.7812 - val_loss: 1.0933 - val_acc: 0.8142\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1887 - acc: 0.7791 - val_loss: 1.0830 - val_acc: 0.8171\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1871 - acc: 0.7800 - val_loss: 1.1269 - val_acc: 0.7929\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1905 - acc: 0.7773 - val_loss: 1.1203 - val_acc: 0.7915\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1926 - acc: 0.7783 - val_loss: 1.0853 - val_acc: 0.8100\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1838 - acc: 0.7776 - val_loss: 1.0763 - val_acc: 0.8179\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1942 - acc: 0.7783 - val_loss: 1.0723 - val_acc: 0.8193\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1909 - acc: 0.7787 - val_loss: 1.1479 - val_acc: 0.7763\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1929 - acc: 0.7786 - val_loss: 1.0655 - val_acc: 0.8184\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1901 - acc: 0.7775 - val_loss: 1.0583 - val_acc: 0.8221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1902 - acc: 0.7801 - val_loss: 1.0521 - val_acc: 0.8230\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1931 - acc: 0.7799 - val_loss: 1.1094 - val_acc: 0.8133\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1863 - acc: 0.7808 - val_loss: 1.1042 - val_acc: 0.8118\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1954 - acc: 0.7779 - val_loss: 1.1004 - val_acc: 0.8096\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1853 - acc: 0.7818 - val_loss: 1.1086 - val_acc: 0.8094\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1906 - acc: 0.7778 - val_loss: 1.0694 - val_acc: 0.8125\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1884 - acc: 0.7800 - val_loss: 1.1154 - val_acc: 0.7899\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1937 - acc: 0.7778 - val_loss: 1.1653 - val_acc: 0.7706\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1978 - acc: 0.7772 - val_loss: 1.1124 - val_acc: 0.7904\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2019 - acc: 0.7772 - val_loss: 1.0575 - val_acc: 0.8230\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1934 - acc: 0.7760 - val_loss: 1.1118 - val_acc: 0.7940\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1899 - acc: 0.7785 - val_loss: 1.1384 - val_acc: 0.7886\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1939 - acc: 0.7795 - val_loss: 1.0926 - val_acc: 0.8083\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1866 - acc: 0.7785 - val_loss: 1.0806 - val_acc: 0.8229\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1867 - acc: 0.7776 - val_loss: 1.0728 - val_acc: 0.8245\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1847 - acc: 0.7785 - val_loss: 1.1156 - val_acc: 0.7999\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1918 - acc: 0.7780 - val_loss: 1.0996 - val_acc: 0.8093\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1915 - acc: 0.7783 - val_loss: 1.0663 - val_acc: 0.8248\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1875 - acc: 0.7804 - val_loss: 1.1366 - val_acc: 0.7892\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1844 - acc: 0.7800 - val_loss: 1.0896 - val_acc: 0.7986\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1886 - acc: 0.7795 - val_loss: 1.0652 - val_acc: 0.8176\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1876 - acc: 0.7786 - val_loss: 1.0855 - val_acc: 0.8129\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1864 - acc: 0.7768 - val_loss: 1.1033 - val_acc: 0.8072\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.2013 - acc: 0.7751 - val_loss: 1.1190 - val_acc: 0.8192\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1816 - acc: 0.7811 - val_loss: 1.1799 - val_acc: 0.7640\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1802 - acc: 0.7826 - val_loss: 1.0906 - val_acc: 0.8149\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1902 - acc: 0.7772 - val_loss: 1.0895 - val_acc: 0.8110\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1869 - acc: 0.7788 - val_loss: 1.0593 - val_acc: 0.8154\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1897 - acc: 0.7805 - val_loss: 1.1263 - val_acc: 0.8022\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1907 - acc: 0.7769 - val_loss: 1.1432 - val_acc: 0.7766\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1856 - acc: 0.7782 - val_loss: 1.0879 - val_acc: 0.8125\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1906 - acc: 0.7791 - val_loss: 1.1040 - val_acc: 0.8011\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1901 - acc: 0.7769 - val_loss: 1.0883 - val_acc: 0.8000\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1788 - acc: 0.7827 - val_loss: 1.0854 - val_acc: 0.8021\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1906 - acc: 0.7792 - val_loss: 1.1472 - val_acc: 0.7927\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1872 - acc: 0.7802 - val_loss: 1.0576 - val_acc: 0.8178\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1850 - acc: 0.7776 - val_loss: 1.1197 - val_acc: 0.7715\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1825 - acc: 0.7774 - val_loss: 1.0545 - val_acc: 0.8234\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1857 - acc: 0.7790 - val_loss: 1.1621 - val_acc: 0.7771\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1916 - acc: 0.7799 - val_loss: 1.0743 - val_acc: 0.8234\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1860 - acc: 0.7806 - val_loss: 1.0810 - val_acc: 0.8149\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1851 - acc: 0.7778 - val_loss: 1.1064 - val_acc: 0.8026\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1794 - acc: 0.7823 - val_loss: 1.1237 - val_acc: 0.7954\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1967 - acc: 0.7788 - val_loss: 1.0962 - val_acc: 0.7987\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1837 - acc: 0.7800 - val_loss: 1.0798 - val_acc: 0.8173\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1923 - acc: 0.7779 - val_loss: 1.0712 - val_acc: 0.8238\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1786 - acc: 0.7804 - val_loss: 1.0614 - val_acc: 0.8175\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1864 - acc: 0.7790 - val_loss: 1.0692 - val_acc: 0.8203\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1880 - acc: 0.7789 - val_loss: 1.0844 - val_acc: 0.8078\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1807 - acc: 0.7815 - val_loss: 1.0762 - val_acc: 0.8129\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1908 - acc: 0.7774 - val_loss: 1.0967 - val_acc: 0.8008\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1914 - acc: 0.7761 - val_loss: 1.1148 - val_acc: 0.8014\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1760 - acc: 0.7822 - val_loss: 1.1015 - val_acc: 0.8035\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1820 - acc: 0.7797 - val_loss: 1.0939 - val_acc: 0.8134\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1825 - acc: 0.7801 - val_loss: 1.0726 - val_acc: 0.8180\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1955 - acc: 0.7762 - val_loss: 1.0648 - val_acc: 0.8208\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1858 - acc: 0.7799 - val_loss: 1.1182 - val_acc: 0.8044\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1793 - acc: 0.7798 - val_loss: 1.2524 - val_acc: 0.7678\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1902 - acc: 0.7770 - val_loss: 1.0728 - val_acc: 0.8195\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1850 - acc: 0.7790 - val_loss: 1.1774 - val_acc: 0.7476\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1913 - acc: 0.7776 - val_loss: 1.0688 - val_acc: 0.8214\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1883 - acc: 0.7780 - val_loss: 1.0647 - val_acc: 0.8136\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1856 - acc: 0.7803 - val_loss: 1.0713 - val_acc: 0.8168\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1889 - acc: 0.7780 - val_loss: 1.0818 - val_acc: 0.8088\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1820 - acc: 0.7828 - val_loss: 1.1219 - val_acc: 0.8050\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1807 - acc: 0.7820 - val_loss: 1.0692 - val_acc: 0.8135\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1846 - acc: 0.7798 - val_loss: 1.1188 - val_acc: 0.8091\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1887 - acc: 0.7779 - val_loss: 1.0677 - val_acc: 0.8142\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1825 - acc: 0.7801 - val_loss: 1.0851 - val_acc: 0.8067\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1904 - acc: 0.7770 - val_loss: 1.1704 - val_acc: 0.7871\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1818 - acc: 0.7799 - val_loss: 1.0621 - val_acc: 0.8217\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1814 - acc: 0.7812 - val_loss: 1.1092 - val_acc: 0.7990\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1806 - acc: 0.7798 - val_loss: 1.1073 - val_acc: 0.7963\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1806 - acc: 0.7796 - val_loss: 1.1100 - val_acc: 0.7981\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1768 - acc: 0.7817 - val_loss: 1.0959 - val_acc: 0.8122\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1814 - acc: 0.7801 - val_loss: 1.0673 - val_acc: 0.8128\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1782 - acc: 0.7822 - val_loss: 1.0704 - val_acc: 0.8206\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1841 - acc: 0.7806 - val_loss: 1.0503 - val_acc: 0.8203\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1864 - acc: 0.7785 - val_loss: 1.0818 - val_acc: 0.8108\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1847 - acc: 0.7789 - val_loss: 1.0789 - val_acc: 0.8151\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1844 - acc: 0.7790 - val_loss: 1.0795 - val_acc: 0.8093\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1858 - acc: 0.7763 - val_loss: 1.0749 - val_acc: 0.8228\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1857 - acc: 0.7793 - val_loss: 1.0528 - val_acc: 0.8171\n"
     ]
    }
   ],
   "source": [
    "m12_history = m12_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m12_history.history['val_loss'])\n",
    "tup = ('m12', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19), ('m10', 0.3003294213294983, 21), ('m11', 0.3035426574230194, 36), ('m12', 1.0502544473648072, 195)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m9 is the best model with specification: 3 layers; 50 epochs; 0.2 dropout rate; all else like initial model\n"
     ]
    }
   ],
   "source": [
    "# select the best model\n",
    "best_model_loss_epoch.sort(key=lambda tup: tup[1])\n",
    "best_model, min_loss, num_epoch = best_model_loss_epoch[0]\n",
    "print(\"{} is the best model with specification: {}\".format(best_model, all_models[best_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_model_list = []\n",
    "sorted_valid_loss = []\n",
    "for m, valid_loss, _ in best_model_loss_epoch:\n",
    "    sorted_model_list.append(m)\n",
    "    sorted_valid_loss.append(valid_loss)\n",
    "plt.bar(np.arange(len(sorted_model_list)), sorted_valid_loss, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(sorted_model_list)), sorted_model_list)\n",
    "plt.ylabel('validation loss')\n",
    "plt.title('Validation loss comparison across models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1803 - acc: 0.9394\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1711 - acc: 0.9405\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1654 - acc: 0.9411\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1619 - acc: 0.9421\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1575 - acc: 0.9440\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1539 - acc: 0.9449\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1488 - acc: 0.9452\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1457 - acc: 0.9470\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1437 - acc: 0.9476\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1444 - acc: 0.9474\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1396 - acc: 0.9485\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1387 - acc: 0.9486\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1375 - acc: 0.9493\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1385 - acc: 0.9490\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1329 - acc: 0.9511\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1314 - acc: 0.9523\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1307 - acc: 0.9516\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1281 - acc: 0.9523\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1286 - acc: 0.9526\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1276 - acc: 0.9530\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1267 - acc: 0.9545\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1240 - acc: 0.9550\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1214 - acc: 0.9555\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1192 - acc: 0.9566\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1191 - acc: 0.9557\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1188 - acc: 0.9564\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1171 - acc: 0.9564\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1150 - acc: 0.9573\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1155 - acc: 0.9578\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1168 - acc: 0.9572\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1125 - acc: 0.9582\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1107 - acc: 0.9582\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1142 - acc: 0.9577\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1093 - acc: 0.9596\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1094 - acc: 0.9602\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1076 - acc: 0.9598\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1048 - acc: 0.9606\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1102 - acc: 0.9600\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1076 - acc: 0.9610\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1068 - acc: 0.9622\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1048 - acc: 0.9622\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1059 - acc: 0.9618\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1034 - acc: 0.9622\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1042 - acc: 0.9624\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1038 - acc: 0.9619\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1026 - acc: 0.9626\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1003 - acc: 0.9635\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1002 - acc: 0.9642\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0984 - acc: 0.9647\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1025 - acc: 0.9636\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "final_m9 = m9_model.fit(x_all_train,\n",
    "                        y_all_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5665860232532024, 0.8954]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the best model\n",
    "m9_model.evaluate(x_final_test, y_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ The final model does not generalize well. When evaluated using unseen test data, the accuracy rate significantly declines from around 96% to 89.54% and the loss rate also increases from around 0.11 to 0.57. This might indicate that my final model overfits the training data or the network architecture is not complex enough to handle the data set. Again, the network architecture is as fllows: 3 layers; 50 epochs; 0.2 dropout rate, which is less complex than our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
