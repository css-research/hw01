{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspectives on Computational Research -- HW 01\n",
    "\n",
    "## Author: Sanittawan Tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_all_train, y_all_train), (x_final_test, y_final_test) = fashion_mnist.load_data()\n",
    "\n",
    "# preprocess data to 2D tensors\n",
    "# convert to float and make the values between 0 and 1\n",
    "x_all_train = x_all_train.reshape((60000, 28 * 28))\n",
    "x_all_train = x_all_train.astype('float32') / 255\n",
    "\n",
    "x_final_test = x_final_test.reshape((10000, 28 * 28))\n",
    "x_final_test = x_final_test.astype('float32') / 255\n",
    "\n",
    "y_all_train = keras.utils.to_categorical(y_all_train)\n",
    "y_final_test = keras.utils.to_categorical(y_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x_all_train, y_all_train, \n",
    "                                                      test_size=10000, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, 201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement a series of neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__i. Initial test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "init_model = models.Sequential()\n",
    "init_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "init_model.add(layers.Dense(512, activation='relu'))\n",
    "init_model.add(layers.Dense(512, activation='relu'))\n",
    "init_model.add(layers.Dense(512, activation='relu'))\n",
    "init_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "init_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.8535 - acc: 0.6840 - val_loss: 0.5970 - val_acc: 0.7842\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.5136 - acc: 0.8105 - val_loss: 0.4837 - val_acc: 0.8196\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.4401 - acc: 0.8353 - val_loss: 0.4455 - val_acc: 0.8313\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3887 - acc: 0.8554 - val_loss: 0.3694 - val_acc: 0.8661\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3577 - acc: 0.8671 - val_loss: 0.3846 - val_acc: 0.8558\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3360 - acc: 0.8742 - val_loss: 0.3609 - val_acc: 0.8700\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3132 - acc: 0.8837 - val_loss: 0.3675 - val_acc: 0.8687\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2984 - acc: 0.8885 - val_loss: 0.3569 - val_acc: 0.8694\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2801 - acc: 0.8938 - val_loss: 0.3273 - val_acc: 0.8838\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2696 - acc: 0.8985 - val_loss: 0.5441 - val_acc: 0.8359\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2616 - acc: 0.9012 - val_loss: 0.4002 - val_acc: 0.8660\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2459 - acc: 0.9056 - val_loss: 0.3427 - val_acc: 0.8824\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2371 - acc: 0.9092 - val_loss: 0.3452 - val_acc: 0.8821\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2334 - acc: 0.9106 - val_loss: 0.3606 - val_acc: 0.8783\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2227 - acc: 0.9157 - val_loss: 0.3558 - val_acc: 0.8890\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2138 - acc: 0.9181 - val_loss: 0.3264 - val_acc: 0.8899\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.2117 - acc: 0.9189 - val_loss: 0.3688 - val_acc: 0.8875\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1994 - acc: 0.9239 - val_loss: 0.3490 - val_acc: 0.8932\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1959 - acc: 0.9253 - val_loss: 0.3792 - val_acc: 0.8874\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1914 - acc: 0.9274 - val_loss: 0.4040 - val_acc: 0.8875\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1856 - acc: 0.9282 - val_loss: 0.3463 - val_acc: 0.8929\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1800 - acc: 0.9307 - val_loss: 0.7315 - val_acc: 0.8349\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1812 - acc: 0.9318 - val_loss: 0.3918 - val_acc: 0.8910\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1723 - acc: 0.9343 - val_loss: 0.4091 - val_acc: 0.8906\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1719 - acc: 0.9350 - val_loss: 0.4231 - val_acc: 0.8925\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1644 - acc: 0.9381 - val_loss: 0.4659 - val_acc: 0.8785\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1616 - acc: 0.9388 - val_loss: 0.4937 - val_acc: 0.8794\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1661 - acc: 0.9373 - val_loss: 0.3936 - val_acc: 0.8977\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1595 - acc: 0.9397 - val_loss: 0.4587 - val_acc: 0.8918\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1562 - acc: 0.9417 - val_loss: 0.4543 - val_acc: 0.8862\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1530 - acc: 0.9425 - val_loss: 0.4292 - val_acc: 0.8933\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1532 - acc: 0.9429 - val_loss: 0.3914 - val_acc: 0.8967\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1451 - acc: 0.9441 - val_loss: 0.4907 - val_acc: 0.8755\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1487 - acc: 0.9456 - val_loss: 0.5679 - val_acc: 0.8742\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1495 - acc: 0.9453 - val_loss: 0.4589 - val_acc: 0.8862\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1461 - acc: 0.9466 - val_loss: 0.4340 - val_acc: 0.8998\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1388 - acc: 0.9480 - val_loss: 0.4734 - val_acc: 0.8678\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1381 - acc: 0.9496 - val_loss: 0.4705 - val_acc: 0.8919\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1389 - acc: 0.9492 - val_loss: 0.5110 - val_acc: 0.8893\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1367 - acc: 0.9504 - val_loss: 0.4627 - val_acc: 0.8934\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1331 - acc: 0.9508 - val_loss: 0.4803 - val_acc: 0.8899\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1259 - acc: 0.9540 - val_loss: 0.5520 - val_acc: 0.8819\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1300 - acc: 0.9516 - val_loss: 0.5248 - val_acc: 0.8902\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1327 - acc: 0.9520 - val_loss: 0.5609 - val_acc: 0.8881\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1283 - acc: 0.9534 - val_loss: 0.4716 - val_acc: 0.8919\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1338 - acc: 0.9538 - val_loss: 0.6056 - val_acc: 0.8674\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1315 - acc: 0.9541 - val_loss: 0.4837 - val_acc: 0.8872\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1270 - acc: 0.9551 - val_loss: 0.5676 - val_acc: 0.9003\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1204 - acc: 0.9569 - val_loss: 0.5600 - val_acc: 0.8862\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1260 - acc: 0.9543 - val_loss: 0.5416 - val_acc: 0.8864\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1195 - acc: 0.9562 - val_loss: 0.6516 - val_acc: 0.8838\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1213 - acc: 0.9576 - val_loss: 0.5635 - val_acc: 0.8960\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1205 - acc: 0.9564 - val_loss: 0.4940 - val_acc: 0.9012\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1338 - acc: 0.9563 - val_loss: 0.5224 - val_acc: 0.9005\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1143 - acc: 0.9597 - val_loss: 0.5619 - val_acc: 0.8845\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1155 - acc: 0.9591 - val_loss: 0.7381 - val_acc: 0.8653\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1167 - acc: 0.9596 - val_loss: 0.6669 - val_acc: 0.8811\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1135 - acc: 0.9585 - val_loss: 0.6080 - val_acc: 0.8911\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1194 - acc: 0.9591 - val_loss: 0.5596 - val_acc: 0.8939\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1267 - acc: 0.9602 - val_loss: 0.5236 - val_acc: 0.8964\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1121 - acc: 0.9610 - val_loss: 0.5036 - val_acc: 0.9001\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1103 - acc: 0.9621 - val_loss: 0.5522 - val_acc: 0.8963\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1132 - acc: 0.9623 - val_loss: 0.5977 - val_acc: 0.8959\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1086 - acc: 0.9615 - val_loss: 0.5802 - val_acc: 0.8926\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1086 - acc: 0.9622 - val_loss: 0.5910 - val_acc: 0.8956\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1060 - acc: 0.9625 - val_loss: 0.5334 - val_acc: 0.8986\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1054 - acc: 0.9643 - val_loss: 0.5505 - val_acc: 0.8974\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1097 - acc: 0.9632 - val_loss: 0.6000 - val_acc: 0.8977\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1098 - acc: 0.9634 - val_loss: 0.6011 - val_acc: 0.8978\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1030 - acc: 0.9642 - val_loss: 0.5882 - val_acc: 0.8968\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1105 - acc: 0.9619 - val_loss: 0.5604 - val_acc: 0.8913\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1058 - acc: 0.9642 - val_loss: 0.6502 - val_acc: 0.8808\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1033 - acc: 0.9654 - val_loss: 0.6116 - val_acc: 0.8983\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1099 - acc: 0.9657 - val_loss: 0.5394 - val_acc: 0.8984\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1031 - acc: 0.9654 - val_loss: 0.6035 - val_acc: 0.8938\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1044 - acc: 0.9656 - val_loss: 0.7247 - val_acc: 0.8890\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0986 - acc: 0.9661 - val_loss: 0.6511 - val_acc: 0.8875\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1112 - acc: 0.9655 - val_loss: 0.4824 - val_acc: 0.8989\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0955 - acc: 0.9673 - val_loss: 0.5944 - val_acc: 0.8987\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0933 - acc: 0.9677 - val_loss: 0.6490 - val_acc: 0.9003\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0949 - acc: 0.9689 - val_loss: 0.6483 - val_acc: 0.8973\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0980 - acc: 0.9677 - val_loss: 0.5708 - val_acc: 0.8890\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0955 - acc: 0.9695 - val_loss: 0.5828 - val_acc: 0.9023\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1010 - acc: 0.9670 - val_loss: 0.5454 - val_acc: 0.9043\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0939 - acc: 0.9698 - val_loss: 0.6761 - val_acc: 0.8962\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0943 - acc: 0.9697 - val_loss: 0.7223 - val_acc: 0.8930\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.1005 - acc: 0.9687 - val_loss: 0.7279 - val_acc: 0.8980\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0971 - acc: 0.9699 - val_loss: 0.6011 - val_acc: 0.8949\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0826 - acc: 0.9720 - val_loss: 0.7721 - val_acc: 0.8875\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0898 - acc: 0.9708 - val_loss: 0.6794 - val_acc: 0.8913\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0926 - acc: 0.9703 - val_loss: 0.7169 - val_acc: 0.8960\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0919 - acc: 0.9701 - val_loss: 0.7893 - val_acc: 0.8682\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0885 - acc: 0.9725 - val_loss: 0.6844 - val_acc: 0.8972\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0960 - acc: 0.9699 - val_loss: 0.6263 - val_acc: 0.8934\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0875 - acc: 0.9719 - val_loss: 0.6811 - val_acc: 0.8991\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0910 - acc: 0.9714 - val_loss: 0.7174 - val_acc: 0.8961\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0879 - acc: 0.9728 - val_loss: 0.7887 - val_acc: 0.8980\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0938 - acc: 0.9710 - val_loss: 0.8039 - val_acc: 0.8843\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0871 - acc: 0.9728 - val_loss: 0.6409 - val_acc: 0.8928\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0880 - acc: 0.9705 - val_loss: 0.5596 - val_acc: 0.8988\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0832 - acc: 0.9746 - val_loss: 0.7893 - val_acc: 0.8769\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0895 - acc: 0.9723 - val_loss: 0.6081 - val_acc: 0.9028\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0802 - acc: 0.9752 - val_loss: 0.6610 - val_acc: 0.9002\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0875 - acc: 0.9744 - val_loss: 0.8712 - val_acc: 0.8823\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0872 - acc: 0.9740 - val_loss: 0.6672 - val_acc: 0.9033\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0879 - acc: 0.9750 - val_loss: 0.6958 - val_acc: 0.8920\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0821 - acc: 0.9751 - val_loss: 0.6281 - val_acc: 0.9054\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0836 - acc: 0.9742 - val_loss: 0.6289 - val_acc: 0.8970\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0873 - acc: 0.9746 - val_loss: 0.7196 - val_acc: 0.8965\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0803 - acc: 0.9758 - val_loss: 0.6187 - val_acc: 0.8974\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0848 - acc: 0.9742 - val_loss: 0.7061 - val_acc: 0.8978\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0790 - acc: 0.9753 - val_loss: 0.6198 - val_acc: 0.9003\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0752 - acc: 0.9762 - val_loss: 0.7894 - val_acc: 0.8799\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0949 - acc: 0.9737 - val_loss: 0.6425 - val_acc: 0.8984\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0757 - acc: 0.9776 - val_loss: 0.6312 - val_acc: 0.9007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0773 - acc: 0.9770 - val_loss: 0.6901 - val_acc: 0.8970\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0835 - acc: 0.9752 - val_loss: 0.6427 - val_acc: 0.8922\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0742 - acc: 0.9783 - val_loss: 0.8119 - val_acc: 0.8811\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0903 - acc: 0.9749 - val_loss: 0.6618 - val_acc: 0.8946\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0845 - acc: 0.9765 - val_loss: 0.7146 - val_acc: 0.8910\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0797 - acc: 0.9773 - val_loss: 0.7067 - val_acc: 0.8909\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0824 - acc: 0.9763 - val_loss: 0.6652 - val_acc: 0.8994\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.6497 - val_acc: 0.8989\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0765 - acc: 0.9780 - val_loss: 0.7944 - val_acc: 0.8989\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0777 - acc: 0.9775 - val_loss: 0.7748 - val_acc: 0.8949\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0792 - acc: 0.9771 - val_loss: 0.6978 - val_acc: 0.8987\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0749 - acc: 0.9786 - val_loss: 0.7342 - val_acc: 0.9013\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0737 - acc: 0.9783 - val_loss: 0.7538 - val_acc: 0.8966\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0730 - acc: 0.9779 - val_loss: 0.7267 - val_acc: 0.8986\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0751 - acc: 0.9780 - val_loss: 0.7094 - val_acc: 0.8994\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0863 - acc: 0.9773 - val_loss: 0.6845 - val_acc: 0.8955\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0700 - acc: 0.9792 - val_loss: 0.6459 - val_acc: 0.8975\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0710 - acc: 0.9802 - val_loss: 0.7723 - val_acc: 0.8967\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0754 - acc: 0.9785 - val_loss: 0.6992 - val_acc: 0.8745\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0747 - acc: 0.9793 - val_loss: 0.6851 - val_acc: 0.8966\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0682 - acc: 0.9795 - val_loss: 0.8098 - val_acc: 0.8853\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0662 - acc: 0.9786 - val_loss: 0.7583 - val_acc: 0.9000\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0684 - acc: 0.9787 - val_loss: 0.7713 - val_acc: 0.8982\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0698 - acc: 0.9808 - val_loss: 0.7948 - val_acc: 0.9019\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0671 - acc: 0.9811 - val_loss: 0.8314 - val_acc: 0.8790\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0733 - acc: 0.9788 - val_loss: 0.7823 - val_acc: 0.8877\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0785 - acc: 0.9792 - val_loss: 0.6970 - val_acc: 0.8988\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0682 - acc: 0.9819 - val_loss: 0.7168 - val_acc: 0.8939\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0779 - acc: 0.9795 - val_loss: 0.9068 - val_acc: 0.8789\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0705 - acc: 0.9796 - val_loss: 0.7508 - val_acc: 0.8950\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0764 - acc: 0.9788 - val_loss: 0.9705 - val_acc: 0.8757\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0706 - acc: 0.9805 - val_loss: 1.0158 - val_acc: 0.8916\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0684 - acc: 0.9810 - val_loss: 0.8286 - val_acc: 0.8976\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0728 - acc: 0.9797 - val_loss: 0.8500 - val_acc: 0.8878\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0729 - acc: 0.9812 - val_loss: 0.6688 - val_acc: 0.9043\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0609 - acc: 0.9832 - val_loss: 1.0010 - val_acc: 0.8913\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0744 - acc: 0.9805 - val_loss: 0.7923 - val_acc: 0.8845\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0680 - acc: 0.9822 - val_loss: 0.8246 - val_acc: 0.9007\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0717 - acc: 0.9819 - val_loss: 0.6989 - val_acc: 0.8970\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0579 - acc: 0.9831 - val_loss: 0.9370 - val_acc: 0.8917\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0631 - acc: 0.9819 - val_loss: 0.8687 - val_acc: 0.8908\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0691 - acc: 0.9807 - val_loss: 0.7627 - val_acc: 0.9013\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0725 - acc: 0.9809 - val_loss: 0.8242 - val_acc: 0.8904\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0830 - acc: 0.9790 - val_loss: 0.6939 - val_acc: 0.8925\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0674 - acc: 0.9825 - val_loss: 0.7370 - val_acc: 0.9022\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0697 - acc: 0.9808 - val_loss: 0.7859 - val_acc: 0.8954\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0577 - acc: 0.9834 - val_loss: 0.9887 - val_acc: 0.8794\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0633 - acc: 0.9828 - val_loss: 0.8424 - val_acc: 0.8929\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0638 - acc: 0.9822 - val_loss: 0.8313 - val_acc: 0.8934\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.0734 - acc: 0.9808 - val_loss: 0.7721 - val_acc: 0.8983\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0675 - acc: 0.9824 - val_loss: 1.1697 - val_acc: 0.8642\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0700 - acc: 0.9832 - val_loss: 0.8245 - val_acc: 0.8990\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0766 - acc: 0.9808 - val_loss: 0.7395 - val_acc: 0.8951\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0710 - acc: 0.9835 - val_loss: 0.9871 - val_acc: 0.8891\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0664 - acc: 0.9815 - val_loss: 0.7828 - val_acc: 0.9015\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0818 - acc: 0.9810 - val_loss: 0.8083 - val_acc: 0.8981\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0707 - acc: 0.9832 - val_loss: 0.7582 - val_acc: 0.9009\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0644 - acc: 0.9819 - val_loss: 0.7723 - val_acc: 0.8952\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0649 - acc: 0.9830 - val_loss: 0.7958 - val_acc: 0.8987\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0700 - acc: 0.9829 - val_loss: 0.8863 - val_acc: 0.8957\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0605 - acc: 0.9842 - val_loss: 0.9219 - val_acc: 0.8959\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0839 - acc: 0.9803 - val_loss: 0.7744 - val_acc: 0.8993\n",
      "Epoch 178/200\n",
      " 8704/50000 [====>.........................] - ETA: 0s - loss: 0.0761 - acc: 0.9840"
     ]
    }
   ],
   "source": [
    "init_history = init_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_history_dict = init_history.history\n",
    "init_val_acc = init_history_dict['val_acc'] \n",
    "init_val_loss = init_history_dict['val_loss']\n",
    "max_accu_epoch = init_val_acc.index(max(init_val_acc))\n",
    "min_loss_epoch = init_val_loss.index(min(init_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, init_val_acc, label='validation accuracy', marker='.')\n",
    "plt.plot(epochs, init_val_loss, label='validation loss', marker='.')\n",
    "plt.axvline(x=max_accu_epoch + 1, linestyle='--', color='k', label='max accuracy')\n",
    "plt.axvline(x=min_loss_epoch + 1 , linestyle='--', color='r', label='min loss')\n",
    "plt.ylabel('Validation set accuracy and loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Initial model validation accuracy and loss rates')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ From eyeball inspection, it seems that the model performance starts to degrade around the 7th epoch based on the validation loss. In terms of validation set accuracy, the model does not seem to perform much better as it reaches around the 7th epoch. However, the maximum accuracy rate was achieved closer to the 200th epoch. It is notable that the shape of the validation loss curve is very jumpy. This could be the result of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ii. implement dropout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_model = models.Sequential()\n",
    "drop_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(512, activation='relu'))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(512, activation='relu'))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(512, activation='relu'))\n",
    "drop_model.add(layers.Dropout(0.5))\n",
    "drop_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "drop_model.compile(optimizer='rmsprop',\n",
    "                   loss=losses.categorical_crossentropy,\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_history = drop_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_history_dict = drop_history.history\n",
    "drop_val_loss = drop_history_dict['val_loss']\n",
    "min_loss_epoch = drop_val_loss.index(min(drop_val_loss))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, init_val_loss, label='initial validation loss', marker='.')\n",
    "plt.plot(epochs, drop_val_loss, label='dropout validation loss', marker='v')\n",
    "plt.axvline(x=min_loss_epoch + 1, linestyle='--', color='r', label='dropout min loss')\n",
    "plt.ylabel('Validation set loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Initial model vs model with dropout layers')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ Based on eyeball inspection, it is obvious that the dropout model is more resistant to overfitting as the loss rates are mostly lower than the initial test model. However, one similarity between the two curves is the U shape. Initially, the models' losses decrease dramatically. Nevertheless, as we train the model for more epochs, the validation losses start to increase or plateau. This also signals potential overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__iii. Weight regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__L1 regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model = models.Sequential()\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu', input_shape=(28 * 28,)))\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "l1_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 14.6055 - acc: 0.5410 - val_loss: 4.2310 - val_acc: 0.5521\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 3.0245 - acc: 0.6547 - val_loss: 2.4671 - val_acc: 0.6561\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 2.2099 - acc: 0.6978 - val_loss: 2.0057 - val_acc: 0.7125\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.9220 - acc: 0.7267 - val_loss: 1.8770 - val_acc: 0.7309\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.7633 - acc: 0.7440 - val_loss: 1.6946 - val_acc: 0.7482\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.6541 - acc: 0.7611 - val_loss: 1.6213 - val_acc: 0.7736\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.5934 - acc: 0.7682 - val_loss: 1.5844 - val_acc: 0.7649\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.5417 - acc: 0.7792 - val_loss: 1.5527 - val_acc: 0.7571\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.5031 - acc: 0.7816 - val_loss: 1.4944 - val_acc: 0.7788\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.4690 - acc: 0.7874 - val_loss: 1.4604 - val_acc: 0.7863\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.4482 - acc: 0.7926 - val_loss: 1.4336 - val_acc: 0.7950\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.4183 - acc: 0.7981 - val_loss: 1.4213 - val_acc: 0.7945\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3957 - acc: 0.8024 - val_loss: 1.4581 - val_acc: 0.7833\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3807 - acc: 0.8033 - val_loss: 1.3706 - val_acc: 0.8072\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3652 - acc: 0.8096 - val_loss: 1.3581 - val_acc: 0.8098\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3556 - acc: 0.8096 - val_loss: 1.3728 - val_acc: 0.8052\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3492 - acc: 0.8092 - val_loss: 1.3908 - val_acc: 0.7905\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3393 - acc: 0.8126 - val_loss: 1.3493 - val_acc: 0.8083\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3296 - acc: 0.8157 - val_loss: 1.3708 - val_acc: 0.7968\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3275 - acc: 0.8148 - val_loss: 1.3170 - val_acc: 0.8180\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3180 - acc: 0.8160 - val_loss: 1.3148 - val_acc: 0.8169\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3121 - acc: 0.8174 - val_loss: 1.3856 - val_acc: 0.7899\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3068 - acc: 0.8194 - val_loss: 1.3232 - val_acc: 0.8109\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.3005 - acc: 0.8195 - val_loss: 1.3423 - val_acc: 0.8036\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2942 - acc: 0.8214 - val_loss: 1.3021 - val_acc: 0.8163\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2894 - acc: 0.8214 - val_loss: 1.3080 - val_acc: 0.8158\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2820 - acc: 0.8231 - val_loss: 1.3074 - val_acc: 0.8153\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2803 - acc: 0.8244 - val_loss: 1.2799 - val_acc: 0.8242\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2768 - acc: 0.8240 - val_loss: 1.3001 - val_acc: 0.8151\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2716 - acc: 0.8249 - val_loss: 1.3325 - val_acc: 0.8055\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2682 - acc: 0.8256 - val_loss: 1.3328 - val_acc: 0.8010\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2656 - acc: 0.8256 - val_loss: 1.2738 - val_acc: 0.8215\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2620 - acc: 0.8252 - val_loss: 1.2763 - val_acc: 0.8221\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2583 - acc: 0.8274 - val_loss: 1.2900 - val_acc: 0.8091\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2519 - acc: 0.8288 - val_loss: 1.2873 - val_acc: 0.8109\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2519 - acc: 0.8282 - val_loss: 1.2579 - val_acc: 0.8258\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2485 - acc: 0.8285 - val_loss: 1.2925 - val_acc: 0.8144\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2462 - acc: 0.8290 - val_loss: 1.2982 - val_acc: 0.8061\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2438 - acc: 0.8285 - val_loss: 1.2543 - val_acc: 0.8235\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2402 - acc: 0.8303 - val_loss: 1.2647 - val_acc: 0.8204\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2356 - acc: 0.8322 - val_loss: 1.2472 - val_acc: 0.8237\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2350 - acc: 0.8308 - val_loss: 1.2392 - val_acc: 0.8268\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2334 - acc: 0.8291 - val_loss: 1.2323 - val_acc: 0.8312\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2290 - acc: 0.8325 - val_loss: 1.2686 - val_acc: 0.8149\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2275 - acc: 0.8323 - val_loss: 1.2539 - val_acc: 0.8175\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2240 - acc: 0.8337 - val_loss: 1.2705 - val_acc: 0.8121\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2231 - acc: 0.8319 - val_loss: 1.2793 - val_acc: 0.8137\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2222 - acc: 0.8328 - val_loss: 1.2582 - val_acc: 0.8213\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2236 - acc: 0.8323 - val_loss: 1.2255 - val_acc: 0.8293\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2199 - acc: 0.8332 - val_loss: 1.2846 - val_acc: 0.8141\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2197 - acc: 0.8325 - val_loss: 1.2174 - val_acc: 0.8334\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2168 - acc: 0.8331 - val_loss: 1.2213 - val_acc: 0.8306\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2159 - acc: 0.8348 - val_loss: 1.2396 - val_acc: 0.8257\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2138 - acc: 0.8335 - val_loss: 1.2494 - val_acc: 0.8195\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2120 - acc: 0.8340 - val_loss: 1.3004 - val_acc: 0.7935\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2135 - acc: 0.8343 - val_loss: 1.2544 - val_acc: 0.8174\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2086 - acc: 0.8352 - val_loss: 1.2325 - val_acc: 0.8233\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2055 - acc: 0.8350 - val_loss: 1.2635 - val_acc: 0.8093\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2079 - acc: 0.8346 - val_loss: 1.3055 - val_acc: 0.7997\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2092 - acc: 0.8343 - val_loss: 1.2647 - val_acc: 0.8132\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2021 - acc: 0.8361 - val_loss: 1.2716 - val_acc: 0.8038\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2034 - acc: 0.8337 - val_loss: 1.2129 - val_acc: 0.8310\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2009 - acc: 0.8368 - val_loss: 1.2542 - val_acc: 0.8166\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1996 - acc: 0.8362 - val_loss: 1.2642 - val_acc: 0.8108\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.2003 - acc: 0.8352 - val_loss: 1.2356 - val_acc: 0.8203\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1998 - acc: 0.8364 - val_loss: 1.2233 - val_acc: 0.8277\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1981 - acc: 0.8341 - val_loss: 1.2557 - val_acc: 0.8109\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1965 - acc: 0.8365 - val_loss: 1.2511 - val_acc: 0.8066\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1975 - acc: 0.8360 - val_loss: 1.2440 - val_acc: 0.8185\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1959 - acc: 0.8356 - val_loss: 1.2347 - val_acc: 0.8251\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1964 - acc: 0.8367 - val_loss: 1.2141 - val_acc: 0.8285\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1938 - acc: 0.8364 - val_loss: 1.2173 - val_acc: 0.8297\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1905 - acc: 0.8386 - val_loss: 1.2187 - val_acc: 0.8258\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1904 - acc: 0.8372 - val_loss: 1.2672 - val_acc: 0.8121\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1893 - acc: 0.8383 - val_loss: 1.2415 - val_acc: 0.8177\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1904 - acc: 0.8372 - val_loss: 1.2440 - val_acc: 0.8109\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1913 - acc: 0.8372 - val_loss: 1.2419 - val_acc: 0.8122\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1862 - acc: 0.8397 - val_loss: 1.2141 - val_acc: 0.8264\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1849 - acc: 0.8384 - val_loss: 1.2293 - val_acc: 0.8253\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1850 - acc: 0.8384 - val_loss: 1.2474 - val_acc: 0.8177\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1838 - acc: 0.8400 - val_loss: 1.1915 - val_acc: 0.8355\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1870 - acc: 0.8360 - val_loss: 1.2190 - val_acc: 0.8259\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1816 - acc: 0.8393 - val_loss: 1.1993 - val_acc: 0.8333\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1823 - acc: 0.8378 - val_loss: 1.2006 - val_acc: 0.8315\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1825 - acc: 0.8376 - val_loss: 1.2103 - val_acc: 0.8230\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1801 - acc: 0.8381 - val_loss: 1.2506 - val_acc: 0.8060\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1817 - acc: 0.8378 - val_loss: 1.2039 - val_acc: 0.8295\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1806 - acc: 0.8390 - val_loss: 1.2289 - val_acc: 0.8192\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1791 - acc: 0.8388 - val_loss: 1.1892 - val_acc: 0.8328\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1790 - acc: 0.8394 - val_loss: 1.1949 - val_acc: 0.8328\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1792 - acc: 0.8381 - val_loss: 1.2174 - val_acc: 0.8245\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1757 - acc: 0.8399 - val_loss: 1.1772 - val_acc: 0.8390\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1782 - acc: 0.8387 - val_loss: 1.2090 - val_acc: 0.8274\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1769 - acc: 0.8380 - val_loss: 1.3014 - val_acc: 0.7999\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1765 - acc: 0.8382 - val_loss: 1.2207 - val_acc: 0.8234\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1766 - acc: 0.8383 - val_loss: 1.1785 - val_acc: 0.8372\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1739 - acc: 0.8402 - val_loss: 1.1882 - val_acc: 0.8367\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1756 - acc: 0.8376 - val_loss: 1.1783 - val_acc: 0.8393\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1738 - acc: 0.8395 - val_loss: 1.2031 - val_acc: 0.8277\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1745 - acc: 0.8397 - val_loss: 1.1961 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1728 - acc: 0.8409 - val_loss: 1.2628 - val_acc: 0.8035\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1715 - acc: 0.8403 - val_loss: 1.2673 - val_acc: 0.8072\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1733 - acc: 0.8388 - val_loss: 1.2161 - val_acc: 0.8206\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1717 - acc: 0.8404 - val_loss: 1.2192 - val_acc: 0.8257\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1684 - acc: 0.8401 - val_loss: 1.2671 - val_acc: 0.7963\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1702 - acc: 0.8401 - val_loss: 1.1779 - val_acc: 0.8372\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1737 - acc: 0.8374 - val_loss: 1.2321 - val_acc: 0.8168\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1713 - acc: 0.8404 - val_loss: 1.1876 - val_acc: 0.8347\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1661 - acc: 0.8415 - val_loss: 1.1807 - val_acc: 0.8337\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1640 - acc: 0.8419 - val_loss: 1.2682 - val_acc: 0.8088\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1701 - acc: 0.8387 - val_loss: 1.2041 - val_acc: 0.8274\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1652 - acc: 0.8420 - val_loss: 1.2265 - val_acc: 0.8226\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1661 - acc: 0.8403 - val_loss: 1.2139 - val_acc: 0.8223\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1641 - acc: 0.8425 - val_loss: 1.2188 - val_acc: 0.8189\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1642 - acc: 0.8432 - val_loss: 1.1898 - val_acc: 0.8308\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1631 - acc: 0.8423 - val_loss: 1.2006 - val_acc: 0.8278\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1657 - acc: 0.8409 - val_loss: 1.2198 - val_acc: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1656 - acc: 0.8406 - val_loss: 1.1736 - val_acc: 0.8373\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1639 - acc: 0.8399 - val_loss: 1.1971 - val_acc: 0.8273\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1619 - acc: 0.8417 - val_loss: 1.2253 - val_acc: 0.8207\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1634 - acc: 0.8421 - val_loss: 1.1883 - val_acc: 0.8328\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1631 - acc: 0.8410 - val_loss: 1.1921 - val_acc: 0.8269\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1628 - acc: 0.8416 - val_loss: 1.2574 - val_acc: 0.8149\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1627 - acc: 0.8404 - val_loss: 1.1944 - val_acc: 0.8286\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1617 - acc: 0.8414 - val_loss: 1.2658 - val_acc: 0.8070\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1622 - acc: 0.8403 - val_loss: 1.1755 - val_acc: 0.8385\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1608 - acc: 0.8411 - val_loss: 1.1878 - val_acc: 0.8287\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1624 - acc: 0.8422 - val_loss: 1.1705 - val_acc: 0.8362\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1599 - acc: 0.8415 - val_loss: 1.1772 - val_acc: 0.8344\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1591 - acc: 0.8411 - val_loss: 1.2234 - val_acc: 0.8212\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1585 - acc: 0.8432 - val_loss: 1.1861 - val_acc: 0.8350\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1605 - acc: 0.8423 - val_loss: 1.2627 - val_acc: 0.7940\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1605 - acc: 0.8403 - val_loss: 1.1852 - val_acc: 0.8327\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1604 - acc: 0.8417 - val_loss: 1.1690 - val_acc: 0.8398\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1587 - acc: 0.8414 - val_loss: 1.1895 - val_acc: 0.8290\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1565 - acc: 0.8436 - val_loss: 1.1755 - val_acc: 0.8349\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1561 - acc: 0.8429 - val_loss: 1.1872 - val_acc: 0.8327\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1593 - acc: 0.8421 - val_loss: 1.1822 - val_acc: 0.8338\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1537 - acc: 0.8427 - val_loss: 1.1972 - val_acc: 0.8273\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1570 - acc: 0.8422 - val_loss: 1.1813 - val_acc: 0.8334\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1550 - acc: 0.8433 - val_loss: 1.1737 - val_acc: 0.8336\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1570 - acc: 0.8416 - val_loss: 1.1952 - val_acc: 0.8296\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1581 - acc: 0.8414 - val_loss: 1.2035 - val_acc: 0.8229\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1568 - acc: 0.8435 - val_loss: 1.1834 - val_acc: 0.8303\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1553 - acc: 0.8432 - val_loss: 1.1784 - val_acc: 0.8303\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1529 - acc: 0.8426 - val_loss: 1.2104 - val_acc: 0.8179\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1536 - acc: 0.8443 - val_loss: 1.1853 - val_acc: 0.8298\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1532 - acc: 0.8438 - val_loss: 1.1875 - val_acc: 0.8303\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1521 - acc: 0.8422 - val_loss: 1.2262 - val_acc: 0.8099\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1540 - acc: 0.8425 - val_loss: 1.2669 - val_acc: 0.8079\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1529 - acc: 0.8422 - val_loss: 1.2080 - val_acc: 0.8158\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1516 - acc: 0.8438 - val_loss: 1.2777 - val_acc: 0.8003\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1559 - acc: 0.8413 - val_loss: 1.1978 - val_acc: 0.8209\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1503 - acc: 0.8437 - val_loss: 1.2418 - val_acc: 0.8026\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1532 - acc: 0.8434 - val_loss: 1.1566 - val_acc: 0.8417\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1535 - acc: 0.8433 - val_loss: 1.1630 - val_acc: 0.8390\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1544 - acc: 0.8418 - val_loss: 1.2479 - val_acc: 0.8034\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1508 - acc: 0.8434 - val_loss: 1.1944 - val_acc: 0.8264\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1514 - acc: 0.8433 - val_loss: 1.2005 - val_acc: 0.8206\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1506 - acc: 0.8437 - val_loss: 1.1729 - val_acc: 0.8338\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1533 - acc: 0.8414 - val_loss: 1.1640 - val_acc: 0.8377\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1510 - acc: 0.8418 - val_loss: 1.1880 - val_acc: 0.8319\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1505 - acc: 0.8431 - val_loss: 1.1702 - val_acc: 0.8384\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1494 - acc: 0.8433 - val_loss: 1.1900 - val_acc: 0.8267\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1516 - acc: 0.8426 - val_loss: 1.2123 - val_acc: 0.8165\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1503 - acc: 0.8428 - val_loss: 1.2443 - val_acc: 0.8137\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1508 - acc: 0.8415 - val_loss: 1.2041 - val_acc: 0.8264\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1486 - acc: 0.8429 - val_loss: 1.2087 - val_acc: 0.8193\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1505 - acc: 0.8409 - val_loss: 1.1908 - val_acc: 0.8258\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1498 - acc: 0.8436 - val_loss: 1.1662 - val_acc: 0.8384\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1480 - acc: 0.8453 - val_loss: 1.2158 - val_acc: 0.8150\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1475 - acc: 0.8441 - val_loss: 1.1798 - val_acc: 0.8314\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1476 - acc: 0.8449 - val_loss: 1.1839 - val_acc: 0.8265\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1500 - acc: 0.8433 - val_loss: 1.2079 - val_acc: 0.8256\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1457 - acc: 0.8447 - val_loss: 1.1675 - val_acc: 0.8374\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1476 - acc: 0.8428 - val_loss: 1.1765 - val_acc: 0.8350\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1477 - acc: 0.8439 - val_loss: 1.1550 - val_acc: 0.8400\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1480 - acc: 0.8440 - val_loss: 1.2170 - val_acc: 0.8185\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1459 - acc: 0.8449 - val_loss: 1.1962 - val_acc: 0.8241\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1472 - acc: 0.8455 - val_loss: 1.1933 - val_acc: 0.8272\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1443 - acc: 0.8445 - val_loss: 1.1794 - val_acc: 0.8324\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1470 - acc: 0.8435 - val_loss: 1.1711 - val_acc: 0.8335\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1437 - acc: 0.8454 - val_loss: 1.1621 - val_acc: 0.8380\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1445 - acc: 0.8442 - val_loss: 1.1599 - val_acc: 0.8379\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1421 - acc: 0.8457 - val_loss: 1.2122 - val_acc: 0.8223\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1474 - acc: 0.8430 - val_loss: 1.2028 - val_acc: 0.8261\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1423 - acc: 0.8450 - val_loss: 1.1839 - val_acc: 0.8257\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1452 - acc: 0.8433 - val_loss: 1.1552 - val_acc: 0.8412\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1407 - acc: 0.8468 - val_loss: 1.4026 - val_acc: 0.7478\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1454 - acc: 0.8445 - val_loss: 1.1841 - val_acc: 0.8305\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1406 - acc: 0.8456 - val_loss: 1.1779 - val_acc: 0.8335\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1435 - acc: 0.8456 - val_loss: 1.1714 - val_acc: 0.8348\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1437 - acc: 0.8434 - val_loss: 1.2121 - val_acc: 0.8220\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1424 - acc: 0.8456 - val_loss: 1.1609 - val_acc: 0.8368\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1413 - acc: 0.8459 - val_loss: 1.2991 - val_acc: 0.7972\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1448 - acc: 0.8429 - val_loss: 1.2566 - val_acc: 0.8104\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1410 - acc: 0.8447 - val_loss: 1.2084 - val_acc: 0.8241\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1400 - acc: 0.8456 - val_loss: 1.1667 - val_acc: 0.8347\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1417 - acc: 0.8444 - val_loss: 1.1763 - val_acc: 0.8313\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1428 - acc: 0.8446 - val_loss: 1.1660 - val_acc: 0.8353\n"
     ]
    }
   ],
   "source": [
    "l1_history = l1_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__L2 Regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu', input_shape=(28 * 28,)))\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation='relu'))\n",
    "l2_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "l2_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 2.1480 - acc: 0.6742 - val_loss: 1.5078 - val_acc: 0.7431\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 1.1808 - acc: 0.7924 - val_loss: 1.0462 - val_acc: 0.7896\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.8801 - acc: 0.8142 - val_loss: 0.8234 - val_acc: 0.8151\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.7490 - acc: 0.8278 - val_loss: 0.7166 - val_acc: 0.8252\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.6699 - acc: 0.8350 - val_loss: 0.6593 - val_acc: 0.8331\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.6230 - acc: 0.8414 - val_loss: 0.7079 - val_acc: 0.8206\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5859 - acc: 0.8469 - val_loss: 0.5701 - val_acc: 0.8506\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5536 - acc: 0.8528 - val_loss: 0.5758 - val_acc: 0.8463\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5332 - acc: 0.8551 - val_loss: 0.5426 - val_acc: 0.8537\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.5169 - acc: 0.8590 - val_loss: 0.4854 - val_acc: 0.8678\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4998 - acc: 0.8636 - val_loss: 0.6316 - val_acc: 0.8197\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4944 - acc: 0.8643 - val_loss: 0.5493 - val_acc: 0.8433\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4828 - acc: 0.8660 - val_loss: 0.5550 - val_acc: 0.8425\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4673 - acc: 0.8710 - val_loss: 0.5017 - val_acc: 0.8569\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4628 - acc: 0.8723 - val_loss: 0.4737 - val_acc: 0.8647\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4579 - acc: 0.8737 - val_loss: 0.5146 - val_acc: 0.8444\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4498 - acc: 0.8742 - val_loss: 0.4879 - val_acc: 0.8600\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4430 - acc: 0.8770 - val_loss: 0.4613 - val_acc: 0.8685\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4363 - acc: 0.8786 - val_loss: 0.4972 - val_acc: 0.8553\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4357 - acc: 0.8800 - val_loss: 0.4495 - val_acc: 0.8676\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4266 - acc: 0.8805 - val_loss: 0.5393 - val_acc: 0.8424\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4238 - acc: 0.8813 - val_loss: 0.4968 - val_acc: 0.8593\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4193 - acc: 0.8824 - val_loss: 0.4651 - val_acc: 0.8637\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4186 - acc: 0.8830 - val_loss: 0.4422 - val_acc: 0.8705\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4143 - acc: 0.8842 - val_loss: 0.4584 - val_acc: 0.8651\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4107 - acc: 0.8855 - val_loss: 0.4248 - val_acc: 0.8832\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4094 - acc: 0.8867 - val_loss: 0.4653 - val_acc: 0.8670\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4068 - acc: 0.8857 - val_loss: 0.4543 - val_acc: 0.8679\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.4013 - acc: 0.8873 - val_loss: 0.5118 - val_acc: 0.8428\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3981 - acc: 0.8899 - val_loss: 0.4451 - val_acc: 0.8695\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3943 - acc: 0.8911 - val_loss: 0.4657 - val_acc: 0.8672\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3969 - acc: 0.8888 - val_loss: 0.4347 - val_acc: 0.8764\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3950 - acc: 0.8892 - val_loss: 0.4772 - val_acc: 0.8598\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3905 - acc: 0.8919 - val_loss: 0.4368 - val_acc: 0.8706\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3857 - acc: 0.8929 - val_loss: 0.4565 - val_acc: 0.8685\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3864 - acc: 0.8921 - val_loss: 0.4686 - val_acc: 0.8629\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3852 - acc: 0.8930 - val_loss: 0.4997 - val_acc: 0.8440\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3840 - acc: 0.8931 - val_loss: 0.4528 - val_acc: 0.8662\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3818 - acc: 0.8931 - val_loss: 0.5099 - val_acc: 0.8496\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3792 - acc: 0.8947 - val_loss: 0.4417 - val_acc: 0.8749\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3789 - acc: 0.8969 - val_loss: 0.5532 - val_acc: 0.8425\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3776 - acc: 0.8951 - val_loss: 0.4462 - val_acc: 0.8719\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3782 - acc: 0.8953 - val_loss: 0.4543 - val_acc: 0.8683\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3725 - acc: 0.8960 - val_loss: 0.4204 - val_acc: 0.8812\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3749 - acc: 0.8967 - val_loss: 0.4185 - val_acc: 0.8802\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3718 - acc: 0.8978 - val_loss: 0.4632 - val_acc: 0.8580\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3717 - acc: 0.8980 - val_loss: 0.4688 - val_acc: 0.8616\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3707 - acc: 0.8981 - val_loss: 0.4159 - val_acc: 0.8809\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3709 - acc: 0.8972 - val_loss: 0.4321 - val_acc: 0.8790\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3679 - acc: 0.8979 - val_loss: 0.4695 - val_acc: 0.8658\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3670 - acc: 0.8992 - val_loss: 0.4451 - val_acc: 0.8713\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3620 - acc: 0.9005 - val_loss: 0.4327 - val_acc: 0.8765\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3662 - acc: 0.8996 - val_loss: 0.4679 - val_acc: 0.8574\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3591 - acc: 0.9019 - val_loss: 0.4171 - val_acc: 0.8801\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3635 - acc: 0.9005 - val_loss: 0.4599 - val_acc: 0.8627\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3609 - acc: 0.9010 - val_loss: 0.4044 - val_acc: 0.8879\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3607 - acc: 0.9005 - val_loss: 0.4119 - val_acc: 0.8838\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3608 - acc: 0.9024 - val_loss: 0.4365 - val_acc: 0.8762\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3592 - acc: 0.9019 - val_loss: 0.4369 - val_acc: 0.8750\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3567 - acc: 0.9034 - val_loss: 0.4411 - val_acc: 0.8712\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3565 - acc: 0.9023 - val_loss: 0.4555 - val_acc: 0.8665\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3556 - acc: 0.9039 - val_loss: 0.4376 - val_acc: 0.8727\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3549 - acc: 0.9037 - val_loss: 0.5352 - val_acc: 0.8446\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3553 - acc: 0.9032 - val_loss: 0.4437 - val_acc: 0.8747\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3555 - acc: 0.9022 - val_loss: 0.4200 - val_acc: 0.8782\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3529 - acc: 0.9026 - val_loss: 0.4231 - val_acc: 0.8802\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3538 - acc: 0.9043 - val_loss: 0.4365 - val_acc: 0.8771\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3490 - acc: 0.9070 - val_loss: 0.4653 - val_acc: 0.8632\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3506 - acc: 0.9036 - val_loss: 0.4168 - val_acc: 0.8814\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3502 - acc: 0.9059 - val_loss: 0.4077 - val_acc: 0.8867\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3507 - acc: 0.9049 - val_loss: 0.4015 - val_acc: 0.8878\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3514 - acc: 0.9035 - val_loss: 0.4652 - val_acc: 0.8672\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3475 - acc: 0.9062 - val_loss: 0.4303 - val_acc: 0.8730\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3470 - acc: 0.9064 - val_loss: 0.4043 - val_acc: 0.8845\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3486 - acc: 0.9056 - val_loss: 0.4687 - val_acc: 0.8656\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3466 - acc: 0.9066 - val_loss: 0.4241 - val_acc: 0.8806\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3447 - acc: 0.9069 - val_loss: 0.4173 - val_acc: 0.8803\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3461 - acc: 0.9072 - val_loss: 0.4269 - val_acc: 0.8764\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3437 - acc: 0.9069 - val_loss: 0.5975 - val_acc: 0.8334\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3441 - acc: 0.9067 - val_loss: 0.4060 - val_acc: 0.8866\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3398 - acc: 0.9089 - val_loss: 0.4334 - val_acc: 0.8783\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3431 - acc: 0.9071 - val_loss: 0.3982 - val_acc: 0.8899\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3447 - acc: 0.9074 - val_loss: 0.4662 - val_acc: 0.8666\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3430 - acc: 0.9081 - val_loss: 0.4318 - val_acc: 0.8753\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3386 - acc: 0.9099 - val_loss: 0.4253 - val_acc: 0.8833\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3393 - acc: 0.9091 - val_loss: 0.4605 - val_acc: 0.8708\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3422 - acc: 0.9083 - val_loss: 0.5057 - val_acc: 0.8596\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3379 - acc: 0.9102 - val_loss: 0.4128 - val_acc: 0.8822\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3412 - acc: 0.9082 - val_loss: 0.4428 - val_acc: 0.8740\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3364 - acc: 0.9097 - val_loss: 0.4347 - val_acc: 0.8746\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3383 - acc: 0.9091 - val_loss: 0.4388 - val_acc: 0.8710\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3414 - acc: 0.9082 - val_loss: 0.4206 - val_acc: 0.8793\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3395 - acc: 0.9091 - val_loss: 0.4165 - val_acc: 0.8816\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3360 - acc: 0.9098 - val_loss: 0.6708 - val_acc: 0.8215\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3373 - acc: 0.9092 - val_loss: 0.4307 - val_acc: 0.8775\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3359 - acc: 0.9108 - val_loss: 0.3909 - val_acc: 0.8913\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3325 - acc: 0.9106 - val_loss: 0.4520 - val_acc: 0.8690\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3369 - acc: 0.9100 - val_loss: 0.3941 - val_acc: 0.8899\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3334 - acc: 0.9103 - val_loss: 0.4476 - val_acc: 0.8730\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3326 - acc: 0.9117 - val_loss: 0.5043 - val_acc: 0.8577\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3342 - acc: 0.9113 - val_loss: 0.4076 - val_acc: 0.8866\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3341 - acc: 0.9118 - val_loss: 0.4215 - val_acc: 0.8792\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3322 - acc: 0.9108 - val_loss: 0.4411 - val_acc: 0.8718\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3349 - acc: 0.9110 - val_loss: 0.4079 - val_acc: 0.8813\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3322 - acc: 0.9119 - val_loss: 0.4259 - val_acc: 0.8813\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3319 - acc: 0.9124 - val_loss: 0.3998 - val_acc: 0.8897\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3318 - acc: 0.9110 - val_loss: 0.4616 - val_acc: 0.8692\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3305 - acc: 0.9119 - val_loss: 0.4074 - val_acc: 0.8874\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3306 - acc: 0.9129 - val_loss: 0.5062 - val_acc: 0.8386\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3286 - acc: 0.9128 - val_loss: 0.4566 - val_acc: 0.8740\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3296 - acc: 0.9131 - val_loss: 0.4071 - val_acc: 0.8887\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3289 - acc: 0.9122 - val_loss: 0.4702 - val_acc: 0.8648\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3302 - acc: 0.9132 - val_loss: 0.4445 - val_acc: 0.8762\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3278 - acc: 0.9134 - val_loss: 0.4213 - val_acc: 0.8802\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3275 - acc: 0.9137 - val_loss: 0.4679 - val_acc: 0.8649\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3252 - acc: 0.9137 - val_loss: 0.4502 - val_acc: 0.8742\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3271 - acc: 0.9136 - val_loss: 0.4323 - val_acc: 0.8793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3293 - acc: 0.9132 - val_loss: 0.4446 - val_acc: 0.8749\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3282 - acc: 0.9127 - val_loss: 0.4384 - val_acc: 0.8812\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3289 - acc: 0.9127 - val_loss: 0.4440 - val_acc: 0.8772\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3269 - acc: 0.9136 - val_loss: 0.4840 - val_acc: 0.8556\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3267 - acc: 0.9139 - val_loss: 0.4448 - val_acc: 0.8732\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3288 - acc: 0.9131 - val_loss: 0.4343 - val_acc: 0.8744\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3292 - acc: 0.9136 - val_loss: 0.4148 - val_acc: 0.8869\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3269 - acc: 0.9142 - val_loss: 0.4559 - val_acc: 0.8697\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3248 - acc: 0.9139 - val_loss: 0.4686 - val_acc: 0.8705\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3247 - acc: 0.9152 - val_loss: 0.4476 - val_acc: 0.8803\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3296 - acc: 0.9127 - val_loss: 0.5337 - val_acc: 0.8527\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3246 - acc: 0.9139 - val_loss: 0.4470 - val_acc: 0.8754\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3301 - acc: 0.9129 - val_loss: 0.4748 - val_acc: 0.8682\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3224 - acc: 0.9149 - val_loss: 0.4749 - val_acc: 0.8663\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3230 - acc: 0.9153 - val_loss: 0.4497 - val_acc: 0.8777\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3237 - acc: 0.9152 - val_loss: 0.4231 - val_acc: 0.8787\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3270 - acc: 0.9132 - val_loss: 0.4404 - val_acc: 0.8749\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3268 - acc: 0.9148 - val_loss: 0.4339 - val_acc: 0.8776\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3244 - acc: 0.9152 - val_loss: 0.4481 - val_acc: 0.8669\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3244 - acc: 0.9152 - val_loss: 0.4254 - val_acc: 0.8802\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3217 - acc: 0.9151 - val_loss: 0.4825 - val_acc: 0.8638\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3262 - acc: 0.9142 - val_loss: 0.4167 - val_acc: 0.8841\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3229 - acc: 0.9149 - val_loss: 0.4637 - val_acc: 0.8634\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3243 - acc: 0.9141 - val_loss: 0.4119 - val_acc: 0.8879\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3226 - acc: 0.9150 - val_loss: 0.4237 - val_acc: 0.8837\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.3173 - acc: 0.9173 - val_loss: 0.4262 - val_acc: 0.8824\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3218 - acc: 0.9169 - val_loss: 0.4599 - val_acc: 0.8718\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3213 - acc: 0.9156 - val_loss: 0.4572 - val_acc: 0.8689\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3245 - acc: 0.9143 - val_loss: 0.4492 - val_acc: 0.8794\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3184 - acc: 0.9181 - val_loss: 0.4494 - val_acc: 0.8771\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3218 - acc: 0.9143 - val_loss: 0.4670 - val_acc: 0.8720\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3213 - acc: 0.9171 - val_loss: 0.4223 - val_acc: 0.8883\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3201 - acc: 0.9167 - val_loss: 0.4425 - val_acc: 0.8764\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3184 - acc: 0.9163 - val_loss: 0.4769 - val_acc: 0.8754\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3216 - acc: 0.9151 - val_loss: 0.4328 - val_acc: 0.8784\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3213 - acc: 0.9151 - val_loss: 0.4788 - val_acc: 0.8669\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3179 - acc: 0.9170 - val_loss: 0.4224 - val_acc: 0.8810\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3210 - acc: 0.9154 - val_loss: 0.4076 - val_acc: 0.8892\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3197 - acc: 0.9160 - val_loss: 0.4219 - val_acc: 0.8835\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3159 - acc: 0.9196 - val_loss: 0.4432 - val_acc: 0.8798\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3238 - acc: 0.9146 - val_loss: 0.4684 - val_acc: 0.8660\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3205 - acc: 0.9169 - val_loss: 0.4329 - val_acc: 0.8793\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3227 - acc: 0.9164 - val_loss: 0.4443 - val_acc: 0.8747\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3184 - acc: 0.9177 - val_loss: 0.4821 - val_acc: 0.8639\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3168 - acc: 0.9183 - val_loss: 0.4426 - val_acc: 0.8734\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3180 - acc: 0.9170 - val_loss: 0.4804 - val_acc: 0.8670\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3210 - acc: 0.9158 - val_loss: 0.4025 - val_acc: 0.8923\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3173 - acc: 0.9179 - val_loss: 0.5277 - val_acc: 0.8521\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3194 - acc: 0.9179 - val_loss: 0.4334 - val_acc: 0.8770\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3162 - acc: 0.9192 - val_loss: 0.4159 - val_acc: 0.8861\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3149 - acc: 0.9189 - val_loss: 0.4160 - val_acc: 0.8899\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3201 - acc: 0.9174 - val_loss: 0.4246 - val_acc: 0.8858\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3202 - acc: 0.9181 - val_loss: 0.5162 - val_acc: 0.8526\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3159 - acc: 0.9185 - val_loss: 0.4255 - val_acc: 0.8846\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3171 - acc: 0.9174 - val_loss: 0.4352 - val_acc: 0.8769\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3177 - acc: 0.9186 - val_loss: 0.4351 - val_acc: 0.8836\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3196 - acc: 0.9180 - val_loss: 0.4297 - val_acc: 0.8826\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3170 - acc: 0.9179 - val_loss: 0.5150 - val_acc: 0.8623\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3157 - acc: 0.9187 - val_loss: 0.5033 - val_acc: 0.8591\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3198 - acc: 0.9184 - val_loss: 0.4149 - val_acc: 0.8867\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3173 - acc: 0.9195 - val_loss: 0.4340 - val_acc: 0.8797\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3150 - acc: 0.9186 - val_loss: 0.4815 - val_acc: 0.8642\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3180 - acc: 0.9188 - val_loss: 0.4297 - val_acc: 0.8858\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3183 - acc: 0.9169 - val_loss: 0.4522 - val_acc: 0.8730\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3186 - acc: 0.9184 - val_loss: 0.4813 - val_acc: 0.8717\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3129 - acc: 0.9199 - val_loss: 0.4771 - val_acc: 0.8649\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3182 - acc: 0.9169 - val_loss: 0.4099 - val_acc: 0.8883\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3155 - acc: 0.9195 - val_loss: 0.4439 - val_acc: 0.8784\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3160 - acc: 0.9188 - val_loss: 0.4833 - val_acc: 0.8653\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3166 - acc: 0.9172 - val_loss: 0.4624 - val_acc: 0.8732\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3147 - acc: 0.9182 - val_loss: 0.4821 - val_acc: 0.8669\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3147 - acc: 0.9184 - val_loss: 0.4854 - val_acc: 0.8639\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3172 - acc: 0.9194 - val_loss: 0.4441 - val_acc: 0.8769\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3230 - acc: 0.9148 - val_loss: 0.4235 - val_acc: 0.8873\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3090 - acc: 0.9205 - val_loss: 0.4701 - val_acc: 0.8734\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3121 - acc: 0.9202 - val_loss: 0.4653 - val_acc: 0.8720\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3151 - acc: 0.9187 - val_loss: 0.4454 - val_acc: 0.8745\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3122 - acc: 0.9187 - val_loss: 0.4338 - val_acc: 0.8832\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3130 - acc: 0.9184 - val_loss: 0.5209 - val_acc: 0.8523\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3159 - acc: 0.9190 - val_loss: 0.4274 - val_acc: 0.8819\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3110 - acc: 0.9207 - val_loss: 0.4367 - val_acc: 0.8762\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3140 - acc: 0.9194 - val_loss: 0.5313 - val_acc: 0.8591\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.3147 - acc: 0.9184 - val_loss: 0.5191 - val_acc: 0.8618\n"
     ]
    }
   ],
   "source": [
    "l2_history = l2_model.fit(X_train,\n",
    "                          y_train,\n",
    "                          epochs=200,\n",
    "                          batch_size=512,\n",
    "                          validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_history_dict = l1_history.history\n",
    "l1_val_loss = l1_history_dict['val_loss']\n",
    "l2_history_dict = l2_history.history\n",
    "l2_val_loss = l2_history_dict['val_loss']\n",
    "min_loss_epoch_l1 = l1_val_loss.index(min(l1_val_loss))\n",
    "min_loss_epoch_l2 = l2_val_loss.index(min(l2_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, init_val_loss, label='initial validation loss', marker='.')\n",
    "plt.plot(epochs, drop_val_loss, label='dropout validation loss', marker='v')\n",
    "plt.plot(epochs, l1_val_loss, label='with L1 validation loss', marker='<')\n",
    "plt.plot(epochs, l2_val_loss, label='with L2 validation loss', marker='>')\n",
    "plt.axvline(x=min_loss_epoch_l1 + 1, linestyle='--', color='r', label='L1 min loss')\n",
    "plt.axvline(x=min_loss_epoch_l2 + 1, linestyle='--', color='b', label='L2 min loss')\n",
    "plt.ylabel('Validation set loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Initial vs Dropout vs L1 vs L2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ Based on visual inspection, the dropout model seems to perform best because its validation loss rates seem to be lower than that of other models. It is quite surprising to me that the L1 weight regularization model performs worst. However, the four validation loss curves still present the distinct U shape, though some are more difficult to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__iv. estimate alternative models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {\n",
    "   'm1': '3 layers; 50 epochs; all else like initial model',\n",
    "   'm2': '6 layers; 50 epochs; all else like initial model',\n",
    "   'm3': '256 hidden units; 50 epochs; all else like initial model',\n",
    "   'm4': '64 hidden units; 50 epochs; all else like initial model',\n",
    "   'm5': '16 hidden units; 50 epochs; all else like initial model',\n",
    "   'm6': '3 layers; 256 hidden units; 50 epochs; all else like initial model',\n",
    "   'm7': '128 batch size; all else like initial model',\n",
    "   'm8': '3 layers; 50 epochs; 0.001 L1; all else like initial model',\n",
    "   'm9': '3 layers; 50 epochs; 0.2 dropout rate; all else like initial model',\n",
    "   'm10': '3 layers; 50 epochs; 0.3 dropout rate; all else like initial model',\n",
    "   'm11': '3 layers; 50 epochs; 0.5 dropout rate; all else like initial model',\n",
    "   'm12': '3 layers; 50 epochs; 0.5 dropout rate; 0.001 L1; all else like initial model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_epoch(val_loss_list):\n",
    "    '''\n",
    "    Find number of epoch that yields the lowest validation loss.\n",
    "    '''\n",
    "    min_loss = min(val_loss_list)\n",
    "    best_num_epoch = val_loss_list.index(min_loss)\n",
    "    return (min_loss, best_num_epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_loss_epoch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_model = models.Sequential()\n",
    "m1_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m1_model.add(layers.Dense(512, activation='relu'))\n",
    "m1_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m1_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 21us/step - loss: 0.7219 - acc: 0.7384 - val_loss: 0.5936 - val_acc: 0.7893\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.4618 - acc: 0.8308 - val_loss: 0.4142 - val_acc: 0.8479\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3948 - acc: 0.8538 - val_loss: 0.4657 - val_acc: 0.8335\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3609 - acc: 0.8650 - val_loss: 0.3844 - val_acc: 0.8569\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3306 - acc: 0.8767 - val_loss: 0.4188 - val_acc: 0.8435\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.3082 - acc: 0.8841 - val_loss: 0.4542 - val_acc: 0.8477\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2921 - acc: 0.8897 - val_loss: 0.3409 - val_acc: 0.8726\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2766 - acc: 0.8949 - val_loss: 0.3313 - val_acc: 0.8772\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2599 - acc: 0.9016 - val_loss: 0.3291 - val_acc: 0.8818\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2487 - acc: 0.9045 - val_loss: 0.4394 - val_acc: 0.8478\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2391 - acc: 0.9086 - val_loss: 0.3816 - val_acc: 0.8664\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2260 - acc: 0.9134 - val_loss: 0.3202 - val_acc: 0.8854\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2190 - acc: 0.9164 - val_loss: 0.4070 - val_acc: 0.8546\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.2120 - acc: 0.9188 - val_loss: 0.3269 - val_acc: 0.8887\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1982 - acc: 0.9249 - val_loss: 0.3668 - val_acc: 0.8782\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1952 - acc: 0.9259 - val_loss: 0.3023 - val_acc: 0.8976\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1865 - acc: 0.9282 - val_loss: 0.3612 - val_acc: 0.8797\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1804 - acc: 0.9313 - val_loss: 0.3651 - val_acc: 0.8824\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1727 - acc: 0.9344 - val_loss: 0.3107 - val_acc: 0.8959\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1638 - acc: 0.9364 - val_loss: 0.3467 - val_acc: 0.8854\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1638 - acc: 0.9383 - val_loss: 0.3471 - val_acc: 0.8909\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1543 - acc: 0.9415 - val_loss: 0.4036 - val_acc: 0.8803\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1494 - acc: 0.9429 - val_loss: 0.3436 - val_acc: 0.8915\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1444 - acc: 0.9445 - val_loss: 0.3989 - val_acc: 0.8866\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1427 - acc: 0.9461 - val_loss: 0.4341 - val_acc: 0.8601\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1358 - acc: 0.9469 - val_loss: 0.3754 - val_acc: 0.8928\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1290 - acc: 0.9509 - val_loss: 0.4166 - val_acc: 0.8913\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1291 - acc: 0.9508 - val_loss: 0.3769 - val_acc: 0.8973\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1224 - acc: 0.9532 - val_loss: 0.4083 - val_acc: 0.8898\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1194 - acc: 0.9527 - val_loss: 0.3803 - val_acc: 0.8940\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1165 - acc: 0.9558 - val_loss: 0.3818 - val_acc: 0.8937\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1135 - acc: 0.9561 - val_loss: 0.3865 - val_acc: 0.8996\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1107 - acc: 0.9593 - val_loss: 0.4146 - val_acc: 0.8923\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1061 - acc: 0.9598 - val_loss: 0.4582 - val_acc: 0.8806\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1013 - acc: 0.9608 - val_loss: 0.5169 - val_acc: 0.8820\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.1022 - acc: 0.9622 - val_loss: 0.4158 - val_acc: 0.8999\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0977 - acc: 0.9635 - val_loss: 0.4106 - val_acc: 0.9003\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0907 - acc: 0.9652 - val_loss: 0.5240 - val_acc: 0.8898\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0917 - acc: 0.9647 - val_loss: 0.5197 - val_acc: 0.8868\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0881 - acc: 0.9661 - val_loss: 0.4802 - val_acc: 0.8956\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0896 - acc: 0.9656 - val_loss: 0.4401 - val_acc: 0.8976\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0864 - acc: 0.9667 - val_loss: 0.5585 - val_acc: 0.8900\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0840 - acc: 0.9672 - val_loss: 0.6674 - val_acc: 0.8766\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0796 - acc: 0.9695 - val_loss: 0.5349 - val_acc: 0.8870\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0849 - acc: 0.9688 - val_loss: 0.4469 - val_acc: 0.9023\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0759 - acc: 0.9716 - val_loss: 0.5312 - val_acc: 0.8981\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0756 - acc: 0.9717 - val_loss: 0.5046 - val_acc: 0.8896\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0748 - acc: 0.9718 - val_loss: 0.4903 - val_acc: 0.8987\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0696 - acc: 0.9734 - val_loss: 0.5256 - val_acc: 0.8952\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0767 - acc: 0.9723 - val_loss: 0.5126 - val_acc: 0.8999\n"
     ]
    }
   ],
   "source": [
    "m1_history = m1_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m1_history.history['val_loss'])\n",
    "tup = ('m1', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_model = models.Sequential()\n",
    "m2_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(512, activation='relu'))\n",
    "m2_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m2_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.9563 - acc: 0.6453 - val_loss: 0.5561 - val_acc: 0.7898\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.5462 - acc: 0.7977 - val_loss: 0.7164 - val_acc: 0.7348\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.4613 - acc: 0.8278 - val_loss: 0.3916 - val_acc: 0.8594\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.4134 - acc: 0.8482 - val_loss: 0.5741 - val_acc: 0.7829\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3762 - acc: 0.8610 - val_loss: 0.4315 - val_acc: 0.8447\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3480 - acc: 0.8704 - val_loss: 0.3947 - val_acc: 0.8506\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3293 - acc: 0.8773 - val_loss: 0.3320 - val_acc: 0.8748\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.3141 - acc: 0.8830 - val_loss: 0.3567 - val_acc: 0.8675\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2962 - acc: 0.8887 - val_loss: 0.3653 - val_acc: 0.8643\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2809 - acc: 0.8944 - val_loss: 0.3445 - val_acc: 0.8721\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2700 - acc: 0.8994 - val_loss: 0.3499 - val_acc: 0.8753\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2593 - acc: 0.9023 - val_loss: 0.3525 - val_acc: 0.8735\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2482 - acc: 0.9054 - val_loss: 0.3582 - val_acc: 0.8757\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2435 - acc: 0.9082 - val_loss: 0.4859 - val_acc: 0.8409\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2353 - acc: 0.9100 - val_loss: 0.3819 - val_acc: 0.8811\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2260 - acc: 0.9148 - val_loss: 0.3705 - val_acc: 0.8740\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2216 - acc: 0.9166 - val_loss: 0.3432 - val_acc: 0.8899\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.2148 - acc: 0.9176 - val_loss: 0.3488 - val_acc: 0.8917\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.2129 - acc: 0.9196 - val_loss: 0.4108 - val_acc: 0.8696\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.2034 - acc: 0.9223 - val_loss: 0.4180 - val_acc: 0.8822\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.2004 - acc: 0.9233 - val_loss: 0.4371 - val_acc: 0.8589\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.1961 - acc: 0.9256 - val_loss: 0.3429 - val_acc: 0.8988\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 18us/step - loss: 0.1969 - acc: 0.9260 - val_loss: 0.3275 - val_acc: 0.8931\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1872 - acc: 0.9285 - val_loss: 0.4700 - val_acc: 0.8705\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1926 - acc: 0.9295 - val_loss: 0.3621 - val_acc: 0.8970\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1822 - acc: 0.9305 - val_loss: 0.4568 - val_acc: 0.8884\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1826 - acc: 0.9307 - val_loss: 0.3992 - val_acc: 0.8984\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1780 - acc: 0.9331 - val_loss: 0.4041 - val_acc: 0.8815\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1795 - acc: 0.9342 - val_loss: 0.4129 - val_acc: 0.8940\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1685 - acc: 0.9377 - val_loss: 0.4508 - val_acc: 0.8726\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1688 - acc: 0.9375 - val_loss: 0.4239 - val_acc: 0.8981\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1669 - acc: 0.9379 - val_loss: 0.3968 - val_acc: 0.8944\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1680 - acc: 0.9379 - val_loss: 0.6102 - val_acc: 0.8573\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1643 - acc: 0.9392 - val_loss: 0.4532 - val_acc: 0.8922\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1638 - acc: 0.9392 - val_loss: 0.7216 - val_acc: 0.8664\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1738 - acc: 0.9381 - val_loss: 0.3766 - val_acc: 0.8950\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1556 - acc: 0.9427 - val_loss: 0.5315 - val_acc: 0.8749\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1594 - acc: 0.9412 - val_loss: 0.7130 - val_acc: 0.8777\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1655 - acc: 0.9439 - val_loss: 0.4649 - val_acc: 0.8815\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1572 - acc: 0.9443 - val_loss: 0.5296 - val_acc: 0.8797\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1541 - acc: 0.9445 - val_loss: 0.4349 - val_acc: 0.9001\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1498 - acc: 0.9459 - val_loss: 0.4493 - val_acc: 0.8954\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1522 - acc: 0.9472 - val_loss: 0.5069 - val_acc: 0.8614\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1469 - acc: 0.9479 - val_loss: 0.4900 - val_acc: 0.8870\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1559 - acc: 0.9478 - val_loss: 0.4277 - val_acc: 0.8960\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1455 - acc: 0.9474 - val_loss: 0.4214 - val_acc: 0.8865\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1411 - acc: 0.9494 - val_loss: 0.3926 - val_acc: 0.8882\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1381 - acc: 0.9491 - val_loss: 0.5387 - val_acc: 0.8914\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1441 - acc: 0.9483 - val_loss: 0.4263 - val_acc: 0.9006\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 17us/step - loss: 0.1363 - acc: 0.9518 - val_loss: 0.5020 - val_acc: 0.8975\n"
     ]
    }
   ],
   "source": [
    "m2_history = m2_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m2_history.history['val_loss'])\n",
    "tup = ('m2', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_model = models.Sequential()\n",
    "m3_model.add(layers.Dense(256, activation='relu', input_shape=(28 * 28,)))\n",
    "m3_model.add(layers.Dense(256, activation='relu'))\n",
    "m3_model.add(layers.Dense(256, activation='relu'))\n",
    "m3_model.add(layers.Dense(256, activation='relu'))\n",
    "m3_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m3_model.compile(optimizer='rmsprop',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.8060 - acc: 0.6983 - val_loss: 0.6078 - val_acc: 0.7655\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.5033 - acc: 0.8126 - val_loss: 0.6147 - val_acc: 0.7764\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.4271 - acc: 0.8410 - val_loss: 0.4823 - val_acc: 0.8236\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3887 - acc: 0.8543 - val_loss: 0.4331 - val_acc: 0.8370\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3548 - acc: 0.8677 - val_loss: 0.3707 - val_acc: 0.8621\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3297 - acc: 0.8743 - val_loss: 0.4142 - val_acc: 0.8472\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.3105 - acc: 0.8835 - val_loss: 0.3614 - val_acc: 0.8673\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2931 - acc: 0.8897 - val_loss: 0.3499 - val_acc: 0.8665\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2851 - acc: 0.8920 - val_loss: 0.3581 - val_acc: 0.8698\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2708 - acc: 0.8970 - val_loss: 0.3340 - val_acc: 0.8773\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2589 - acc: 0.9022 - val_loss: 0.3369 - val_acc: 0.8769\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2458 - acc: 0.9058 - val_loss: 0.3319 - val_acc: 0.8771\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2397 - acc: 0.9072 - val_loss: 0.3445 - val_acc: 0.8818\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2278 - acc: 0.9130 - val_loss: 0.3219 - val_acc: 0.8886\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2216 - acc: 0.9134 - val_loss: 0.3650 - val_acc: 0.8783\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2152 - acc: 0.9161 - val_loss: 0.3336 - val_acc: 0.8880\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2055 - acc: 0.9205 - val_loss: 0.3568 - val_acc: 0.8810\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.2017 - acc: 0.9220 - val_loss: 0.3454 - val_acc: 0.8788\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1919 - acc: 0.9252 - val_loss: 0.3462 - val_acc: 0.8819\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1845 - acc: 0.9277 - val_loss: 0.3609 - val_acc: 0.8867\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1774 - acc: 0.9306 - val_loss: 0.4181 - val_acc: 0.8806\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1793 - acc: 0.9308 - val_loss: 0.3213 - val_acc: 0.8892\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1691 - acc: 0.9345 - val_loss: 0.3559 - val_acc: 0.8892\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1625 - acc: 0.9359 - val_loss: 0.3659 - val_acc: 0.8888\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1604 - acc: 0.9379 - val_loss: 0.4075 - val_acc: 0.8831\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1569 - acc: 0.9395 - val_loss: 0.3796 - val_acc: 0.8946\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1515 - acc: 0.9406 - val_loss: 0.4151 - val_acc: 0.8886\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1478 - acc: 0.9418 - val_loss: 0.4354 - val_acc: 0.8761\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1436 - acc: 0.9438 - val_loss: 0.4282 - val_acc: 0.8941\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1398 - acc: 0.9446 - val_loss: 0.4134 - val_acc: 0.8904\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1330 - acc: 0.9480 - val_loss: 0.4394 - val_acc: 0.8902\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1336 - acc: 0.9489 - val_loss: 0.4411 - val_acc: 0.8694\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1297 - acc: 0.9497 - val_loss: 0.3912 - val_acc: 0.8939\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1252 - acc: 0.9519 - val_loss: 0.3959 - val_acc: 0.8905\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1184 - acc: 0.9531 - val_loss: 0.4730 - val_acc: 0.8903\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1190 - acc: 0.9543 - val_loss: 0.4585 - val_acc: 0.8939\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1171 - acc: 0.9549 - val_loss: 0.4626 - val_acc: 0.8887\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1139 - acc: 0.9555 - val_loss: 0.4717 - val_acc: 0.8850\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1101 - acc: 0.9560 - val_loss: 0.4906 - val_acc: 0.8873\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1104 - acc: 0.9578 - val_loss: 0.4811 - val_acc: 0.8932\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1035 - acc: 0.9598 - val_loss: 0.5425 - val_acc: 0.8697\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1022 - acc: 0.9594 - val_loss: 0.4819 - val_acc: 0.8912\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.1002 - acc: 0.9617 - val_loss: 0.4957 - val_acc: 0.8959\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0993 - acc: 0.9626 - val_loss: 0.5578 - val_acc: 0.8884\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0956 - acc: 0.9633 - val_loss: 0.5450 - val_acc: 0.8827\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0946 - acc: 0.9640 - val_loss: 0.5375 - val_acc: 0.8885\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0925 - acc: 0.9642 - val_loss: 0.5113 - val_acc: 0.8956\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0898 - acc: 0.9661 - val_loss: 0.6237 - val_acc: 0.8929\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0888 - acc: 0.9657 - val_loss: 0.6247 - val_acc: 0.8933\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0881 - acc: 0.9664 - val_loss: 0.5723 - val_acc: 0.8921\n"
     ]
    }
   ],
   "source": [
    "m3_history = m3_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m3_history.history['val_loss'])\n",
    "tup = ('m3', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. model 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_model = models.Sequential()\n",
    "m4_model.add(layers.Dense(64, activation='relu', input_shape=(28 * 28,)))\n",
    "m4_model.add(layers.Dense(64, activation='relu'))\n",
    "m4_model.add(layers.Dense(64, activation='relu'))\n",
    "m4_model.add(layers.Dense(64, activation='relu'))\n",
    "m4_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m4_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 23us/step - loss: 0.9261 - acc: 0.6657 - val_loss: 0.6246 - val_acc: 0.7662\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.5588 - acc: 0.7966 - val_loss: 0.5060 - val_acc: 0.8263\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.4857 - acc: 0.8255 - val_loss: 0.4922 - val_acc: 0.8217\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.4419 - acc: 0.8401 - val_loss: 0.4309 - val_acc: 0.8414\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.4135 - acc: 0.8484 - val_loss: 0.5364 - val_acc: 0.8059\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3901 - acc: 0.8575 - val_loss: 0.4538 - val_acc: 0.8289\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3719 - acc: 0.8631 - val_loss: 0.3853 - val_acc: 0.8599\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3561 - acc: 0.8686 - val_loss: 0.3766 - val_acc: 0.8571\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3438 - acc: 0.8725 - val_loss: 0.3837 - val_acc: 0.8553\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3308 - acc: 0.8777 - val_loss: 0.3848 - val_acc: 0.8543\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3231 - acc: 0.8809 - val_loss: 0.3861 - val_acc: 0.8507\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3128 - acc: 0.8821 - val_loss: 0.3638 - val_acc: 0.8688\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.3050 - acc: 0.8858 - val_loss: 0.3447 - val_acc: 0.8690\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2988 - acc: 0.8877 - val_loss: 0.3574 - val_acc: 0.8658\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2930 - acc: 0.8914 - val_loss: 0.3947 - val_acc: 0.8515\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2847 - acc: 0.8930 - val_loss: 0.3538 - val_acc: 0.8633\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2808 - acc: 0.8950 - val_loss: 0.3413 - val_acc: 0.8724\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2737 - acc: 0.8973 - val_loss: 0.3566 - val_acc: 0.8687\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2688 - acc: 0.8988 - val_loss: 0.3420 - val_acc: 0.8764\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2615 - acc: 0.9022 - val_loss: 0.3366 - val_acc: 0.8710\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2583 - acc: 0.9035 - val_loss: 0.3260 - val_acc: 0.8777\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2546 - acc: 0.9042 - val_loss: 0.3333 - val_acc: 0.8796\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2470 - acc: 0.9068 - val_loss: 0.3982 - val_acc: 0.8594\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2448 - acc: 0.9070 - val_loss: 0.4007 - val_acc: 0.8528\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2418 - acc: 0.9096 - val_loss: 0.3435 - val_acc: 0.8747\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2384 - acc: 0.9100 - val_loss: 0.3503 - val_acc: 0.8767\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2312 - acc: 0.9134 - val_loss: 0.3470 - val_acc: 0.8791\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2289 - acc: 0.9129 - val_loss: 0.3346 - val_acc: 0.8828\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2257 - acc: 0.9143 - val_loss: 0.3395 - val_acc: 0.8772\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2213 - acc: 0.9175 - val_loss: 0.3382 - val_acc: 0.8827\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2182 - acc: 0.9184 - val_loss: 0.3564 - val_acc: 0.8802\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2145 - acc: 0.9186 - val_loss: 0.3720 - val_acc: 0.8791\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2121 - acc: 0.9181 - val_loss: 0.3542 - val_acc: 0.8832\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2064 - acc: 0.9220 - val_loss: 0.3373 - val_acc: 0.8822\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2084 - acc: 0.9217 - val_loss: 0.3467 - val_acc: 0.8806\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.2029 - acc: 0.9233 - val_loss: 0.3411 - val_acc: 0.8795\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1998 - acc: 0.9242 - val_loss: 0.3462 - val_acc: 0.8782\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1972 - acc: 0.9260 - val_loss: 0.3659 - val_acc: 0.8786\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1947 - acc: 0.9247 - val_loss: 0.3370 - val_acc: 0.8887\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 0s 10us/step - loss: 0.1906 - acc: 0.9276 - val_loss: 0.3818 - val_acc: 0.8781\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1862 - acc: 0.9289 - val_loss: 0.3594 - val_acc: 0.8846\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1841 - acc: 0.9306 - val_loss: 0.3808 - val_acc: 0.8791\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1850 - acc: 0.9292 - val_loss: 0.3481 - val_acc: 0.8824\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1821 - acc: 0.9303 - val_loss: 0.3627 - val_acc: 0.8777\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1772 - acc: 0.9331 - val_loss: 0.3589 - val_acc: 0.8777\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1771 - acc: 0.9318 - val_loss: 0.3615 - val_acc: 0.8846\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1733 - acc: 0.9344 - val_loss: 0.3680 - val_acc: 0.8798\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1703 - acc: 0.9354 - val_loss: 0.4329 - val_acc: 0.8655\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1704 - acc: 0.9348 - val_loss: 0.3527 - val_acc: 0.8863\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 10us/step - loss: 0.1659 - acc: 0.9366 - val_loss: 0.3829 - val_acc: 0.8841\n"
     ]
    }
   ],
   "source": [
    "m4_history = m4_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m4_history.history['val_loss'])\n",
    "tup = ('m4', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. model 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_model = models.Sequential()\n",
    "m5_model.add(layers.Dense(16, activation='relu', input_shape=(28 * 28,)))\n",
    "m5_model.add(layers.Dense(16, activation='relu'))\n",
    "m5_model.add(layers.Dense(16, activation='relu'))\n",
    "m5_model.add(layers.Dense(16, activation='relu'))\n",
    "m5_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m5_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 0.0729 - acc: 0.9846 - val_loss: 0.9496 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 16us/step - loss: 0.0568 - acc: 0.9868 - val_loss: 0.9095 - val_acc: 0.8973\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0553 - acc: 0.9856 - val_loss: 0.9049 - val_acc: 0.8985\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0638 - acc: 0.9849 - val_loss: 0.8479 - val_acc: 0.8977\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9861 - val_loss: 0.8433 - val_acc: 0.8936\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0556 - acc: 0.9866 - val_loss: 0.7711 - val_acc: 0.8921\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0573 - acc: 0.9876 - val_loss: 0.8463 - val_acc: 0.8946\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0510 - acc: 0.9870 - val_loss: 0.9319 - val_acc: 0.8904\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0699 - acc: 0.9857 - val_loss: 0.7972 - val_acc: 0.9037\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0541 - acc: 0.9873 - val_loss: 0.8245 - val_acc: 0.8998\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0548 - acc: 0.9881 - val_loss: 0.8221 - val_acc: 0.8950\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0562 - acc: 0.9863 - val_loss: 0.9467 - val_acc: 0.8968\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0510 - acc: 0.9875 - val_loss: 0.9477 - val_acc: 0.8932\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0800 - acc: 0.9835 - val_loss: 0.8654 - val_acc: 0.8975\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0532 - acc: 0.9877 - val_loss: 0.9771 - val_acc: 0.8785\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0539 - acc: 0.9866 - val_loss: 0.8814 - val_acc: 0.9019\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0484 - acc: 0.9883 - val_loss: 1.0617 - val_acc: 0.8931\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0743 - acc: 0.9850 - val_loss: 0.8041 - val_acc: 0.8974\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0494 - acc: 0.9884 - val_loss: 0.8662 - val_acc: 0.8993\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0679 - acc: 0.9865 - val_loss: 0.8708 - val_acc: 0.8977\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0574 - acc: 0.9872 - val_loss: 0.9909 - val_acc: 0.8786\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0559 - acc: 0.9876 - val_loss: 1.0061 - val_acc: 0.8946\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0609 - acc: 0.9864 - val_loss: 0.9879 - val_acc: 0.8981\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0564 - acc: 0.9869 - val_loss: 0.9428 - val_acc: 0.8830\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0614 - acc: 0.9864 - val_loss: 0.9171 - val_acc: 0.8954\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0672 - acc: 0.9855 - val_loss: 0.7766 - val_acc: 0.8963\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9878 - val_loss: 0.9837 - val_acc: 0.8925\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0661 - acc: 0.9854 - val_loss: 0.9219 - val_acc: 0.8981\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0690 - acc: 0.9869 - val_loss: 0.8125 - val_acc: 0.8924\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0670 - acc: 0.9860 - val_loss: 0.9309 - val_acc: 0.8877\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0560 - acc: 0.9878 - val_loss: 0.9550 - val_acc: 0.8866\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0643 - acc: 0.9863 - val_loss: 1.0348 - val_acc: 0.8963\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0658 - acc: 0.9868 - val_loss: 0.9072 - val_acc: 0.8965\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0547 - acc: 0.9879 - val_loss: 1.0186 - val_acc: 0.8913\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9874 - val_loss: 0.9535 - val_acc: 0.8941\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0483 - acc: 0.9884 - val_loss: 0.9594 - val_acc: 0.8919\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0867 - acc: 0.9858 - val_loss: 0.9381 - val_acc: 0.8959\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0565 - acc: 0.9885 - val_loss: 0.8649 - val_acc: 0.9010\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0567 - acc: 0.9886 - val_loss: 0.8913 - val_acc: 0.8987\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0645 - acc: 0.9873 - val_loss: 0.8779 - val_acc: 0.8874\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0561 - acc: 0.9877 - val_loss: 0.8765 - val_acc: 0.8831\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0633 - acc: 0.9866 - val_loss: 0.7585 - val_acc: 0.8957\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0540 - acc: 0.9876 - val_loss: 1.0877 - val_acc: 0.8654\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0591 - acc: 0.9869 - val_loss: 0.9296 - val_acc: 0.8949\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0581 - acc: 0.9887 - val_loss: 0.9580 - val_acc: 0.8935\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0663 - acc: 0.9880 - val_loss: 0.9188 - val_acc: 0.8975\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0561 - acc: 0.9884 - val_loss: 1.0852 - val_acc: 0.8747\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9874 - val_loss: 0.8796 - val_acc: 0.8959\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0566 - acc: 0.9883 - val_loss: 0.9867 - val_acc: 0.8933\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9869 - val_loss: 0.9337 - val_acc: 0.8952\n"
     ]
    }
   ],
   "source": [
    "m5_history = init_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m5_history.history['val_loss'])\n",
    "tup = ('m5', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. model 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m6_model = models.Sequential()\n",
    "m6_model.add(layers.Dense(256, activation='relu', input_shape=(28 * 28,)))\n",
    "m6_model.add(layers.Dense(256, activation='relu'))\n",
    "m6_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m6_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 20us/step - loss: 0.0686 - acc: 0.9744 - val_loss: 0.5410 - val_acc: 0.8964\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0660 - acc: 0.9762 - val_loss: 0.5900 - val_acc: 0.8845\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0657 - acc: 0.9758 - val_loss: 0.5789 - val_acc: 0.8956\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0639 - acc: 0.9754 - val_loss: 0.5310 - val_acc: 0.8987\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0623 - acc: 0.9768 - val_loss: 0.4891 - val_acc: 0.8991\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0625 - acc: 0.9775 - val_loss: 0.5374 - val_acc: 0.8956\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0601 - acc: 0.9781 - val_loss: 0.5756 - val_acc: 0.8962\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0597 - acc: 0.9778 - val_loss: 0.6844 - val_acc: 0.8891\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0635 - acc: 0.9773 - val_loss: 0.5559 - val_acc: 0.8984\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0600 - acc: 0.9787 - val_loss: 0.5622 - val_acc: 0.8967\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0554 - acc: 0.9792 - val_loss: 0.6040 - val_acc: 0.8928\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0620 - acc: 0.9783 - val_loss: 0.5267 - val_acc: 0.9000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0549 - acc: 0.9800 - val_loss: 0.5648 - val_acc: 0.8960\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0556 - acc: 0.9803 - val_loss: 0.5967 - val_acc: 0.8988\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0555 - acc: 0.9811 - val_loss: 0.6656 - val_acc: 0.8912\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0526 - acc: 0.9819 - val_loss: 0.6242 - val_acc: 0.8953\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0590 - acc: 0.9804 - val_loss: 0.6203 - val_acc: 0.8925\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0555 - acc: 0.9819 - val_loss: 0.6177 - val_acc: 0.8968\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0535 - acc: 0.9810 - val_loss: 0.5887 - val_acc: 0.8977\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0476 - acc: 0.9831 - val_loss: 0.6211 - val_acc: 0.8999\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0496 - acc: 0.9828 - val_loss: 0.6410 - val_acc: 0.9017\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0491 - acc: 0.9834 - val_loss: 0.6113 - val_acc: 0.9008\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0485 - acc: 0.9835 - val_loss: 0.5949 - val_acc: 0.9023\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0525 - acc: 0.9832 - val_loss: 0.6053 - val_acc: 0.8979\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0456 - acc: 0.9847 - val_loss: 0.6146 - val_acc: 0.8986\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0457 - acc: 0.9841 - val_loss: 0.7430 - val_acc: 0.8789\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0442 - acc: 0.9848 - val_loss: 0.7319 - val_acc: 0.8871\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0449 - acc: 0.9845 - val_loss: 0.6563 - val_acc: 0.8956\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0484 - acc: 0.9842 - val_loss: 0.6613 - val_acc: 0.8974\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0470 - acc: 0.9847 - val_loss: 0.6522 - val_acc: 0.9007\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0473 - acc: 0.9843 - val_loss: 0.6515 - val_acc: 0.9017\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0471 - acc: 0.9847 - val_loss: 0.6368 - val_acc: 0.9024\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0429 - acc: 0.9858 - val_loss: 0.6947 - val_acc: 0.8960\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0441 - acc: 0.9857 - val_loss: 0.6985 - val_acc: 0.8991\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0436 - acc: 0.9854 - val_loss: 0.8285 - val_acc: 0.8697\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0452 - acc: 0.9851 - val_loss: 0.7740 - val_acc: 0.8887\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0428 - acc: 0.9859 - val_loss: 0.6875 - val_acc: 0.8991\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0400 - acc: 0.9869 - val_loss: 0.7328 - val_acc: 0.8927\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0386 - acc: 0.9863 - val_loss: 0.8003 - val_acc: 0.8895\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0441 - acc: 0.9855 - val_loss: 0.7526 - val_acc: 0.8916\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.9767 - val_acc: 0.8755\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.0491 - acc: 0.9849 - val_loss: 0.6363 - val_acc: 0.9006\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0386 - acc: 0.9879 - val_loss: 0.7372 - val_acc: 0.8970\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0412 - acc: 0.9862 - val_loss: 0.8248 - val_acc: 0.8873\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0385 - acc: 0.9874 - val_loss: 0.7628 - val_acc: 0.8922\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0456 - acc: 0.9871 - val_loss: 0.7155 - val_acc: 0.8973\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0384 - acc: 0.9879 - val_loss: 0.6687 - val_acc: 0.8996\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0374 - acc: 0.9882 - val_loss: 0.7032 - val_acc: 0.9024\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0373 - acc: 0.9884 - val_loss: 0.7282 - val_acc: 0.9007\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.0397 - acc: 0.9881 - val_loss: 0.6883 - val_acc: 0.8966\n"
     ]
    }
   ],
   "source": [
    "m6_history = m1_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m6_history.history['val_loss'])\n",
    "tup = ('m6', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. model 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m7_model = models.Sequential()\n",
    "m7_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m7_model.add(layers.Dense(512, activation='relu'))\n",
    "m7_model.add(layers.Dense(512, activation='relu'))\n",
    "m7_model.add(layers.Dense(512, activation='relu'))\n",
    "m7_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m7_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 3s 63us/step - loss: 0.6310 - acc: 0.7660 - val_loss: 0.5010 - val_acc: 0.8235\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.4202 - acc: 0.8484 - val_loss: 0.4688 - val_acc: 0.8341\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3777 - acc: 0.8653 - val_loss: 0.4673 - val_acc: 0.8421\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3519 - acc: 0.8755 - val_loss: 0.4188 - val_acc: 0.8571\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3364 - acc: 0.8804 - val_loss: 0.4076 - val_acc: 0.8639\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3322 - acc: 0.8828 - val_loss: 0.3656 - val_acc: 0.8726\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3184 - acc: 0.8875 - val_loss: 0.4108 - val_acc: 0.8503\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3107 - acc: 0.8887 - val_loss: 0.3775 - val_acc: 0.8745\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3056 - acc: 0.8917 - val_loss: 0.3613 - val_acc: 0.8824\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2979 - acc: 0.8940 - val_loss: 0.4450 - val_acc: 0.8653\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2936 - acc: 0.8966 - val_loss: 0.4490 - val_acc: 0.8544\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2833 - acc: 0.8992 - val_loss: 0.3329 - val_acc: 0.8893\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2814 - acc: 0.9001 - val_loss: 0.3678 - val_acc: 0.8766\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2791 - acc: 0.9033 - val_loss: 0.4054 - val_acc: 0.8853\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2776 - acc: 0.9035 - val_loss: 0.3719 - val_acc: 0.8851\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2706 - acc: 0.9060 - val_loss: 0.4519 - val_acc: 0.8722\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2698 - acc: 0.9067 - val_loss: 0.3545 - val_acc: 0.8823\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2632 - acc: 0.9080 - val_loss: 0.3776 - val_acc: 0.8854\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2598 - acc: 0.9108 - val_loss: 0.4303 - val_acc: 0.8722\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.3429 - val_acc: 0.8830\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2524 - acc: 0.9118 - val_loss: 0.4265 - val_acc: 0.8850\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2549 - acc: 0.9141 - val_loss: 0.4946 - val_acc: 0.8655\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2563 - acc: 0.9149 - val_loss: 0.4880 - val_acc: 0.8616\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2678 - acc: 0.9139 - val_loss: 0.4597 - val_acc: 0.8762\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2541 - acc: 0.9143 - val_loss: 0.4014 - val_acc: 0.8903\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2519 - acc: 0.9176 - val_loss: 0.5788 - val_acc: 0.8796\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2496 - acc: 0.9189 - val_loss: 0.4676 - val_acc: 0.8667\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2473 - acc: 0.9212 - val_loss: 0.4527 - val_acc: 0.8845\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2445 - acc: 0.9198 - val_loss: 0.4691 - val_acc: 0.8752\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2493 - acc: 0.9193 - val_loss: 0.5302 - val_acc: 0.8688\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2577 - acc: 0.9215 - val_loss: 0.4717 - val_acc: 0.8895\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2465 - acc: 0.9221 - val_loss: 0.4908 - val_acc: 0.8764\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2438 - acc: 0.9236 - val_loss: 0.4981 - val_acc: 0.8868\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2410 - acc: 0.9237 - val_loss: 0.5172 - val_acc: 0.8803\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2470 - acc: 0.9256 - val_loss: 0.4304 - val_acc: 0.8913\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2320 - acc: 0.9274 - val_loss: 0.6607 - val_acc: 0.8460\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2371 - acc: 0.9267 - val_loss: 0.4929 - val_acc: 0.8681\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2354 - acc: 0.9261 - val_loss: 0.4967 - val_acc: 0.8805\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2404 - acc: 0.9265 - val_loss: 0.6020 - val_acc: 0.8775\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2330 - acc: 0.9275 - val_loss: 0.4695 - val_acc: 0.8889\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2187 - acc: 0.9308 - val_loss: 0.5328 - val_acc: 0.8847\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2293 - acc: 0.9302 - val_loss: 0.5443 - val_acc: 0.8862\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2417 - acc: 0.9289 - val_loss: 0.4805 - val_acc: 0.8882\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2466 - acc: 0.9312 - val_loss: 0.5932 - val_acc: 0.8784\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2263 - acc: 0.9325 - val_loss: 0.4857 - val_acc: 0.8731\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2214 - acc: 0.9322 - val_loss: 0.5322 - val_acc: 0.8897\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2320 - acc: 0.9331 - val_loss: 0.5095 - val_acc: 0.8790\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2248 - acc: 0.9328 - val_loss: 0.5368 - val_acc: 0.8740\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2358 - acc: 0.9329 - val_loss: 0.6116 - val_acc: 0.8791\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2337 - acc: 0.9325 - val_loss: 0.4833 - val_acc: 0.8840\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2225 - acc: 0.9338 - val_loss: 0.5512 - val_acc: 0.8920\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2336 - acc: 0.9332 - val_loss: 0.5376 - val_acc: 0.8945\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2341 - acc: 0.9337 - val_loss: 0.5431 - val_acc: 0.8718\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2287 - acc: 0.9359 - val_loss: 0.5692 - val_acc: 0.8882\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2259 - acc: 0.9347 - val_loss: 0.5405 - val_acc: 0.8839\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2092 - acc: 0.9384 - val_loss: 0.5276 - val_acc: 0.8900\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2193 - acc: 0.9360 - val_loss: 0.6293 - val_acc: 0.8907\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2183 - acc: 0.9377 - val_loss: 0.6509 - val_acc: 0.8834\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2251 - acc: 0.9393 - val_loss: 0.6398 - val_acc: 0.8786\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2323 - acc: 0.9373 - val_loss: 0.5390 - val_acc: 0.8890\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2102 - acc: 0.9389 - val_loss: 0.5879 - val_acc: 0.8849\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2118 - acc: 0.9399 - val_loss: 0.5148 - val_acc: 0.8910\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2108 - acc: 0.9411 - val_loss: 0.6145 - val_acc: 0.8856\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2133 - acc: 0.9411 - val_loss: 0.5677 - val_acc: 0.8874\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2236 - acc: 0.9403 - val_loss: 0.5975 - val_acc: 0.8861\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2306 - acc: 0.9378 - val_loss: 0.6104 - val_acc: 0.8840\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2076 - acc: 0.9409 - val_loss: 0.6370 - val_acc: 0.8825\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2089 - acc: 0.9403 - val_loss: 0.5450 - val_acc: 0.8875\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2057 - acc: 0.9426 - val_loss: 0.6341 - val_acc: 0.8848\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2153 - acc: 0.9399 - val_loss: 0.5762 - val_acc: 0.8911\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2057 - acc: 0.9413 - val_loss: 0.7083 - val_acc: 0.8716\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2130 - acc: 0.9422 - val_loss: 0.6614 - val_acc: 0.8865\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2144 - acc: 0.9417 - val_loss: 0.6735 - val_acc: 0.8820\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2174 - acc: 0.9426 - val_loss: 1.3971 - val_acc: 0.8268\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2324 - acc: 0.9410 - val_loss: 0.5886 - val_acc: 0.8838\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2142 - acc: 0.9442 - val_loss: 0.6512 - val_acc: 0.8886\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2308 - acc: 0.9421 - val_loss: 0.6027 - val_acc: 0.8952\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2383 - acc: 0.9419 - val_loss: 0.8559 - val_acc: 0.8162\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2268 - acc: 0.9439 - val_loss: 0.6297 - val_acc: 0.8842\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2341 - acc: 0.9420 - val_loss: 0.5904 - val_acc: 0.8851\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2238 - acc: 0.9426 - val_loss: 0.6021 - val_acc: 0.8855\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2078 - acc: 0.9443 - val_loss: 0.6316 - val_acc: 0.8673\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2136 - acc: 0.9439 - val_loss: 0.7463 - val_acc: 0.8826\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2186 - acc: 0.9453 - val_loss: 0.6093 - val_acc: 0.8937\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2244 - acc: 0.9446 - val_loss: 0.6157 - val_acc: 0.8868\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2441 - acc: 0.9426 - val_loss: 0.7038 - val_acc: 0.8908\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2381 - acc: 0.9455 - val_loss: 0.7364 - val_acc: 0.8838\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2382 - acc: 0.9438 - val_loss: 0.6451 - val_acc: 0.8873\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2198 - acc: 0.9459 - val_loss: 0.7281 - val_acc: 0.8895\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2358 - acc: 0.9425 - val_loss: 0.7418 - val_acc: 0.8878\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2475 - acc: 0.9434 - val_loss: 0.8162 - val_acc: 0.8819\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2398 - acc: 0.9453 - val_loss: 0.6758 - val_acc: 0.8842\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2322 - acc: 0.9470 - val_loss: 0.7366 - val_acc: 0.8890\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2291 - acc: 0.9451 - val_loss: 0.8881 - val_acc: 0.8668\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2451 - acc: 0.9440 - val_loss: 0.6352 - val_acc: 0.8942\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2200 - acc: 0.9471 - val_loss: 0.7358 - val_acc: 0.8869\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2200 - acc: 0.9471 - val_loss: 0.6981 - val_acc: 0.8894\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2164 - acc: 0.9462 - val_loss: 0.6631 - val_acc: 0.8723\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2382 - acc: 0.9465 - val_loss: 0.6720 - val_acc: 0.8897\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2361 - acc: 0.9463 - val_loss: 0.7231 - val_acc: 0.8691\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2122 - acc: 0.9481 - val_loss: 0.7692 - val_acc: 0.8889\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2550 - acc: 0.9455 - val_loss: 0.7299 - val_acc: 0.8893\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2876 - acc: 0.9423 - val_loss: 0.5756 - val_acc: 0.8953\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2249 - acc: 0.9475 - val_loss: 0.6724 - val_acc: 0.8894\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2413 - acc: 0.9457 - val_loss: 0.7120 - val_acc: 0.8904\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2459 - acc: 0.9466 - val_loss: 0.6849 - val_acc: 0.8862\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2659 - acc: 0.9458 - val_loss: 0.8104 - val_acc: 0.8832\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2418 - acc: 0.9471 - val_loss: 0.7678 - val_acc: 0.8899\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2552 - acc: 0.9465 - val_loss: 0.7597 - val_acc: 0.8844\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2490 - acc: 0.9450 - val_loss: 0.6897 - val_acc: 0.8835\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2246 - acc: 0.9483 - val_loss: 0.6891 - val_acc: 0.8929\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2372 - acc: 0.9472 - val_loss: 0.7701 - val_acc: 0.8852\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2644 - acc: 0.9455 - val_loss: 0.7187 - val_acc: 0.8952\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2518 - acc: 0.9457 - val_loss: 0.6815 - val_acc: 0.8875\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2373 - acc: 0.9483 - val_loss: 0.7894 - val_acc: 0.8838\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2435 - acc: 0.9482 - val_loss: 0.6791 - val_acc: 0.8811\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2426 - acc: 0.9469 - val_loss: 0.7122 - val_acc: 0.8865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2267 - acc: 0.9507 - val_loss: 0.6451 - val_acc: 0.8893\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2310 - acc: 0.9503 - val_loss: 0.6974 - val_acc: 0.8915\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2451 - acc: 0.9487 - val_loss: 0.7914 - val_acc: 0.8888\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2394 - acc: 0.9517 - val_loss: 0.6761 - val_acc: 0.8914\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2353 - acc: 0.9500 - val_loss: 0.7945 - val_acc: 0.8832\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2358 - acc: 0.9487 - val_loss: 0.8703 - val_acc: 0.8864\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2554 - acc: 0.9463 - val_loss: 0.7225 - val_acc: 0.8886\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2542 - acc: 0.9498 - val_loss: 0.7287 - val_acc: 0.8894\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2348 - acc: 0.9500 - val_loss: 0.7973 - val_acc: 0.8749\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2360 - acc: 0.9495 - val_loss: 0.8368 - val_acc: 0.8824\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2402 - acc: 0.9487 - val_loss: 0.6800 - val_acc: 0.8906\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2376 - acc: 0.9493 - val_loss: 0.7184 - val_acc: 0.8862\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2512 - acc: 0.9491 - val_loss: 0.8455 - val_acc: 0.8771\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2208 - acc: 0.9531 - val_loss: 0.6618 - val_acc: 0.8935\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2597 - acc: 0.9491 - val_loss: 0.7775 - val_acc: 0.8853\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2182 - acc: 0.9532 - val_loss: 0.8419 - val_acc: 0.8850\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2289 - acc: 0.9519 - val_loss: 0.8042 - val_acc: 0.8888\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2531 - acc: 0.9494 - val_loss: 0.7931 - val_acc: 0.8876\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2513 - acc: 0.9501 - val_loss: 0.9120 - val_acc: 0.8727\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2576 - acc: 0.9503 - val_loss: 0.9425 - val_acc: 0.8804\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2472 - acc: 0.9510 - val_loss: 0.9021 - val_acc: 0.8868\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2721 - acc: 0.9499 - val_loss: 0.7979 - val_acc: 0.8876\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2761 - acc: 0.9490 - val_loss: 0.9943 - val_acc: 0.8703\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2333 - acc: 0.9524 - val_loss: 0.8144 - val_acc: 0.8835\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2981 - acc: 0.9481 - val_loss: 0.7653 - val_acc: 0.8871\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2348 - acc: 0.9540 - val_loss: 0.8669 - val_acc: 0.8876\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2465 - acc: 0.9506 - val_loss: 0.8176 - val_acc: 0.8847\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2485 - acc: 0.9516 - val_loss: 0.8487 - val_acc: 0.8832\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2642 - acc: 0.9516 - val_loss: 0.8776 - val_acc: 0.8727\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2812 - acc: 0.9487 - val_loss: 0.7614 - val_acc: 0.8918\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2660 - acc: 0.9515 - val_loss: 0.9377 - val_acc: 0.8863\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2589 - acc: 0.9527 - val_loss: 1.0104 - val_acc: 0.8774\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2577 - acc: 0.9525 - val_loss: 0.8883 - val_acc: 0.8806\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2667 - acc: 0.9515 - val_loss: 0.7890 - val_acc: 0.8857\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2695 - acc: 0.9514 - val_loss: 0.8800 - val_acc: 0.8877\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2836 - acc: 0.9496 - val_loss: 0.7821 - val_acc: 0.8658\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2368 - acc: 0.9546 - val_loss: 0.7967 - val_acc: 0.8852\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2617 - acc: 0.9522 - val_loss: 0.9822 - val_acc: 0.8863\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2383 - acc: 0.9547 - val_loss: 0.8070 - val_acc: 0.8914\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2730 - acc: 0.9505 - val_loss: 0.8802 - val_acc: 0.8893\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2491 - acc: 0.9540 - val_loss: 0.8923 - val_acc: 0.8847\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2473 - acc: 0.9552 - val_loss: 0.8957 - val_acc: 0.8894\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2669 - acc: 0.9535 - val_loss: 0.8934 - val_acc: 0.8878\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2364 - acc: 0.9576 - val_loss: 0.9082 - val_acc: 0.8877\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2619 - acc: 0.9545 - val_loss: 0.8232 - val_acc: 0.8845\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2522 - acc: 0.9539 - val_loss: 0.9365 - val_acc: 0.8855\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3020 - acc: 0.9507 - val_loss: 0.8423 - val_acc: 0.8788\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2901 - acc: 0.9519 - val_loss: 0.8815 - val_acc: 0.8841\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2758 - acc: 0.9548 - val_loss: 0.9409 - val_acc: 0.8801\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2665 - acc: 0.9560 - val_loss: 0.9959 - val_acc: 0.8699\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2796 - acc: 0.9541 - val_loss: 0.8488 - val_acc: 0.8887\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2985 - acc: 0.9520 - val_loss: 1.0982 - val_acc: 0.8647\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2829 - acc: 0.9536 - val_loss: 1.0562 - val_acc: 0.8864\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3292 - acc: 0.9482 - val_loss: 0.8725 - val_acc: 0.8887\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2982 - acc: 0.9512 - val_loss: 1.0032 - val_acc: 0.8839\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2805 - acc: 0.9526 - val_loss: 0.9851 - val_acc: 0.8773\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2733 - acc: 0.9554 - val_loss: 0.8489 - val_acc: 0.8862\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2888 - acc: 0.9555 - val_loss: 0.8406 - val_acc: 0.8885\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2596 - acc: 0.9544 - val_loss: 0.8726 - val_acc: 0.8849\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2914 - acc: 0.9549 - val_loss: 1.4161 - val_acc: 0.8581\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3067 - acc: 0.9543 - val_loss: 0.9823 - val_acc: 0.8793\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2860 - acc: 0.9565 - val_loss: 0.9265 - val_acc: 0.8817\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2892 - acc: 0.9536 - val_loss: 0.9366 - val_acc: 0.8833\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.2803 - acc: 0.9557 - val_loss: 0.8832 - val_acc: 0.8868\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2652 - acc: 0.9543 - val_loss: 0.8378 - val_acc: 0.8864\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2757 - acc: 0.9554 - val_loss: 0.9692 - val_acc: 0.8784\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2876 - acc: 0.9550 - val_loss: 1.0473 - val_acc: 0.8824\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2659 - acc: 0.9562 - val_loss: 1.5801 - val_acc: 0.8529\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3500 - acc: 0.9502 - val_loss: 0.9496 - val_acc: 0.8825\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2592 - acc: 0.9576 - val_loss: 0.9425 - val_acc: 0.8852\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2868 - acc: 0.9566 - val_loss: 0.8569 - val_acc: 0.8866\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3129 - acc: 0.9550 - val_loss: 0.9962 - val_acc: 0.8845\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2880 - acc: 0.9563 - val_loss: 0.9246 - val_acc: 0.8857\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3027 - acc: 0.9564 - val_loss: 1.2169 - val_acc: 0.8644\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3170 - acc: 0.9548 - val_loss: 0.8832 - val_acc: 0.8881\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2979 - acc: 0.9546 - val_loss: 0.9236 - val_acc: 0.8836\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2894 - acc: 0.9544 - val_loss: 0.8921 - val_acc: 0.8811\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2831 - acc: 0.9554 - val_loss: 0.9696 - val_acc: 0.8799\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3040 - acc: 0.9545 - val_loss: 0.9535 - val_acc: 0.8852\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2997 - acc: 0.9548 - val_loss: 0.9259 - val_acc: 0.8899\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.2911 - acc: 0.9567 - val_loss: 1.1993 - val_acc: 0.8784\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.3179 - acc: 0.9522 - val_loss: 1.1144 - val_acc: 0.8534\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 0.3543 - acc: 0.9501 - val_loss: 0.8850 - val_acc: 0.8877\n"
     ]
    }
   ],
   "source": [
    "m7_history = m7_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=128,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m7_history.history['val_loss'])\n",
    "tup = ('m7', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. model 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m8_model = models.Sequential()\n",
    "m8_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu', input_shape=(28 * 28,)))\n",
    "m8_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu'))\n",
    "m8_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m8_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 9.1376 - acc: 0.6610 - val_loss: 2.9679 - val_acc: 0.7465\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 2.1710 - acc: 0.7373 - val_loss: 1.6803 - val_acc: 0.7548\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.5086 - acc: 0.7667 - val_loss: 1.4339 - val_acc: 0.7657\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.3125 - acc: 0.7792 - val_loss: 1.2575 - val_acc: 0.7843\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.2102 - acc: 0.7924 - val_loss: 1.1901 - val_acc: 0.7817\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1527 - acc: 0.8016 - val_loss: 1.1780 - val_acc: 0.7882\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 1.1045 - acc: 0.8078 - val_loss: 1.0977 - val_acc: 0.8001\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 1.0687 - acc: 0.8144 - val_loss: 1.0817 - val_acc: 0.8040\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.0484 - acc: 0.8175 - val_loss: 1.0773 - val_acc: 0.8060\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.0315 - acc: 0.8204 - val_loss: 1.0469 - val_acc: 0.8082\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.0119 - acc: 0.8235 - val_loss: 1.0271 - val_acc: 0.8153\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9963 - acc: 0.8277 - val_loss: 1.0262 - val_acc: 0.8134\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9856 - acc: 0.8284 - val_loss: 0.9754 - val_acc: 0.8284\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9709 - acc: 0.8316 - val_loss: 1.0612 - val_acc: 0.7872\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9619 - acc: 0.8334 - val_loss: 0.9789 - val_acc: 0.8230\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9565 - acc: 0.8329 - val_loss: 0.9727 - val_acc: 0.8223\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9484 - acc: 0.8356 - val_loss: 0.9564 - val_acc: 0.8287\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9435 - acc: 0.8358 - val_loss: 0.9704 - val_acc: 0.8205\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9401 - acc: 0.8380 - val_loss: 0.9682 - val_acc: 0.8262\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9359 - acc: 0.8382 - val_loss: 0.9471 - val_acc: 0.8332\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9305 - acc: 0.8395 - val_loss: 0.9551 - val_acc: 0.8281\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9301 - acc: 0.8379 - val_loss: 0.9676 - val_acc: 0.8263\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9278 - acc: 0.8395 - val_loss: 0.9752 - val_acc: 0.8214\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9227 - acc: 0.8407 - val_loss: 0.9899 - val_acc: 0.8167\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.9203 - acc: 0.8409 - val_loss: 1.0165 - val_acc: 0.7918\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9177 - acc: 0.8411 - val_loss: 0.9608 - val_acc: 0.8193\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9173 - acc: 0.8408 - val_loss: 0.9155 - val_acc: 0.8419\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9151 - acc: 0.8428 - val_loss: 0.9119 - val_acc: 0.8430\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9108 - acc: 0.8419 - val_loss: 0.9850 - val_acc: 0.8157\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9112 - acc: 0.8423 - val_loss: 0.9206 - val_acc: 0.8382\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9087 - acc: 0.8425 - val_loss: 0.9629 - val_acc: 0.8164\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9074 - acc: 0.8422 - val_loss: 0.9622 - val_acc: 0.8222\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9044 - acc: 0.8439 - val_loss: 0.9291 - val_acc: 0.8284\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9022 - acc: 0.8442 - val_loss: 0.9652 - val_acc: 0.8266\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9011 - acc: 0.8455 - val_loss: 0.9279 - val_acc: 0.8361\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.9008 - acc: 0.8450 - val_loss: 0.9085 - val_acc: 0.8402\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8974 - acc: 0.8450 - val_loss: 0.9539 - val_acc: 0.8191\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8970 - acc: 0.8455 - val_loss: 0.9246 - val_acc: 0.8318\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8953 - acc: 0.8442 - val_loss: 0.9660 - val_acc: 0.8193\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8940 - acc: 0.8446 - val_loss: 0.9218 - val_acc: 0.8313\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8931 - acc: 0.8454 - val_loss: 0.9625 - val_acc: 0.8146\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8882 - acc: 0.8462 - val_loss: 0.9189 - val_acc: 0.8308\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8901 - acc: 0.8464 - val_loss: 0.9116 - val_acc: 0.8407\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8884 - acc: 0.8471 - val_loss: 0.9286 - val_acc: 0.8303\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8871 - acc: 0.8459 - val_loss: 0.9898 - val_acc: 0.8034\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8858 - acc: 0.8487 - val_loss: 0.9256 - val_acc: 0.8307\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8865 - acc: 0.8478 - val_loss: 0.8931 - val_acc: 0.8450\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8828 - acc: 0.8493 - val_loss: 0.8955 - val_acc: 0.8400\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8815 - acc: 0.8470 - val_loss: 0.8930 - val_acc: 0.8439\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8833 - acc: 0.8464 - val_loss: 0.9106 - val_acc: 0.8336\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8811 - acc: 0.8501 - val_loss: 0.9233 - val_acc: 0.8332\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8793 - acc: 0.8480 - val_loss: 0.9480 - val_acc: 0.8201\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8786 - acc: 0.8484 - val_loss: 0.9123 - val_acc: 0.8351\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8785 - acc: 0.8485 - val_loss: 0.9466 - val_acc: 0.8229\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8788 - acc: 0.8489 - val_loss: 0.8931 - val_acc: 0.8430\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8726 - acc: 0.8492 - val_loss: 0.9179 - val_acc: 0.8321\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8753 - acc: 0.8490 - val_loss: 0.8813 - val_acc: 0.8472\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8749 - acc: 0.8511 - val_loss: 0.8924 - val_acc: 0.8389\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8759 - acc: 0.8488 - val_loss: 0.9141 - val_acc: 0.8295\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8725 - acc: 0.8504 - val_loss: 0.8880 - val_acc: 0.8434\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8740 - acc: 0.8500 - val_loss: 0.8799 - val_acc: 0.8465\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8716 - acc: 0.8495 - val_loss: 0.8815 - val_acc: 0.8443\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8704 - acc: 0.8513 - val_loss: 0.9118 - val_acc: 0.8334\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 0.8676 - acc: 0.8517 - val_loss: 0.9089 - val_acc: 0.8368\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8708 - acc: 0.8506 - val_loss: 0.9079 - val_acc: 0.8302\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8707 - acc: 0.8499 - val_loss: 0.9217 - val_acc: 0.8283\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8690 - acc: 0.8502 - val_loss: 0.9063 - val_acc: 0.8342\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8689 - acc: 0.8503 - val_loss: 0.9070 - val_acc: 0.8325\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8675 - acc: 0.8500 - val_loss: 0.8883 - val_acc: 0.8424\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8662 - acc: 0.8511 - val_loss: 0.9148 - val_acc: 0.8298\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8673 - acc: 0.8503 - val_loss: 0.8783 - val_acc: 0.8448\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8646 - acc: 0.8516 - val_loss: 0.9017 - val_acc: 0.8333\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8632 - acc: 0.8520 - val_loss: 0.8819 - val_acc: 0.8377\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8640 - acc: 0.8524 - val_loss: 0.8964 - val_acc: 0.8388\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8638 - acc: 0.8521 - val_loss: 0.8959 - val_acc: 0.8364\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8612 - acc: 0.8534 - val_loss: 0.9230 - val_acc: 0.8257\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8618 - acc: 0.8526 - val_loss: 0.8871 - val_acc: 0.8432\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8610 - acc: 0.8531 - val_loss: 0.8859 - val_acc: 0.8414\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8624 - acc: 0.8502 - val_loss: 0.8849 - val_acc: 0.8383\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8608 - acc: 0.8525 - val_loss: 0.8901 - val_acc: 0.8410\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8612 - acc: 0.8516 - val_loss: 0.8979 - val_acc: 0.8365\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8615 - acc: 0.8515 - val_loss: 0.8870 - val_acc: 0.8398\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8589 - acc: 0.8527 - val_loss: 0.9004 - val_acc: 0.8379\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8583 - acc: 0.8520 - val_loss: 0.9359 - val_acc: 0.8205\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8577 - acc: 0.8540 - val_loss: 0.9441 - val_acc: 0.8215\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8597 - acc: 0.8519 - val_loss: 0.9203 - val_acc: 0.8290\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8589 - acc: 0.8518 - val_loss: 0.8782 - val_acc: 0.8418\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8594 - acc: 0.8518 - val_loss: 0.8724 - val_acc: 0.8463\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8559 - acc: 0.8534 - val_loss: 0.8843 - val_acc: 0.8421\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8555 - acc: 0.8534 - val_loss: 0.8762 - val_acc: 0.8415\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8565 - acc: 0.8519 - val_loss: 0.9426 - val_acc: 0.8194\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8581 - acc: 0.8525 - val_loss: 0.8775 - val_acc: 0.8432\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8546 - acc: 0.8531 - val_loss: 0.8679 - val_acc: 0.8459\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8537 - acc: 0.8542 - val_loss: 0.8845 - val_acc: 0.8408\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8536 - acc: 0.8545 - val_loss: 0.9061 - val_acc: 0.8345\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8527 - acc: 0.8551 - val_loss: 0.9056 - val_acc: 0.8328\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8524 - acc: 0.8535 - val_loss: 0.9002 - val_acc: 0.8375\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8525 - acc: 0.8539 - val_loss: 0.8696 - val_acc: 0.8469\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8537 - acc: 0.8525 - val_loss: 0.9424 - val_acc: 0.8134\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8519 - acc: 0.8546 - val_loss: 0.9053 - val_acc: 0.8325\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8518 - acc: 0.8549 - val_loss: 0.8985 - val_acc: 0.8377\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8526 - acc: 0.8548 - val_loss: 0.8669 - val_acc: 0.8460\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8496 - acc: 0.8543 - val_loss: 0.9076 - val_acc: 0.8287\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8473 - acc: 0.8556 - val_loss: 0.8899 - val_acc: 0.8378\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8493 - acc: 0.8549 - val_loss: 0.9360 - val_acc: 0.8227\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8504 - acc: 0.8561 - val_loss: 0.9046 - val_acc: 0.8312\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8481 - acc: 0.8535 - val_loss: 0.9156 - val_acc: 0.8353\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8470 - acc: 0.8554 - val_loss: 0.9911 - val_acc: 0.8021\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8496 - acc: 0.8543 - val_loss: 0.8890 - val_acc: 0.8353\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8469 - acc: 0.8549 - val_loss: 0.9244 - val_acc: 0.8259\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8487 - acc: 0.8556 - val_loss: 0.8773 - val_acc: 0.8369\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8473 - acc: 0.8556 - val_loss: 0.8717 - val_acc: 0.8447\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8463 - acc: 0.8552 - val_loss: 0.9170 - val_acc: 0.8262\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8470 - acc: 0.8553 - val_loss: 0.8728 - val_acc: 0.8434\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8462 - acc: 0.8563 - val_loss: 0.8629 - val_acc: 0.8459\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8466 - acc: 0.8549 - val_loss: 0.8891 - val_acc: 0.8380\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8440 - acc: 0.8567 - val_loss: 0.8677 - val_acc: 0.8474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8444 - acc: 0.8563 - val_loss: 0.8654 - val_acc: 0.8454\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8438 - acc: 0.8570 - val_loss: 0.8832 - val_acc: 0.8385\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8457 - acc: 0.8550 - val_loss: 0.8583 - val_acc: 0.8479\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8453 - acc: 0.8559 - val_loss: 0.9061 - val_acc: 0.8293\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8438 - acc: 0.8557 - val_loss: 0.9236 - val_acc: 0.8257\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8446 - acc: 0.8564 - val_loss: 0.8775 - val_acc: 0.8409\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8450 - acc: 0.8559 - val_loss: 0.8650 - val_acc: 0.8438\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8429 - acc: 0.8567 - val_loss: 0.8785 - val_acc: 0.8364\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8420 - acc: 0.8570 - val_loss: 0.8973 - val_acc: 0.8348\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8452 - acc: 0.8552 - val_loss: 0.8628 - val_acc: 0.8445\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8405 - acc: 0.8579 - val_loss: 0.8581 - val_acc: 0.8481\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8451 - acc: 0.8551 - val_loss: 0.9333 - val_acc: 0.8271\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8411 - acc: 0.8566 - val_loss: 0.8928 - val_acc: 0.8366\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8423 - acc: 0.8563 - val_loss: 0.8558 - val_acc: 0.8508\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8425 - acc: 0.8563 - val_loss: 0.8886 - val_acc: 0.8388\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8396 - acc: 0.8565 - val_loss: 0.8611 - val_acc: 0.8469\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8404 - acc: 0.8581 - val_loss: 0.8964 - val_acc: 0.8331\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8408 - acc: 0.8571 - val_loss: 0.8591 - val_acc: 0.8467\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8412 - acc: 0.8559 - val_loss: 0.8703 - val_acc: 0.8453\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8389 - acc: 0.8573 - val_loss: 0.8871 - val_acc: 0.8351\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8404 - acc: 0.8562 - val_loss: 0.8706 - val_acc: 0.8416\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8390 - acc: 0.8572 - val_loss: 0.8599 - val_acc: 0.8463\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8377 - acc: 0.8587 - val_loss: 0.8748 - val_acc: 0.8411\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8396 - acc: 0.8564 - val_loss: 0.9348 - val_acc: 0.8238\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8419 - acc: 0.8549 - val_loss: 0.8503 - val_acc: 0.8504\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8369 - acc: 0.8571 - val_loss: 0.8488 - val_acc: 0.8499\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8379 - acc: 0.8572 - val_loss: 0.8804 - val_acc: 0.8378\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8384 - acc: 0.8575 - val_loss: 0.8810 - val_acc: 0.8403\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8382 - acc: 0.8575 - val_loss: 0.8492 - val_acc: 0.8507\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8354 - acc: 0.8584 - val_loss: 0.8793 - val_acc: 0.8413\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8371 - acc: 0.8579 - val_loss: 0.8572 - val_acc: 0.8516\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8383 - acc: 0.8577 - val_loss: 0.8648 - val_acc: 0.8443\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8354 - acc: 0.8594 - val_loss: 0.8590 - val_acc: 0.8457\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8360 - acc: 0.8577 - val_loss: 0.8825 - val_acc: 0.8401\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8376 - acc: 0.8569 - val_loss: 0.8817 - val_acc: 0.8348\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8370 - acc: 0.8573 - val_loss: 0.8752 - val_acc: 0.8417\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8381 - acc: 0.8566 - val_loss: 0.8597 - val_acc: 0.8447\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8352 - acc: 0.8570 - val_loss: 0.8578 - val_acc: 0.8493\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8363 - acc: 0.8572 - val_loss: 0.9148 - val_acc: 0.8275\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8354 - acc: 0.8575 - val_loss: 0.8940 - val_acc: 0.8356\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8370 - acc: 0.8564 - val_loss: 0.9250 - val_acc: 0.8201\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8364 - acc: 0.8576 - val_loss: 0.9041 - val_acc: 0.8248\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8362 - acc: 0.8566 - val_loss: 0.8853 - val_acc: 0.8344\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8347 - acc: 0.8583 - val_loss: 0.8607 - val_acc: 0.8490\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8349 - acc: 0.8574 - val_loss: 0.8531 - val_acc: 0.8480\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8341 - acc: 0.8576 - val_loss: 0.8551 - val_acc: 0.8484\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8371 - acc: 0.8564 - val_loss: 0.8649 - val_acc: 0.8455\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8338 - acc: 0.8583 - val_loss: 0.8603 - val_acc: 0.8443\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8325 - acc: 0.8583 - val_loss: 0.9003 - val_acc: 0.8305\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8333 - acc: 0.8592 - val_loss: 0.9124 - val_acc: 0.8230\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8337 - acc: 0.8586 - val_loss: 0.8898 - val_acc: 0.8303\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8345 - acc: 0.8572 - val_loss: 0.8687 - val_acc: 0.8456\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8330 - acc: 0.8588 - val_loss: 0.8433 - val_acc: 0.8521\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8313 - acc: 0.8582 - val_loss: 0.8563 - val_acc: 0.8489\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8338 - acc: 0.8590 - val_loss: 0.8780 - val_acc: 0.8391\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8319 - acc: 0.8580 - val_loss: 0.8516 - val_acc: 0.8515\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8326 - acc: 0.8577 - val_loss: 0.9101 - val_acc: 0.8286\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8313 - acc: 0.8577 - val_loss: 0.9009 - val_acc: 0.8293\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8348 - acc: 0.8558 - val_loss: 0.8625 - val_acc: 0.8446\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8312 - acc: 0.8584 - val_loss: 0.8674 - val_acc: 0.8433\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8330 - acc: 0.8577 - val_loss: 0.8784 - val_acc: 0.8410\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8315 - acc: 0.8590 - val_loss: 0.8767 - val_acc: 0.8398\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8321 - acc: 0.8587 - val_loss: 0.9301 - val_acc: 0.8235\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8310 - acc: 0.8588 - val_loss: 0.9036 - val_acc: 0.8320\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8335 - acc: 0.8577 - val_loss: 0.8683 - val_acc: 0.8431\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8314 - acc: 0.8584 - val_loss: 0.8549 - val_acc: 0.8478\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8335 - acc: 0.8578 - val_loss: 0.8813 - val_acc: 0.8366\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8306 - acc: 0.8581 - val_loss: 0.8944 - val_acc: 0.8319\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8324 - acc: 0.8579 - val_loss: 0.8762 - val_acc: 0.8376\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8317 - acc: 0.8590 - val_loss: 0.8767 - val_acc: 0.8397\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8302 - acc: 0.8582 - val_loss: 0.8768 - val_acc: 0.8390\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8312 - acc: 0.8591 - val_loss: 0.8706 - val_acc: 0.8425\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8306 - acc: 0.8597 - val_loss: 0.9156 - val_acc: 0.8315\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8297 - acc: 0.8579 - val_loss: 0.8846 - val_acc: 0.8397\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8317 - acc: 0.8577 - val_loss: 0.8693 - val_acc: 0.8421\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8301 - acc: 0.8598 - val_loss: 0.8446 - val_acc: 0.8521\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8288 - acc: 0.8581 - val_loss: 0.8501 - val_acc: 0.8490\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8331 - acc: 0.8577 - val_loss: 0.9072 - val_acc: 0.8234\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8284 - acc: 0.8600 - val_loss: 0.8535 - val_acc: 0.8496\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8302 - acc: 0.8583 - val_loss: 0.8453 - val_acc: 0.8498\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8288 - acc: 0.8591 - val_loss: 0.8765 - val_acc: 0.8409\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8295 - acc: 0.8582 - val_loss: 0.9110 - val_acc: 0.8261\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 12us/step - loss: 0.8289 - acc: 0.8587 - val_loss: 0.8628 - val_acc: 0.8478\n"
     ]
    }
   ],
   "source": [
    "m8_history = m8_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m8_history.history['val_loss'])\n",
    "tup = ('m8', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. model 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m9_model = models.Sequential()\n",
    "m9_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m9_model.add(layers.Dropout(0.2))\n",
    "m9_model.add(layers.Dense(512, activation='relu'))\n",
    "m9_model.add(layers.Dropout(0.2))\n",
    "m9_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m9_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 1s 30us/step - loss: 0.7547 - acc: 0.7291 - val_loss: 0.5037 - val_acc: 0.8216\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4779 - acc: 0.8214 - val_loss: 0.4463 - val_acc: 0.8367\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4141 - acc: 0.8474 - val_loss: 0.4062 - val_acc: 0.8517\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3806 - acc: 0.8597 - val_loss: 0.3703 - val_acc: 0.8666\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3510 - acc: 0.8679 - val_loss: 0.3876 - val_acc: 0.8568\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3347 - acc: 0.8759 - val_loss: 0.4000 - val_acc: 0.8557\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3177 - acc: 0.8806 - val_loss: 0.4498 - val_acc: 0.8397\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3057 - acc: 0.8861 - val_loss: 0.3501 - val_acc: 0.8628\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2882 - acc: 0.8917 - val_loss: 0.3240 - val_acc: 0.8805\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2834 - acc: 0.8954 - val_loss: 0.3100 - val_acc: 0.8860\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2719 - acc: 0.8965 - val_loss: 0.3133 - val_acc: 0.8854\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2634 - acc: 0.9012 - val_loss: 0.3197 - val_acc: 0.8827\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2539 - acc: 0.9042 - val_loss: 0.3094 - val_acc: 0.8902\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2489 - acc: 0.9047 - val_loss: 0.3153 - val_acc: 0.8847\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2408 - acc: 0.9081 - val_loss: 0.3335 - val_acc: 0.8825\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2355 - acc: 0.9109 - val_loss: 0.3334 - val_acc: 0.8821\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2268 - acc: 0.9134 - val_loss: 0.3235 - val_acc: 0.8873\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2202 - acc: 0.9150 - val_loss: 0.3113 - val_acc: 0.8940\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2183 - acc: 0.9159 - val_loss: 0.2956 - val_acc: 0.8954\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2121 - acc: 0.9196 - val_loss: 0.3272 - val_acc: 0.8867\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2058 - acc: 0.9203 - val_loss: 0.3106 - val_acc: 0.8968\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2045 - acc: 0.9219 - val_loss: 0.3522 - val_acc: 0.8761\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1968 - acc: 0.9256 - val_loss: 0.3500 - val_acc: 0.8849\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1951 - acc: 0.9261 - val_loss: 0.3699 - val_acc: 0.8780\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1929 - acc: 0.9270 - val_loss: 0.3182 - val_acc: 0.8932\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1873 - acc: 0.9285 - val_loss: 0.3565 - val_acc: 0.8831\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1830 - acc: 0.9314 - val_loss: 0.3312 - val_acc: 0.8978\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1819 - acc: 0.9297 - val_loss: 0.3628 - val_acc: 0.8841\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1740 - acc: 0.9336 - val_loss: 0.3710 - val_acc: 0.8813\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1717 - acc: 0.9343 - val_loss: 0.3611 - val_acc: 0.8930\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1699 - acc: 0.9351 - val_loss: 0.3810 - val_acc: 0.8904\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1653 - acc: 0.9363 - val_loss: 0.3297 - val_acc: 0.8996\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1656 - acc: 0.9368 - val_loss: 0.3523 - val_acc: 0.8934\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1596 - acc: 0.9395 - val_loss: 0.3463 - val_acc: 0.8927\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1606 - acc: 0.9384 - val_loss: 0.3520 - val_acc: 0.8945\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1567 - acc: 0.9403 - val_loss: 0.3700 - val_acc: 0.8900\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1539 - acc: 0.9403 - val_loss: 0.4502 - val_acc: 0.8777\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1513 - acc: 0.9426 - val_loss: 0.3905 - val_acc: 0.8866\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1497 - acc: 0.9428 - val_loss: 0.3653 - val_acc: 0.8934\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1490 - acc: 0.9430 - val_loss: 0.3865 - val_acc: 0.8933\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1458 - acc: 0.9433 - val_loss: 0.4568 - val_acc: 0.8732\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1432 - acc: 0.9448 - val_loss: 0.3542 - val_acc: 0.9003\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1425 - acc: 0.9448 - val_loss: 0.3802 - val_acc: 0.8967\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1367 - acc: 0.9482 - val_loss: 0.3649 - val_acc: 0.8952\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1388 - acc: 0.9473 - val_loss: 0.3908 - val_acc: 0.8949\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1369 - acc: 0.9488 - val_loss: 0.4569 - val_acc: 0.8879\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1392 - acc: 0.9468 - val_loss: 0.4091 - val_acc: 0.8914\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1318 - acc: 0.9503 - val_loss: 0.3970 - val_acc: 0.8993\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1334 - acc: 0.9499 - val_loss: 0.3801 - val_acc: 0.9013\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1304 - acc: 0.9505 - val_loss: 0.3919 - val_acc: 0.9007\n"
     ]
    }
   ],
   "source": [
    "m9_history = m9_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m9_history.history['val_loss'])\n",
    "tup = ('m9', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. model 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m10_model = models.Sequential()\n",
    "m10_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m10_model.add(layers.Dropout(0.3))\n",
    "m10_model.add(layers.Dense(512, activation='relu'))\n",
    "m10_model.add(layers.Dropout(0.3))\n",
    "m10_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m10_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.7503 - acc: 0.7292 - val_loss: 0.5447 - val_acc: 0.7976\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4845 - acc: 0.8203 - val_loss: 0.4805 - val_acc: 0.8285\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4232 - acc: 0.8434 - val_loss: 0.4016 - val_acc: 0.8460\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3843 - acc: 0.8580 - val_loss: 0.4085 - val_acc: 0.8464\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3656 - acc: 0.8647 - val_loss: 0.4042 - val_acc: 0.8460\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3455 - acc: 0.8706 - val_loss: 0.3965 - val_acc: 0.8534\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3291 - acc: 0.8779 - val_loss: 0.3510 - val_acc: 0.8712\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3143 - acc: 0.8828 - val_loss: 0.3811 - val_acc: 0.8591\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3074 - acc: 0.8843 - val_loss: 0.3861 - val_acc: 0.8630\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2987 - acc: 0.8881 - val_loss: 0.3360 - val_acc: 0.8742\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2864 - acc: 0.8912 - val_loss: 0.3095 - val_acc: 0.8868\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2786 - acc: 0.8948 - val_loss: 0.3434 - val_acc: 0.8727\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2735 - acc: 0.8960 - val_loss: 0.3181 - val_acc: 0.8873\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2661 - acc: 0.8987 - val_loss: 0.3166 - val_acc: 0.8831\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2618 - acc: 0.9002 - val_loss: 0.3309 - val_acc: 0.8826\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2544 - acc: 0.9037 - val_loss: 0.3483 - val_acc: 0.8736\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2472 - acc: 0.9058 - val_loss: 0.3149 - val_acc: 0.8894\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2446 - acc: 0.9076 - val_loss: 0.3677 - val_acc: 0.8749\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2396 - acc: 0.9090 - val_loss: 0.3091 - val_acc: 0.8907\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2349 - acc: 0.9116 - val_loss: 0.3080 - val_acc: 0.8888\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2310 - acc: 0.9128 - val_loss: 0.3003 - val_acc: 0.8954\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2281 - acc: 0.9145 - val_loss: 0.3173 - val_acc: 0.8877\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2205 - acc: 0.9159 - val_loss: 0.3202 - val_acc: 0.8880\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2185 - acc: 0.9174 - val_loss: 0.3303 - val_acc: 0.8867\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2121 - acc: 0.9189 - val_loss: 0.3662 - val_acc: 0.8757\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2116 - acc: 0.9198 - val_loss: 0.3119 - val_acc: 0.8915\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2101 - acc: 0.9199 - val_loss: 0.3478 - val_acc: 0.8824\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2062 - acc: 0.9217 - val_loss: 0.3183 - val_acc: 0.8930\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2075 - acc: 0.9214 - val_loss: 0.3639 - val_acc: 0.8794\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2011 - acc: 0.9241 - val_loss: 0.3421 - val_acc: 0.8834\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1984 - acc: 0.9247 - val_loss: 0.3084 - val_acc: 0.8957\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1967 - acc: 0.9248 - val_loss: 0.3454 - val_acc: 0.8917\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1909 - acc: 0.9285 - val_loss: 0.3317 - val_acc: 0.8928\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1889 - acc: 0.9283 - val_loss: 0.3209 - val_acc: 0.8951\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1898 - acc: 0.9279 - val_loss: 0.3243 - val_acc: 0.8987\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1868 - acc: 0.9284 - val_loss: 0.3169 - val_acc: 0.9003\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1834 - acc: 0.9304 - val_loss: 0.3560 - val_acc: 0.8908\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1827 - acc: 0.9309 - val_loss: 0.3331 - val_acc: 0.8982\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1781 - acc: 0.9318 - val_loss: 0.3357 - val_acc: 0.8984\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1760 - acc: 0.9332 - val_loss: 0.3452 - val_acc: 0.8909\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1739 - acc: 0.9337 - val_loss: 0.3516 - val_acc: 0.8934\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1751 - acc: 0.9344 - val_loss: 0.3155 - val_acc: 0.9018\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1678 - acc: 0.9360 - val_loss: 0.3759 - val_acc: 0.8957\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1680 - acc: 0.9354 - val_loss: 0.3358 - val_acc: 0.9010\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1698 - acc: 0.9337 - val_loss: 0.3574 - val_acc: 0.8952\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1639 - acc: 0.9376 - val_loss: 0.3770 - val_acc: 0.8972\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1660 - acc: 0.9371 - val_loss: 0.3423 - val_acc: 0.9015\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1648 - acc: 0.9374 - val_loss: 0.3330 - val_acc: 0.9028\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1623 - acc: 0.9389 - val_loss: 0.3570 - val_acc: 0.8957\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.1594 - acc: 0.9398 - val_loss: 0.3965 - val_acc: 0.8946\n"
     ]
    }
   ],
   "source": [
    "m10_history = m10_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m10_history.history['val_loss'])\n",
    "tup = ('m10', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19), ('m10', 0.3003294213294983, 21)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. model 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "m11_model = models.Sequential()\n",
    "m11_model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "m11_model.add(layers.Dropout(0.5))\n",
    "m11_model.add(layers.Dense(512, activation='relu'))\n",
    "m11_model.add(layers.Dropout(0.5))\n",
    "m11_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m11_model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.7932 - acc: 0.7140 - val_loss: 0.5045 - val_acc: 0.8132\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.5170 - acc: 0.8113 - val_loss: 0.4461 - val_acc: 0.8308\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4588 - acc: 0.8313 - val_loss: 0.4367 - val_acc: 0.8368\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4259 - acc: 0.8448 - val_loss: 0.4178 - val_acc: 0.8472\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.4015 - acc: 0.8535 - val_loss: 0.4009 - val_acc: 0.8531\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3821 - acc: 0.8613 - val_loss: 0.4245 - val_acc: 0.8455\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3695 - acc: 0.8627 - val_loss: 0.3444 - val_acc: 0.8730\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3578 - acc: 0.8694 - val_loss: 0.3538 - val_acc: 0.8639\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3509 - acc: 0.8725 - val_loss: 0.3398 - val_acc: 0.8738\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3399 - acc: 0.8742 - val_loss: 0.3811 - val_acc: 0.8567\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3356 - acc: 0.8784 - val_loss: 0.3741 - val_acc: 0.8631\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3261 - acc: 0.8807 - val_loss: 0.3309 - val_acc: 0.8767\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3178 - acc: 0.8838 - val_loss: 0.3311 - val_acc: 0.8770\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3172 - acc: 0.8825 - val_loss: 0.3301 - val_acc: 0.8781\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3069 - acc: 0.8875 - val_loss: 0.3202 - val_acc: 0.8817\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3040 - acc: 0.8875 - val_loss: 0.3638 - val_acc: 0.8624\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.3029 - acc: 0.8889 - val_loss: 0.3206 - val_acc: 0.8852\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2932 - acc: 0.8901 - val_loss: 0.3327 - val_acc: 0.8756\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2945 - acc: 0.8907 - val_loss: 0.3173 - val_acc: 0.8859\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2873 - acc: 0.8945 - val_loss: 0.3471 - val_acc: 0.8781\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2880 - acc: 0.8932 - val_loss: 0.3088 - val_acc: 0.8882\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2818 - acc: 0.8953 - val_loss: 0.3355 - val_acc: 0.8846\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2767 - acc: 0.8976 - val_loss: 0.3285 - val_acc: 0.8810\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2780 - acc: 0.8966 - val_loss: 0.3325 - val_acc: 0.8810\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2722 - acc: 0.8992 - val_loss: 0.3164 - val_acc: 0.8914\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2715 - acc: 0.8984 - val_loss: 0.3302 - val_acc: 0.8832\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2665 - acc: 0.9021 - val_loss: 0.3244 - val_acc: 0.8853\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2685 - acc: 0.9016 - val_loss: 0.3175 - val_acc: 0.8864\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2640 - acc: 0.9014 - val_loss: 0.3314 - val_acc: 0.8856\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2622 - acc: 0.9020 - val_loss: 0.3522 - val_acc: 0.8798\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2602 - acc: 0.9033 - val_loss: 0.3200 - val_acc: 0.8905\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2587 - acc: 0.9037 - val_loss: 0.3208 - val_acc: 0.8899\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2547 - acc: 0.9066 - val_loss: 0.3235 - val_acc: 0.8878\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2569 - acc: 0.9040 - val_loss: 0.3272 - val_acc: 0.8881\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2523 - acc: 0.9065 - val_loss: 0.3362 - val_acc: 0.8851\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2481 - acc: 0.9084 - val_loss: 0.3035 - val_acc: 0.8945\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2457 - acc: 0.9087 - val_loss: 0.3397 - val_acc: 0.8896\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2471 - acc: 0.9098 - val_loss: 0.3282 - val_acc: 0.8942\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2432 - acc: 0.9101 - val_loss: 0.3642 - val_acc: 0.8844\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2414 - acc: 0.9106 - val_loss: 0.3319 - val_acc: 0.8915\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2392 - acc: 0.9109 - val_loss: 0.3183 - val_acc: 0.8922\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2401 - acc: 0.9110 - val_loss: 0.3353 - val_acc: 0.8936\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2391 - acc: 0.9103 - val_loss: 0.3360 - val_acc: 0.8906\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2385 - acc: 0.9131 - val_loss: 0.3300 - val_acc: 0.8901\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2350 - acc: 0.9119 - val_loss: 0.3408 - val_acc: 0.8893\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2321 - acc: 0.9141 - val_loss: 0.3120 - val_acc: 0.8991\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2306 - acc: 0.9142 - val_loss: 0.3349 - val_acc: 0.8911\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2326 - acc: 0.9137 - val_loss: 0.3325 - val_acc: 0.8908\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2282 - acc: 0.9152 - val_loss: 0.3224 - val_acc: 0.8940\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 0.2270 - acc: 0.9170 - val_loss: 0.3257 - val_acc: 0.8929\n"
     ]
    }
   ],
   "source": [
    "m11_history = m11_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=50,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m11_history.history['val_loss'])\n",
    "tup = ('m11', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19), ('m10', 0.3003294213294983, 21), ('m11', 0.3035426574230194, 36)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. model 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "m12_model = models.Sequential()\n",
    "m12_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu', input_shape=(28 * 28,)))\n",
    "m12_model.add(layers.Dropout(0.5))\n",
    "m12_model.add(layers.Dense(512, kernel_regularizer=regularizers.l1(0.001),\n",
    "                        activation='relu'))\n",
    "m12_model.add(layers.Dropout(0.5))\n",
    "m12_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "m12_model.compile(optimizer='rmsprop',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 8.9216 - acc: 0.6389 - val_loss: 2.9850 - val_acc: 0.6993\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 2.2435 - acc: 0.6990 - val_loss: 1.7952 - val_acc: 0.7444\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.7196 - acc: 0.7173 - val_loss: 1.5472 - val_acc: 0.7502\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.5666 - acc: 0.7281 - val_loss: 1.4505 - val_acc: 0.7546\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4942 - acc: 0.7345 - val_loss: 1.3656 - val_acc: 0.7773\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4383 - acc: 0.7434 - val_loss: 1.3078 - val_acc: 0.7845\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.4123 - acc: 0.7443 - val_loss: 1.2762 - val_acc: 0.7846\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3904 - acc: 0.7492 - val_loss: 1.2594 - val_acc: 0.7888\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3665 - acc: 0.7517 - val_loss: 1.2756 - val_acc: 0.7741\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3557 - acc: 0.7522 - val_loss: 1.3039 - val_acc: 0.7853\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3403 - acc: 0.7569 - val_loss: 1.2800 - val_acc: 0.7764\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3382 - acc: 0.7555 - val_loss: 1.2449 - val_acc: 0.7827\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3237 - acc: 0.7570 - val_loss: 1.2182 - val_acc: 0.7904\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3110 - acc: 0.7615 - val_loss: 1.2366 - val_acc: 0.7830\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3099 - acc: 0.7602 - val_loss: 1.2531 - val_acc: 0.7802\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.3076 - acc: 0.7610 - val_loss: 1.1937 - val_acc: 0.8003\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2983 - acc: 0.7630 - val_loss: 1.2118 - val_acc: 0.7919\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2919 - acc: 0.7630 - val_loss: 1.1777 - val_acc: 0.8021\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2844 - acc: 0.7663 - val_loss: 1.1636 - val_acc: 0.8066\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2769 - acc: 0.7659 - val_loss: 1.1502 - val_acc: 0.8102\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2771 - acc: 0.7668 - val_loss: 1.1501 - val_acc: 0.8101\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2753 - acc: 0.7662 - val_loss: 1.1505 - val_acc: 0.8061\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2732 - acc: 0.7648 - val_loss: 1.1779 - val_acc: 0.8002\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2659 - acc: 0.7693 - val_loss: 1.1702 - val_acc: 0.7997\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2648 - acc: 0.7670 - val_loss: 1.1749 - val_acc: 0.7993\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2574 - acc: 0.7680 - val_loss: 1.2088 - val_acc: 0.7880\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2560 - acc: 0.7681 - val_loss: 1.1561 - val_acc: 0.7997\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2541 - acc: 0.7678 - val_loss: 1.2036 - val_acc: 0.7752\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2560 - acc: 0.7660 - val_loss: 1.2155 - val_acc: 0.7858\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2511 - acc: 0.7697 - val_loss: 1.1342 - val_acc: 0.8127\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2471 - acc: 0.7696 - val_loss: 1.1459 - val_acc: 0.7922\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2431 - acc: 0.7694 - val_loss: 1.1666 - val_acc: 0.7883\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2420 - acc: 0.7709 - val_loss: 1.1932 - val_acc: 0.7828\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2397 - acc: 0.7703 - val_loss: 1.1227 - val_acc: 0.8129\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2412 - acc: 0.7725 - val_loss: 1.1376 - val_acc: 0.8037\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2322 - acc: 0.7739 - val_loss: 1.1758 - val_acc: 0.7826\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2404 - acc: 0.7714 - val_loss: 1.1524 - val_acc: 0.7901\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2325 - acc: 0.7725 - val_loss: 1.1260 - val_acc: 0.7990\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2279 - acc: 0.7736 - val_loss: 1.1243 - val_acc: 0.8110\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2333 - acc: 0.7718 - val_loss: 1.1792 - val_acc: 0.7864\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2307 - acc: 0.7703 - val_loss: 1.1354 - val_acc: 0.8046\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2313 - acc: 0.7739 - val_loss: 1.1046 - val_acc: 0.8127\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2222 - acc: 0.7732 - val_loss: 1.1544 - val_acc: 0.7880\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2258 - acc: 0.7734 - val_loss: 1.1423 - val_acc: 0.7900\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2277 - acc: 0.7724 - val_loss: 1.1070 - val_acc: 0.8095\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2238 - acc: 0.7710 - val_loss: 1.1338 - val_acc: 0.7981\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2266 - acc: 0.7732 - val_loss: 1.1276 - val_acc: 0.8015\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2197 - acc: 0.7759 - val_loss: 1.1310 - val_acc: 0.8005\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2187 - acc: 0.7738 - val_loss: 1.1729 - val_acc: 0.7872\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2176 - acc: 0.7740 - val_loss: 1.1245 - val_acc: 0.7952\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2196 - acc: 0.7731 - val_loss: 1.0881 - val_acc: 0.8182\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2142 - acc: 0.7761 - val_loss: 1.1372 - val_acc: 0.8056\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2162 - acc: 0.7743 - val_loss: 1.0972 - val_acc: 0.8133\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2170 - acc: 0.7739 - val_loss: 1.1418 - val_acc: 0.7941\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2158 - acc: 0.7741 - val_loss: 1.0765 - val_acc: 0.8195\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2130 - acc: 0.7768 - val_loss: 1.1683 - val_acc: 0.7799\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2136 - acc: 0.7759 - val_loss: 1.1501 - val_acc: 0.7940\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2205 - acc: 0.7733 - val_loss: 1.0879 - val_acc: 0.8153\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2129 - acc: 0.7767 - val_loss: 1.1421 - val_acc: 0.7896\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2093 - acc: 0.7765 - val_loss: 1.1259 - val_acc: 0.7991\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2064 - acc: 0.7764 - val_loss: 1.1714 - val_acc: 0.7923\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2125 - acc: 0.7756 - val_loss: 1.1158 - val_acc: 0.8204\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2098 - acc: 0.7756 - val_loss: 1.1409 - val_acc: 0.7994\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2125 - acc: 0.7748 - val_loss: 1.1361 - val_acc: 0.7971\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2036 - acc: 0.7770 - val_loss: 1.1158 - val_acc: 0.7903\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2064 - acc: 0.7764 - val_loss: 1.1467 - val_acc: 0.8088\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2072 - acc: 0.7770 - val_loss: 1.1109 - val_acc: 0.8149\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2069 - acc: 0.7768 - val_loss: 1.0748 - val_acc: 0.8186\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1988 - acc: 0.7788 - val_loss: 1.1297 - val_acc: 0.7918\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2032 - acc: 0.7786 - val_loss: 1.0950 - val_acc: 0.8145\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2069 - acc: 0.7778 - val_loss: 1.0872 - val_acc: 0.8232\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2051 - acc: 0.7773 - val_loss: 1.0788 - val_acc: 0.8209\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2002 - acc: 0.7777 - val_loss: 1.1234 - val_acc: 0.8066\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2125 - acc: 0.7736 - val_loss: 1.1259 - val_acc: 0.8046\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1996 - acc: 0.7779 - val_loss: 1.1127 - val_acc: 0.7993\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2008 - acc: 0.7767 - val_loss: 1.1546 - val_acc: 0.7889\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2019 - acc: 0.7774 - val_loss: 1.0848 - val_acc: 0.8194\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1972 - acc: 0.7790 - val_loss: 1.0825 - val_acc: 0.8168\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1942 - acc: 0.7777 - val_loss: 1.2143 - val_acc: 0.7743\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2024 - acc: 0.7787 - val_loss: 1.1052 - val_acc: 0.8003\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2035 - acc: 0.7757 - val_loss: 1.0832 - val_acc: 0.8193\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1962 - acc: 0.7776 - val_loss: 1.2346 - val_acc: 0.7618\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2046 - acc: 0.7753 - val_loss: 1.0950 - val_acc: 0.8193\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1978 - acc: 0.7791 - val_loss: 1.0893 - val_acc: 0.8158\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.2009 - acc: 0.7743 - val_loss: 1.0657 - val_acc: 0.8211\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1968 - acc: 0.7783 - val_loss: 1.0594 - val_acc: 0.8234\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1962 - acc: 0.7770 - val_loss: 1.1071 - val_acc: 0.8080\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1985 - acc: 0.7778 - val_loss: 1.0886 - val_acc: 0.8132\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1883 - acc: 0.7798 - val_loss: 1.1826 - val_acc: 0.7740\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1996 - acc: 0.7779 - val_loss: 1.1185 - val_acc: 0.8067\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2034 - acc: 0.7769 - val_loss: 1.0733 - val_acc: 0.8164\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1911 - acc: 0.7791 - val_loss: 1.1302 - val_acc: 0.7900\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1862 - acc: 0.7815 - val_loss: 1.1291 - val_acc: 0.7936\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2047 - acc: 0.7753 - val_loss: 1.0845 - val_acc: 0.8128\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1955 - acc: 0.7775 - val_loss: 1.0805 - val_acc: 0.8211\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1991 - acc: 0.7759 - val_loss: 1.1188 - val_acc: 0.7996\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1916 - acc: 0.7773 - val_loss: 1.1168 - val_acc: 0.7914\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1957 - acc: 0.7771 - val_loss: 1.1247 - val_acc: 0.7948\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1910 - acc: 0.7792 - val_loss: 1.2160 - val_acc: 0.7490\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1985 - acc: 0.7773 - val_loss: 1.1301 - val_acc: 0.7762\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1925 - acc: 0.7776 - val_loss: 1.2857 - val_acc: 0.7533\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1990 - acc: 0.7783 - val_loss: 1.0924 - val_acc: 0.8100\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1987 - acc: 0.7764 - val_loss: 1.1123 - val_acc: 0.8030\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1928 - acc: 0.7794 - val_loss: 1.1127 - val_acc: 0.7950\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1958 - acc: 0.7784 - val_loss: 1.0600 - val_acc: 0.8184\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1975 - acc: 0.7785 - val_loss: 1.0979 - val_acc: 0.8036\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1957 - acc: 0.7771 - val_loss: 1.1862 - val_acc: 0.7525\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1850 - acc: 0.7812 - val_loss: 1.0933 - val_acc: 0.8142\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1887 - acc: 0.7791 - val_loss: 1.0830 - val_acc: 0.8171\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1871 - acc: 0.7800 - val_loss: 1.1269 - val_acc: 0.7929\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1905 - acc: 0.7773 - val_loss: 1.1203 - val_acc: 0.7915\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1926 - acc: 0.7783 - val_loss: 1.0853 - val_acc: 0.8100\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1838 - acc: 0.7776 - val_loss: 1.0763 - val_acc: 0.8179\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1942 - acc: 0.7783 - val_loss: 1.0723 - val_acc: 0.8193\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1909 - acc: 0.7787 - val_loss: 1.1479 - val_acc: 0.7763\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1929 - acc: 0.7786 - val_loss: 1.0655 - val_acc: 0.8184\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1901 - acc: 0.7775 - val_loss: 1.0583 - val_acc: 0.8221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1902 - acc: 0.7801 - val_loss: 1.0521 - val_acc: 0.8230\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1931 - acc: 0.7799 - val_loss: 1.1094 - val_acc: 0.8133\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1863 - acc: 0.7808 - val_loss: 1.1042 - val_acc: 0.8118\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1954 - acc: 0.7779 - val_loss: 1.1004 - val_acc: 0.8096\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1853 - acc: 0.7818 - val_loss: 1.1086 - val_acc: 0.8094\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1906 - acc: 0.7778 - val_loss: 1.0694 - val_acc: 0.8125\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1884 - acc: 0.7800 - val_loss: 1.1154 - val_acc: 0.7899\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1937 - acc: 0.7778 - val_loss: 1.1653 - val_acc: 0.7706\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1978 - acc: 0.7772 - val_loss: 1.1124 - val_acc: 0.7904\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.2019 - acc: 0.7772 - val_loss: 1.0575 - val_acc: 0.8230\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1934 - acc: 0.7760 - val_loss: 1.1118 - val_acc: 0.7940\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1899 - acc: 0.7785 - val_loss: 1.1384 - val_acc: 0.7886\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1939 - acc: 0.7795 - val_loss: 1.0926 - val_acc: 0.8083\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1866 - acc: 0.7785 - val_loss: 1.0806 - val_acc: 0.8229\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1867 - acc: 0.7776 - val_loss: 1.0728 - val_acc: 0.8245\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1847 - acc: 0.7785 - val_loss: 1.1156 - val_acc: 0.7999\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1918 - acc: 0.7780 - val_loss: 1.0996 - val_acc: 0.8093\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1915 - acc: 0.7783 - val_loss: 1.0663 - val_acc: 0.8248\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1875 - acc: 0.7804 - val_loss: 1.1366 - val_acc: 0.7892\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1844 - acc: 0.7800 - val_loss: 1.0896 - val_acc: 0.7986\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1886 - acc: 0.7795 - val_loss: 1.0652 - val_acc: 0.8176\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1876 - acc: 0.7786 - val_loss: 1.0855 - val_acc: 0.8129\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1864 - acc: 0.7768 - val_loss: 1.1033 - val_acc: 0.8072\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.2013 - acc: 0.7751 - val_loss: 1.1190 - val_acc: 0.8192\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 1s 13us/step - loss: 1.1816 - acc: 0.7811 - val_loss: 1.1799 - val_acc: 0.7640\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1802 - acc: 0.7826 - val_loss: 1.0906 - val_acc: 0.8149\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1902 - acc: 0.7772 - val_loss: 1.0895 - val_acc: 0.8110\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1869 - acc: 0.7788 - val_loss: 1.0593 - val_acc: 0.8154\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1897 - acc: 0.7805 - val_loss: 1.1263 - val_acc: 0.8022\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1907 - acc: 0.7769 - val_loss: 1.1432 - val_acc: 0.7766\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1856 - acc: 0.7782 - val_loss: 1.0879 - val_acc: 0.8125\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1906 - acc: 0.7791 - val_loss: 1.1040 - val_acc: 0.8011\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1901 - acc: 0.7769 - val_loss: 1.0883 - val_acc: 0.8000\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1788 - acc: 0.7827 - val_loss: 1.0854 - val_acc: 0.8021\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1906 - acc: 0.7792 - val_loss: 1.1472 - val_acc: 0.7927\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1872 - acc: 0.7802 - val_loss: 1.0576 - val_acc: 0.8178\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1850 - acc: 0.7776 - val_loss: 1.1197 - val_acc: 0.7715\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1825 - acc: 0.7774 - val_loss: 1.0545 - val_acc: 0.8234\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1857 - acc: 0.7790 - val_loss: 1.1621 - val_acc: 0.7771\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1916 - acc: 0.7799 - val_loss: 1.0743 - val_acc: 0.8234\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1860 - acc: 0.7806 - val_loss: 1.0810 - val_acc: 0.8149\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1851 - acc: 0.7778 - val_loss: 1.1064 - val_acc: 0.8026\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1794 - acc: 0.7823 - val_loss: 1.1237 - val_acc: 0.7954\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1967 - acc: 0.7788 - val_loss: 1.0962 - val_acc: 0.7987\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1837 - acc: 0.7800 - val_loss: 1.0798 - val_acc: 0.8173\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1923 - acc: 0.7779 - val_loss: 1.0712 - val_acc: 0.8238\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1786 - acc: 0.7804 - val_loss: 1.0614 - val_acc: 0.8175\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1864 - acc: 0.7790 - val_loss: 1.0692 - val_acc: 0.8203\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1880 - acc: 0.7789 - val_loss: 1.0844 - val_acc: 0.8078\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1807 - acc: 0.7815 - val_loss: 1.0762 - val_acc: 0.8129\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1908 - acc: 0.7774 - val_loss: 1.0967 - val_acc: 0.8008\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1914 - acc: 0.7761 - val_loss: 1.1148 - val_acc: 0.8014\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1760 - acc: 0.7822 - val_loss: 1.1015 - val_acc: 0.8035\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1820 - acc: 0.7797 - val_loss: 1.0939 - val_acc: 0.8134\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1825 - acc: 0.7801 - val_loss: 1.0726 - val_acc: 0.8180\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1955 - acc: 0.7762 - val_loss: 1.0648 - val_acc: 0.8208\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1858 - acc: 0.7799 - val_loss: 1.1182 - val_acc: 0.8044\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1793 - acc: 0.7798 - val_loss: 1.2524 - val_acc: 0.7678\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1902 - acc: 0.7770 - val_loss: 1.0728 - val_acc: 0.8195\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1850 - acc: 0.7790 - val_loss: 1.1774 - val_acc: 0.7476\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1913 - acc: 0.7776 - val_loss: 1.0688 - val_acc: 0.8214\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1883 - acc: 0.7780 - val_loss: 1.0647 - val_acc: 0.8136\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1856 - acc: 0.7803 - val_loss: 1.0713 - val_acc: 0.8168\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1889 - acc: 0.7780 - val_loss: 1.0818 - val_acc: 0.8088\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1820 - acc: 0.7828 - val_loss: 1.1219 - val_acc: 0.8050\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1807 - acc: 0.7820 - val_loss: 1.0692 - val_acc: 0.8135\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1846 - acc: 0.7798 - val_loss: 1.1188 - val_acc: 0.8091\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1887 - acc: 0.7779 - val_loss: 1.0677 - val_acc: 0.8142\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1825 - acc: 0.7801 - val_loss: 1.0851 - val_acc: 0.8067\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1904 - acc: 0.7770 - val_loss: 1.1704 - val_acc: 0.7871\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1818 - acc: 0.7799 - val_loss: 1.0621 - val_acc: 0.8217\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1814 - acc: 0.7812 - val_loss: 1.1092 - val_acc: 0.7990\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1806 - acc: 0.7798 - val_loss: 1.1073 - val_acc: 0.7963\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1806 - acc: 0.7796 - val_loss: 1.1100 - val_acc: 0.7981\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1768 - acc: 0.7817 - val_loss: 1.0959 - val_acc: 0.8122\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1814 - acc: 0.7801 - val_loss: 1.0673 - val_acc: 0.8128\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1782 - acc: 0.7822 - val_loss: 1.0704 - val_acc: 0.8206\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1841 - acc: 0.7806 - val_loss: 1.0503 - val_acc: 0.8203\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1864 - acc: 0.7785 - val_loss: 1.0818 - val_acc: 0.8108\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1847 - acc: 0.7789 - val_loss: 1.0789 - val_acc: 0.8151\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1844 - acc: 0.7790 - val_loss: 1.0795 - val_acc: 0.8093\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1858 - acc: 0.7763 - val_loss: 1.0749 - val_acc: 0.8228\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 1s 14us/step - loss: 1.1857 - acc: 0.7793 - val_loss: 1.0528 - val_acc: 0.8171\n"
     ]
    }
   ],
   "source": [
    "m12_history = m12_model.fit(X_train,\n",
    "                              y_train,\n",
    "                              epochs=200,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss, best_num_epoch = find_best_epoch(m12_history.history['val_loss'])\n",
    "tup = ('m12', min_loss, best_num_epoch)\n",
    "best_model_loss_epoch.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m1', 0.3023020066976547, 16), ('m2', 0.3274553401708603, 23), ('m3', 0.321343349313736, 22), ('m4', 0.32604879693984984, 21), ('m5', 0.7584855156898499, 42), ('m6', 0.48910057401657103, 5), ('m7', 0.3329300110340118, 12), ('m8', 0.843311605644226, 170), ('m9', 0.2955756016016006, 19), ('m10', 0.3003294213294983, 21), ('m11', 0.3035426574230194, 36), ('m12', 1.0502544473648072, 195)]\n"
     ]
    }
   ],
   "source": [
    "print(best_model_loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_models = [m1_history, m2_history, m3_history, m4_history,\n",
    "                  m5_history, m6_history, m7_history, m8_history,\n",
    "                  m9_history, m10_history, m11_history, m12_history]\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(1, 13):\n",
    "    cur_mod = history_models[i-1]\n",
    "    val_loss = cur_mod.history['val_loss']\n",
    "    val_acc = cur_mod.history['val_acc']\n",
    "    ax = fig.add_subplot(4, 3, i)\n",
    "    ax.plot(np.arange(len(val_loss)), init_val_loss, label='validation loss', linestyle=':')\n",
    "    ax.plot(np.arange(len(val_acc)), drop_val_loss, label='validation accuracy', marker='v')\n",
    "    ax.legend()\n",
    "    ax.set_title(\"model {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m9 is the best model with specification: 3 layers; 50 epochs; 0.2 dropout rate; all else like initial model\n"
     ]
    }
   ],
   "source": [
    "# select the best model\n",
    "best_model_loss_epoch.sort(key=lambda tup: tup[1])\n",
    "best_model, min_loss, num_epoch = best_model_loss_epoch[0]\n",
    "print(\"{} is the best model with specification: {}\".format(best_model, all_models[best_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_model_list = []\n",
    "sorted_valid_loss = []\n",
    "for m, valid_loss, _ in best_model_loss_epoch:\n",
    "    sorted_model_list.append(m)\n",
    "    sorted_valid_loss.append(valid_loss)\n",
    "plt.bar(np.arange(len(sorted_model_list)), sorted_valid_loss, align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(len(sorted_model_list)), sorted_model_list)\n",
    "plt.ylabel('validation loss')\n",
    "plt.title('Validation loss comparison across models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1803 - acc: 0.9394\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1711 - acc: 0.9405\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1654 - acc: 0.9411\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1619 - acc: 0.9421\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1575 - acc: 0.9440\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1539 - acc: 0.9449\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1488 - acc: 0.9452\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1457 - acc: 0.9470\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1437 - acc: 0.9476\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1444 - acc: 0.9474\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1396 - acc: 0.9485\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1387 - acc: 0.9486\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1375 - acc: 0.9493\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1385 - acc: 0.9490\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1329 - acc: 0.9511\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1314 - acc: 0.9523\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1307 - acc: 0.9516\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1281 - acc: 0.9523\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1286 - acc: 0.9526\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1276 - acc: 0.9530\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1267 - acc: 0.9545\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1240 - acc: 0.9550\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1214 - acc: 0.9555\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1192 - acc: 0.9566\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1191 - acc: 0.9557\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1188 - acc: 0.9564\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1171 - acc: 0.9564\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1150 - acc: 0.9573\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1155 - acc: 0.9578\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1168 - acc: 0.9572\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1125 - acc: 0.9582\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1107 - acc: 0.9582\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1142 - acc: 0.9577\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1093 - acc: 0.9596\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1094 - acc: 0.9602\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1076 - acc: 0.9598\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1048 - acc: 0.9606\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1102 - acc: 0.9600\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1076 - acc: 0.9610\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1068 - acc: 0.9622\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1048 - acc: 0.9622\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1059 - acc: 0.9618\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1034 - acc: 0.9622\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1042 - acc: 0.9624\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1038 - acc: 0.9619\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1026 - acc: 0.9626\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1003 - acc: 0.9635\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1002 - acc: 0.9642\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0984 - acc: 0.9647\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.1025 - acc: 0.9636\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "final_m9 = m9_model.fit(x_all_train,\n",
    "                        y_all_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5665860232532024, 0.8954]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the best model\n",
    "m9_model.evaluate(x_final_test, y_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion:__ The final model does not generalize well. When evaluated using unseen test data, the accuracy rate significantly declines from around 96% to 89.54% and the loss rate also increases from around 0.30 to 0.57. This might indicate that my final model overfits the training data or the network architecture is not complex enough to handle the data set. Again, the network architecture is as fllows: 3 layers; 50 epochs; 0.2 dropout rate, which is less complex than our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
